---
title: "iDRAC9 User's Guide"
author: "Dell"
source: "d:\Tools\AICode\doc-to-md\doc_to_md\sample_data\idrac9-user-s-guide.pdf"
page_count: 375
chunk_count: 1057
---



# iDRAC9 User's Guide

**7.xx Series**

**December 2025**
**Rev. A11**

Notes, cautions, and warnings

**NOTE:** A NOTE indicates important information that helps you make better use of your product.

**CAUTION: A CAUTION indicates either potential damage to hardware or loss of data and tells you how to avoid**
**the problem.**

**WARNING: A WARNING indicates a potential for property damage, personal injury, or death.**

Copyright © 2023-2025 Dell Inc. All Rights Reserved. Dell Technologies, Dell, and other trademarks are trademarks of Dell Inc. or its
subsidiaries. Other trademarks may be trademarks of their respective owners.

**Table 1. Revision history**



### Revision history

|Date|Document<br>revision|Description of changes|
|---|---|---|
|December 2025|A11|iDRAC9 version 7.20.80.50 updates|
|November 2025|A10|iDRAC9 version 7.20.70.50 updates|
|September 2025|A09|iDRAC9 version 7.20.60.50 updates|
|June 2025|A08|iDRAC9 version 7.20.30.50 updates|
|March 2025|A07|iDRAC9 version 7.20.10.50 updates|
|December 2024|A06|iDRAC9 version 7.10.90.00 updates|
|September 2024|A05|iDRAC9 version 7.10.70.00 updates|
|June 2024|A04|iDRAC9 version 7.10.50.00 updates|
|March 2024|A00|iDRAC9 version 7.10.30.00 updates|
|December 2023|A00|iDRAC9 version 7.00.60.00 updates|



# Contents

Revision history..........................................................................................................................................................................3

**Chapter 1: Overview of iDRAC......................................................................................................17**

Benefits of using iDRAC................................................................................................................................................... 17
Key features........................................................................................................................................................................ 18
New features or changes added .................................................................................................................................. 20

Firmware version 7.20.80.50....................................................................................................................................20
Firmware version 7.20.70.50....................................................................................................................................20
Firmware version 7.20.60.50....................................................................................................................................20
Firmware version 7.20.30.50.....................................................................................................................................21
Firmware version 7.20.10.50......................................................................................................................................21
Firmware version 7.10.90.00..................................................................................................................................... 21
Firmware version 7.10.70.00.....................................................................................................................................22
Firmware version 7.10.50.00.....................................................................................................................................22
Firmware version 7.10.30.00.....................................................................................................................................23
Firmware version 7.00.60.00....................................................................................................................................23
Firmware version 7.00.30.00....................................................................................................................................23
How to use this guide.......................................................................................................................................................23
Supported web browsers................................................................................................................................................ 24

Supported operating systems and hypervisors....................................................................................................24
iDRAC licenses ..................................................................................................................................................................24

Types of licenses......................................................................................................................................................... 24
Methods for acquiring licenses................................................................................................................................ 24
Acquiring license key from Dell Digital Locker......................................................................................................25
License operations...................................................................................................................................................... 25
Licensed features in iDRAC9..........................................................................................................................................26
Interfaces and protocols to access iDRAC................................................................................................................. 32
iDRAC port information....................................................................................................................................................34
Other documents you may need................................................................................................................................... 35
Contacting Dell.................................................................................................................................................................. 36
Accessing documents from the Dell Support site.....................................................................................................36
Accessing Redfish API Guide......................................................................................................................................... 36

**Chapter 2: Logging in to iDRAC................................................................................................... 38**

Force Change of Password (FCP)................................................................................................................................39
Logging into iDRAC using OpenID Connect................................................................................................................39
Logging in to iDRAC as local user, Active Directory user, or LDAP user.............................................................39
Logging in to iDRAC as a local user using a smart card...........................................................................................40

Logging in to iDRAC as an Active Directory user using a smart card............................................................. 41
Logging in to iDRAC using Single Sign-On ................................................................................................................. 41

Logging in to iDRAC SSO using iDRAC web interface........................................................................................41
Logging in to iDRAC SSO using CMC web interface..........................................................................................42
Accessing iDRAC using remote RACADM...................................................................................................................42

Validating CA certificate to use remote RACADM on Linux............................................................................. 42
Accessing iDRAC using local RACADM........................................................................................................................43

Accessing iDRAC using firmware RACADM................................................................................................................43
Simple 2-Factor Authentication (Simple 2FA)........................................................................................................... 43
RSA SecurID 2FA...............................................................................................................................................................43
Viewing system health..................................................................................................................................................... 44
Logging in to iDRAC using public key authentication...............................................................................................45
Multiple iDRAC sessions.................................................................................................................................................. 45
Secure default password.................................................................................................................................................46

Resetting default iDRAC password locally............................................................................................................ 46
Resetting default iDRAC password remotely........................................................................................................47
Changing the default login password........................................................................................................................... 47

Changing the default login password using web interface............................................................................... 48
Changing the default login password using RACADM........................................................................................48
Changing the default login password using iDRAC settings utility..................................................................48
Enabling or disabling default password warning message ..................................................................................... 48
Password Strength Policy...............................................................................................................................................49
IP Blocking.......................................................................................................................................................................... 49
Enabling or disabling an operating system to iDRAC Pass-through using web interface............................... 50
Enabling or disabling alerts using RACADM.................................................................................................................51

**Chapter 3: Setting up managed system....................................................................................... 52**

Setting up iDRAC IP address..........................................................................................................................................52

Setting up iDRAC IP using iDRAC settings utility................................................................................................53
Setting up iDRAC IP using the CMC web interface............................................................................................57
Autodiscovery...............................................................................................................................................................57
Configuring servers and server components using Auto Config..................................................................... 58
Using hash passwords for improved security.......................................................................................................63
Modifying local administrator account settings.........................................................................................................65
Setting up managed system location........................................................................................................................... 65

Setting up managed system location using web interface................................................................................65
Setting up managed system location using RACADM........................................................................................65
Setting up managed system location using iDRAC settings utility..................................................................65
Optimizing system performance and power consumption......................................................................................65

Modifying thermal settings using iDRAC web interface.................................................................................... 66
Modifying thermal settings using RACADM..........................................................................................................68
Modifying thermal settings using iDRAC settings utility.....................................................................................71
Modifying PCIe airflow settings using iDRAC web interface.............................................................................71
Setting up management station.....................................................................................................................................72

Accessing iDRAC remotely........................................................................................................................................72
Configuring supported web browsers.......................................................................................................................... 72

Configuring Mozilla Firefox....................................................................................................................................... 72
Configuring web browsers to use virtual console................................................................................................73
Viewing localized versions of web interface......................................................................................................... 74
Firmware updates..............................................................................................................................................................74

Firmware image files and supported tools ............................................................................................................75
Methods for firmware updates................................................................................................................................ 76
Considerations for PSU firmware updates............................................................................................................76
iLKM and SEKM considerations............................................................................................................................... 77
LC logs during firmware updates............................................................................................................................. 77
Supported components in MX platforms for firmware updates.......................................................................77
Updating single device firmware using web interface .......................................................................................78

Scheduling automatic firmware updates................................................................................................................79
Configuring quick reboot after firmware updates................................................................................................81
Updating device firmware using RACADM............................................................................................................ 81
Updating firmware using CMC web interface.......................................................................................................81
Updating firmware using DUP..................................................................................................................................82
Updating firmware using remote RACADM.......................................................................................................... 82
Updating firmware using Lifecycle Controller Remote Services..................................................................... 83
Updating CMC firmware from iDRAC.................................................................................................................... 83
Rebootless updates.....................................................................................................................................................83
Viewing and managing staged updates........................................................................................................................84

Viewing and managing staged updates using iDRAC web interface...............................................................84
Viewing and managing staged updates using RACADM.................................................................................... 84
Rolling back device firmware..........................................................................................................................................85

Rollback firmware using iDRAC web interface.....................................................................................................85
Rollback firmware using CMC web interface....................................................................................................... 86
Rollback firmware using RACADM..........................................................................................................................86
Rollback firmware using Lifecycle Controller....................................................................................................... 86
Rollback firmware using Lifecycle Controller-Remote Services...................................................................... 86
Recovering iDRAC.......................................................................................................................................................86
Easy Restore.......................................................................................................................................................................87
Monitoring iDRAC using other Systems Management tools...................................................................................87
Support Server Configuration Profile — Import and Export .................................................................................87

Importing server configuration profile using iDRAC web interface.................................................................88
Exporting server configuration profile using iDRAC web interface.................................................................89
Secure Boot Configuration from BIOS Settings or F2.............................................................................................89
BIOS recovery....................................................................................................................................................................90

**Chapter 4: Data Processing Unit (DPU)....................................................................................... 91**

**Chapter 5: Plugin Management................................................................................................... 93**

Installing a plugin............................................................................................................................................................... 93
Uninstalling a plugin.......................................................................................................................................................... 93
Restarting a plugin............................................................................................................................................................ 93
Enabling or disabling a plugin..........................................................................................................................................94
Viewing the plugin details................................................................................................................................................94

**Chapter 6: Configuring iDRAC.....................................................................................................95**

Viewing iDRAC information.............................................................................................................................................96

Viewing iDRAC information using web interface.................................................................................................96
Viewing iDRAC information using RACADM......................................................................................................... 97
Modifying network settings............................................................................................................................................ 97

Modifying network settings using web interface.................................................................................................97
Modifying network settings using local RACADM...............................................................................................97
Configuring IP filtering............................................................................................................................................... 98
Cipher suite selection.......................................................................................................................................................99

Configuring cipher suite selection using iDRAC web interface........................................................................99
Configuring cipher suite selection using RACADM............................................................................................100
FIPS mode.........................................................................................................................................................................100

Enabling FIPS Mode..................................................................................................................................................100

Disabling FIPS mode.................................................................................................................................................. 101
Configuring services........................................................................................................................................................ 101

Configuring services using web interface.............................................................................................................101
Configuring services using RACADM....................................................................................................................102
SEKM Functionalities................................................................................................................................................102
iLKM functionalities...................................................................................................................................................103
Enabling or disabling HTTPS redirection..............................................................................................................104
Using VNC client to manage remote server............................................................................................................. 104

Configuring VNC server using iDRAC web interface........................................................................................105
Configuring VNC server using RACADM............................................................................................................. 105
Setting up VNC viewer with SSL encryption......................................................................................................105
Setting up VNC viewer without SSL encryption................................................................................................105
Configuring front panel display.................................................................................................................................... 106

Configuring LCD setting...........................................................................................................................................106
Configuring system ID LED setting........................................................................................................................107
Configuring time zone and NTP...................................................................................................................................107

Configuring time zone and NTP using iDRAC web interface..........................................................................108
Configuring time zone and NTP using RACADM............................................................................................... 108
Setting first boot device................................................................................................................................................108

Setting first boot device using web interface.................................................................................................... 108
Setting first boot device using RACADM............................................................................................................ 109
Setting first boot device using virtual console................................................................................................... 109
Enabling last crash screen.......................................................................................................................................109
Enabling or disabling OS to iDRAC Pass-through....................................................................................................109

Supported cards for OS to iDRAC Pass-through ..............................................................................................110
Supported operating systems for USB NIC......................................................................................................... 110
Enabling or disabling an operating system to iDRAC Pass-through using web interface..........................111
Enabling or disabling OS to iDRAC Pass-through using RACADM.................................................................112
Enabling or disabling OS to iDRAC Pass-through using iDRAC settings utility...........................................112
Obtaining certificates...................................................................................................................................................... 112

SSL server certificates..............................................................................................................................................113
Generating a new certificate signing request......................................................................................................114
Automatic Certificate Enrollment...........................................................................................................................115
Uploading server certificate.....................................................................................................................................115
Viewing server certificate.........................................................................................................................................116
Uploading custom signing certificate.....................................................................................................................116
Downloading custom SSL certificate signing certificate ................................................................................. 117
Deleting custom SSL certificate signing certificate...........................................................................................117
Configuring multiple iDRACs using RACADM............................................................................................................118
Disabling access to modify iDRAC configuration settings on host system........................................................ 118
Self Heal..............................................................................................................................................................................119

Enable Self Heal in iDRAC web interface..............................................................................................................119

**Chapter 7: Delegated Authorization using OAuth 2.0..................................................................120**

**Chapter 8: Viewing iDRAC and managed system information...................................................... 121**

Viewing managed system health and properties...................................................................................................... 121
Configuring Asset Tracking............................................................................................................................................121
Viewing system inventory..............................................................................................................................................122

Viewing system components........................................................................................................................................ 124
Monitoring performance index of CPU, memory, and input output modules................................................... 125

Monitoring performance index of CPU, memory, and input output modules using web interface........126
Monitoring performance index for of CPU, memory, and input output modules using RACADM......... 127
Reading Firmware and Hardware inventories........................................................................................................... 127
Performing and checking firmware update status...................................................................................................127
Performing and checking system/ component configuration status..................................................................128
Idle Server Detection...................................................................................................................................................... 128
GPU (Accelerators) Management...............................................................................................................................129
Checking the system for Fresh Air compliance........................................................................................................132
Viewing historical temperature data........................................................................................................................... 132

Viewing historical temperature data using iDRAC web interface.................................................................. 132
Viewing historical temperature data using RACADM........................................................................................133
Configuring warning threshold for inlet temperature....................................................................................... 133
Viewing network interfaces available on host OS................................................................................................... 133

Viewing network interfaces available on host OS using web interface........................................................134
Viewing network interfaces available on host OS using RACADM......................................................................134
Viewing FlexAddress mezzanine card fabric connections..................................................................................... 134
Viewing or terminating iDRAC sessions..................................................................................................................... 135

Terminating iDRAC sessions using web interface..............................................................................................135

**Chapter 9: Setting up iDRAC communication............................................................................. 136**

Communicating with iDRAC through serial connection using DB9 cable...........................................................137

Configuring BIOS for serial connection................................................................................................................ 137
Enabling RAC serial connection..............................................................................................................................137
Enabling IPMI serial connection basic and terminal modes............................................................................. 138
Switching between RAC serial and serial console while using DB9 cable......................................................... 140

Switching from serial console to RAC serial........................................................................................................140
Switching from RAC serial to serial console........................................................................................................140
Communicating with iDRAC using IPMI SOL............................................................................................................140

Configuring BIOS for serial connection................................................................................................................ 140
Configuring iDRAC to use SOL................................................................................................................................141
Enabling supported protocol................................................................................................................................... 142
Communicating with iDRAC using IPMI over LAN.................................................................................................. 145

Configuring IPMI over LAN using web interface................................................................................................145
Configuring IPMI over LAN using iDRAC settings utility..................................................................................145
Configuring IPMI over LAN using RACADM........................................................................................................145
Enabling or disabling remote RACADM...................................................................................................................... 146

Enabling or disabling remote RACADM using web interface...........................................................................146
Enabling or disabling remote RACADM using RACADM...................................................................................146
Disabling local RACADM.................................................................................................................................................146
Enabling IPMI on managed system..............................................................................................................................146
Configuring Linux for serial console during boot in RHEL 6..................................................................................147

Enabling login to the virtual console after boot..................................................................................................147
Configuring serial terminal in RHEL 7......................................................................................................................... 149

Controlling GRUB from serial console...................................................................................................................149
Supported SSH cryptography schemes.....................................................................................................................150

Using public key authentication for SSH.............................................................................................................. 151

**Chapter 10: Configuring user accounts and privileges................................................................ 154**

iDRAC user roles and privileges................................................................................................................................... 154
Recommended characters in user names and passwords.....................................................................................155
Configuring local users...................................................................................................................................................155

Configuring local users using iDRAC web interface.......................................................................................... 156
Configuring local users using RACADM............................................................................................................... 156
Configuring Active Directory users............................................................................................................................. 157

Prerequisites for using Active Directory authentication for iDRAC.............................................................. 158
Supported Active Directory authentication mechanisms.................................................................................159
Standard schema Active Directory overview......................................................................................................159
Configuring Standard schema Active Directory.................................................................................................160
Extended schema Active Directory overview.....................................................................................................162
Configuring Extended schema Active Directory................................................................................................ 164
Testing Active Directory settings........................................................................................................................... 171
Configuring generic LDAP users................................................................................................................................... 171

Configuring generic LDAP directory service using iDRAC web-based interface........................................172
Configuring generic LDAP directory service using RACADM..........................................................................172
Testing LDAP directory service settings..............................................................................................................172

**Chapter 11: System Configuration Lockdown mode.................................................................... 174**

**Chapter 12: Configuring iDRAC for Single Sign-On or smart card login.......................................176**

Prerequisites for Active Directory Single Sign-On or Smart Card login.............................................................176

Registering iDRAC on Domain name System...................................................................................................... 176
Creating Active Directory objects and providing privileges.............................................................................177
Configuring iDRAC SSO login for Active Directory users...................................................................................... 177

Creating a User in Active Directory for SSO.......................................................................................................177
Generating Kerberos keytab file.............................................................................................................................178
Configuring iDRAC SSO login for Active Directory users using web interface...........................................178
Configuring iDRAC SSO login for Active Directory users using RACADM...................................................179
Management Station Settings................................................................................................................................179
Enabling or disabling smart card login.........................................................................................................................179

Enabling or disabling smart card login using web interface.............................................................................179
Enabling or disabling smart card login using RACADM.....................................................................................179
Enabling or disabling smart card login using iDRAC settings utility...............................................................180
Configuring Smart Card Login......................................................................................................................................180

Configuring iDRAC smart card login for Active Directory users.................................................................... 180
Configuring iDRAC smart card login for local users.......................................................................................... 180
Log in using Smart Card................................................................................................................................................. 181

**Chapter 13: Configuring iDRAC to send alerts............................................................................ 182**

Enabling or disabling alerts............................................................................................................................................182

Enabling or disabling alerts using web interface................................................................................................ 182
Enabling or disabling alerts using RACADM........................................................................................................ 183
Enabling or disabling alerts using iDRAC settings utility.................................................................................. 183
Setting event alerts.........................................................................................................................................................183

Setting event alerts using web interface.............................................................................................................183
Setting event alerts using RACADM.....................................................................................................................184

Setting alert recurrence event..................................................................................................................................... 184

Setting alert recurrence events using RACADM................................................................................................184
Setting alert recurrence events using iDRAC web interface.......................................................................... 184
Setting event actions......................................................................................................................................................184

Setting event actions using web interface..........................................................................................................184
Setting event actions using RACADM..................................................................................................................185
Configuring email alert, SNMP trap, or IPMI trap settings................................................................................... 185

Configuring IP alert destinations............................................................................................................................185
Configuring email alert settings..............................................................................................................................187
Configuring WS Eventing.............................................................................................................................................. 189
Configuring Redfish Eventing.......................................................................................................................................189
Configuring Remote System Logging.........................................................................................................................189

Configuring remote system logging using web interface.................................................................................189
Configuring remote system logging using RACADM.........................................................................................190
Enabling Secure Remote System Logs in RACADM......................................................................................... 190
Monitoring chassis events.............................................................................................................................................190

Monitoring chassis events using the iDRAC web interface............................................................................ 190
Monitoring chassis events using RACADM......................................................................................................... 190
Alerts message IDs...........................................................................................................................................................191
Liquid cooling leak detection.........................................................................................................................................192

Configuring leak detection.......................................................................................................................................193

**Chapter 14: iDRAC9 Group Manager...........................................................................................194**

Group Manager................................................................................................................................................................ 194
Summary View..................................................................................................................................................................195
Network Configuration requirements.........................................................................................................................196
Manage Logins..................................................................................................................................................................197

Add a New User......................................................................................................................................................... 197
Change User Password............................................................................................................................................ 197
Delete User..................................................................................................................................................................198
Configure Alerts ..............................................................................................................................................................198
Export.................................................................................................................................................................................198
Discovered Servers View...............................................................................................................................................199
Jobs View.......................................................................................................................................................................... 199
Jobs Export...................................................................................................................................................................... 200
Group Information Panel...............................................................................................................................................200
Group Settings................................................................................................................................................................ 200
Actions on a selected Server........................................................................................................................................201
iDRAC Group Firmware Update...................................................................................................................................202

**Chapter 15: Managing logs........................................................................................................ 203**

Viewing System Event Log...........................................................................................................................................203

Viewing System Event Log using web interface............................................................................................... 203
Viewing System Event Log using RACADM....................................................................................................... 203
Viewing System Event Log using iDRAC settings utility................................................................................. 204
Viewing Lifecycle log .................................................................................................................................................... 204

Viewing Lifecycle log using web interface..........................................................................................................204
Viewing Lifecycle log using RACADM..................................................................................................................205
Exporting Lifecycle Controller logs.............................................................................................................................205

Exporting Lifecycle Controller logs using web interface.................................................................................205
Exporting Lifecycle Controller logs using RACADM.........................................................................................205
Prevent Lifecycle Log Overflow..................................................................................................................................206
Adding work notes..........................................................................................................................................................206

**Chapter 16: Monitoring and managing power in iDRAC...............................................................207**

Monitoring power............................................................................................................................................................207

Monitoring performance index of CPU, memory, and input output modules using web interface....... 207
Monitoring performance index for of CPU, memory, and input output modules using RACADM........ 208
Setting warning threshold for power consumption................................................................................................208

Setting warning threshold for power consumption using web interface.................................................... 208
Performing power control operations........................................................................................................................208

Performing power control operations using web interface............................................................................ 209
Performing power control operations using RACADM.................................................................................... 209
Power capping.................................................................................................................................................................209

Power capping in Blade servers............................................................................................................................ 209
Viewing and configuring power cap policy.......................................................................................................... 210
Configuring power supply options................................................................................................................................211

Configuring power supply options using web interface.................................................................................... 211
Configuring power supply options using RACADM............................................................................................ 211
Configuring power supply options using iDRAC settings utility...................................................................... 211
Enabling or disabling power button............................................................................................................................. 212
Multi-Vector Cooling.......................................................................................................................................................212

**Chapter 17: iDRAC Direct Updates............................................................................................. 214**

**Chapter 18: Inventorying, monitoring, and configuring network devices.....................................215**

Inventorying and monitoring network devices..........................................................................................................215

Monitoring network devices using web interface..............................................................................................215
Monitoring network devices using RACADM......................................................................................................216
Connection View........................................................................................................................................................216
Inventorying and monitoring FC HBA devices..........................................................................................................218

Monitoring FC HBA devices using web interface.............................................................................................. 218
Monitoring FC HBA devices using RACADM...................................................................................................... 218
Inventorying and monitoring SFP Transceiver devices.......................................................................................... 218

Monitoring SFP Transceiver devices using web interface...............................................................................219
Monitoring SFP Transceiver devices using RACADM.......................................................................................219
Telemetry Streaming.......................................................................................................................................................219

Metric Report Definition...........................................................................................................................................221
Triggers........................................................................................................................................................................ 221
Serial Data Capture........................................................................................................................................................ 222
Dynamic configuration of virtual addresses, initiator, and storage target settings........................................222

Supported cards for I/O Identity Optimization..................................................................................................223
Supported NIC firmware versions for IO Identity Optimization.....................................................................224
Virtual or Remote assigned Address and Persistence Policy behavior when iDRAC is set to

Remote-Assigned Address mode or Console mode......................................................................................224
System behavior for FlexAddress and IO Identity.............................................................................................226
Enabling or disabling IO Identity Optimization................................................................................................... 226
SSD Wear Threshold................................................................................................................................................ 227

Configuring persistence policy settings...............................................................................................................228

**Chapter 19: Managing storage devices ...................................................................................... 231**

Understanding RAID concepts.....................................................................................................................................233

What is RAID.............................................................................................................................................................. 233
Organizing data storage for availability and performance.............................................................................. 234
Choosing RAID levels .............................................................................................................................................. 235
Comparing RAID level performance......................................................................................................................240
Supported controllers.....................................................................................................................................................241
Supported enclosures.................................................................................................................................................... 242
Summary of supported features for storage devices............................................................................................ 242
Inventorying and monitoring storage devices.......................................................................................................... 247

Monitoring storage devices using web interface.............................................................................................. 248
Monitoring storage devices using RACADM...................................................................................................... 249
Monitoring backplane using iDRAC settings utility........................................................................................... 249
Viewing storage device topology................................................................................................................................ 249
Managing physical disks................................................................................................................................................ 249

Assigning or unassigning physical disk as global hot spare.............................................................................249
Converting a physical disk to RAID or non-RAID mode...................................................................................250
Erasing physical disks............................................................................................................................................... 251
Erasing SED/ISE device data.................................................................................................................................252
Rebuild Physical Disk................................................................................................................................................253
Managing virtual disks................................................................................................................................................... 253

Creating virtual disks................................................................................................................................................254
Editing virtual disk cache policies......................................................................................................................... 255
Deleting virtual disks................................................................................................................................................ 256
Checking virtual disk consistency.........................................................................................................................256
Initializing virtual disks..............................................................................................................................................257
Encrypting virtual disks............................................................................................................................................257
Assigning or unassigning dedicated hot spares................................................................................................. 258
Managing virtual disks using web interface........................................................................................................260
Managing virtual disks using RACADM.................................................................................................................261
RAID Configuration Features........................................................................................................................................261
Managing controllers......................................................................................................................................................262

Configuring controller properties.......................................................................................................................... 262
Security Protocol and Data Model (SPDM)....................................................................................................... 265
Importing or auto importing foreign configuration............................................................................................266
Clearing foreign configuration................................................................................................................................267
Resetting controller configuration........................................................................................................................ 268
Switching the controller mode...............................................................................................................................268
HBA adapter operations.......................................................................................................................................... 270
Monitoring predictive failure analysis on drives..................................................................................................271
Controller operations in non-RAID mode or HBA mode....................................................................................271
Running RAID configuration jobs on multiple storage controllers..................................................................271
Manage Preserved cache.........................................................................................................................................271
Managing PCIe SSDs......................................................................................................................................................272

Inventorying and monitoring PCIe SSDs..............................................................................................................272
Preparing to remove PCIe SSD..............................................................................................................................273
Erasing PCIe SSD device data............................................................................................................................... 274
Managing enclosures or backplanes...........................................................................................................................275

Configuring backplane mode.................................................................................................................................. 276
Viewing universal slots.............................................................................................................................................279
Setting SGPIO mode................................................................................................................................................ 279
Set Enclosure Asset Tag......................................................................................................................................... 279
Set Enclosure Asset Name..................................................................................................................................... 280
Choosing operation mode to apply settings.............................................................................................................280

Choosing operation mode using web interface................................................................................................. 280
Choosing operation mode using RACADM......................................................................................................... 280
Viewing and applying pending operations..................................................................................................................281

Viewing, applying, or deleting pending operations using web interface.......................................................281
Viewing and applying pending operations using RACADM.............................................................................. 281
Storage devices — apply operation scenarios........................................................................................................ 282
Blinking or unblinking component LEDs.....................................................................................................................283

Blinking or unblinking component LEDs using web interface.........................................................................283
Blinking or unblinking component LEDs using RACADM.................................................................................283
Warm reboot.................................................................................................................................................................... 283

**Chapter 20: BIOS Settings ....................................................................................................... 285**

BIOS Live Scanning........................................................................................................................................................ 286
BIOS Recovery and Hardware Root of Trust (RoT)...............................................................................................287

**Chapter 21: Configuring and using virtual console..................................................................... 288**

Supported screen resolutions and refresh rates.....................................................................................................289
Configuring virtual console...........................................................................................................................................290

Configuring virtual console using web interface............................................................................................... 290
Configuring virtual console using RACADM....................................................................................................... 290
Previewing virtual console............................................................................................................................................290
Launching virtual console............................................................................................................................................. 290

Launching virtual console using web interface...................................................................................................291
Launching virtual console using a URL.................................................................................................................291
Using virtual console viewer......................................................................................................................................... 291

Using a virtual console.............................................................................................................................................292

**Chapter 22: Using iDRAC Service Module.................................................................................. 295**

Installing iDRAC Service Module.................................................................................................................................295
Supported operating systems for iDRAC Service Module....................................................................................296
iDRAC Service Module monitoring features.............................................................................................................296
Using iDRAC Service Module from iDRAC web interface.....................................................................................302
Using iDRAC Service Module from RACADM..........................................................................................................302

**Chapter 23: Using USB port for server management..................................................................303**

Accessing iDRAC interface over direct USB connection......................................................................................303
Configuring iDRAC using server configuration profile on USB device...............................................................304

Configuring USB management port settings..................................................................................................... 304
Importing Server Configuration Profile from USB device ..............................................................................306

**Chapter 24: Using Quick Sync 2................................................................................................ 308**

Configuring iDRAC Quick Sync 2................................................................................................................................308

Configuring iDRAC Quick Sync 2 settings using web interface.................................................................... 309

Configuring iDRAC Quick Sync 2 settings using RACADM............................................................................ 309
Configuring iDRAC Quick Sync 2 settings using iDRAC settings utility...................................................... 309
Using mobile device to view iDRAC information.....................................................................................................309

**Chapter 25: Managing virtual media...........................................................................................310**

Supported drives and devices....................................................................................................................................... 311
Configuring virtual media................................................................................................................................................311

Configuring virtual media using iDRAC web interface.......................................................................................311
Configuring virtual media using RACADM............................................................................................................ 311
Configuring virtual media using iDRAC settings utility...................................................................................... 311
Attached media state and system response........................................................................................................311
Accessing virtual media..................................................................................................................................................312

Launching virtual media using virtual console.....................................................................................................312
Launching virtual media without using virtual console..................................................................................... 312
Adding virtual media images....................................................................................................................................313
Viewing virtual device details..................................................................................................................................313
Resetting USB............................................................................................................................................................ 313
Mapping virtual drive................................................................................................................................................ 314
Unmapping virtual drive........................................................................................................................................... 315
Enabling boot once for virtual media.......................................................................................................................... 315
Remote File Share........................................................................................................................................................... 316
Setting boot order through BIOS................................................................................................................................ 318
Accessing drivers.............................................................................................................................................................318

**Chapter 26: Managing vFlash SD card....................................................................................... 320**

Configuring vFlash SD card..........................................................................................................................................320

Viewing vFlash SD card properties.......................................................................................................................320
Enabling or disabling vFlash functionality............................................................................................................ 321
Initializing vFlash SD card....................................................................................................................................... 322
Getting the last status using RACADM............................................................................................................... 322
Managing vFlash partitions...........................................................................................................................................323

Creating an empty partition....................................................................................................................................323
Creating a partition using an image file............................................................................................................... 324
Formatting a partition.............................................................................................................................................. 325
Viewing available partitions.................................................................................................................................... 325
Modifying a partition................................................................................................................................................ 326
Attaching or detaching partitions..........................................................................................................................327
Deleting existing partitions..................................................................................................................................... 328
Downloading partition contents.............................................................................................................................328
Booting to a partition............................................................................................................................................... 329

**Chapter 27: Using SMCLP......................................................................................................... 330**

System management capabilities using SMCLP......................................................................................................330
Running SMCLP commands.........................................................................................................................................330
iDRAC SMCLP syntax.....................................................................................................................................................331
Navigating the map address space.............................................................................................................................334
Using show verb..............................................................................................................................................................334

Using the -display option.........................................................................................................................................334
Using the -level option.............................................................................................................................................334

Using the -output option.........................................................................................................................................334
Usage examples...............................................................................................................................................................334

Server power management.................................................................................................................................... 335
SEL management...................................................................................................................................................... 335
Map target navigation..............................................................................................................................................336

**Chapter 28: Installing operating systems...................................................................................337**

Deploying an operating system using remote file share........................................................................................ 337

Managing remote file shares.................................................................................................................................. 337
Configuring remote file share using web interface...........................................................................................337
Configuring remote file share using RACADM...................................................................................................338
Deploying operating system using virtual media..................................................................................................... 340
Deploying embedded operating system on SD card...............................................................................................340

Enabling SD module and redundancy in BIOS.....................................................................................................341

**Chapter 29: Troubleshooting managed system using iDRAC...................................................... 342**

Using diagnostic console...............................................................................................................................................342

Reset iDRAC and Reset iDRAC to default .........................................................................................................342
Scheduling remote automated diagnostics.........................................................................................................343
Scheduling remote automated diagnostics and exporting the results using RACADM........................... 343
Viewing post codes.........................................................................................................................................................344
Viewing boot and crash capture videos.................................................................................................................... 344

Configuring video capture settings.......................................................................................................................344
Viewing logs..................................................................................................................................................................... 345
Viewing last system crash screen...............................................................................................................................345
Viewing System status.................................................................................................................................................. 345

Viewing system front panel LCD status.............................................................................................................. 345
Viewing system front panel LED status...............................................................................................................346
Hardware trouble indicators.........................................................................................................................................346
Viewing system health...................................................................................................................................................346
Checking server status screen for error messages................................................................................................347
Restarting iDRAC............................................................................................................................................................ 347
Reset to Custom Defaults (RTD)................................................................................................................................347

Resetting iDRAC using iDRAC web interface.....................................................................................................347
Resetting iDRAC using RACADM..........................................................................................................................348
Erasing system and user data......................................................................................................................................348
Resetting iDRAC to factory default settings........................................................................................................... 349

Resetting iDRAC to factory default settings using iDRAC web interface.................................................. 349
Resetting iDRAC to factory default settings using iDRAC settings utility..................................................349

**Chapter 30: SupportAssist Integration in iDRAC....................................................................... 350**

SupportAssist...................................................................................................................................................................350
SupportAssist...................................................................................................................................................................350
Collection Log..................................................................................................................................................................350
Generating SupportAssist Collection......................................................................................................................... 350

Generating SupportAssist Collection manually using iDRAC web interface................................................351
Collection Settings......................................................................................................................................................... 352

**Chapter 31: Frequently asked questions.................................................................................... 353**

System Event Log...........................................................................................................................................................353
Custom sender email configuration for iDRAC alerts............................................................................................ 353
Network security.............................................................................................................................................................353
Telemetry streaming...................................................................................................................................................... 354
Active Directory.............................................................................................................................................................. 354
Single Sign-On.................................................................................................................................................................356
Smart card login.............................................................................................................................................................. 357
Virtual console................................................................................................................................................................. 357
Virtual media.................................................................................................................................................................... 359
vFlash SD card................................................................................................................................................................. 361
SNMP authentication..................................................................................................................................................... 361
Storage devices...............................................................................................................................................................362
GPU (Accelerators)........................................................................................................................................................362
iDRAC Service Module...................................................................................................................................................362
RACADM...........................................................................................................................................................................364
Permanently setting the default password to calvin..............................................................................................365
Miscellaneous...................................................................................................................................................................365
Proxy server settings......................................................................................................................................................371

**Chapter 32: Use case scenarios................................................................................................. 372**

Troubleshooting an inaccessible managed system................................................................................................. 372
Obtaining system information and assess system health......................................................................................372
Setting up alerts and configuring email alerts..........................................................................................................373
Viewing and exporting System Event Log and Lifecycle Log.............................................................................. 373
Interfaces to update iDRAC firmware........................................................................................................................373
Performing a graceful shutdown.................................................................................................................................373
Creating new administrator user account.................................................................................................................374
Launching servers remote console and mounting a USB drive........................................................................... 374
Installing bare metal OS using attached virtual media and remote file share...................................................374
Managing rack density...................................................................................................................................................374
Installing new electronic license.................................................................................................................................. 374
Applying IO Identity configuration settings for multiple network cards in single host system reboot ......375



# 1 Overview of iDRAC

The Integrated Dell Remote Access Controller (iDRAC) is designed to make you more productive as a system administrator and
improve the overall availability of Dell servers. iDRAC alerts you to system issues, helps you to perform remote management, and
reduces the need for physical access to the system.

iDRAC technology is part of a larger data center solution that increases the availability of business critical applications and
workloads. The technology allows you to deploy, monitor, manage, configure, update, and troubleshoot Dell systems from any
location without using any agents or an operating system.

**NOTE:** iDRAC behavior may not be consistent when used with Non-Dell hardware.

Several products work with the iDRAC to simplify and streamline IT operations. The following are some of the tools:

- OpenManage Enterprise
- OpenManage Power Center Plug in.
- OpenManage Integration for VMware vCenter
- Dell Repository Manager

iDRAC is available in the following variants:

- iDRAC Basic—Available by default for 100-500 series servers
- iDRAC Express—Available by default on all 600 and higher series of rack or tower servers, and all blade servers
- iDRAC Enterprise—Available on all server models
- iDRAC Datacenter—Available on all server models
**Topics:**

- Benefits of using iDRAC
- Key features
- New features or changes added
- How to use this guide
- Supported web browsers
- iDRAC licenses
- Licensed features in iDRAC9
- Interfaces and protocols to access iDRAC
- iDRAC port information
- Other documents you may need
- Contacting Dell
- Accessing documents from the Dell Support site
- Accessing Redfish API Guide



## Benefits of using iDRAC

The benefits include:

- Increased Availability — Early notification of potential or actual failures that help prevent a server failure or reduce recovery
time after failure.

- Improved Productivity and Lower Total Cost of Ownership (TCO) — Extending the reach of administrators to larger
numbers of distant servers can make IT staff more productive while driving down operational costs such as travel.

- Secure Environment — By providing secure access to remote servers, administrators can perform critical management
functions while maintaining server and network security.

- Enhanced Embedded Management through Lifecycle Controller — Lifecycle Controller provides deployment and simplified
serviceability through Lifecycle Controller GUI for local deployment and Remote Services (WSMan) interfaces for remote
deployment integrated with Dell OpenManage Enterprise and partner consoles.

For more information about Lifecycle Controller GUI, see _Dell Lifecycle Controller User's Guide_ and for remote services, see
_Lifecycle Controller Remote Services Quick Start Guide_ [available at iDRAC Manuals.](https://www.dell.com/idracmanuals)



## Key features

The key features of iDRAC include:

**NOTE:** Some features are available only with iDRAC Enterprise or Datacenter license. For information about the features
available for a license, see iDRAC licenses .

**Inventory and Monitoring**

- Telemetry data streaming.
- View managed server health.
- Inventory and monitor network adapters and storage subsystem (PERC and direct attached storage) without any operating
system agents.

- View and export system inventory.
- View sensor information such as temperature, voltage, and intrusion.
- Monitor CPU state, processor automatic throttling, and predictive failure.
- View memory information.
- Monitor and control power usage.
- Support for SNMPv3 gets and alerts.
- For blade servers: Launch Management Module web interface, view OpenManage Enterprise-Modular information, and
WWN/MAC addresses.

**NOTE:** CMC provides access to iDRAC through the M1000E Chassis LCD panel and local console connections. For more
information, see _Chassis Management Controller User's Guide_ [available on the CMC manuals page.](https://www.dell.com/cmcmanuals)

- View network interfaces available on host operating systems.
- iDRAC9 provides improved monitoring and management functionality with Quick Sync 2. You need the OpenManage Mobile
app configured in your Android or iOS mobile device.

**Deployment**

- Manage vFlash SD card partitions.
- Configure front panel display settings.
- Manage iDRAC network settings.
- Configure and use virtual console and virtual media.
- Deploy operating systems using remote file share, and virtual media.
- Enable auto-discovery.
- Perform server configuration using the export or import XML or JSON profile feature through RACADM, WS-Man, and
Redfish. For more information, see _Lifecycle Controller Remote Services Quick Start Guide_ [available on the iDRAC manuals](https://www.dell.com/idracmanuals)
page.

- Configure a persistence policy for virtual addresses, initiator, and storage targets.
- Remotely configure storage devices attached to the system at run-time.
- Perform the following operations for storage devices:
  - Physical disks: Assign or unassign a physical disk as a global hot spare.
  - Virtual disks:
￭ Create virtual disks.
￭ Edit virtual disks cache policies.
￭ Check virtual disk consistency.
￭ Initialize virtual disks.
￭ Encrypt virtual disks.
￭ Assign or unassign dedicated hot spare.
￭ Delete virtual disks.

  - Controllers:
￭ Configure controller properties.
￭ Import or auto-import foreign configuration.
￭ Clear foreign configuration.
￭ Reset the controller configuration.

￭ Create or change security keys.

  - PCIe SSD devices:
￭ Inventory and remotely monitor the health of PCIe SSD devices in the server.
￭ Prepare the PCIe SSD to be removed.
￭ Securely erase the data.

  - Set the backplane mode (unified or split mode).
  - Blink or unblink component LEDs.
  - Apply the device settings immediately, at the next system reboot, at a scheduled time, or as a pending operation to be
applied as a batch as part of the single job.

**Update**

- Manage iDRAC licenses.
- Update BIOS and device firmware for devices supported by Lifecycle Controller.
- Update or rollback iDRAC firmware and Lifecycle Controller firmware using a single firmware image.
- Manage staged updates.
- Access iDRAC interface over direct USB connection.
- Configure iDRAC using Server Configuration Profiles on a USB device.
**Maintenance and Troubleshooting**

- Perform power-related operations and monitor power consumption.
- Optimize system performance and power consumption by modifying the thermal settings.
- No dependency on OpenManage Server Administrator for generation of alerts.
- Log event data: Lifecycle and RAC logs.
- Set email alerts, IPMI alerts, remote system logs, WS Eventing logs, Redfish event, and SNMP traps (v1, v2c, and v3) for
events and improved email alert notification.

- Capture last system crash image.
- View boot and crash capture videos.
- Out-of-band monitor and alert the performance index of CPU, memory, and I/O modules.
- Configure a warning threshold for inlet temperature and power consumption.
- Use iDRAC Service Module to:
  - View operating system information.
  - Replicate Lifecycle Controller logs to operating system logs.
  - Automate system recovery options.
  - Enable or disable the status of Full Power Cycle for all System components except the PSU.
  - Remotely hard-reset iDRAC
  - Enable in-band iDRAC SNMP alerts.
  - Access iDRAC using host operating system (experimental feature)
  - Populate Windows Management Instrumentation (WMI) information.
  - Integrate with the SupportAssist collection. This is applicable only if iDRAC Service Module Version 2.0 or later is
installed.

- Generate SupportAssist collection in the following ways:
  - Automatic—Using iDRAC Service Module that automatically invokes the operating system Collector tool.
**Dell Best Practices regarding iDRAC**

- Dell iDRAC’s are intended to be on a separate management network; they are not designed nor intended to be placed on or
connected directly to the Internet. Doing so could expose the connected system to security and other risks for which Dell is
not responsible.

- Dell Technologies recommends using the Dedicated Gigabit Ethernet port available on rack and tower servers. This interface
is not shared with the host operating system and routes the management traffic to a separate physical network, enabling
it to be separated from the application traffic. This option implies that iDRAC's dedicated network port routes its traffic
separately from the server's LOM or NIC ports. The Dedicated option allows iDRAC to be assigned an IP address from the
same subnet or different subnet in comparison to the IP addresses assigned to the Host LOM or NICs.

- Along with locating iDRACs on a separate management subnet, users should isolate the management subnet/vLAN with
technologies such as firewalls, and limit access to the subnet/vLAN to authorized server administrators.

**Secure Connectivity**

Securing access to critical network resources is a priority. iDRAC implements a range of security features that includes:

- Custom signing certificate for Secure Socket Layer (SSL) certificate.
- Signed firmware updates.
- User authentication through Microsoft Active Directory, generic Lightweight Directory Access Protocol (LDAP) Directory
Service, or locally administered user IDs and passwords.

- Two-factor authentication using the Smart–Card login feature. The two-factor authentication is based on the physical smart
card and the smart card PIN.

- Single Sign-On and Public Key Authentication.
- Role-based authorization, to configure specific privileges for each user.
- SNMPv3 authentication for user accounts stored locally in the iDRAC. It is recommended to use this, but it is disabled by
default.

- User ID and password configuration.
- Default login password modification.
- Set user passwords and BIOS passwords using one-way hash format for improved security.
- FIPS 140-2 Level 1 capability.
- Session time-out configuration (in seconds).
- Configurable IP ports (for HTTP, HTTPS, SSH, Virtual Console, and Virtual Media).
- Secure Shell (SSH) that uses an encrypted transport layer for higher security.
- Login failure limits per IP address, with login blocking from that IP address when the limit is exceeded.
- Limited IP address range for clients connecting to iDRAC.
- Dedicated Gigabit Ethernet adapter available on rack and tower servers (additional hardware may be required).



## New features or changes added

The section provides a list of new features, or changes added in different iDRAC9 releases.

**NOTE:** For details about releases, if applicable, or to determine the most recent release for your platform, and for the latest
[documentation version, see iDRAC9 versions and release notes.](https://www.dell.com/support/kbdoc/en-in/000178115/idrac9-versions-and-release-notes)



### Firmware version 7.20.80.50

The following are the new features or changes in the iDRAC9 7.20.80.50 release:

- Dynamic ASHRAE rating adjustment based on BOSS Drive Size configuration for optimized thermal compliance and energy
efficiency.

- Enhanced iDRAC Redfish custom HTTP/HTTPS port information in Dell Connectivity Client (DCC) plugin for improved
remote manageability and security.

- CX8 Dual-Port Channel 400 GbE NIC support across all PowerEdge 16G servers for ultrahigh-speed networking and future
scalability.

- Telemetry and Open Telemetry (OTEL) support for InfiniBand devices for enhanced observability and performance
monitoring.

- Field Accessible Reliability Metrics (FARM) for Seagate SATA and SAS drives for better predictive maintenance and
improved reliability.

- Support for setting BIOS time through the Redfish API for accurate time synchronization (provided the BIOS version is
compatible with iDRAC).



### Firmware version 7.20.70.50

The following are the new features or changes in the iDRAC9 7.20.70.50 release:

- Accelerated AI and graphics performance with support for NVIDIA RTX Pro 6000 GPUs
- Improved data processing and networking through support for NVIDIA BF3 B3220 DPUs in AMD configurations
- Stronger data security and compliance with enhanced SEKM functionality supporting CloudLink Key Management Server
(KMS).



### Firmware version 7.20.60.50

The following are the new features or changes in the iDRAC9 7.20.60.50 release:

- Introduced support for open-loop control on Nokia Rinline 2 DPU cards to enable flexible thermal management.
- Added a BIOS knob for UMONITOR settings to improve thermal tuning.
- Improved Error and Event Messages (EEMs) for better diagnostics.
- Aligned naming conventions for the inlet temperature sensor to ensure consistency across monitoring tools.
- Enhanced self-healing mechanisms to automatically recover from communication errors between iDRAC and end devices.
- Integrated the latest version of the End User License Agreement to streamline compliance within the iDRAC interface.
- Enabled editing of the system contact field to store custom information.
- Removed the **Install iSM** option to simplify the iDRAC UI.
- Enabled automatic server power-off when FTR is disabled and PSU/PDU loss is detected to protect the hardware on the
PowerEdge C6620 systems.



### Firmware version 7.20.30.50

In iDRAC9 7.20.30.50 release, the following features are added in iDRAC:

- Enhanced design for debugging and usability messages.
- Added throttling and CoolIT features for thermal management.
- Support for PLDM updates for PERC 12.3.
- Support for Kingston MLC EMMC16G.
- Added support for multirated 2800 W or 3000 W PSUs on PowerEdge XE8640, PowerEdge XE9640, and PowerEdge
XE9680.

- Included NIC card temperature gauge in iDRAC through Redfish API.
- Enabled autodeletion of old cores after iDRAC firmware updates.
- Support for authentication types SHA384 and SHA512, and privacy type AES-256.
- Added Redfish OriginOfCondition object support to LC log entries PDR16, PDR113, and PDR114.
- Support for OpenSSH version 9.9p2.



### Firmware version 7.20.10.50

In iDRAC 7.20.10.50 release, the following features are added in iDRAC:

- Support for PERC 12.3.
- Implemented Redfish DMTF support to identify and report the blinking or unblinking status of hard drives.
- Efficient CMOS Battery failure messaging (LC logs) is added when the CMOS battery voltage drops below 2.2 V during AC
Power ON.

- Support for MEM0001 and MEM9072 events to include PPID, part number, or vendor part number in the Event Messages.
- Added GPU metrics:
  - GPUThermalViolationDuration
  - GPUPowerViolationDuration
  - GPUSWViolationDuration
  - GPUNVLinkTxThroughput
  - GPUNVLinkRxThroughput
  - GPUResetRecommendedState
  - GPUDMMAUsage
  - GPUPerformanceState
  - GPUNVLinkTrainingError
  - GPUNVLinkRuntimeError
  - GPUNVLinkStatusFlag
  - GPUNVLinksCount
- Added the alert group **Liquid Cooling System Default Action UnGraceful Power Off** for diligent leak detection and
management.



### Firmware version 7.10.90.00

In the iDRAC 7.10.90.00 release, the following features are added:

- Support for TPM 2.0 v6.
- Support for the SCV attribute **iDRAC.SCV.FirmwareCertificateVersion** .
- Support for NOKIA Cloud RAN Combined Boots State PLDM sensor.
- Integrated NOKIA Cloud RAN PLDM Virtual Temperature Sensor into server cooling.
- Support for Qualcomm X100 5G RAN accelerator card.
- Support for NVIDIA ConnectX-6 LX OCP 3.0.
- Support for Intel 2x100GbE IPU PCIe adapter for PowerEdge R660.
- Support for Broadcom Thor2 2x200/1x400 GbE PCIe adapter.
- Support for Dell L1 Inline Open Radio Access Network (RAN) Accelerator PCIe card.
- Support for HBA465e for MD JBODs.
- Enabled software RAID on PowerEdge R260 6 x 2.5" chassis configuration.
- Support for Dell Connectivity Client (DCC) plugin.
- Included Origin of Condition details for system health events (NOKIA Cloud RAN).
- Support for NOKIA Cloud RAN I2C sensors.
- Firmware Certificate support in the Secured Component Verification (SCV) tool.
- Added additional GPU metrics from iDRAC to OpenManage Enterprise for AIOps Observability.
- Included APEX AIOps infrastructure Observability SSD Smart Data Telemetry support.
- Support for 128 GB 32 Gb 5600 MT/s DIMMs on the following platforms:
  - PowerEdge R860
  - PowerEdge R760xa
  - PowerEdge R760
  - PowerEdge R660
  - PowerEdge XE8640
  - PowerEdge XE9680
  - PowerEdge MX760c
  - PowerEdge XE9640
  - PowerEdge XR5610
  - PowerEdge R960
- Support for 2800 W Titanium PSU on PowerEdge R7615.



### Firmware version 7.10.70.00

In iDRAC 7.10.70.00 release, the following features are added in iDRAC:

- Support crypto-erase on drives behind BOSS-N1 in a single action through a Redfish API.
- Added the alert **Liquid Cooling System Default Action Power Off for Graceful Power Off** if there is a GPU liquid leak.
- Improved machine check errors and CPU messages.
- Support for SNMPv3-AES-256.
- Universal Base Board (UBB) FRU support.
- AMD MI300X GPU FRU support.
- Enhanced manual catalog updates with **Additional Filter Options**, **Apply Same Version** and **Apply Downgrade Versions.**
**NOTE:** When either or both parameters are selected, the highest firmware version available in the repository is listed or
applied.



### Firmware version 7.10.50.00

In iDRAC 7.10.50.00 release, the following features are added in iDRAC:

- Support for M-CRPS 800/1100/1400W Titanium PSUs.
- Alert configuration added for thermal shutdown of the system.
- Support for system thermal shutdown events on critical conditions.
- Support for HBA465i enablement.
- Support for SDPM BBU Rollback and catalog update.
- Support for CPLD-based coordinated shutdown for 2x200G and 1x400G OEM cards, and I2C based DPU inventory.
- Motherboard and hardware diagnostics improvements
- Support for AMD Mi300x GPU
- Support for 2x200G and 1x400G OEM cards with CPLD-based coordinated shutdown and I2C-based DPU inventory.
- Support for iLKM and SEKM on HBA465i
- Support for SEKM scheduled rekey
- Support for SEKM periodic sync
- Support for SEKM custom PEM file certificates
- Support for the Redfish.OperationApplyTime property to enable security on BOSS-N1 controllers.
- Support for real-time erase operation on VOSS SEDs.



### Firmware version 7.10.30.00

In iDRAC 7.10.30.00 release, the following features are added in iDRAC:

- SEKM support on 3.2 TB KIOXIA CM7 NVMe E3.S drives.
- Support for dual-port VPI adapter card.
- Support to import externally generated CSR signed certificate and private key for SEKM into iDRAC.
- Support for sensor hot shutdown (sensor hot detection and shutdown request).
- Support for M.2 Micron 7450 drives.
- Support SDPM BBU model number in inventory.
- Closed Loop Thermals and Inventory support for Dell Open RAN Accelerator Card, Nokia RINLINE2 RAN, and Qualcomm
X100 RAN DPUs.

- Support for NVIDIA BlueField-3 2x200 GbE channel DPUs.
- Support for Intel 2x100 GbE DPUs.
- Support for NVIDIA RTX 5000 Ada Generation GPU on Precision R7960R.
- Support for Intel Ethernet Network Adapter E810-2CQDA2 (Dell customized hardware).
- Support for 2023.1 Redfish schema updates.
- UI support for in-application feedback and help.
- Improved PSU fault status reporting for precise detection and reporting of PSU hardware failures (for example, PSU0001
event in Lifecycle logs and SEL logs).



### Firmware version 7.00.60.00

In iDRAC 7.00.60.00 release, the following features are added in iDRAC:

- Added support for SPDM for Emulex.
- Optimized OS installation with eHTML5.



### Firmware version 7.00.30.00

This release includes all the features from the previous releases. Following are the new features that are added in this release:

**NOTE:** For information about supported systems, see the respective version of Release Notes available on the Dell
Supportsite.

In iDRAC 7.00.30.00 release, the following features are added in iDRAC:

- Added support for changing language on vKeyboard.
- Added support for UPN suffixes in iDRAC AD authentication.
- Added Watts property for Power Supply Unit (PSU) readings section.



## How to use this guide

User instructions

The contents of this user's guide enable you to perform various tasks using:

1. iDRAC web interface—Only task-related information is provided in this guide . For information about the fields and options,
see the **iDRAC Online Help** that you can access from the web interface.

2. RACADM—The RACADM commands to perform specific tasks are provided in this guide. For more information, see the

[Integrated Dell Remote Access Controller 9 RACADM CLI guide.](https://www.dell.com/support/home/en-us/product-support/product/idrac9-lifecycle-controller-v7.x-series/docs)

3. iDRAC Settings Utility—Only the task-related information is provided here. For information about the fields and options, see
the **iDRAC Settings Utility Online Help** that you can access when you click **Help** in the iDRAC Settings GUI (press <F2>
during boot, and then click **iDRAC Settings** on the **System Setup Main Menu** page).

4. [Redfish—Redish API-related information is provided in this guide. For more information, see the iDRAC Redfish API guide..](HTTPS://DEVELOPER.DELL.COM/APIS/2978/VERSIONS/7.XX/DOCS/0WHATSNEW.MD)
For further assistance on how to access the API guide, see the section Accessing the iDRAC API guide.



## Supported web browsers

[For the list of supported versions, see the iDRAC9 Release Notes for your server model.](https://www.dell.com/support/kbdoc/en-in/000178115/idrac9-versions-and-release-notes)



### Supported operating systems and hypervisors

[For the list of supported versions of operating systems and hypervisors, see the iDRAC9 Release Notes for your server model.](https://www.dell.com/support/kbdoc/en-in/000178115/idrac9-versions-and-release-notes)



## iDRAC licenses

iDRAC features are available based on the type of the license. Depending on the system model, iDRAC Basic or iDRAC Express
license is installed by default. iDRAC Enterprise license, iDRAC Datacenter license, and iDRAC Secure Enterprise Key Manager
(SEKM) license are available as an upgrade and can be purchased anytime. Only licensed features are available in the interfaces
that enable you to configure or use iDRAC. For more information, see Licensed features in iDRAC9.



### Types of licenses

The standard licenses iDRAC Basic or iDRAC Express are available by default on your system. iDRAC Enterprise and Datacenter
licenses include all the licensed features and can be purchased at any time. The types of upsell that is offered are:

- 30-day evaluation—Evaluation licenses are duration-based and the timer runs when power is applied to the system. This
license cannot be extended.

- Perpetual—The license is bound to the Service Tag and is permanent.

The following table lists the default licenses available on the systems:

**Table 2. Default Licenses**

|iDRAC Basic License|iDRAC Express License|iDRAC Enterprise License|iDRAC Datacenter License|
|---|---|---|---|
|PowerEdge Rack and Tower<br>servers|●<br>Standard offering on<br>PowerEdge Series 600<br>and above<br>●<br>Standard offering on<br>PowerEdge Series 100 and<br>above<br>●<br>PowerEdge XR and XE<br>series<br>●<br>PowerEdge MX750C and<br>MX7650C<br>●<br>PowerEdge Rack and<br>Tower servers (with<br>Upgrade option)|All platforms with upgrade<br>option|All platforms with upgrade<br>option|

**NOTE:** Express for Blades license is the default license for PowerEdge MX75XX and newer blades and MX chassis servers.



### Methods for acquiring licenses

Use any of the following methods to acquire the licenses:

- Dell Digital Locker — Dell Digital Locker allows you to view and manage your products, software, and licensing information in
one location. A link to the Dell Digital Locker is available in DRAC web interface- go to **Configuration**   - **Licenses** .

**NOTE:** [To know more about Dell Digital Locker, refer to FAQ on the website.](https://www.dell.com/support/software/us/en/19/Default/QuickStartGuide)

- Email — License is attached to an email that is sent after requesting it from the technical support center.
- Point-of-sale — License is acquired while placing the order for a system.
**NOTE:** [To manage licenses or purchase new licenses, go to the Dell Digital Locker.](HTTPS://WWW.DELL.COM/SUPPORT/SOFTWARE)



### Acquiring license key from Dell Digital Locker

To obtain the license key from your account, you must first register your product using the registration code that is sent in the
order confirmation email. This code must be entered in the **Product Registration** tab after logging into Dell Digital Locker.

From the left pane, click the **Products** or **Order History** tab to view the list of your products. Subscription-based products are
listed under **Billing accounts** tab.

To download the license key from your Dell Digital Locker account:

1. Sign in to your Dell Digital Locker account.
2. From the left pane, click **Products** .
3. Click the product that you want to view.
4. Click the product name.
5. On the **Product management** page, click **Get Key** .
6. Follow the instructions on the screen to obtain the license key.
**NOTE:** If you do not have a Dell Digital Locker account, create an account using the email address provided during your
purchase.

**NOTE:** To generate multiple license keys for new purchases, follow the instructions under **Tools**  - **License Activation**  **Unactivated licenses**



### License operations

Before you perform the license management tasks, ensure that you acquire the licenses. For more information, see the Methods
for acquiring licenses.

**NOTE:** If you have purchased a system with all the licenses preinstalled, then license management is not required.

**NOTE:** To ensure that iDRAC UI reflects licenses installed using RACADM, Redfish, SCV factory, or other interfaces, log in
to iDRAC UI again or refresh the browser.

You can perform the following licensing operations using iDRAC UI, RACADM, WSMan, Redfish and Lifecycle Controller-Remote
Services for one-to-one license management, and Dell License Manager for one-to-many license management:

- View—View the current license information.
- Import—After acquiring the license, store the license in a local storage and import it into iDRAC using one of the supported
interfaces. The license is imported if it passes the validation checks.

**NOTE:** Although you can export the factory-installed license, you cannot import it. To import the license, download the
equivalent license from the Digital Locker or retrieve it from the email you received when you purchased the license.

- Export—Exports the installed license. For more information, see the **iDRAC Online Help** .
- Delete—Deletes the license. For more information, see the **iDRAC Online Help** .
- Learn More—Learn more about an installed license, or the licenses available for a component installed in the server.
**NOTE:** For the Learn More option to display the correct page, ensure that ***.dell.com** is added to the list of Trusted
Sites in the Security Settings. For more information, see the Internet Explorer help documentation.

For one-to-many license deployment, you can use Dell License Manager. For more information, see _Dell License Manager User's_
_Guide_ [available on the Enterprise Systems Managementpage..](https://www.dell.com/esmmanuals)

Following are the user privilege requirements for different license operation:

- License View and Export: Login privilege.
- License Import and Delete: Login + Configure iDRAC + Server Control privilege.



#### Managing licenses using iDRAC web interface

License management

To manage the licenses using the iDRAC web interface, go to **Configuration** - **Licenses** .

The **Licensing** page displays the licenses that are associated to devices, or the licenses that are installed but the device is not
present in the system. For more information on importing, exporting, or deleting a license, see the **iDRAC Online Help** .



#### Managing licenses using RACADM

License management

1. To manage licenses using RACADM, use the **license** sub-command.
2. [For more information, see the Integrated Dell Remote Access Controller 9 RACADM CLI guide.](https://www.dell.com/support/home/en-us/product-support/product/idrac9-lifecycle-controller-v7.x-series/docs)



## Licensed features in iDRAC9

The following table lists iDRAC9 features that are enabled based on the license purchased:



## Table 3. Licensed features in iDRAC9

|Feature|iDRAC9 Basic|iDRAC9<br>Express|iDRAC9<br>Express for<br>Blades|iDRAC9<br>Enterprise|iDRAC9 Datacenter|
|---|---|---|---|---|---|
|**Interfaces/Standards**|**Interfaces/Standards**|**Interfaces/Standards**|**Interfaces/Standards**|**Interfaces/Standards**|**Interfaces/Standards**|
|iDRAC RESTful API and<br>Redfish|Yes|Yes|Yes|Yes|Yes|
|IPMI 2.0|Yes|Yes|Yes|Yes|Yes|
|DCMI 1.5|Yes|Yes|Yes|Yes|Yes|
|Web-based UI|Yes|Yes|Yes|Yes|Yes|
|RACADM command line<br>(local/remote)|Yes|Yes|Yes|Yes|Yes|
|SSH|Yes|Yes|Yes|Yes|Yes|
|Serial Redirection|Yes|Yes|Yes|Yes|Yes|
|WSMan|Yes|Yes|Yes|Yes|Yes|
|Network Time Protocol|No|Yes|Yes|Yes|Yes|
|**Connectivity**|**Connectivity**|**Connectivity**|**Connectivity**|**Connectivity**|**Connectivity**|
|Shared NIC (LOM)|Yes|Yes|N/A|Yes|Yes|
|Dedicated NIC|Yes|Yes|Yes|Yes|Yes|
|VLAN tagging|Yes|Yes|Yes|Yes|Yes|
|IPv4|Yes|Yes|Yes|Yes|Yes|
|IPv6|Yes|Yes|Yes|Yes|Yes|
|DHCP|Yes|Yes|Yes|Yes|Yes|
|DHCP with zero touch|No|No|No|Yes|Yes|
|Dynamic DNS|Yes|Yes|Yes|Yes|Yes|
|OS pass-through|Yes|Yes|Yes|Yes|Yes|
|iDRAC Direct -Front<br>panel USB|Yes|Yes|Yes|Yes|Yes|
|Connection View|Yes|Yes|No|Yes|Yes|
|DPU|No|No|No|Yes|Yes|
|**Security**|**Security**|**Security**|**Security**|**Security**|**Security**|
|Role-based authority|Yes|Yes|Yes|Yes|Yes|
|Local users|Yes|Yes|Yes|Yes|Yes|
|SSL encryption|Yes|Yes|Yes|Yes|Yes|
|Secure Enterprise Key<br>Management and iDRAC<br>Local Key Manager|No|No|No|Yes (with SEKM<br>license)|Yes (with SEKM<br>license)|
|IP blocking|No|Yes|Yes|Yes|Yes|
|Directory services (AD,<br>LDAP)|No|No|No|Yes|Yes|
|Two-factor<br>authentication (smart<br>card)|No|No|No|Yes|Yes|
|Single sign-On|No|No|No|Yes|Yes|
|PK authentication (for<br>SSH)|No|Yes|Yes|Yes|Yes|
|OAuth integration<br>with Web based<br>Authentication services|No|No|No|No|Yes|
|Port-based Network<br>Access Control (IEEE<br>802.1x)|No|No|No|No|Yes|
|OpenID Connect for Dell<br>Consoles|No|No|No|No|Yes|
|FIPS 140-2|Yes|Yes|Yes|Yes|Yes|
|Secure UEFI boot -<br>certificate management|Yes|Yes|Yes|Yes|Yes|
|Lock down mode|No|No|No|Yes|Yes|
|Unique iDRAC default<br>password|Yes|Yes|Yes|Yes|Yes|
|Customizable Security<br>Policy Banner - login page|Yes|Yes|Yes|Yes|Yes|
|Easy Multi Factor<br>Authentication|No|No|No|Yes|Yes|
|Auto Certificate<br>Enrollment (SSL Certs)|No|No|No|No|Yes|
|iDRAC Quick Sync 2 -<br>optional auth for read<br>operations|Yes|Yes|Yes|Yes|Yes|

**Table 3. Licensed features in iDRAC9 (continued)**

|Feature|iDRAC9 Basic|iDRAC9<br>Express|iDRAC9<br>Express for<br>Blades|iDRAC9<br>Enterprise|iDRAC9 Datacenter|
|---|---|---|---|---|---|
|iDRAC Quick Sync 2 -<br>add mobile device number<br>to LCL|Yes|Yes|Yes|Yes|Yes|
|System Erase of internal<br>storage devices|Yes|Yes|Yes|Yes|Yes|
|**Remote Presence**|**Remote Presence**|**Remote Presence**|**Remote Presence**|**Remote Presence**|**Remote Presence**|
|Power control|Yes|Yes|Yes|Yes|Yes|
|Boot control|Yes|Yes|Yes|Yes|Yes|
|Serial-over-LAN|Yes|Yes|Yes|Yes|Yes|
|Virtual Media|No|No|Yes|Yes|Yes|
|Virtual Folders|No|No|No|Yes|Yes|
|Remote File Share|No|No|No|Yes|Yes|
|HTML5 access to Virtual<br>Console|No|No|Yes|Yes|Yes|
|Virtual Console|No|No|Yes<br>**NOTE:**<br>Virtual<br>Console is<br>not<br>available on<br>PowerEdge<br>MX750c<br>and<br>MX7650c.|Yes|Yes|
|Virtual Clipboard|No|No|No|Yes|Yes|
|VNC connection to<br>operating system|No|No|No|Yes|Yes|
|Quality/bandwidth<br>control|No|No|No|Yes|Yes|
|Virtual Console<br>collaboration (up to six<br>simultaneous users)|No|No|No (One user<br>only)|Yes|Yes|
|Virtual Console chat|No|No|No|Yes|Yes|
|Virtual Flash partitions|No|No|No|Yes|Yes|
|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** vFlash is not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|
|Group Manager|No|No|No|Yes|Yes|
|HTTP / HTTPS support<br>along with NFS/CIFS|Yes|Yes|Yes|Yes|Yes|
|**Power and Thermal**|**Power and Thermal**|**Power and Thermal**|**Power and Thermal**|**Power and Thermal**|**Power and Thermal**|
|Real-time power meter|No|No|No|Yes|Yes|
|Power thresholds and<br>alerts|No|Yes|Yes|Yes|Yes|
|Real-time power graphing|No|No|No|Yes|Yes|
|Historical power counters|No|No|No|Yes|Yes|
|Power capping|No|No|No|Yes|Yes|
|Power Center integration|No|No|No|Yes|Yes|
|Temperature monitoring|Yes|Yes|Yes|Yes|Yes|
|Temperature graphing|No|Yes|Yes|Yes|Yes|
|PCIe airflow<br>customization (LFM)|No|No|No|No|Yes|
|Custom Exhaust Control|No|No|No|No|Yes|
|Custom Delta-T control|No|No|No|No|Yes|
|System Airflow<br>Consumption|No|No|No|No|Yes|
|Custom PCIe inlet<br>temperature|No|No|No|No|Yes|
|**Health Monitoring**|**Health Monitoring**|**Health Monitoring**|**Health Monitoring**|**Health Monitoring**|**Health Monitoring**|
|Full agent-free monitoring|Yes|Yes|Yes|Yes|Yes|
|Predictive failure<br>monitoring|Yes|Yes|Yes|Yes|Yes|
|SNMPv1, v2, and v3<br>(traps and gets)|Yes|Yes|Yes|Yes|Yes|
|Email Alerting|No|Yes|Yes|Yes|Yes|
|Configurable thresholds|Yes|Yes|Yes|Yes|Yes|
|Fan monitoring|Yes|Yes|Yes|Yes|Yes|
|Power Supply monitoring|Yes|Yes|Yes|Yes|Yes|
|Memory monitoring|Yes|Yes|Yes|Yes|Yes|
|GPU|No|No|No|Yes|Yes|
|CPU monitoring|Yes|Yes|Yes|Yes|Yes|
|CPU and GPU leak<br>detection|Yes|Yes|Yes|Yes|Yes|
|RAID monitoring|Yes|Yes|Yes|Yes|Yes|
|NIC monitoring|Yes|Yes|Yes|Yes|Yes|
|Optic Inventory|Yes|Yes|Yes|Yes|Yes|
|Optic Statistics|No|No|No|No|Yes|
|HD monitoring<br>(enclosure)|Yes|Yes|Yes|Yes|Yes|
|Out of Band Performance<br>Monitoring|No|No|No|Yes|Yes|
|Alerts for excessive SSD<br>wear|Yes|Yes|Yes|Yes|Yes|

**Table 3. Licensed features in iDRAC9 (continued)**

|Feature|iDRAC9 Basic|iDRAC9<br>Express|iDRAC9<br>Express for<br>Blades|iDRAC9<br>Enterprise|iDRAC9 Datacenter|
|---|---|---|---|---|---|
|Customizable settings<br>for Exhaust Temperature<br>(For 14G only)|Yes|Yes|Yes|Yes|Yes|
|Customizable settings<br>for Exhaust Temperature<br>(For 15/16G)|No|No|No|No|Yes|
|Serial Console Logs|No|No|No|No|Yes|
|SMART logs for Storage<br>Drives|Yes|Yes|Yes|Yes|Yes|
|**NOTE:** SMART logs are also available using SupportAssist collection.|**NOTE:** SMART logs are also available using SupportAssist collection.|**NOTE:** SMART logs are also available using SupportAssist collection.|**NOTE:** SMART logs are also available using SupportAssist collection.|**NOTE:** SMART logs are also available using SupportAssist collection.|**NOTE:** SMART logs are also available using SupportAssist collection.|
|Idle Server detection|No|No|No|No|Yes|
|Telemetry Streaming|No|No|No|No|Yes|
|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|**NOTE:** The OpenManage Enterprise Advanced license and the PowerManage Plugin support telemetry data pulls from the<br>iDRAC.|
|**Update**|**Update**|**Update**|**Update**|**Update**|**Update**|
|Remote agent-free<br>update|Yes|Yes|Yes|Yes|Yes|
|Embedded update tools|Yes|Yes|Yes|Yes|Yes|
|Update from repository|Yes|Yes|Yes|Yes|Yes|
|Schedule update from<br>repository (Auto-Update)|Yes|Yes|Yes|Yes|Yes|
|Improved PSU firmware<br>updates|Yes|Yes|Yes|Yes|Yes|
|**Deployment and Configuration**|**Deployment and Configuration**|**Deployment and Configuration**|**Deployment and Configuration**|**Deployment and Configuration**|**Deployment and Configuration**|
|Local configuration using<br>F2/F10|Yes|Yes|Yes|Yes|Yes|
|Embedded OS<br>deployment tools|Yes|Yes|Yes|Yes|Yes|
|Embedded configuration<br>tools|Yes|Yes|Yes|Yes|Yes|
|Auto-Discovery|No|Yes|Yes|Yes|Yes|
|Remote operating system<br>deployment|No|Yes|Yes|Yes|Yes|
|Embedded driver pack|Yes|Yes|Yes|Yes|Yes|
|Full configuration<br>inventory|Yes|Yes|Yes|Yes|Yes|
|Inventory export|Yes|Yes|Yes|Yes|Yes|
|Remote configuration|Yes|Yes|Yes|Yes|Yes|
|Zero-touch configuration|No|No|No|Yes|Yes|
|System Retire/Repurpose|Yes|Yes|Yes|Yes|Yes|
|Server Configuration<br>Profile in UI|Yes|Yes|Yes|Yes|Yes|
|Add BIOS configuration<br>to iDRAC UI|Yes|Yes|Yes|Yes|Yes|
|GPU properties|No|No|No|Yes|Yes|
|**Diagnostics, Service, and Logging**|**Diagnostics, Service, and Logging**|**Diagnostics, Service, and Logging**|**Diagnostics, Service, and Logging**|**Diagnostics, Service, and Logging**|**Diagnostics, Service, and Logging**|
|Embedded diagnostic<br>tools|Yes|Yes|Yes|Yes|Yes|
|Part Replacement|No|Yes|Yes|Yes|Yes|
|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|**NOTE:** After performing part replacement on RAID hardware, and the process is complete for replacing firmware and<br>configuration, Lifecycle Logs reports double part replacement entries which is expected behavior.|
|Easy Restore (system<br>configuration)|Yes|Yes|Yes|Yes|Yes|
|Easy Restore Auto<br>Timeout|Yes|Yes|Yes|Yes|Yes|
|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|**NOTE:** Server Backup and Restore features are not available in iDRAC9 for PowerEdge Rx5xx/Cx5xx.|
|LED Health status<br>indicators|Yes|Yes|N/A|Yes|Yes|
|LCD screen (iDRAC9<br>requires optional)|Yes|Yes|N/A|Yes|Yes|
|iDRAC Quick Sync 2<br>(BLE/Wi-Fi hardware)|Yes|Yes|Yes|Yes|Yes|
|iDRAC Direct (front USB<br>management port)|Yes|Yes|Yes|Yes|Yes|
|iDRAC Service Module<br>(iSM) embedded|Yes|Yes|Yes|Yes|Yes|
|iSM to in-band alert<br>forwarding to consoles|Yes|Yes|Yes|Yes|Yes|
|SupportAssist Collection<br>(embedded)|Yes|Yes|Yes|Yes|Yes|
|Crash screen capture|No|Yes|Yes|Yes|Yes|
|Crash video capture1|No|No|No|Yes|Yes|
|Agent Free Crash Video<br>Capture (Windows only)|No|No|No|No|Yes|
|Boot capture|No|No|No|Yes|Yes|
|Manual reset for iDRAC<br>(LCD ID button)|Yes|Yes|Yes|Yes|Yes|
|Remote reset for iDRAC<br>(requires iSM)|Yes|Yes|Yes|Yes|Yes|
|Virtual NMI|Yes|Yes|Yes|Yes|Yes|
|OS watchdog|Yes|Yes|Yes|Yes|Yes|
|System Event Log|Yes|Yes|Yes|Yes|Yes|

**Table 3. Licensed features in iDRAC9 (continued)**

|Feature|iDRAC9 Basic|iDRAC9<br>Express|iDRAC9<br>Express for<br>Blades|iDRAC9<br>Enterprise|iDRAC9 Datacenter|
|---|---|---|---|---|---|
|Lifecycle Log|Yes|Yes|Yes|Yes|Yes|
|Enhanced Logging in<br>Lifecycle Controller Log|Yes|Yes|Yes|Yes|Yes|
|Work notes|Yes|Yes|Yes|Yes|Yes|
|Remote Syslog|No|No|No|Yes|Yes|
|License management|Yes|Yes|Yes|Yes|Yes|

[1] Requires iSM or OMSA agent on target server.



## Interfaces and protocols to access iDRAC

The following table lists the interfaces to access iDRAC.

**NOTE:** Using more than one interface simultaneously may generate unexpected results.



## Table 4. Interfaces and protocols to access iDRAC

|Interface or Protocol|Description|
|---|---|
|iDRAC Settings Utility<br>(F2)|Use the iDRAC Settings utility to perform pre-OS operations. It has a subset of the features that<br>are available in the iDRAC web interface along with other features. To access iDRAC Settings utility,<br>press`<F2>` during boot and then click**iDRAC Settings** on the**System Setup Main Menu** page.|
|Lifecycle Controller<br>(F10)|Use Lifecycle Controller to perform iDRAC configurations. To access Lifecycle Controller, press<br><F10> during boot and go to**System Setup** >**Advanced Hardware Configuration** >**iDRAC**<br>**Settings**. For more information, see**Lifecycle Controller User’s Guide** available at**dell.com/**<br>**idracmanuals**.|
|iDRAC Web Interface|Use the iDRAC web interface to manage iDRAC and monitor the managed system. The browser<br>connects to the web server through the HTTPS port. Data streams are encrypted using 128-bit<br>SSL to provide privacy and integrity. Any connection to the HTTP port is redirected to HTTPS.<br>Administrators can upload their own SSL certificate through an SSL CSR generation process to<br>secure the web server. The default HTTP and HTTPS ports can be changed. The user access is<br>based on user privileges.|
|OpenManage<br>Enterprise (OME)<br>Modular Web Interface|**NOTE:** This interface is only available for MX platforms.<br>In addition to monitoring and managing the chassis, use the OME-Modular web interface to:<br>●<br>View the status of a managed system<br>●<br>Update iDRAC firmware<br>●<br>Configure iDRAC network settings<br>●<br>Log in to iDRAC web interface<br>●<br>Start, stop, or reset the managed system<br>●<br>Update BIOS, PERC, and supported network adapters<br>For more information, see the_Dell OpenManage Enterprise-Modular for PowerEdge MX7000_<br>_Chassis User's Guide_ available on theOpenManage manuals page.|
|CMC Web Interface|**NOTE:** This interface is not available in MX platforms.<br>In addition to monitoring and managing the chassis, use the CMC web interface to:<br>●<br>View the status of a managed system<br>●<br>Update iDRAC firmware<br>●<br>Configure iDRAC network settings<br>●<br>Log in to iDRAC web interface<br>●<br>Start, stop, or reset the managed system|
||●<br>Update BIOS, PERC, and supported network adapters|
|Server LCD Panel/<br>Chassis LCD Panel|Use the LCD on the server front panel to:<br>●<br>View alerts, iDRAC IP or MAC address, user programmable strings.<br>●<br>Set DHCP<br>●<br>Configure iDRAC static IP settings.<br>For blade servers, the LCD is on the chassis front panel and is shared between all the blades. To<br>reset iDRAC without rebooting the server, press and hold the System Identification button<br> for 16<br>seconds.<br>**NOTE:** LCD panel is only available with rack or tower systems that support front bezel. For blade<br>servers, the LCD is on the chassis front panel and is shared between all the blades.|
|RACADM|Use this command-line utility to perform iDRAC and server management. You can use RACADM<br>locally and remotely.<br>●<br>Local RACADM command-line interface runs on the managed systems that have Server<br>Administrator installed. Local RACADM communicates with iDRAC through its in-band IPMI host<br>interface. Since it is installed on the local managed system, users are required to log in to the<br>operating system to run this utility. A user must have a full administrator privilege or be a root<br>user to use this utility.<br>●<br>Remote RACADM is a client utility that runs on a management station. It uses the out-of-band<br>network interface to run RACADM commands on the managed system and uses the HTTPs<br>channel. The**–r** option runs the RACADM command over a network.<br>●<br>Firmware RACADM is accessible by logging in to iDRAC using SSH. You can run the firmware<br>RACADM commands without specifying the iDRAC IP, user name, or password.<br>●<br>You do not have to specify the iDRAC IP, user name, or password to run the firmware RACADM<br>commands. After you enter the RACADM prompt, you can directly run the commands without<br>the racadm prefix.|
|iDRAC RESTful API and<br>Redfish|The Redfish Scalable Platforms Management API is a standard defined by the Distributed<br>Management Task Force (DMTF). Redfish is a next-generation systems management interface<br>standard, which enables scalable, secure, and open server management. It is a new interface that<br>uses RESTful interface semantics to access data that is defined in model format to perform out-<br>of-band systems management. It is suitable for a wide range of servers ranging from stand-alone<br>servers to rack mount and bladed environments and for large scale cloud environments. Redfish<br>provides the following benefits over existing server management methods:<br>●<br>Increased simplicity and usability<br>●<br>High data security<br>●<br>Programmable interface that can be easily scripted<br>●<br>Follows widely used standards<br>See the**iDRAC9 Redfish API**guide.|
|WSMan|The LC-Remote Service is based on the WSMan protocol to do one-to-many systems management<br>tasks. You must use WSMan client such as WinRM client (Windows) or the OpenWSMan client<br>(Linux) to use the LC-Remote Services functionality. You can also use Power Shell or Python to<br>script to the WSMan interface. Web Services for Management (WSMan) is a Simple Object Access<br>Protocol (SOAP)–based protocol used for systems management. iDRAC uses WSMan to convey<br>Distributed Management Task Force (DMTF) Common Information Model (CIM)–based management<br>information. The CIM information defines the semantics and information types that can be modified<br>in a managed system. The data available through WSMan is provided by iDRAC instrumentation<br>interface mapped to the DMTF profiles and extension profiles. For more information, see the<br>following:<br>●<br>_Lifecycle Controller Remote Services Quick Start Guide_ available on theiDRAC manuals page.<br>●<br>DMTF website|
|SSH|Use SSH to run RACADM commands. The SSH service is enabled by default on iDRAC. The SSH<br>service can be disabled in iDRAC. iDRAC only supports SSH version 2 with the RSA host key<br>algorithm. A unique 1024-bit RSA host key is generated when you power-up iDRAC for the first time.|
|IPMITool|Use the IPMITool to access the remote system’s basic management features through iDRAC. The<br>interface includes local IPMI, IPMI over LAN, IPMI over Serial, and Serial over LAN. For more|

**Table 4. Interfaces and protocols to access iDRAC (continued)**

|Interface or Protocol|Description|
|---|---|
||information about IPMITool, see the**Dell OpenManage Baseboard Management Controller**<br>**Utilities User’s Guide**.<br>**NOTE:** IPMI version 1.5 is not supported.|
|NTLM|iDRAC allows NTLM to provide authentication, integrity, and confidentiality to the users. NT LAN<br>Manager (**NTLM**) is a suite of Microsoft security protocols and it works in a Windows network.|
|SMB|iDRAC9 supports the Server Message Block (SMB) protocol. This is a network file sharing protocol.<br>The SMB versions supported are 2.0 - 3.11. SMBv1 is no longer supported.<br>**NOTE:** The SMB3 share encryption security feature is supported starting with iDRAC firmware<br>7.00.00.171 for 14th generation Dell PowerEdge servers, and 7.10.50.00 for 15th and 16th<br>generation of Dell PowerEdge servers.|
|NFS|iDRAC9 supports** Network File System** (**NFS**). This is a distributed filesystem protocol that<br>enables users to**mount** remote directories on the servers.|



## iDRAC port information

The following table lists the ports that are required to remotely access iDRAC through firewall. These are the default ports
iDRAC listens to for connections. Optionally, you can modify most of the ports. To modify ports, see Configuring services.

**Table 5. Ports iDRAC listens for connections**

|Port<br>number|Type|Function|Configurabl<br>e port|Maximum Encryption Level|
|---|---|---|---|---|
|22|TCP|SSH|Yes|256-bit SSL|
|80|TCP|HTTP|Yes|None|
|161|UDP|SNMP Agent|Yes|None|
|443|TCP|●<br>Web GUI access with HTTPS<br>●<br>Virtual Console and Virtual Media with<br>eHTML5 option<br>**NOTE:** Starting with release version<br>6.00.02.00, access to vConsole and vMedia<br>uses only eHTML5. Java and ActiveX are no<br>longer supported.|Yes|256-bit SSL|
|623|UDP|RMCP/RMCP+|No|128-bit SSL|
|5000|TCP|iDRAC to iSM|No|256-bit SSL|
|**NOTE:** Maximum encryption level is 256-bit SSL if both iSM 3.4 or higher and iDRAC firmware 3.30.30.30 or higher are<br>installed.|**NOTE:** Maximum encryption level is 256-bit SSL if both iSM 3.4 or higher and iDRAC firmware 3.30.30.30 or higher are<br>installed.|**NOTE:** Maximum encryption level is 256-bit SSL if both iSM 3.4 or higher and iDRAC firmware 3.30.30.30 or higher are<br>installed.|**NOTE:** Maximum encryption level is 256-bit SSL if both iSM 3.4 or higher and iDRAC firmware 3.30.30.30 or higher are<br>installed.|**NOTE:** Maximum encryption level is 256-bit SSL if both iSM 3.4 or higher and iDRAC firmware 3.30.30.30 or higher are<br>installed.|
|5670|UDP|For discovery, on-boarding, and presence of<br>ZeroMQ Realtime Exchange Protocol for iDRAC<br>Group manager feature. This port is used only<br>when Group Manager is enabled,|No|None|
|5901|TCP|VNC|Yes|128-bit SSL|
|**NOTE:** Port 5901 opens when VNC feature is enabled.|**NOTE:** Port 5901 opens when VNC feature is enabled.|**NOTE:** Port 5901 opens when VNC feature is enabled.|**NOTE:** Port 5901 opens when VNC feature is enabled.|**NOTE:** Port 5901 opens when VNC feature is enabled.|
|Port<br>number|Type|Function|Configurable<br>port|Maximum Encryption Level|
|25|TCP|SMTP|Yes|None|
|53|UDP|DNS|No|None|
|68|UDP|DHCP-assigned IP address|No|None|
|69|TFTP|TFTP|No|None|
|123|UDP|Network Time Protocol (NTP)|No|None|
|162|UDP|SNMP trap|Yes|None|
|445|TCP|Common Internet File System (CIFS)|No|None|
|636|TCP|LDAP Over SSL (LDAPS)|No|256-bit SSL|
|2049|TCP|Network File System (NFS)|No|None|
|3269|TCP|LDAPS for global catalog (GC)|No|256-bit SSL|
|5353|UDP|mDNS|No|None|
|**NOTE:** When node initiated discovery or Group Manager is enabled, iDRAC uses mDNS to communicate through port<br>5353. However, when both are disabled, port 5353 is blocked by iDRAC's internal firewall and appears as open|filtered port<br>in the port scans.|**NOTE:** When node initiated discovery or Group Manager is enabled, iDRAC uses mDNS to communicate through port<br>5353. However, when both are disabled, port 5353 is blocked by iDRAC's internal firewall and appears as open|filtered port<br>in the port scans.|**NOTE:** When node initiated discovery or Group Manager is enabled, iDRAC uses mDNS to communicate through port<br>5353. However, when both are disabled, port 5353 is blocked by iDRAC's internal firewall and appears as open|filtered port<br>in the port scans.|**NOTE:** When node initiated discovery or Group Manager is enabled, iDRAC uses mDNS to communicate through port<br>5353. However, when both are disabled, port 5353 is blocked by iDRAC's internal firewall and appears as open|filtered port<br>in the port scans.|**NOTE:** When node initiated discovery or Group Manager is enabled, iDRAC uses mDNS to communicate through port<br>5353. However, when both are disabled, port 5353 is blocked by iDRAC's internal firewall and appears as open|filtered port<br>in the port scans.|
|514|UDP|Remote syslog|Yes|None|



## Other documents you may need

The iDRAC UI interface supports integrated **Online Help** that can be accessed by clicking the **Help & Feedback** tab. The
**Online Help** provides detailed information about the fields available on the web interface and the descriptions for the same.
In addition, the following documents are available on the Dell Support website at **dell.com/support** that provide additional
information about the setup and operation of iDRAC in your system.

- [The iDRAC Redfish API guide. guide provides information about the Redfish API. For further assistance on how to access the](HTTPS://DEVELOPER.DELL.COM/APIS/2978/VERSIONS/7.XX/DOCS/0WHATSNEW.MD)
API guide, see the section Accessing the iDRAC API guide.

- The Integrated Dell Remote Access Controller RACADM CLI Guide provides information about the RACADM subcommands,
supported interfaces, and iDRAC property database groups and object definitions.

- The _Systems Management Overview Guide_ provides brief information about the various software available to perform
systems management tasks.

- The **Dell Remote Access Configuration Tool User’s Guide** provides information about how to use the tool to discover
iDRAC IP addresses in your network and perform one-to-many firmware updates and active directory configurations for the
discovered IP addresses.

- The **Dell Systems Software Support Matrix** provides information about the various Dell systems, the operatingsystems
that are supported by these systems, and the Dell OpenManage components that can be installed on these systems.

- The **iDRAC Service Module User's Guide** provides information to install the iDRAC Service Module.
- The **Dell OpenManage Server Administrator Installation Guide** contains instructions to help you install Dell
OpenManage Server Administrator.

- The **Dell OpenManage Management Station Software Installation Guide** contains instructions to help you install Dell
OpenManage management station software that includes Baseboard Management Utility, DRAC Tools, and Active Directory
Snap-In.

- The **Dell OpenManage Baseboard Management Controller Management Utilities User’s Guide** has information about
the IPMI interface.

- The **Release Notes** provides last-minute updates to the system or documentation or advanced technical reference material
that is intended for experienced users or technicians.

- The **Integrated Dell Remote Access Controller 9 Attribute Registry** provides the details about the groups and objects
in the iDRAC property database.

- [The iDRAC9 white papers provide specific use cases and solutions that are provided by iDRAC9.](https://www.dell.com/support/kbdoc/en-us/000178016/support-for-integrated-dell-remote-access-controller-9-idrac9)

The following system documents are available to provide more information:

- The safety instructions that came with your system provide important safety and regulatory information. For additional
regulatory information, see the Regulatory Compliance home page at **dell.com/regulatory_compliance** . Warranty
information may be included within this document or as a separate document.

- The **Rack Installation Instructions** included with your rack solution describe how to install your system into a rack.
- The _Getting Started Guide_ provides an overview of system features, setting up your system, and technical specifications.
- The _Installation and Service Manual_ provides information about system features and describes how to troubleshoot the
system and install or replace system components.



## Contacting Dell

Dell provides several online and telephone-based support and service options. Availability varies by country or region and
product, and some services may not be available in your area. To contact Dell for sales, technical support, or customer service
[issues, go to Contact Dell.](https://www.dell.com/support/home/en-us)

**NOTE:** If you do not have an active Internet connection, you can find contact information about your purchase invoice,
packing slip, bill, or Dell product catalog.



## Accessing documents from the Dell Support site

Click the following links to access the documents from the Dell Support site:

- [Enterprise Systems Management and OpenManage Connections documents](https://www.dell.com/support/home/en-us/products/software_int/software_ent_systems_mgmt)
- [OpenManage documents](https://www.dell.com/support/home/en-us/products/software_int/software_ent_systems_mgmt)
- [iDRAC and Lifecycle Controller documents](https://www.dell.com/support/home/en-us/products/software_int/software_ent_systems_mgmt/remote_ent_sys_mgmt)
- [Serviceability Tools documents](https://www.dell.com/support/home/en-us/products/software_int/software_service_tools)
- [Client Command Suite Systems Management documents](https://www.dell.com/support/home/en-us/products/software_int/software_client_systems_mgmt)



##### Accessing documents using the product search

1. [Go to the Dell support site.](https://www.dell.com/support)
2. In the **Enter a Service Tag**, **Serial Number...** search box, type the product name. For example, **PowerEdge** or **iDRAC** . A
list of matching products is displayed.
3. Select your product and click the search icon or press enter.
4. Click **DOCUMENTATION** .
5. Click **MANUALS AND DOCUMENTS** .



##### Accessing documents using product selector

You can also access documents by selecting your product.
1. [Go to Dell support.](https://www.dell.com/support)
2. Click **Browse all products** .
3. Click the required product category, such as Servers, Software, Storage, and so on.
4. Click the required product and then click the version if applicable.
**NOTE:** For some products, you may have to navigate through the subcategories.

5. Click **DOCUMENTATION** .
6. Click **MANUALS AND DOCUMENTS** .



## Accessing Redfish API Guide

The Redfish API guide is available on the Dell API Marketplace. To access the Redfish API guide:
1. [Go to developer.dell.com.](https://developer.dell.com)
2. Click **Explore APIs** and search for **iDRAC9 Redfish API** or select **Servers** in the filters.
3. Click **iDRAC9 Redfish API** .



# 2 Logging in to iDRAC

You can log in to iDRAC as an iDRAC user, a Microsoft Active Directory user, or a Lightweight Directory Access Protocol
(LDAP) user. You can also log in using OpenID Connect and Single Sign-On or Smart Card.

To improve security, each system is shipped with a unique password for iDRAC, which is available on the system information
tag. This unique password improves security of iDRAC and your server. The default user name is **root** .

While ordering the system, you can choose to retain the legacy password—calvin—as the default password. If you choose to
retain the legacy password, the password is not available on the system information tag.

In this version, DHCP is enabled by default and iDRAC IP address is assigned dynamically.

**NOTE:**

  - You must have login to iDRAC privilege to log in to iDRAC.
  - iDRAC GUI does not support browser buttons such as **Back**, **Forward**, or **Refresh** .
**NOTE:** For information about recommended characters for user names and passwords, see Recommended characters in
user names and passwords.

To change the default password, see Changing the default login password.



#### Customizable security banner

You can customize the security notice that is displayed on the login page. You can use SSH, RACADM, Redfish, or WSMan to
customize the notice. Depending on the language you use, the notice can be either 1024 or 512 UTF-8 characters long.



#### OpenID Connect

**NOTE:** This feature is only available for MX platforms.

You can log in to iDRAC using credentials of other web consoles such as Dell OpenManage Enterprise (OME) - Modular. When
this feature is enabled, the console starts managing the user permissions on the iDRAC. iDRAC provides the user session with all
the permissions that are specified by the console.

**NOTE:** When lockdown mode is enabled, OpenID Connect login options are not displayed in iDRAC login page.

You can now get access to detailed help without logging in to iDRAC. Use the links on the iDRAC login page to access help and
version information, drivers and downloads, manuals and TechCenter.

**Topics:**

- Force Change of Password (FCP)
- Logging into iDRAC using OpenID Connect
- Logging in to iDRAC as local user, Active Directory user, or LDAP user
- Logging in to iDRAC as a local user using a smart card
- Logging in to iDRAC using Single Sign-On
- Accessing iDRAC using remote RACADM
- Accessing iDRAC using local RACADM
- Accessing iDRAC using firmware RACADM
- Simple 2-Factor Authentication (Simple 2FA)
- RSA SecurID 2FA
- Viewing system health
- Logging in to iDRAC using public key authentication
- Multiple iDRAC sessions
- Secure default password
- Changing the default login password
- Enabling or disabling default password warning message
- Password Strength Policy
- IP Blocking
- Enabling or disabling an operating system to iDRAC Pass-through using web interface
- Enabling or disabling alerts using RACADM



## Force Change of Password (FCP)

The 'Force Change of Password' feature prompts you to change the factory default password of the device. The feature can be
enabled as part of factory configuration.

The FCP screen appears after successful user authentication and cannot be skipped. Only after the user enters a password,
normal access and operation will be allowed. The state of this attribute will not be affected by a 'Reset Configuration to
Defaults' operation.

**NOTE:** To set or reset the FCP attribute, you must have Login privilege and User configuration privilege.

**NOTE:** When FCP is enabled, 'Default Password Warning' setting is disabled after changing the default user password.

**NOTE:** When root user logs in via Public Key Authentication (PKA), FCP is bypassed.

When FCP is enabled, following actions are not allowed:

- Login to iDRAC through any UI except IPMIpover-LAN interface which uses CLI with default user credentials.
- Login to iDRAC through OMM app via Quick Sync-2
- Add a member iDRAC in Group Manager.



## Logging into iDRAC using OpenID Connect

**NOTE:** This feature is only available in MX platforms.

To log in to iDRAC using the OpenID Connect:

1. In a supported web browser, type `https://[iDRAC-IP-address]` and press Enter.
The Login page is displayed.

2. Select **OME Modular** from the **Log In with:** menu.

The console login page is displayed.

3. Enter the console **User name** and **Password** .
4. Click **Log in** .

You are logged in to iDRAC with the console user privileges.

**NOTE:** When lockdown mode is enabled, OpenID Connect login option is not displayed in iDRAC login page.



## Logging in to iDRAC as local user, Active Directory user, or LDAP user

Before you log in to iDRAC using the web interface, ensure that you have configured a supported web browser and the user
account is created with the required privileges.

You can configure the user name, password, and access permissions for a new or existing iDRAC user using **Add / Edit user**
option in iDRAC GUI.

To configure the user, use a unique user name. It should contain 16 characters including whitespace. The following characters
are supported:

- 0-9
- A-Z
- a-z
- Special characters: + % ) > $ [| ! & = * ., - {] # ( ? < ; _ } I ^

When the user name is changed, the new name appears in the Web interface only after the next user login.

**NOTE:** Do not use a space before or after the user name.

Password field can have upto 127 characters. The characters are masked. The following characters are supported:

- 0-9
- A-Z
- a-z
- Special characters: + & ? > - } | . ! ( ', _ [" @ # ) * ; $] / % = < : { I \ `
**NOTE:** To improve security, it is recommended to use complex passwords that have 8 or more characters and include
lower-case alphabets, upper-case alphabets, numbers, and special characters. It is also recommended to regularly change
the passwords, if possible.

**NOTE:** The user name is not case-sensitive for an Active Directory user. The password is case-sensitive for all users.

**NOTE:** In addition to Active Directory, openLDAP, openDS, Novell eDir, and Fedora-based directory services are supported.

**NOTE:** LDAP authentication with OpenDS is supported. The DH key must be larger than 768 bits.

**NOTE:** RSA feature can be configured and enabled for LDAP user, but the RSA does not support if the LDAP is configured
on Microsoft active directory. Hence LDAP user login fails. RSA is supported only for OpenLDAP.

To log in to iDRAC as local user, Active Directory user, or LDAP user:

1. Open a supported web browser.
2. In the **Address** field, type `https://[iDRAC-IP-address]` and press Enter.
**NOTE:** If the default HTTPS port number (port 443) changes, enter: `https://[iDRAC-IP-address]:[port-`

`number]` where `[iDRAC-IP-address]` is the iDRAC IPv4 or IPv6 address and `[port-number]` is the HTTPS port

number.

The **Login** page is displayed.

3. For a local user:
  - In the **Username** and **Password** fields, enter your iDRAC user name and password.
  - From the **Domain** drop-down menu, select **This iDRAC** .
4. For an Active Directory user, in the **User name** and **Password** fields, enter the Active Directory user name and password. If
you have specified the domain name as a part of the username, select **This iDRAC** from the drop-down menu. The format of
the user name can be: <domain>\<username>, <domain>/<username>, or <user>@<domain>.

For example, dell.com\john_doe, or JOHN_DOE@DELL.COM.

Active Directory domain from the **Domain** drop-down menu displays the last used domain.

5. For an LDAP user, in the **Username** and **Password** fields, enter your LDAP user name and password. Domain name is not
required for LDAP login. By default, **This iDRAC** is selected in the drop-down menu.

6. Click **Submit** . You are logged in to iDRAC with the required user privileges.

If you log in with Configure Users privileges and the default account credentials, and if the default password warning feature
is enabled, the **Default Password Warning** page is displayed allowing you to easily change the password.



## Logging in to iDRAC as a local user using a smart card

Before you log in as a local user using Smart Card, make sure to:

- Upload user smart card certificate and the trusted Certificate Authority (CA) certificate to iDRAC.
- Enable smart card logon.

The iDRAC web interface displays the smart card logon page for users who are configured to use the smart card.

To log in to iDRAC as a local user using a smart card:

1. Access the iDRAC web interface using the link `https://[IP address]` .

The **iDRAC Login** page is displayed prompting you to insert the smart card.

**NOTE:** If the default HTTPS port number (port 443) changes, type: `https://[IP address]:[port number]`

where, `[IP address]` is the IP address for the iDRAC and `[port number]` is the HTTPS port number.

2. Insert the smart card into the reader and click **Login** .

A prompt is displayed for the smart card’s PIN. A password is not required.

3. Enter the Smart Card PIN for local smart card users.

You are logged in to the iDRAC.

**NOTE:** If you are a local user for whom **Enable CRL check for Smart Card Logon** is enabled, iDRAC attempts
to download the certificate revocation list (CRL) and checks the CRL for the user's certificate. The login fails if the
certificate is listed as revoked in the CRL or if the CRL cannot be downloaded for some reason.

**NOTE:** If you log in to iDRAC using smart card when RSA is enabled, RSA token is bypassed and you can login directly.



### Logging in to iDRAC as an Active Directory user using a smart card

Before you log in as an Active Directory user using smart card, ensure that you:

- Upload a Trusted Certificate Authority (CA) certificate (CA-signed Active Directory certificate) to iDRAC.
- Configure the DNS server.
- Enable Active Directory login.
- Enable smart card login.

To log in to iDRAC as an Active Directory user using smart card:

1. Log in to iDRAC using the link `https://[IP address]` .

The **iDRAC Login** page is displayed prompting you to insert the smart card.

**NOTE:** If the default HTTPS port number (port 443) is changed, type: `https://[IP address]:[port number]`

where, `[IP address]` is the iDRAC IP address and `[port number]` is the HTTPS port number.

2. Insert the smart card and click **Login** .

A prompt is displayed for the smart card's **PIN** .

3. Enter the PIN and click **Submit** .

You are logged in to iDRAC with your Active Directory credentials.

**NOTE:** If the smart card user is present in Active Directory, an Active Directory password is not required.

**NOTE:** For client workstations that are part of the Active Directory domain, smart card usage restricts the certificate
chain depth to 10. However, use of smart card on non-domain client workstations are not limited to any depth of the
client certificate chains.



## Logging in to iDRAC using Single Sign-On

When Single Sign-On (SSO) is enabled, you can log in to iDRAC without entering your domain user authentication credentials,
such as user name and password.

**NOTE:** When AD user configures SSO while RSA is enabled, the RSA token is bypassed and user logs in directly.



### Logging in to iDRAC SSO using iDRAC web interface

Before logging in to iDRAC using Single Sign-On, ensure that:

- You have logged in to your system using a valid Active Directory user account.
- Single Sign-On option is enabled during Active Directory configuration.

To log in to iDRAC using web interface:

1. Log in to your management station using a valid Active Directory account.
2. In a web browser, type `https://[FQDN address]` .
**NOTE:** If the default HTTPS port number (port 443) has been changed, type: `https://[FQDN address]:[port`

`number]` where `[FQDN address]` is the iDRAC FQDN (iDRACdnsname.domain. name) and `[port number]` is the

HTTPS port number.

**NOTE:** If you use IP address instead of FQDN, SSO fails.

iDRAC logs you in with appropriate Microsoft Active Directory privileges, using your credentials that were cached in the
operating system when you logged in using a valid Active Directory account.



### Logging in to iDRAC SSO using CMC web interface

Using the SSO feature, users with CMC user privileges can launch the iDRAC web interface from the CMC web interface. If the
user account is present in CMC and not in iDRAC, the user can still launch iDRAC from CMC.

**NOTE:** This feature is not available on MX platforms.

If iDRAC network LAN is disabled (LAN Enabled = No), SSO is not available.

If the server is removed from the chassis, iDRAC IP address is changed, or there is a problem in iDRAC network connection, the
option to Launch iDRAC is grayed-out in the CMC web interface.

For more information, see the _Chassis Management Controller User's Guide_ [available on the CMC manuals page..](https://www.dell.com/cmcmanuals)



## Accessing iDRAC using remote RACADM

You can use remote RACADM to access iDRAC using RACADM utility.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

If the management station has not stored the iDRAC SSL certificate in its default certificate storage, a warning message is
displayed when you run the RACADM command. However, the command is performed successfully.

**NOTE:** The iDRAC certificate is the certificate iDRAC sends to the RACADM client to establish the secure session. This
certificate is either issued by a CA or self-signed. In either case, if the management station does not recognize the CA or
signing authority, a warning is displayed.



### Validating CA certificate to use remote RACADM on Linux

Before running remote RACADM commands, validate the CA certificate that is used for secure communications.

To validate the certificate for using remote RACADM:

1. Convert the certificate in DER format to PEM format (using openssl command-line tool):

```
  openssl x509 -inform pem -in [yourdownloadedderformatcert.crt] –outform pem -out
  [outcertfileinpemformat.pem] –text

```

2. Find the location of the default CA certificate bundle on the management station. For example, for RHEL5 64 bit, it
is **/etc/pki/tls/cert.pem** .

3. Append the PEM formatted CA certificate to the management station CA certificate.

For example, use the `cat command: cat testcacert.pem >> cert.pem`

4. Generate and upload the server certificate to iDRAC.



## Accessing iDRAC using local RACADM

[For information to access iDRAC using local RACADM, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Accessing iDRAC using firmware RACADM

You can use SSH interface to access iDRAC and run firmware RACADM commands. For more information, see the Integrated
Dell Remote Access Controller RACADM CLI Guide.



## Simple 2-Factor Authentication (Simple 2FA)

iDRAC offers simple 2-factor authentication option to enhance the security to the local users for logging in. When you log in
from a source IP-address which is different from the last login, you will be prompted to enter the second factor authentication
details.

At any given point of time, only one source IP address is remembered for login, irrespective of the time interval.

Simple two factor authentication has two steps of authentication:

- iDRAC User name and password
- Simple 6 digit code which is sent to the user via email. User needs to enter this 6 digit code when prompted at login.

From 6.00.02.00 release onwards, Timeout can be set that makes it necessary for a 2FA user to authenticate periodically
regardless of the IP change. User can set the timeout range.

**NOTE:**

  - To receive 6 digit code, it is mandatory to configure 'Custom Sender Address' and have valid SMTP configuration.
  - The 2FA code expires after configured interval of time or is invalidated if it is already consumed before expiry.
  - If a user attempts to login from another location with a different IP-Address while a pending 2FA challenge for the
original IP-Address is still outstanding, the same token will be sent for login attempt from the new IP address.

  - The feature is supported with iDRAC Enterprise or Datacenter license.

When 2FA is enabled, following actions are not allowed:

- Login to iDRAC through any UI which uses CLI with default user credentials.
- Login to iDRAC through OMM app via Quick Sync-2
- Add a member iDRAC in Group Manager.
**NOTE:** Racadm, Redfish, WSMAN, IPMI LAN, Serial, CLI from a source IP works only after successful login from supported
interfaces like iDRAC GUI and SSH.



## RSA SecurID 2FA

iDRAC can be configured to authenticate with a single RSA AM server at a time. The global settings on RSA AM server apply to
all iDRAC local users, AD, and LDAP users.

**NOTE:** RSA SecurID 2FA feature is available only on Datacenter license.

Following are the pre-requisites before you configure iDRAC to enable RSA SecurID:

- Configure Microsoft Active Directory server.
- If you try to enable RSA SecurID on all AD users, add the AD server to the RSA AM server as an Identity Source.
- Ensure you have a generic LDAP server.
- For all LDAP users, the Identity Source to the LDAP server must be added in RSA AM server.

To enable RSA SecurID on iDRAC, the following attributes from the RSA AM server are required:

1. **RSA Authentication API URL** - The URL syntax is: `https://<rsa-am-server-hostname>:<port>/mfa/v1_1`,
and by default the port is 5555.
2. **RSA Client-ID** - By default, the RSA client ID is the same as the RSA AM server hostname. Find the RSA client ID at RSA
AM server's authentication agent configuration page.

3. **RSA Access Key** - The Access Key can be retreived on RSA AM by navigating to **Setup**
  - **System Settings**   - **RSA SecurID**   - **Authentication API** section, which is usually displayed as
`l98cv5x195fdi86u43jw0q069byt0x37umlfwxc2gnp4s0xk11ve2lffum4s8302` . To configure the settings through
iDRAC GUI:

  - Go to **iDRAC Settings**  - **Users** .
  - From **Local Users** section, select an existing local user and click **Edit** .
  - Scroll down to the bottom of the Configuration page.
  - In **RSA SecurID** section, Click the link **RSA SecurID Configuration** to view or edit these settings.
You can also configure the settings as follows:

  - Go to **iDRAC Settings**  - **Users** .
  - From **Directory Services** section, select **Microsoft Active Service** or **Generic LDAP Directory Service**, and click
**Edit** .

  - In **RSA SecurID** section, Click the link **RSA SecurID Configuration** to view or edit these settings.
4. **RSA AM server certificate (chain)**

You can login to iDRAC using RSA SecurID token via iDRAC GUI and SSH.



##### RSA SecurID Token App

You need to install RSA SecurID Token app on you system or on smart phone. When you try to log in to iDRAC, you are asked to
input the passcode shown in the app.

If a wrong passcode is entered, the RSA AM server challenges the user to provide the "Next Token." This may happen even
though the user may have entered the correct passcode. This entry proves that the user owns the right Token that generates
the right passcode.

You get the **Next Token** from RSA SecurID Token app by clicking on **Options** . Check **Next Token**, and the next passcode
is available. Time is critical in this step. Otherwise, iDRAC may fail the verification of the next token. If the iDRAC user login
session times out, it requires another attempt to log in

If a wrong passcode is entered, the RSA AM server will challenge the user to provide the "Next Token." This challenge happens
even though the user may have later entered the correct passcode. This entry proves that the user owns the right Token that
generates the right passcodes.

To get the next token from RSA SecurID Token app, click on **Options** and check **Next Token** . A new token is generated. Time
is critical in this step. Otherwise, iDRAC may fail the verification of the next token. If the iDRAC user login session times out, it
requires another attempt to log in.



## Viewing system health

Before you perform a task or trigger an event, you can use RACADM to check if the system is in a suitable state. To view the
remote service status from RACADM, use the `getremoteservicesstatus` command.

**NOTE:** The Real Time Status is displayed as **Not Applicable** if there are no real time capable controllers present on the
system.

**Table 7. Possible values for system status**

|Host System|Lifecycle Controller (LC)|Real Time Status|Overall Status|
|---|---|---|---|
|●<br>Powered Off<br>●<br>In POST<br>●<br>Out of POST<br>●<br>Collecting System<br>Inventory<br>●<br>Automated Task Execution<br>●<br>Lifecycle Controller<br>Unified Server<br>Configurator<br>●<br>Server has halted at F1/F2<br>error prompt because of a<br>POST error|●<br>Ready<br>●<br>Not Initialized<br>●<br>Reloading data<br>●<br>Disabled<br>●<br>In Recovery<br>●<br>In Use|●<br>Ready<br>●<br>Not Ready<br>●<br>Not Applicable|●<br>Ready<br>●<br>Not Ready|
|●<br>Server has halted at<br>F1/F2/F11 prompt because<br>there are no bootable<br>devices available<br>●<br>Server has entered F2<br>setup menu<br>●<br>Server has entered F11<br>Boot Manager menu||||
|1.<br>Read/Write: Read Only<br>2. User Privilege: Login User<br>3. License Required: iDRAC Express or iDRAC Enterprise<br>4. Dependency: None|1.<br>Read/Write: Read Only<br>2. User Privilege: Login User<br>3. License Required: iDRAC Express or iDRAC Enterprise<br>4. Dependency: None|1.<br>Read/Write: Read Only<br>2. User Privilege: Login User<br>3. License Required: iDRAC Express or iDRAC Enterprise<br>4. Dependency: None|1.<br>Read/Write: Read Only<br>2. User Privilege: Login User<br>3. License Required: iDRAC Express or iDRAC Enterprise<br>4. Dependency: None|



## Logging in to iDRAC using public key authentication

You can log in to the iDRAC over SSH without entering a password. You can also send a single RACADM command as a
command line argument to the SSH application. The command line options behave like remote RACADM since the session ends
after the command is completed.

For example:

**Logging in:**

```
 ssh username@<domain>

```

or

```
 ssh username@<IP_address>

```

where `IP_address` is the IP address of the iDRAC.

**Sending RACADM commands:**

```
 ssh username@<domain> racadm getversion

 ssh username@<domain> racadm getsel



## Multiple iDRAC sessions

```

The following table provides the number of iDRAC sessions that are possible using the various interfaces.



## Table 8. Multiple iDRAC sessions

|Interface|Number of Sessions|
|---|---|
|iDRAC Web Interface|8|
|Remote RACADM|4|
|Firmware RACADM|SSH - 4, Serial - 1|

iDRAC allows multiple sessions for the same user. After a user has created the maximum number of allowed sessions, other
users cannot log in to the iDRAC. This can cause a **Denial of Service** for a legitimate administrator user.

In case of session exhaustion, perform the following remedies:

- If webserver-based sessions are exhausted, you can still login via SSH or local RACADM.
- An administrator can then terminate existing sessions using racadm commands ( `racadm getssninfo` ; `racadm`
`closessn -i <index>` ).



## Secure default password

All supported systems are shipped with a unique default password for iDRAC, unless you choose to set **calvin** as the password
while ordering the system. The unique password helps improve the security of iDRAC and your server. To further enhance
security, it is recommended that you change the default password.

The unique password for your system is available on the system information tag. To locate the tag, see the documentation for
[your server at Dell Support page.](https://www.dell.com/support)

**NOTE:** For PowerEdge C6420, M640, and FC640, the default password is **calvin** .

**NOTE:** Resetting iDRAC to the factory default settings reverts the default password to the one that the server was
shipped with.

If you have forgotten the password and do not have access to the system information tag, there are a few methods to reset the
password locally or remotely.



### Resetting default iDRAC password locally

If you have physical access to the system, you can reset the password using the following:

- iDRAC Setting utility (System Setup)
- Local RACADM
- OpenManage Mobile
- Server management USB port
- USB-NIC



#### Resetting default password using the iDRAC Settings utility

You can access the iDRAC settings utility using the System Setup of your server. Using the iDRAC reset to defaults all feature,
you can reset the iDRAC login credentials to default.

**WARNING: Resetting iDRAC to default all, resets the iDRAC to the factory defaults.**

To reset iDRAC using iDRAC Settings utility:

1. Reboot the server and press <F2>.
2. In the **System Setup** page, click **iDRAC Settings** .
3. Click **Reset iDRAC configurations to defaults all** .
4. Click **Yes** to confirm, and then click **Back** .
5. Click **Finish** .

The server restarts after all iDRAC settings are set to default settings.



#### Resetting default password using local RACADM

1. Log in to the host OS installed on the system.
2. Access the local RACADM interface.
3. Follow the instructions in Changing the default login password using RACADM.



#### Resetting default password using OpenManage Mobile

You can use the OpenManage Mobile (OMM) to log in and change the default password. To log in to iDRAC using OMM, scan
the QR code on the system information tag. For more information about using OMM, see the OMM documentation at _Dell_
_OpenManage Enterprise-Modular for PowerEdge MX7000 Chassis User's Guide_ [available on the OpenManage manuals page.](https://www.dell.com/openmanagemanuals)

**NOTE:** Scanning the QR code logs you into iDRAC only if the default credentials are at default values. If you have changed
them from the default values, enter the updated credentials.



#### Resetting default password using the server management USB port

**NOTE:** These steps require that the USB management port is enabled and configured.

Using Server Configuration Profile file

Create a Server Configuration Profile (SCP) file with a new password for the default account, place it on a memory key, and use
the server management USB port on the server to upload the SCP file. For more information on creating the file, see Using USB
port for server management.

Accessing iDRAC using a laptop

Connect a laptop to the server management USB port and access iDRAC to change the password. For more information, see
Accessing iDRAC interface over direct USB connection.



#### Changing default password using USB-NIC

If you have access to a keyboard, mouse, and a display device, connect to the server using the USB-NIC to access the iDRAC
interface and change the default password.

1. Connect the devices to the system.
2. Use a supported browser to access the iDRAC interface using the iDRAC IP.
3. Follow the instructions in Changing the default login password using web interface.



### Resetting default iDRAC password remotely

If you do not have physical access to the system, you can reset the default password remotely.



#### Remote — Provisioned system

If you have an operating system installed on the system, use a remote desktop client to log in to the server. After you log into
the server, use any of the local interfaces such as RACADM or web interface to change the password.



#### Remote — Non-provisioned system

If there is no operating system installed on the server and if you have a PXE setup available, use PXE and then use RACADM to
reset the password.



## Changing the default login password

The warning message that allows you to change the default password is displayed if:

- You log in to iDRAC with Configure User privilege.
- The default password warning feature is enabled.
- The default iDRAC user name and password are provided on the system information tag.

A warning message is also displayed when you log in to iDRAC using SSH, remote RACADM, or the Web interface. For Web
interface and SSH, a single warning message is displayed for each session. For remote RACADM, the warning message is
displayed for each command.

**NOTE:** For information on recommended characters for user names and passwords, see Recommended characters in user
names and passwords.



### Changing the default login password using web interface

When you log in to the iDRAC web interface, if the **Default Password Warning** page is displayed, you can change the
password. To do this:

1. Select the **Change Default Password** option.
2. In the **New Password** field, enter the new password.
**NOTE:** For information on recommended characters for user names and passwords, see Recommended characters in
user names and passwords.

3. In the **Confirm Password** field, enter the password again.
4. Click **Continue** .

The new password is configured and you are logged in to iDRAC.

**NOTE:** **Continue** is enabled only if the passwords entered in the **New Password** and **Confirm Password** fields match.

For information about the other fields, see the **iDRAC Online Help** .



### Changing the default login password using RACADM

To change the password, run the following RACADM command:

```
 racadm set iDRAC.Users.<index>.Password <Password>

```

where, `<index>` is a value from 1 to 16 (indicates the user account) and `<password>` is the new user defined password.

**NOTE:** The index for the default account is 2.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

**NOTE:** For information on recommended characters for user names and passwords, see Recommended characters in user
names and passwords.



### Changing the default login password using iDRAC settings utility

To change the default login password using iDRAC settings utility:

1. In the iDRAC Settings utility, go to **User Configuration** .
The **iDRAC Settings User Configuration** page is displayed.

2. In the **Change Password** field, enter the new password.
**NOTE:** For information on recommended characters for user names and passwords, see Recommended characters in
user names and passwords.

3. Click **Back**, click **Finish**, and then click **Yes** .

The details are saved.



## Enabling or disabling default password warning message

You can enable or disable the display of the default password warning message. To do this, you must have Configure Users
privilege.



## Password Strength Policy

Using iDRAC interface, you can check the password strength policy and check any errors if the policy is not met. The password
policy cannot be applied to previously saved passwords, Server Configuration Profiles (SCP) copied from other servers, and
embedded passwords in the profile.

In iDRAC9 releases 4.40.00.00 and later, iDRAC offers two password policy options:

- **`Simple Policy`** - Simple Policy is based on LUDS, i.e., lower- and uppercase letters, digits, and symbols.
- **Regular Expression** [— Regular Expression Password Policy Enforcement is a based on the POSIX definition.](https://en.wikibooks.org/wiki/REGULAR_EXPRESSIONS/POSIX_BASIC_REGULAR_EXPRESSIONS)

To access Password settings, go to **iDRAC Settings** - **Users** - **Password Settings** .

Following fields are available in this section:

- **Minimum Score** - Specifies the minimum password strength policy score. The values in this field are:
  - 0 — No protection
  - 1 — Weak protection
  - 2 — Medium protection
  - 3 — Strong protection
Scoring is based on zxcvbn's entropy value and map to the following values:

  - 0 - No Protection; too easy to guess: risky password
  - 1 - Weak Protection; very easy to guess: protection from throttled online attacks
  - 2 - Moderate Protection; somewhat able to guess: protection from un-throttled online attacks
  - 3 - Strong Protection; safely to very not able to guess: moderate protection from offline slow-hash scenario
- **Simple Policy** - Specifies the required characters in a secure password. It has the following options:
  - Upper Case Letters
  - Numbers
  - Symbols
  - Minimum Length
- **Regular Expression** - The Regular expression along with the Minimum score is used for password enforcement.



## IP Blocking

Use IP blocking to dynamically determine when excessive login failures occur from an IP address and block or prevent the IP
address from logging into the iDRAC for a preselected time span.

IP blocking includes the following:

- The number of allowable login failures.
- The timeframe in seconds when these failures must occur.
- The amount of time, in seconds, when the IP address is prevented from establishing a session after the total allowable
number of failures is exceeded.

As consecutive login failures accumulate from a specific IP address, they are tracked by an internal counter. When the user logs
in successfully, the failure history is cleared and the internal counter is reset.

**NOTE:**

  - When consecutive login attempts are refused from the client IP address, some SSH clients may display the following
message:

```
    ssh exchange identification: Connection closed by remote host

```

  - IP blocking feature supports upto five IP ranges. You can view and set these IPs only through RACADM
  - The IP Filtering and IP Blocking features support only IPv4 addresses. IPv6 addresses and ranges are not supported for
these features.

.

**Table 9. Login Retry Restriction Properties**

|Property|Definition|
|---|---|
|`iDRAC.IPBlocking.BlockEnable`|Enables the IP blocking feature. When consecutive failures<br>`iDRAC.IPBlocking.FailCount`<br>from a single IP address are encountered within a specific<br>amount of time<br>`iDRAC.IPBlocking.FailWindow`<br>all further attempts to establish a session from that address are<br>rejected for a certain timespan<br>`iDRAC.IPBlocking.PenaltyTime`|
|`iDRAC.IPBlocking.FailCount`|Sets the number of login failures from an IP address before the<br>login attempts are rejected.|
|`iDRAC.IPBlocking.FailWindow`|The time, in seconds during which the failed attempts are<br>counted. When the failures occur beyond this time period, the<br>counter gets reset.|
|`iDRAC.IPBlocking.PenaltyTime`|Defines the timespan in seconds when all login attempts from<br>an IP address with excessive failures are rejected.|



### Enabling or disabling an operating system to iDRAC Pass-through using web interface

To enable operating system to iDRAC Pass-through using web interface:

1. Go to **iDRAC Settings** - **Connectivity** - **Network** - **OS to iDRAC Pass-through** .
The **OS to iDRAC Pass-through** page is displayed.

2. Change the **State** to **Enabled** .
3. Select any of the following options for Pass-through Mode:
  - **LOM** —The operating system to iDRAC pass-through link between the iDRAC and the host operating system is
established through the LOM or NDC.

  - **USB NIC** —The operating system to iDRAC pass-through link between the iDRAC and the host operating system is
established through the internal USB bus.

**NOTE:** If you set the pass-through mode to LOM, ensure that:

   - The operating system and iDRAC are on the same subnet.
   - NIC selection in Network Settings is set to LOM.
4. If the server is connected in shared LOM mode, then the **OS IP Address** field is disabled.
**NOTE:** If the VLAN is enabled on the iDRAC, the LOM-Passthrough functions only in shared LOM mode with VLAN
taggings that are configured on the host.

**NOTE:**

   - When Pass-through mode is set to LOM, it is not possible to launch iDRAC from the host operating system after cold
boot.

   - The LOM Pass-through is removed using the Dedicated Mode feature.
5. If you select **USB NIC** as the pass-through configuration, enter the IP address of the USB NIC.

The default value is 169.254.1.1. It is recommended to use the default IP address. However, if this IP address conflicts with
an IP address of other interfaces of the host system or the local network, you must change it.

Do not enter 169.254.0.3 and 169.254.0.4 IPs. These IPs are reserved for the USB NIC port on the front panel when an A/A
cable is used.

**NOTE:** If IPv6 is preferred, the default address is fde1:53ba:e9a0:de11::1. If needed, this address can be modified in the
idrac.OS-BMC.UsbNicULA setting. If IPv6 is not wanted on the USB-NIC, it can be disabled by changing the address to
"::"

**NOTE:** When you modify the static IP address of the USB NIC, it automatically adjusts the DHCP address range to align
with the new static IP. For instance, if you set the static IP to 169.250.1.1, the DHCP address updates to 169.250.1.2.
This change is compatible with the network manager, Wicked, which accepts the new DHCP address.

**NOTE:** When the USB NIC is enabled, iDRAC can be accessed using the name idrac.local from either Windows or Linux
[operating system. In Linux, for iDRAC local to work, the avahi, nss-mdns, and dependent packages must be installed.](HTTPS://IDRAC.LOCAL/)

6. Click **Apply** .
7. Click **Test Network Configuration** to check if the IP is accessible and the link is established between the iDRAC and the
host operating system.



### Enabling or disabling alerts using RACADM

Use the following command:

```
 racadm set iDRAC.IPMILan.AlertEnable <n>

```

n=0 — Disabled

n=1 — Enabled



# 3 Setting up managed system

If you need to run local RACADM or enable Last Crash Screen capture, install the following from the **Dell Systems**
**Management Tools and Documentation** DVD:

- Local RACADM
- Server Administrator

For more information about Server Administrator, see _OpenManage Server Administrator User's Guide_ available on the
[OpenManage manuals page.](https://www.dell.com/openmanagemanuals)

**NOTE:** For any update requiring iDRAC reset/ reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is
fully ready by waiting for few seconds of interval with maximum timeout of 5 minutes before using any other command.

**Topics:**

- Setting up iDRAC IP address
- Modifying local administrator account settings
- Setting up managed system location
- Optimizing system performance and power consumption
- Setting up management station
- Configuring supported web browsers
- Firmware updates
- Viewing and managing staged updates
- Rolling back device firmware
- Easy Restore
- Monitoring iDRAC using other Systems Management tools
- Support Server Configuration Profile — Import and Export
- Secure Boot Configuration from BIOS Settings or F2
- BIOS recovery



## Setting up iDRAC IP address

You must configure the initial network settings based on your network infrastructure to enable the communication to and from
iDRAC. You can set up the IP address using one of the following interfaces:

- iDRAC Settings utility
- Lifecycle Controller (see _Dell Lifecycle Controller User's Guide_ )
- Chassis or Server LCD panel (see the system’s _Installation and Service Manual_ )
**NOTE:** On blade servers, you can configure the network settings using the chassis LCD panel only during the initial CMC
configuration. You cannot reconfigure iDRAC using the Chassis LCD panel after the chassis is deployed.

- CMC Web interface (not applicable for MX platforms) (see _Chassis Management Controller User's Guide_ )

In case of rack and tower servers, you can set up the IP address or use the default iDRAC IP address 192.168.0.120 to configure
initial network settings, including setting up DHCP or the static IP for iDRAC.

In case of blade servers, the iDRAC network interface is disabled by default.

After you configure iDRAC IP address:

- Ensure that you change the default user name and password.
- Access iDRAC through any of the following interfaces:
  - iDRAC Web interface using a supported browser (Internet Explorer, Firefox, Chrome, or Safari)
  - Secure Shell (SSH) — Requires a client such as PuTTY on Windows. SSH is available by default in most of the Linux
systems and hence does not require a client.

  - IPMITool (uses IPMI command) or shell prompt (requires Dell customized installer in Windows or Linux, available from
**Systems Management Documentation and Tools** [DVD or Dell Support page)](https://www.dell.com/support)



### Setting up iDRAC IP using iDRAC settings utility

To set up the iDRAC IP address:

1. Turn on the managed system.
2. Press <F2> during Power-on Self-test (POST).
3. In the **System Setup Main Menu** page, click **iDRAC Settings** .

The **iDRAC Settings** page is displayed.

4. Click **Network** .

The **Network** page is displayed.

5. Specify the following settings:
  - Network Settings
  - Common Settings
  - IPv4 Settings
  - IPv6 Settings
  - IPMI Settings
  - VLAN Settings
6. Click **Back**, click **Finish**, and then click **Yes** .

The network information is saved and the system reboots.



#### Configuring the network settings

To configure the network settings:

**NOTE:** For information about the options, see the **iDRAC Settings Utility Online Help** .

**NOTE:** While configuring network settings, **Use DHCP to Obtain DNS Server Addresses**, **Use DHCPv6 to Obtain**
**DNS Server Addresses**, and **Auto Config Domain Name** options are enabled by default after updating iDRAC to release
version 6.00.00.00. Also **DNS Domain Name** gets DHCP Domain name and older static domain name gets ignored after
updating to version 6.00.00.00.

1. Under **Enable NIC**, select **Enabled** .
2. From the **NIC Selection** drop-down menu, select one of the following ports based on the network requirement:
**NOTE:** This option is not available in MX platforms.

  - **Dedicated** —Enables the remote access device to use the dedicated network interface available on the Remote Access
Controller (RAC). This interface is not shared with the host operating system and routes the management traffic to a
separate physical network, enabling it to be separated from the application traffic.

**NOTE:** This option implies that iDRAC's dedicated network port routes its traffic separately from the server's LOM
or NIC ports. The Dedicated option allows iDRAC to be assigned an IP address from the same subnet or different
subnet in comparison to the IP addresses assigned to the Host LOM or NICs to manage the network traffic.

**NOTE:** In blade servers, the Dedicated option is displayed as **Chassis (Dedicated)** .

  - **LOM1**
  - **LOM2**
  - **LOM3**
  - **LOM4**
**NOTE:** In the case of rack and tower servers, two LOM options (LOM1 and LOM2) or all four LOM options are available
depending on the server model. In blade servers with two NDC ports, two LOM options (LOM1 and LOM2) are available
and on servers with four NDC ports, all four LOM options are available.

**NOTE:** Shared LOM is not supported on the **Intel 2P X520–k bNDC 10 G** if they are used in a full-height server with
two NDCs because they do not support hardware arbitration.

3. From the **NIC Selection** drop-down menu, select the port from which you want to access the system remotely, following
are the options:

**NOTE:** This feature is not available in MX platforms.

**NOTE:** You can select either the dedicated network interface card or from a list of LOMs available in the Quad port or
Dual port mezzanine cards.

  - **Chassis (Dedicated)** : Enables the remote access device to use the dedicated network interface available on the
Remote Access Controller (RAC). This interface is not shared with the host operating system and routes the
management traffic to a separate physical network, enabling it to be separated from the application traffic.

**NOTE:** This option implies that iDRAC's dedicated network port routes its traffic separately from the server's LOM
or NIC ports. The Dedicated option allows iDRAC to be assigned an IP address from the same subnet or different
subnet in comparison to the IP addresses assigned to the Host LOM or NICs to manage the network traffic.

  - **For Quad port cards—LOM1-LOM16**
  - **For Dual port cards—LOM1, LOM2, LOM5, LOM6, LOM9, LOM10, LOM13, LOM14.**
4. From the **Failover Network** list select one of the remaining LOMs. If a network fails, the traffic is routed through the
failover network.

For example, to route the iDRAC network traffic through LOM2 when LOM1 is down, select **LOM1** for **NIC Selection** and
**LOM2** for **Failover Network** .

**NOTE:** This option is disabled if **NIC Selection** is set to **Dedicated** .

**NOTE:** When using the **Failover network** settings, it is recommended that all the LOM ports to be connected to the
same network.

For more details, see the section Modifying network settings using web interface.

5. Under **Auto** **Negotiation**, select **On** if iDRAC must automatically set the duplex mode and network speed.

This option is available only for dedicated mode. If enabled, iDRAC sets the network speed to 10, 100, or 1000 Mbps based on
the network speed.

6. Under **Network** **Speed**, select either 10 Mbps or 100 Mbps.
**NOTE:** You cannot manually set the Network Speed to 1000 Mbps. This option is available only if **Auto Negotiation**
option is enabled.

7. Under **Duplex Mode**, select **Half Duplex** or **Full Duplex** option.
**NOTE:** This option is disabled if **Auto Negotiation** is set to **Enabled** .

**NOTE:** If network teaming is configured for the host OS using the same network adapter as NIC Selection, then
the Failover Network should also be configured. NIC Selection and Failover Network should use the ports that are
configured as a part of the network team. If more than two ports are used as part of the network team, then the
Failover Network selection should be **All** .

8. Under **NIC MTU**, enter the Maximum Transmission Unit size on the NIC.
**NOTE:** The default and maximum limit for MTU on NIC is 1500, and the minimum value is 576. An MTU value of 1280 or
greater is required if IPv6 is enabled.



#### Common settings

If network infrastructure has DNS server, register iDRAC on the DNS. These are the initial settings requirements for advanced
features such as Directory services—Active Directory or LDAP, Single Sign On, and smart card.

To register iDRAC:

1. Enable **Register DRAC on DNS** .
2. Enter the **DNS DRAC Name** .
3. Select **Auto Config Domain Name** to automatically acquire domain name from DHCP. Else, provide the **DNS Domain**
**Name** .

For **DNS iDRAC Name** field, the default name format is **idrac-Service_Tag**, where Service_Tag is the service tag of the
server. The maximum length is 63 characters and the following characters are supported:

  - A-Z
  - a-z
  - 0-9
  - Hyphen (-)



#### Configuring the IPv4 settings

To configure the IPv4 settings:

1. Select **Enabled** option under **Enable IPv4** .
**NOTE:** In the 14th generation of the PowerEdge servers, DHCP is enabled by default.

2. Select **Enabled** option under **Enable DHCP**, so that DHCP can automatically assign the IP address, gateway, and subnet
mask to iDRAC. Else, select **Disabled** and enter the values for:

  - Static IP Address
  - Static Gateway
  - Static Subnet Mask
3. **Use DHCP to Obtain DNS Server Addresses**, **Use DHCPv6 to Obtain DNS Server Addresses**, and **Auto Config**
**Domain Name** options are enabled by default after updating iDRAC to release version 6.00.00.00. Also **DNS Domain Name**
gets DHCP Domain name and older static domain name gets ignored after updating to version 6.00.00.00.



#### Configuring the IPv6 settings

Based on the infrastructure setup, you can use IPv6 address protocol.

To configure the IPv6 settings:

**NOTE:** If IPv6 is set to static, ensure that you configure the IPv6 gateway manually, which is not needed in case of dynamic
IPV6. Failing to configure manually in case of static IPv6 results in loss of communication.

1. Select **Enabled** option under **Enable IPv6** .
2. For the DHCPv6 server to automatically assign the IP address and prefix length to iDRAC, select the **Enabled** option under
**Enable Auto-configuration** .

**NOTE:** You can configure both static IP and DHCP IP at the same time.

3. In the **Static IP Address 1** box, enter the static IPv6 address.
4. In the **Static Prefix Length** box, enter a value between 1 and 128.
5. In the **Static Gateway** box, enter the gateway address.
**NOTE:** If you configure static IP, the current IP address 1 displays static IP and the IP address 2 displays dynamic IP. If
you clear the static IP settings, the current IP address 1 displays dynamic IP.

6. **Use DHCP to Obtain DNS Server Addresses**, **Use DHCPv6 to Obtain DNS Server Addresses**, and **Auto Config**
**Domain Name** options are enabled by default after updating iDRAC to release version 6.00.00.00. Also **DNS Domain Name**
gets DHCP Domain name and older static domain name gets ignored after updating to version 6.00.00.00. You can configure
the following if required:

  - In the **Static Preferred DNS Server** box, enter the static DNS server IPv6 address.
  - In the **Static Alternate DNS Server** box, enter the static alternate DNS server.
7. When DNS information is not obtainable by either DHCPv6 or static configuration, you can use RFC 8106 "IPv6 Router
Advertisement Options for DNS Configuration. It is identified by IPv6 Router. Using RA DNS configuration does not impact
existing DNS configurations (either DHCPv6 or static).

  - The iDRAC can obtain DNS name server and DNS search domain information from IPv6 Router Advertisement messages.
Please refer to RFC 8106 and your IPv6 router's user guide for details on how to configure the router to advertise this
information.

  - If DNS information is available from both the DHCPv6 server and the IPv6 Router Advertisement, the iDRAC uses both.
In case of conflict, the DHCPv6 server's DNS information takes precedence in the iDRAC's /etc/resolv.conf settings.

**NOTE:** For iDRAC to use RA DNS information, IPv6.Enable and IPv6.Autoconfig must be enabled. If Auto-configuration
is disabled, the iDRAC does not process IPv6 RA messages, and uses only static DNS settings as configured.



#### Configuring the IPMI settings

To enable the IPMI Settings:

1. Under **Enable IPMI Over LAN**, select **Enabled** .
2. Under **Channel Privilege Limit**, select **Administrator**, **Operator**, or **User** .
3. In the **Encryption Key** box, enter the encryption key in the format 0 to 40 hexadecimal characters (without any blanks
characters.) The default value is all zeros.



#### VLAN settings

You can configure iDRAC into the VLAN infrastructure. To configure VLAN settings, perform the following steps:

**NOTE:** On blade servers that are set as **Chassis (Dedicated)**, the VLAN settings are read-only and can be changed only
using CMC. If the server is set in shared mode, you can configure VLAN settings in shared mode in iDRAC.

1. Under **Enable VLAN ID**, select **Enabled** .
2. In the **VLAN ID** box, enter a valid number from 1 to 4094.
3. In the **Priority** box, enter a number from 0 to 7 to set the priority of the VLAN ID.
**NOTE:** After enabling VLAN, the iDRAC IP is not accessible for some time.



#### Port-based Network Access Control (IEEE 802.1x)

Starting from iDRAC release 6.10.00.00, iDRAC provides Port-based network access control (IEEE802.1x). It provides a secured
authentication mechanism to devices wishing to attach to a LAN.

This feature requires iDRAC Datacenter license.

You can access this feature using iDRAC GUI by navigating to- **iDRAC Settings** - **Connectivity** - **Network** - **Advanced**
**Network Settings** - **802.1x Security** . You can enable or disable the option using the drop-down. The feature is enabled by
default.

**NOTE:** The effect of 802.1x does not work in Shared LOM mode with VLAN enabled.

Port-based Network Access Control has three ways of configuring the authentication certificates:

- **Default IDevID** - This is the default iDRAC certificate installed in the factory.
- **Custom Signing LDevID** - Using this option, you are able to define a Certificate Signing Request (CSR) which is signed by
the uploaded LDEVID Signing Certificate.

- **Custom LDevID** - Using this option, you are able to upload a custom certificate of choice.

There is option to enable or disable **Authentication Server Certificate**, for providing the necessary information to validate the
certificate. This option is disabled by default.

**NOTE:**

  - This feature is disabled by default in modular servers.
  - Any change in 802.1x configuration, including certificate uploads and enabling/disabling settings, takes effect on the
next iDRAC boot.

  - Switching iDRAC network between 802.1x enabled switch & Non 802.1x switch needs idrac reboot.
  - If the ports on the Ethernet Switch which are connected to the server's LOM ports are enabled for 802.1X security,
then all downstream devices on those ports need to be enabled for 8021.X security. This means the host is impacted if it
has not been enabled for 802.1X security.



### Setting up iDRAC IP using the CMC web interface

To set up the iDRAC IP address using the Chassis Management Controller (CMC) Web interface:

**NOTE:** You must have Chassis Configuration Administrator privilege to set up iDRAC network settings from CMC. The
CMC option is applicable only for blade servers.

1. Log in to the CMC Web interface.
2. Go to **iDRAC Settings** - **Settings** - **CMC** .

The **Deploy iDRAC** page is displayed.

3. Under **iDRAC Network Settings**, select **Enable LAN** and other network parameters as per requirements. For more
information, see **CMC online help** .

4. For additional network settings specific to each blade server, go to **Server Overview** - **<server name>** .

The **Server Status** page is displayed.

5. Click **Launch iDRAC** and go to **iDRAC Settings** - **Connectivity** - **Network** .
6. In the **Network** page, specify the following settings:
  - Network Settings
  - Common Settings
  - IPV4 Settings
  - IPV6 Settings
  - IPMI Settings
  - VLAN Settings
  - Advanced Network Settings
**NOTE:** For more information, see **iDRAC Online Help** .

7. To save the network information, click **Apply** .

For more information, see the _Chassis Management Controller User's Guide_ [available on the CMC manuals page..](https://www.dell.com/cmcmanuals)



### Autodiscovery

The Autodiscovery feature allows newly installed servers to automatically discover the remote management console that
hosts the provisioning server. The **provisioning server** provides custom administrative user credentials to iDRAC so that
the unprovisioned server can be discovered and managed from the management console. For more information about
Autodiscovery, see the _Lifecycle Controller Remote Services Quick Start Guide_ [available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)

Autodiscovery works with a static IP address. Autodiscovery feature on the iDRAC is used to find the provisioning server using
DHCP/Unicast DNS/mDNS.

- When iDRAC has the console address, it sends its own service tag, IP address, Redfish port number, Web certificate and so
on.

- This information is periodically published to consoles.

DHCP, DNS server, or the default DNS hostname discovers the provisioning server. If DNS is specified, the provisioning server
IP is retrieved from DNS, and the DHCP settings are not required. If Autodiscovery is specified, discovery is skipped, so neither
DHCP nor DNS is required.

Autodiscovery can be enabled using the following ways:

1. Using iDRAC UI: **iDRAC Settings** - **Connectivity** - **iDRAC Auto Discovery**
2. Using RACADM: `racadm set iDRAC.AutoDiscovery.EnableIPChangeAnnounce 1`

To enable Autodiscovery using iDRAC Settings utility:

1. Turn on the managed system.
2. During POST, press F2, and go to **iDRAC Settings** - **Remote Enablement** .

The **iDRAC Settings Remote Enablement** page is displayed.

3. Enable autodiscovery, enter the provisioning server IP address, and click **Back** .
**NOTE:** Specifying the provisioning server IP is optional. If it is not set, it is discovered using DHCP or DNS settings
(step 7).

4. Click **Network** .

The **iDRAC Settings Network** page is displayed.

5. Enable NIC.
6. Enable IPv4.
**NOTE:** IPv6 is not supported for autodiscovery.

7. Enable DHCP and get the domain name, DNS server address, and DNS domain name from DHCP.
**NOTE:** Step 7 is optional if the provisioning server IP address (step 3) is provided.



### Configuring servers and server components using Auto Config

The Auto Config feature configures and provisions all the components in a server in a single operation. These components
include BIOS, iDRAC, and PERC. Auto Config automatically imports a Server Configuration Profile (SCP) XML or JSON file
containing all configurable parameters. The DHCP server that assigns the IP address also provides the details for accessing the
SCP file.

SCP files are created by configuring a gold configuration server. This configuration is then exported to a shared NFS, CIFS,
HTTP or HTTPS network location that is accessible by the DHCP server and the iDRAC of the server being configured. The SCP
file name can be based on the Service Tag or model number of the target server or can be given as a generic name. The DHCP
server uses a DHCP server option to specify the SCP file name (optionally), SCP file location, and the user credentials to access
the file location.

When the iDRAC obtains an IP address from the DHCP server that is configured for Auto Config, iDRAC uses the SCP to
configure the server’s devices. Auto Config is invoked only after the iDRAC gets its IP address from the DHCP server. If it does
not get a response or an IP address from the DHCP server, then Auto Config is not invoked.

HTTP and HTTPS file sharing options are supported for iDRAC firmware 3.00.00.00 or later. Details of the HTTP or HTTPS
address need to be provided. In case the proxy is enabled on the server, the user needs to provide further proxy settings to
allow HTTP or HTTPS to transfer information. The `-s` option flag is updated as:

**Table 10. Different Share Types and pass in values**

|-s (ShareType)|pass in|
|---|---|
|NFS|`0` or`nfs`|
|CIFS|`2` or`cifs`|
|HTTP|`5` or`http`|
|HTTPS|`6` or`https`|

**NOTE:** HTTPS certificates are not supported with Auto Config. Auto Config ignores certificate warnings.

Following list describes the required and optional parameters to pass in for the string value:

`-f (Filename)` : name of exported Server Configuration Profile file. This is required for iDRAC firmware versions prior to
2.20.20.20.

`-n (Sharename)` : name of network share. This is required for NFS or CIFS.

`-s (ShareType)` : pass in either 0 for NFS, 2 for CIFS, 5 for HTTP and 6 for HTTPS. This is a mandatory field for iDRAC
firmware versions 3.00.00.00.

`-i (IPAddress)` : IP address of the network share. This is a mandatory field.

`-u (Username)` : username that has access to network share. This is a mandatory field for CIFS.

`-p (Password)` : user password that has access to network share. This is a mandatory field for CIFS.

`-d (ShutdownType)` : either 0 for graceful or 1 for forced (default setting: 0). This is an optional field.

`-t (Timetowait)` : time to wait for the host to shutdown (default setting: 300). This is an optional field.

`-e (EndHostPowerState)` : either 0 for OFF or 1 for ON (default setting 1). This is an optional field.

The additional option flags are supported in iDRAC firmware 3.00.00.00 or later to enable the configuration of HTTP proxy
parameters and set the retry timeout for accessing the Profile file:

`—pd (ProxyDefault)` : Use default proxy setting. This is an optional field.

`—pt (ProxyType)` : The user can pass in `http` or `socks` (default setting http). This is an optional field.

`—ph (ProxyHost)` : IP address of the proxy host. This is an optional field.

`—pu (ProxyUserName)` : username that has access to the proxy server. This is required for proxy support.

`—pp (ProxyPassword)` : user password that has access to the proxy server. This is required for proxy support.

`—po (ProxyPort)` : port for the proxy server (default setting is 80). This is an optional field.

`—to (Timeout)` : specifies the retry timeout in minutes for obtaining config file (default is 60 minutes).

For iDRAC firmware 3.00.00.00 or later, JSON format Profile files are supported. The following file names will be used if the
Filename parameter is not present:

- <service tag>-config.xml, Example: CDVH7R1-config.xml
- <model number>-config.xml, Example: R640-config.xml
- config.xml
- <service tag>-config.json, Example:CDVH7R1-config.json
- <model number>-config.json, Example: R630-config.json
- config.json
**NOTE:**

  - Auto Config can only be enabled when **DHCPv4** and the **Enable IPV4** options are enabled.
  - Auto Config and Auto Discovery features are mutually exclusive. Disable Auto Discovery for Auto Config to work.
  - The Auto Config is disabled after a server has carried out an Auto Config operation.

If all the Dell PowerEdge servers in the DHCP server pool are of the same model type and number, then a single SCP file
( `config.xml` ) is required. The `config.xml` file name is used as the default SCP file name. In addition to `.xml` file, `.json`
files can also be used with 15/16G systems. The file can be `config.json` .

The user can configure individual servers requiring different configuration files mapped using individual server Service Tags or
server models. In an environment that has different servers with specific requirements, different SCP file names can be used
to distinguish each server or server type. For example, if there are two server models to configure — PowerEdge R740s and
PowerEdge R540s, use two SCP files, `R740-config.xml` and `R540-config.xml` .

**NOTE:** iDRAC server configuration agent automatically generates the configuration filename using the server Service Tag,
model number, or the default filename — `config.xml` .

**NOTE:** If none of these files are on the network share, then the server configuration profile import job is marked as failed
for file not found.



#### Auto Config sequence

1. Create or modify the SCP file that configures the attributes of Dell servers.
2. Place the SCP file in a share location that is accessible by the DHCP server and all the Dell servers that are assigned IP
address from the DHCP server.

3. Specify the SCP file location in vendor-option 43 field of DHCP server.
4. The iDRAC while acquiring IP address advertises vendor class identifier. (Option 60)
5. The DHCP server matches the vendor class to the vendor option in the `dhcpd.conf` file and sends the SCP file location
and, if specified the SCP file name to the iDRAC.

6. The iDRAC processes the SCP file and configures all the attributes listed in the file.



#### DHCP options

DHCPv4 allows many globally defined parameters to be passed to the DHCP clients. Each parameter is known as a DHCP
option. Each option is identified with an option tag, which is a 1-byte value. Option tags 0 and 255 are reserved for padding and
end of options, respectively. All other values are available for defining options.

The DHCP Option 43 is used to send information from the DHCP server to the DHCP client. The option is defined as a text
string. This text string is set to contain the values of the SCP filename, share location and the credentials to access the location.
For example,

```
 option myname code 43 = text;
 subnet 192.168.0.0 netmask 255.255.255.0 {
 # default gateway
 option routers 192.168.0.1;
 option subnet-mask 255.255.255.0;
 option nis-domain "domain.org";
 option domain-name "domain.org";
 option domain-name-servers 192.168.1.1;
 option time-offset -18000; #Eastern Standard Time
 option vendor-class-identifier "iDRAC";
 set vendor-string = option vendor-class-identifier;
```

`option myname "-f system_config.xml -i 192.168.0.130 -u` **user** `-p` **password** `-n cifs -s 2`
```
 -d 0 -t 500";

```

where, -i is the location of the Remote File Share and –f is the file name in the string along with the credentials to the Remote
File Share.

The DHCP Option 60 identifies and associates a DHCP client with a particular vendor. Any DHCP server configured to take
action based on a client’s vendor ID should have Option 60 and Option 43 configured. With Dell PowerEdge servers, the iDRAC
identifies itself with vendor ID: **iDRAC** . Therefore, you must add a new ‘Vendor Class’ and create a ‘scope option’ under it for
‘code 60,’ and then enable the new scope option for the DHCP server.



##### Configuring option 43 on Windows

To configure option 43 on Windows:

1. On the DHCP server, go to **Start** - **Administration Tools** - **DHCP** to open the DHCP server administration tool.
2. Find the server and expand all items under it.
3. Right-click on **Scope Options** and select **Configure Options** .

The **Scope Options** dialog box is displayed.

4. Scroll down and select **043 Vendor Specific Info** .
5. In the **Data Entry** field, click anywhere in the area under **ASCII** and enter the IP address of the server that has the share
location, which contains the SCP file.
The value appears as you type it under the **ASCII**, but it also appears in binary to the left.

6. Click **OK** to save the configuration.



##### Configuring option 60 on Windows

To configure option 60 on Windows:

1. On the DHCP server, go to **Start** - **Administration Tools** - **DHCP** to open the DHCP server administration tool.
2. Find the server and expand the items under it.
3. Right-click on **IPv4** and choose **Define Vendor Classes** .
4. Click **Add** .

A dialog box with the following fields is displayed:

  - **Display name:**
  - **Description:**
  - **ID: Binary: ASCII:**
5. In the **Display name:** field, type `iDRAC` .
6. In the **Description:** field, type `Vendor Class` .
7. Click in the **ASCII:** section and type `iDRAC` .
8. Click **OK** and then **Close** .
9. On the DHCP window, right-click **IPv4** and select **Set Predefined Options** .
10. From the **Option class** drop-down menu, select **iDRAC** (created in step 4) and click **Add** .
11. In the **Option Type** dialog box, enter the following information:
  - **Name**  - `iDRAC`
  - **Data Type**  - String
  - **Code**  - 060
  - **Description**  - Dell vendor class identifier
12. Click **OK** to return to the **DHCP** window.
13. Expand all items under the server name, right-click **Scope Options** and select **Configure Options** .
14. Click the **Advanced** tab.
15. From the **Vendor class** drop-down menu, select **iDRAC** . The `060 iDRAC` is displayed in the **Available Options** column.
16. Select **060 iDRAC** option.
17. Enter the string value that must be sent to the iDRAC (along with a standard DHCP provided IP address). The string value
helps in importing the correct SCP file.

For the option’s **DATA entry, String Value** setting, use a text parameter that has the following letter options and values:

  - `Filename (–f)`  - Indicates the name of the exported Server Configuration Profile(SCP) file.
  - `Sharename (-n)`  - Indicates the name of the network share.
  - `ShareType (-s)`  - Alongside supporting NFS and CIFS-based file sharing, iDRAC firmware 3.00.00.00 or later
also supports accessing profile files by using HTTP and HTTPS. The `-s option` flag is updated as follows: `-s`
`(ShareType)` : type nfs or 0 for NFS; cifs or 2 for CIFS; http or 5 for HTTP; or https or 6 for HTTPS (mandatory).

  - `IPAddress (-i)`  - Indicates the IP address of the file share.
**NOTE:** `Sharename (-n)`, `ShareType (-s)`, and `IPAddress (-i)` are required attributes that must be

passed. -n is not required for HTTP or HTTPs.

  - `Username (-u)`  - Indicates the user name required to access the network share. This information is required only for
CIFS.

  - `Password (-p)`  - Indicates the password required to access the network share. This information is required only for
CIFS.

  - `ShutdownType (-d)`  - Indicates the mode of shutdown. 0 indicates Graceful shutdown and 1 indicates Forced
shutdown.

**NOTE:** The default setting is 0.

  - `Timetowait (-t)`  - Indicates the time the host system waits before shutting down. The default setting is 300.
  - `EndHostPowerState (-e)`  - Indicates the power state of the host. 0 indicates OFF and 1 indicates ON. The default
setting is 1.

**NOTE:** `ShutdownType (-d)`, `Timetowait (-t)`, and `EndHostPowerState (-e)` are optional attributes.

**NFS** : -f system_config.xml -i 192.168.1.101 -n /nfs_share -s 0 -d 1
**CIFS** : -f system_config.xml -i 192.168.1.101 -n cifs_share -s 2 -u < **USERNAME**  - -p < **PASSWORD**  - -d 1 -t 400
**HTTP** : -f system_config.json -i 192.168.1.101 -s 5
**HTTP** : -f http_share/system_config.xml -i 192.168.1.101 -s http
**HTTP** : -f system_config.xml -i 192.168.1.101 -s http -n http_share
**HTTPS** : -f system_config.json -i 192.168.1.101 -s https



##### Configuring option 43 and option 60 on Linux

Update the `/etc/dhcpd.conf` file. The steps to configure the options are similar to the steps for Windows:

1. Set aside a block or pool of addresses that this DHCP server can allocate.
2. Set the option 43 and use the name vendor class identifier for option 60.
**option myname code 43 = text** `;`
```
  subnet 192.168.0.0 netmask 255.255.0.0 {
  #default gateway
  option routers      192.168.0.1;
  option subnet-mask    255.255.255.0;
  option nis-domain    "domain.org";
  option domain-name    "domain.org";
  option domain-name-servers  192.168.1.1;
  option time-offset    -18000;  # Eastern Standard Time
```

**option vendor-class-identifier "iDRAC";**
**set vendor-string = option vendor-class-identifier;**

**option myname "-f system_config.xml -i 192.168.0.130 -u user -p password -n cifs -s 2 -d 0 -t 500"** `;`
```
  range dynamic-bootp 192.168.0.128 192.168.0.254;
  default-lease-time 21600;
  max-lease-time 43200;
  }
  }

```

The following are the required and optional parameters that must be passed in the vendor class identifier string:

  - Filename (–f) — Indicates the name of the exported Server Configuration Profile file.
**NOTE:** For more information on file naming rules, see Configuring servers and server components using Auto Config.

  - Sharename (-n) — Indicates the name of the network share.
  - ShareType (-s) — Indicates the share type. 0 indicates NFS, 2 indicates CIFS, 5 indicates HTTP, and 6 indicates HTTPS.
**NOTE:** Example for Linux NFS, CIFS, HTTP, HTTPS share:

    - **NFS** : `-f system_config.xml -i 192.168.0.130 -n /nfs -s 0 -d 0 -t 500`
**NOTE:** Ensure that you use NFS2 or NFS3 for NFS network share.

    - **CIFS** : `-f system_config.xml -i 192.168.0.130 -n sambashare/config_files -s 2 -u`
```
       user -p password -d 1 -t 400
```

    - **HTTP** : `-f system_config.xml -i 192.168.1.101 -s http -n http_share`
    - **HTTPS** : `-f system_config.json -i 192.168.1.101 -s https`
  - IPAddress (-i) — Indicates the IP address of the file share.
**NOTE:** Sharename (-n), ShareType (-s), and IPAddress (-i) are required attributes that must be passed. -n is not
required for HTTP or HTTPS.

  - Username (-u) — Indicates the user name required to access the network share. This information is required only for
CIFS.

  - Password (-p) — Indicates the password required to access the network share. This information is required only for
CIFS.

  - ShutdownType (-d) — Indicates the mode of shutdown. 0 indicates Graceful shutdown and 1 indicates Forced shutdown.
**NOTE:** The default setting is 0.

  - Timetowait (-t) — Indicates the time the host system waits before shutting down. The default setting is 300.
  - EndHostPowerState (-e) — Indicates the power state of the host. 0 indicates OFF and 1 indicates ON. The default
setting is 1.

**NOTE:** ShutdownType (-d), Timetowait (-t), and EndHostPowerState (-e) are optional attributes.

The following is an example of a static DHCP reservation from a dhcpd.conf file:

```
  host my_host {
  host my_host {
  hardware ethernet b8:2a:72:fb:e6:56;
  fixed-address 192.168.0.211;
  option host-name "my_host";
  option myname " -f r630_raid.xml -i 192.168.0.1 -n /nfs -s 0 -d 0 -t 300";
  }

```

**NOTE:** After editing the `dhcpd.conf` file, make sure to restart the dhcpd service to apply the changes.



#### Prerequisites before enabling Auto Config

Before enabling the Auto config feature, make sure that following are already set:

- Supported network share (NFS, CIFS, HTTP and HTTPS) is available on the same subnet as the iDRAC and DHCP server.
Test the network share to ensure that it can be accessed and that the firewall and user permissions are set correctly.

- Server configuration profile is exported to the network share. Also, make sure that the necessary changes in the SCP file are
complete so that proper settings can be applied when the Auto Config process is initiated.

- DHCP server is set and the DHCP configuration is updated as required for iDRAC to call the server and initiate the Auto
Config feature.



#### Enabling Auto Config using iDRAC web interface

Make sure that DHCPv4 and the Enable IPv4 options are enabled and Auto-discovery is disabled.

To enable Auto Config:

1. In the iDRAC web interface, go to **iDRAC Settings** - **Connectivity** - **Network** - **Auto Config** .
The **Network** page is displayed.

2. In the **Auto Config** section, select one of the following options from the **Enable DHCP Provisioning** drop-down menu:
  - **Enable Once**  - Configures the component only once using the SCP file referenced by the DHCP server. After this,
Auto Config is disabled.

  - **Enable once after reset**  - After the iDRAC is reset, configures the components only once using the SCP file
referenced by the DHCP server. After this, Auto Config is disabled.

  - **Disable**  - Disables the Auto Config feature.
3. Click **Apply** to apply the setting.

The network page automatically refreshes.



#### Enabling Auto Config using RACADM

To enable Auto Config feature using RACADM, use the `iDRAC.NIC.AutoConfig` object.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

For more information on the Auto Config feature, see the **Zero-Touch, bare-metal server provisioning using the Dell**
**iDRAC with Lifecycle Controller Auto Config feature** [white paper available at the Dell Support page.](https://www.dell.com/support)



### Using hash passwords for improved security

On PowerEdge servers with iDRAC version 3.00.00.00, you can set user passwords and BIOS passwords using a one-way hash
format. The user authentication mechanism is not affected (except for SNMPv3 and IPMI) and you can provide the password in
plain text format.

With the new password hash feature:

- You can generate your own SHA256 hashes to set iDRAC user passwords and BIOS passwords. This allows you to have the
SHA256 values in the server configuration profile, RACADM, and WSMan. When you provide the SHA256 password values,
you cannot authenticate through SNMPv3 and IPMI.

**NOTE:** Remote RACADM or WSMan or Redfish cannot be used for Hash password Configuration / Replacement for
IDRAC. You can use SCP for Hash Password Configuration / Replacement on Remote RACADM or WSMan or Redfish.

- You can set up a template server including all the iDRAC user accounts and BIOS passwords using the current plain text
mechanism. After the server is set up, you can export the server configuration profile with the password hash values. The
export includes the hash values required for SNMPv3 and IPMI authentication. After importing this profile, you must use the
the latest Dell IPMI tool, if you use an older tool, the IPMI authentication fails for the users who have the hashed password
values set.

- The other interfaces such as IDRAC GUI will show the user accounts enabled.

You can generate the hash password with and without Salt using SHA256.

You must have Server Control privileges to include and export hash passwords.

If access to all accounts is lost, use iDRAC Settings Utility or local RACADM and perform reset iDRAC to default task.

If the password of the iDRAC user account is set with the SHA256 password hash only and not the other hashes (SHA1v3Key or
MD5v3Key or IPMIKey), then authentication through SNMP v3 and IPMI is not available.



#### Hash password using RACADM

To set hash passwords, use the following objects with the `set` command:

- iDRAC.Users.SHA256Password
- iDRAC.Users.SHA256PasswordSalt
**NOTE:** `SHA256Password` and `SHA256PasswordSalt` fields are reserved for XML import and do not set them using

command line tools. Setting one of the fields can potentially lock out the current user from logging into iDRAC. When a
password is imported using `SHA256Password`, the iDRAC will not be enforcing the password length check.

Use the following command to include the hash password in the exported server configuration profile:

```
 racadm get -f <file name> -l <NFS / CIFS / HTTP / HTTPS share> -u <username> -p
 <password> -t <filetype> --includePH

```

You must set the Salt attribute when the associated hash is set.

**NOTE:** The attributes are not applicable to the INI configuration file.



#### Hash password in server configuration profile

The new hash passwords can be optionally exported in the server configuration profile.

When importing server configuration profile, you can uncomment the existing password attribute or the new password hash
attribute(s). If both are uncommented an error is generated and the password is not set. A commented attribute is not applied
during an import.



#### Generating hash password without SNMPv3 and IPMI authentication

Hash password can be generated without SNMPv3 and IPMI authentication with or without salt. Both require SHA256.

To generate hash password with salt:

1. For the iDRAC user accounts, you must salt the password using SHA256.
  - When you salt the password, a 16-bytes binary string is appended. The Salt is required to be 16 bytes long, if provided.
Once appended, it becomes a 32 character string. The format is "password"+"salt", for example:

   - Password = SOMEPASSWORD
   - Salt = ALITTLEBITOFSALT—16 characters are appended
2. Open a Linux command prompt, and run the following command:

```
  Generate Hash-> echo-n SOMEPASSWORDALITTLEBITOFSALT|sha256sum -><HASH>

  Generate Hex Representation of Salt -> echo -n ALITTLEBITOFSALT | xxd –p  -> <HEX  SALT>

  set iDRAC.Users.4.SHA256Password <HASH>

  set iDRAC.Users.4.SHA256PasswordSalt <HEX-SALT>

```

3. Provide hash value and salt in the imported server configuration profile, the RACADM commands, Redfish, or WSMan.
4. After setting the password, the normal plain text password authentication works except that SNMP v3 and IPMI
authentication fails for the iDRAC user accounts that had passwords updated with hash.



## Modifying local administrator account settings

After setting the iDRAC IP address, you can modify the local administrator account settings (that is, user 2) using the iDRAC
Settings utility. To do this:

1. In the iDRAC Settings utility, go to **User Configuration** .
The **iDRAC Settings User Configuration** page is displayed.

2. Specify the details for **User Name**, **LAN User Privilege**, **Serial Port User Privilege**, and **Change Password** .

For information about the options, see the **iDRAC Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The local administrator account settings are configured.



## Setting up managed system location

You can specify the location details of the managed system in the data center using the iDRAC Web interface or iDRAC Settings
utility.



### Setting up managed system location using web interface

To specify the system location details:

1. In the iDRAC web interface, go to **System** - **Details** - **System Details** .
The **System Details** page is displayed.

2. Under **System Location**, enter the location details of the managed system in the data center.

For information about the options, see the **iDRAC Online Help** .

3. Click **Apply** . The system location details are saved in iDRAC.



### Setting up managed system location using RACADM

To specify the system location details, use the `System.Location` group objects.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Setting up managed system location using iDRAC settings utility

To specify the system location details:

1. In the iDRAC Settings utility, go to **System Location** .
The **iDRAC Settings System Location** page is displayed.

2. Enter the location details of the managed system in the data center. For information about the options, see the **iDRAC**
**Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The details are saved.



## Optimizing system performance and power consumption

The power required to cool a server can contribute a significant amount to the overall system power. Thermal control is the
active management of system cooling through fan speed and system power management to make sure that the system is
reliable while minimizing system power consumption, airflow, and system acoustic output. You can adjust the thermal control
settings and optimize against the system performance and performance-per-Watt requirements.

Using the iDRAC Web interface, RACADM, or the iDRAC Settings Utility, you can change the following thermal settings:

- Optimize for performance
- Optimize for minimum power
- Set the maximum air exhaust temperature
- Increase airflow through a fan offset, if required
- Increase airflow through increasing minimum fan speed

Following are the list of features in thermal management:

- **System Airflow Consumption** : Displays the real-time system airflow consumption (in CFM), allowing airflow balancing at
rack and datacenter level.

- **Custom Delta-T** : Limit air temperature rise from inlet air to exhaust to right-size your infrastructure level cooling.
- **Exhaust Temperature Control** : Specify the temperature limit of the air exiting the server to match your datacenter needs.
- **Custom PCIe inlet temperature** : Choose the right input inlet temperature to match 3rd party device requirements.
- **PCIe Airflow settings** : Provides a comprehensive PCIe device cooling view of the server and allows cooling customization
of 3rd party cards.



### Modifying thermal settings using iDRAC web interface

To modify the thermal settings:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **Cooling Configuration** .
2. Specify the following:
  - **Thermal Profile Optimization**  - Select the thermal profile:
   - **Default Thermal Profile Settings (Minimum Power)**   - Implies that the thermal algorithm uses the same system
profile settings that is defined under **System BIOS**      - **System BIOS Settings**      - **System Profile Settings** page.
By default, this option is set to **Default Thermal Profile Settings** . You can also select a custom algorithm, which is
independent of the BIOS profile. The options available are:

   - **Maximum Performance (Performance Optimized)** :
￭ Reduced probability of memory or CPU throttling.
￭ Increased probability of turbo mode activation.
￭ Generally, higher fan speeds at idle and stress loads.

   - **Minimum Power (Performance per Watt Optimized)** :
￭ Optimized for lowest system power consumption based on optimum fan power state.
￭ Generally, lower fan speeds at idle and stress loads.

   - **Sound Cap**   - Sound Cap provides reduced acoustical output from a server at the expense of some performance.
Enabling Sound Cap may include temporary deployment or evaluation of a server in an occupied space, but it should
not be used during benchmarking or performance sensitive applications.

**NOTE:** Selecting **Maximum Performance** or **Minimum Power**, overrides thermal settings associated to System
Profile setting under **System BIOS**       - **System BIOS Settings.System Profile Settings** page.

  - **Maximum Exhaust Temperature Limit**  - From the drop-down menu, select the maximum exhaust air temperature.
The values are displayed based on the system.

**NOTE:** The default value is **Default, 70°C (158 °F)** .

This option allows the system fans speeds to change such that the exhaust temperature does not exceed the selected
exhaust temperature limit. This cannot always be guaranteed under all system operating conditions due to dependency on
system load and system cooling capability.

  - **Fan Speed Offset**  - Selecting this option allows additional cooling to the server. In case hardware is added (example,
new PCIe cards), it may require additional cooling. A fan speed offset causes fan speeds to increase (by the offset %
value) over baseline fan speeds calculated by the Thermal Control algorithm. Possible values are:

   - **Low Fan Speed**   - Drives fan speeds to a moderate fan speed.
   - **Medium Fan Speed**   - Drives fan speeds close to medium.
   - **High Fan Speed**   - Drives fan speeds close to full speed.
   - **Max Fan Speed**   - Drives fan speeds to full speed.
   - **Off**   - Fan speed offset is set to off. This is the default value. When set to off, the percentage does not display. The
default fan speed is applied with no offset. Conversely, the maximum setting will result in all fans running at maximum
speed.

**NOTE:**

    - The fan speed offset is dynamic and based on the system. The fan speed increase for each offset is displayed
next to each option.

    - The fan speed offset increases all fan speeds by the same percentage. Fan speeds may increase beyond the
offset speeds based on individual component cooling needs. The overall system power consumption is expected
to increase.

    - Fan speed offset allows you to increase the system fan speed with four incremental steps. These steps are
equally divided between the typical baseline speed and the maximum speed of the server system fans. Some
hardware configurations results in higher baseline fan speeds, which results in offsets other than the maximum
offset to achieve maximum speed.

    - The most common usage scenario is non-standard PCIe adapter cooling. However, the feature can be used to
increase system cooling for other purposes.

**NOTE:** FAN configuration setting is available in iDRAC even when system does not have any FANs. This is because,
iDRAC sends the specified configuration to Chassis manager and Chassis manager can process the data from iDRAC
and send the required cooling to the system as per configuration.

  - **Thresholds**
   - **Maximum PCIe Inlet Temperature Limit**   - Default value is 55°C. Select the lower temperature of 45°C for third
party PCIe cards which require lower inlet temperature.

   - **Exhaust Temperature Limits**   - By modifying the values for the following you can set the exhaust temperature
limits:
￭ **Set Maximum Exhaust Temperature Limit**
￭ **Set Air Temperature Rise Limit**

   - **Minimum Fan Speed in PWM (% of Max)**   - Select this option to fine tune the fan speed. Using this option, you
can set a higher baseline system fan speed or increase the system fan speed if other custom fan speed options are
not resulting in the required higher fan speeds.
￭ **Default**     - Sets minimum fan speed to default value as determined by the system cooling algorithm.
￭ **Custom**     - Enter the percentage by which you want to change the fan speed. Range is between 9-100.

**NOTE:**

￭ The allowable range for minimum fan speed PWM is dynamic based on the system configuration. The first
value is the idle speed and the second value is the configuration max (Depending on the system configuration,
the maximum speed may be up to 100%.).

￭ For all SAS/SATA storage configurations, fan speed will be is capped down to 95%.

￭ System fans can run higher than this speed as per thermal requirements of the system but not lower than the
defined minimum speed. For example, setting Minimum Fan Speed at 35% limits the fan speed to never go
lower than 35% PWM.

￭ 0% PWM does not indicate fan is off. It is the lowest fan speed that the fan can achieve.

The settings are persistent, which means that once they are set and applied, they do not automatically change to the default
setting during system reboot, power cycling, iDRAC, or BIOS updates. The custom cooling options may not be supported on
all servers. If the options are not supported, they are not displayed or you cannot provide a custom value.

3. Click **Apply** to apply the settings.

The following message is displayed:

```
  It is recommended to reboot the system when a thermal profile change has been made. This
  is to ensure all power and thermal settings are activated.
```

4. Click **Reboot Later** or **Reboot Now** .
**NOTE:** The fan enablement depend on the relevant thermal configuration (open loop) getting enabled, which again depends
on the respective hardware configurations present on the setup. Example: The required rear HDD drives.

**NOTE:** You must reboot the system for the settings to take effect.



### Modifying thermal settings using RACADM

To modify the thermal settings, use the objects in the **system.thermalsettings** group with the **set** sub command as provided
in the following table.

**Table 11. Thermal Settings**

|Object|Description|Usage|Example|
|---|---|---|---|
|`AirExhaustTemp`|Allows you to set the<br>maximum air exhaust<br>temperature limit.|Set to any of the<br>following values (based<br>on the system):<br>●<br>0 — Indicates 40°C<br>●<br>1 — Indicates 45°C<br>●<br>2 — Indicates 50°C<br>●<br>3 — Indicates 55°C<br>●<br>4 — Indicates 60°C<br>●<br>255 — Indicates<br>70°C (default)|●<br>To check the existing setting on the<br>system:<br>`racadm get`<br>`system.thermalsettings.`<br>`AirExhaustTemp`<br>●<br>The output is:<br>`AirExhaustTemp=70`<br>●<br>This output indicates that the<br>system is set to limit the air exhaust<br>temperature to 70°C. To set the<br>exhaust temperature limit to 60°C:<br>`racadm set`<br>`system.thermalsettings.`<br>`AirExhaustTemp 4`<br>●<br>The output is:<br>`Object value modified`<br>`successfully.`<br>●<br>If a system does not support a<br>particular air exhaust temperature<br>limit, then when you run the<br>following command:<br>`racadm set`<br>`system.thermalsettings.`<br>`AirExhaustTemp 0`<br>●<br>The following error message is<br>displayed:<br>`ERROR: RAC947: Invalid`<br>`object value specified.`<br>●<br>Make sure to specify the value<br>depending on the type of object.<br>For more information, see RACADM<br>help. To set the limit to the default<br>value:<br>`racadm set`<br>`system.thermalsettings.`<br>`AirExhaustTemp 255`|
|`FanSpeedHighOffsetVa`<br>`l`|●<br>Getting this variable<br>reads the fan speed<br>offset value in %PWM<br>for High Fan Speed<br>Offset setting.<br>●<br>This value depends on<br>the system.|Values from 0-100|`racadm get`<br>`system.thermalsettings`<br>`FanSpeedHighOffsetVal`<br>A numerical value, for example 66,<br>is returned. This value indicates that<br>when you use the following command,<br>it applies a fan speed offset of High|
||●<br>Use`FanSpeedOffset`<br>object to set this value<br>using index value 1.||(66% PWM) over the baseline fan<br>speed<br>`racadm set`<br>`system.thermalsettings`<br>`FanSpeedOffset 1`|
|`FanSpeedLowOffsetVal`|●<br>Getting this variable<br>reads the fan speed<br>offset value in %PWM<br>for Low Fan Speed<br>Offset setting.<br>●<br>This value depends on<br>the system.<br>●<br>Use`FanSpeedOffset`<br>object to set this value<br>using index value 0.|Values from 0-100|`racadm get`<br>`system.thermalsettings`<br>`FanSpeedLowOffsetVal`<br>This returns a value such as “23”. This<br>means that when you use the following<br>command, it applies a fan speed offset<br>of Low (23% PWM) over baseline fan<br>speed.<br>`racadm set`<br>`system.thermalsettings`<br>`FanSpeedOffset 0`|
|`FanSpeedMaxOffsetVal`|●<br>Getting this variable<br>reads the fan speed<br>offset value in %PWM<br>for Max Fan Speed<br>Offset setting.<br>●<br>This value depends on<br>the system.<br>●<br>Use`FanSpeedOffset`<br>to set this value using<br>index value 3|Values from 0-100|`racadm get`<br>`system.thermalsettings`<br>`FanSpeedMaxOffsetVal`<br>This returns a value such as “100”. This<br>means that when you use the following<br>command, it applies a fan speed offset<br>of Max (meaning full speed, 100%<br>PWM). Usually, this offset results in<br>fan speed increasing to full speed.<br>`racadm set`<br>`system.thermalsettings`<br>`FanSpeedOffset 3`|
|`FanSpeedMediumOffset`<br>`Val`|●<br>Getting this variable<br>reads the fan speed<br>offset value in %PWM<br>for Medium Fan Speed<br>Offset setting.<br>●<br>This value depends on<br>the system.<br>●<br>Use`FanSpeedOffset`<br>object to set this value<br>using index value 2|Values from 0-100|`racadm get`<br>`system.thermalsettings`<br>`FanSpeedMediumOffsetVal`<br>This returns a value such as “47”. This<br>means that when you use the following<br>command, it applies a fan speed offset<br>of Medium (47% PWM) over baseline<br>fan speed<br>`racadm set`<br>`system.thermalsettings`<br>`FanSpeedOffset 2`|
|`FanSpeedOffset`|●<br>Using this object with<br>get command displays<br>the existing Fan Speed<br>Offset value.<br>●<br>Using this object with<br>set command allows<br>setting the required fan<br>speed offset value.|Values are:<br>●<br>0 — Low Fan<br>Speed<br>●<br>1 — High Fan<br>Speed<br>●<br>2 — Medium Fan<br>Speed|To view the existing setting:<br>`racadm get`<br>`system.thermalsettings.Fan`<br>`SpeedOffset`|

**Table 11. Thermal Settings (continued)**

|Object|Description|Usage|Example|
|---|---|---|---|
||●<br>The index value decides<br>the offset that is applied<br>and the<br>`FanSpeedLowOffsetV`<br>`al`, <br>`FanSpeedMaxOffsetV`<br>`al`, <br>`FanSpeedHighOffset`<br>`Val`, and<br>`FanSpeedMediumOffs`<br>`etVal` objects (defined<br>earlier) are the values at<br>which the offsets are<br>applied.|●<br>3 — Max Fan<br>Speed<br>●<br>255 — None|**NOTE:** To set the fan speed<br>offset to High value (as defined in<br>`FanSpeedHighOffsetVal`)<br>`racadm set`<br>`system.thermalsettings.Fan`<br>`SpeedOffset 1`|
|`MFSMaximumLimit`|Read Maximum limit for<br>MFS|Values from 1 — 100|To display the highest value that<br>can be set using`MinimumFanSpeed`<br>option:<br>`racadm get`<br>`system.thermalsettings.MFS`<br>`MaximumLimit`|
|`MFSMinimumLimit`|Read Minimum limit for MFS|Values from 0 to<br>`MFSMaximumLimit`De<br>fault is 255 (means<br>None)|To display the lowest value that can be<br>set using`MinimumFanSpeed` option.<br>`racadm get`<br>`system.thermalsettings.MFS`<br>`MinimumLimit`|
|`MinimumFanSpeed`|●<br>Allows configuring the<br>Minimum Fan speed<br>that is required for the<br>system to operate.<br>●<br>It defines the baseline<br>(floor) value for fan<br>speed and system allows<br>fans to go lower than<br>this defined fan speed<br>value.<br>●<br>This value is %PWM<br>value for fan speed.|Values from<br>`MFSMinimumLimit` to<br>`MFSMaximumLimit`W<br>hen get command<br>reports 255, it means<br>user configured offset<br>is not applied.|To make sure that the system<br>minimum speed does not decrease<br>lower than 45% PWM (45 must be a<br>value between`MFSMinimumLimit` to<br>`MFSMaximumLimit`):<br>`racadm set`<br>`system.thermalsettings.Min`<br>`imumFanSpeed 45`|
|`ThermalProfile`|●<br>Allows you to specify the<br>Thermal Base Algorithm.<br>●<br>Allows you to set<br>the system profile as<br>required for thermal<br>behavior associated to<br>the profile.|Values:<br>●<br>0 — Auto<br>●<br>1 — Maximum<br>performance<br>●<br>2 — Minimum<br>Power|To view the existing thermal profile<br>setting:<br>`racadm get`<br>`system.thermalsettings.The`<br>`rmalProfile`<br>**NOTE:** To set the thermal profile<br>to Maximum Performance:<br>`racadm set`<br>`system.thermalsettings.The`<br>`rmalProfile 1`|
|`ThirdPartyPCIFanResp`<br>`onse`|●<br>Thermal overrides for<br>third-party PCI cards.<br>●<br>Allows you to disable<br>or enable the default<br>system fan response for<br>detected third-party PCI<br>cards.<br>●<br>You can confirm the<br>presence of third-party<br>PCI card by viewing the<br>message ID PCI3018 in<br>the Lifecycle Controller<br>log.|Values:<br>●<br>1 — Enabled<br>●<br>0 — Disabled<br>**NOTE:** The default<br>value is 1.|To disable any default fan speed<br>response set for a detected third-party<br>PCI card:<br>`racadm set`<br>`system.thermalsettings.Thi`<br>`rdPartyPCIFanResponse 0`|



### Modifying thermal settings using iDRAC settings utility

To modify the thermal settings:

1. In the iDRAC Settings utility, go to **Thermal** .
The **iDRAC Settings Thermal** page is displayed.

2. Specify the following:
  - Thermal Profile
  - Maximum Exhaust Temperature Limit
  - Fan Speed Offset
  - Minimum Fan Speed

The settings are persistent, which means that once they are set and applied, they do not automatically change to the default
setting during system reboot, power cycling, iDRAC, or BIOS updates. A few Dell servers may or may not support some or
all of these custom user cooling options. If the options are not supported, they are not displayed or you cannot provide a
custom value.

3. Click **Back**, click **Finish**, and then click **Yes** .

The thermal settings are configured.



### Modifying PCIe airflow settings using iDRAC web interface

The **PCIe Airflow Settings** page enables you to select **LFM Mode** and **Custom LFM** values.

**NOTE:** PCIe airflow settings are not available for M.2 drives that are connected through direct risers or BOSS.

To modify the PCIe airflow settings:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **Cooling Configuration** .
The **PCIe Airflow Settings** page is displayed in the fan settings section.

**NOTE:** For NVIDIA H100 GPU cards, **Max LFM** and **Inlet Temperature** readings are displayed as **0** . For empty PCIe
slots, **Max LFM** and **Inlet Temperature** values are displayed, regardless of whether the slot is populated.

2. Specify the following:
  - **LFM Mode** —Select the **Custom** mode to enable the custom LFM option.
  - **Custom LFM** —Enter the LFM value.
3. Click **Apply** to apply the settings.

The following message is displayed:

```
  It is recommended to reboot the system when a thermal profile change has been made. This
  is to ensure all power and thermal settings are activated.

```

Click **Reboot Later** or **Reboot Now** .

**NOTE:** Reboot the system to apply the settings.



## Setting up management station

A management station is a computer used for accessing iDRAC interfaces to remotely monitor and manage the PowerEdge
server(s).

To set up the management station:

1. Install a supported operating system. For more information, see the release notes.
2. Install and configure a supported Web browser. For more information, see the release notes.
3. From the **Dell Systems Management Tools and Documentation** DVD, install Remote RACADM VMCLI from the
SYSMGMT folder. Else, run **Setup** on the DVD to install Remote RACADM by default and other OpenManage software.
[For more information about RACADM, see Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

4. Install the following based on the requirement:
  - SSH client
  - TFTP
  - Dell OpenManage Essentials



### Accessing iDRAC remotely

To remotely access iDRAC Web interface from a management station, make sure that the management station is in the same
network as iDRAC. For example:

- Blade servers — The management station must be on the same network as CMC and OME Modular. For more information
on isolating CMC network from the managed system’s network, see the _Chassis Management Controller User's Guide_
[available on the CMC manuals page..](https://www.dell.com/cmcmanuals)

- Rack and tower servers — Set the iDRAC NIC to Dedicated or LOM1 and make sure that the management station is on the
same network as iDRAC.

To access the managed system’s console from a management station, use Virtual Console through iDRAC Web interface.



## Configuring supported web browsers

**NOTE:** For information about the supported browsers and their versions, see the **Release Notes** available at iDRAC
Manuals.

Most features of iDRAC web interface can be accessed using these browsers with default settings. For certain feature to work,
you must change a few settings. These settings include disabling pop-up blockers, enabling eHTML5 plug-in support and so on.

If you are connecting to iDRAC web interface from a management station that connects to the Internet through a proxy server,
configure the web browser to access the Internet through this server.

**NOTE:** If you use Internet Explorer or Firefox to access the iDRAC web interface, you may need to configure certain
settings as described in this section. You can use other supported browsers with their default settings.

**NOTE:** Blank proxy settings are treated equivalent to No proxy.



### Configuring Mozilla Firefox

This section provides details about configuring Firefox to ensure you can access and use all features of the iDRAC web
interface. These settings include:

- Disabling whitelist feature
- Configuring Firefox to enable Active Directory SSO
**NOTE:** Mozilla Firefox browser may not have scroll bar for iDRAC Online Help page.



#### Disabling whitelist feature in Firefox

Firefox has a "whitelist" security feature that requires user permission to install plug-ins for each distinct site that hosts a
plug-in. If enabled, the whitelist feature requires you to install a Virtual Console viewer for each iDRAC you visit, even though
the viewer versions are identical.

To disable the whitelist feature and avoid unnecessary plug-in installations, perform the following steps:

1. Open a Firefox Web browser window.
2. In the address field, enter `about:config` and press <Enter>.
3. In the **Preference Name** column, locate and double-click **xpinstall.whitelist.required** .

The values for **Preference Name**, **Status**, **Type**, and **Value** change to bold text. The **Status** value changes to user set and
the **Value** changes to false.

4. In the **Preferences Name** column, locate **xpinstall.enabled** .

Make sure that **Value** is **true** . If not, double-click **xpinstall.enabled** to set **Value** to **true** .



#### Configuring Firefox to enable Active Directory SSO

To configure the browser settings for Firefox:

1. In Firefox address bar, enter `about:config` .
2. In **Filter**, enter `network.negotiate` .
3. Add the domain name to network.negotiate-auth.trusted-uris (using comma separated list.)
4. Add the domain name to network.negotiate-auth.delegation-uris (using comma separated list.)



### Configuring web browsers to use virtual console

**NOTE:** Starting with release version 6.00.02.00, access to vConsole uses only eHTML5. Java and ActiveX are no longer
supported.

To use Virtual Console on your management station:

1. Make sure that a supported version of the browser (Internet Explorer/Edge (Windows), or Mozilla Firefox (Windows or
Linux), Google Chrome, Safari) is installed.

**NOTE:** In RHEL OS with Mozilla browser, we could see the below observation during the network drop (removing and
re-inserting Network cable):

   - Reconnecting message may not be seen in vConsole until the network is up.
   - You may see **Login denied** pop-up message instead of **Failed to Reconnect** error if the network is down for more
than 180s.

**NOTE:** While using the Safari browser, it is recommended to unselect the **NSURLSession WebSocket** options if it
selected and then open the vConsole. For disabling the **NSURLSession WebSocket** in Safari by unselecting **Safari**
**=>Develop=>Experimental Features=>NSURLSession WebSocket options** .

For more information about the supported browser versions, see the **Release Notes** [available at iDRAC Manuals.](https://www.dell.com/idracmanuals)

**NOTE:** It is recommended to disable the Virtual search feature in edge browser as best practice. It is enabled by default.
There may be risk of images being searched without your knowledge. Hence you can disable this behavior by configuring
the Edge browser settings.

2. To use Internet Explorer/Edge, set IE/Edge to **Run As Administrator** .
3. Configure the Web browser to use eHTML5 plug-in.
4. Import the root certificates on the managed system to avoid the pop-ups that prompt you to verify the certificates.
5. Install the **compat-libstdc++-33-3.2.3-61** related package.
**NOTE:** On Windows, the `compat-libstdc++-33-3.2.3-61` related package may be included in the .NET

framework package or the operating system package.

6. If you are using MAC operating system, select the **Enable access for assistive devices** option in the **Universal Access**

window.

For more information, see the MAC operating system documentation.



#### Importing CA certificates to management station

When you launch Virtual Console or Virtual Media, prompts are displayed to verify the certificates. If you have custom Web
server certificates, you can avoid these prompts by importing the CA certificates to the trusted certificate store.

For more information about Automatic Certificate Enrollment (ACE), see section Automatic Certificate Enrollment



##### Importing CA certificate to Java trusted certificate store

To import the CA certificate to the Java trusted certificate store:

1. Launch the **Java Control Panel** .
2. Click **Security** tab and then click **Certificates** .

The **Certificates** dialog box is displayed.

3. From the Certificate type drop-down menu, select **Trusted Certificates** .
4. Click **Import**, browse, select the CA certificate (in Base64 encoded format), and click **Open** .

The selected certificate is imported to the Web start trusted certificate store.

5. Click **Close** and then click **OK** . The **Java Control Panel** window closes.



### Viewing localized versions of web interface

iDRAC web interface is supported in the following languages:

- English (en-us)
- French (fr)
- German (de)
- Spanish (es)
- Japanese (ja)
- Simplified Chinese (zh-cn)

The ISO identifiers in parentheses denote the supported language variants. For some supported languages, resizing the browser
window to 1024 pixels wide is required to view all features.

iDRAC Web interface is designed to work with localized keyboards for the supported language variants. Some features of iDRAC
Web interface, such as Virtual Console, may require additional steps to access certain functions or letters. Other keyboards are
not supported and may cause unexpected problems.

**NOTE:** See the browser documentation on how to configure or setup different languages and view localized versions of
iDRAC Web interface.



## Firmware updates

Using iDRAC, you can update the iDRAC itself, the BIOS, and all device firmware components in the system. This enhances
performance, security, and compatibility with new software or hardware.

The following firmware and devices are supported for updates:

- Fibre Channel (FC) cards
- Diagnostics
- Operating System Driver Pack
- Network Interface Card (NIC)
- RAID Controller
- Power Supply Unit (PSU)
- Accelerator (GPU)
- NVMe PCIe devices
- SAS/SATA hard drives
- Backplane update for internal and external enclosures

loop mode.

**NOTE:** When upgrading or downgrading firmware for channel devices or hard drives, see the product documentation for
brand-specific limitations, including flash limits.



### Firmware image files and supported tools

The following firmware image file extensions are supported for iDRAC updates:

- .exe: Windows-based Dell Update Package (DUP).
- .d10: Contains both iDRAC and Lifecycle Controller firmware.

update, Redfish Simple update, and iDRAC UI update.

There are multiple tools and interfaces that can be used to update the iDRAC firmware. The following table is applicable only to
iDRAC firmware. The table lists the supported interfaces, image-file types, and whether the Lifecycle Controller must be in an
enabled state for the firmware to be updated.

|Table 12. Image file types and dependencies|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
|**.D10 Image**|**.D10 Image**|**.D10 Image**|**iDRAC DUP**|**iDRAC DUP**|
|**Interface**|**Supported**|**Requires LC enabled**|**Supported**|**Requires LC enabled**|
|RACADM update<br>(new)|Yes|Yes|Yes|Yes|
|iDRAC UI|Yes|Yes|Yes|Yes|
|In-band operating<br>system DUP|No|N/A|Yes|No|
|**NOTE:** After you perform an in-band DUP update, if the update does not get staged to iDRAC, a Multipart: Rollback job is<br>created.|**NOTE:** After you perform an in-band DUP update, if the update does not get staged to iDRAC, a Multipart: Rollback job is<br>created.|**NOTE:** After you perform an in-band DUP update, if the update does not get staged to iDRAC, a Multipart: Rollback job is<br>created.|**NOTE:** After you perform an in-band DUP update, if the update does not get staged to iDRAC, a Multipart: Rollback job is<br>created.|**NOTE:** After you perform an in-band DUP update, if the update does not get staged to iDRAC, a Multipart: Rollback job is<br>created.|
|Redfish|Yes|N/A|Yes|N/A|
|Diagnostics|No|No|No|No|
|Operating system<br>Driver Pack|No|No|No|No|
|iDRAC|Yes|No|No*|Yes|
|BIOS|Yes|Yes|Yes|Yes|
|RAID Controller|Yes|Yes|Yes|Yes|
|BOSS|Yes|Yes|Yes|Yes|
|NVDIMM|No|Yes|Yes|Yes|
|Backplanes|Yes|Yes|Yes|Yes|
|**NOTE:** For Expander (Active) backplanes, a system restart is required.|**NOTE:** For Expander (Active) backplanes, a system restart is required.|**NOTE:** For Expander (Active) backplanes, a system restart is required.|**NOTE:** For Expander (Active) backplanes, a system restart is required.|**NOTE:** For Expander (Active) backplanes, a system restart is required.|
|Enclosures|Yes|Yes|No|Yes|
|NIC|Yes|Yes|Yes|Yes|
|Power Supply Unit|Yes|Yes|Yes|Yes|
|**NOTE:** When a manual reboot is performed or when an update is performed from an<br>operating system, PSU update requires a cold reboot for the update to start.|**NOTE:** When a manual reboot is performed or when an update is performed from an<br>operating system, PSU update requires a cold reboot for the update to start.|**NOTE:** When a manual reboot is performed or when an update is performed from an<br>operating system, PSU update requires a cold reboot for the update to start.|**NOTE:** When a manual reboot is performed or when an update is performed from an<br>operating system, PSU update requires a cold reboot for the update to start.|Yes|
|Table 12. Image file types and dependencies (continued)|Col2|Col3|Col4|Col5|
|**.D10 Image**|**.D10 Image**|**.D10 Image**|**iDRAC DUP**|**iDRAC DUP**|
|**Interface**|**Supported**|**Requires LC enabled**|**Supported**|**Requires LC enabled**|
|FPGA|No|Yes|Yes|Yes|
|**NOTE:** After the FPGA firmware upgrade is complete, iDRAC restarts automatically.<br>**NOTE:** Repo update is not supported for FPGA while performing FPGA update alone or FPGA stacked with other updates.<br>**NOTE:** When an A/C cycle is performed, wait approximately 20 seconds for the power drain to complete to ensure a<br>proper reset of the system. Otherwise, you may encounter the following errors:<br>●<br>○<br>**SWC9016**: Unable to authenticate FPGA due to unsuccessful cryptographic authentication or integrity issues.<br>○<br>**SWC9018**: Unable to recover the FPGA autorecovery operation due to an internal error.|**NOTE:** After the FPGA firmware upgrade is complete, iDRAC restarts automatically.<br>**NOTE:** Repo update is not supported for FPGA while performing FPGA update alone or FPGA stacked with other updates.<br>**NOTE:** When an A/C cycle is performed, wait approximately 20 seconds for the power drain to complete to ensure a<br>proper reset of the system. Otherwise, you may encounter the following errors:<br>●<br>○<br>**SWC9016**: Unable to authenticate FPGA due to unsuccessful cryptographic authentication or integrity issues.<br>○<br>**SWC9018**: Unable to recover the FPGA autorecovery operation due to an internal error.|**NOTE:** After the FPGA firmware upgrade is complete, iDRAC restarts automatically.<br>**NOTE:** Repo update is not supported for FPGA while performing FPGA update alone or FPGA stacked with other updates.<br>**NOTE:** When an A/C cycle is performed, wait approximately 20 seconds for the power drain to complete to ensure a<br>proper reset of the system. Otherwise, you may encounter the following errors:<br>●<br>○<br>**SWC9016**: Unable to authenticate FPGA due to unsuccessful cryptographic authentication or integrity issues.<br>○<br>**SWC9018**: Unable to recover the FPGA autorecovery operation due to an internal error.|**NOTE:** After the FPGA firmware upgrade is complete, iDRAC restarts automatically.<br>**NOTE:** Repo update is not supported for FPGA while performing FPGA update alone or FPGA stacked with other updates.<br>**NOTE:** When an A/C cycle is performed, wait approximately 20 seconds for the power drain to complete to ensure a<br>proper reset of the system. Otherwise, you may encounter the following errors:<br>●<br>○<br>**SWC9016**: Unable to authenticate FPGA due to unsuccessful cryptographic authentication or integrity issues.<br>○<br>**SWC9018**: Unable to recover the FPGA autorecovery operation due to an internal error.|**NOTE:** After the FPGA firmware upgrade is complete, iDRAC restarts automatically.<br>**NOTE:** Repo update is not supported for FPGA while performing FPGA update alone or FPGA stacked with other updates.<br>**NOTE:** When an A/C cycle is performed, wait approximately 20 seconds for the power drain to complete to ensure a<br>proper reset of the system. Otherwise, you may encounter the following errors:<br>●<br>○<br>**SWC9016**: Unable to authenticate FPGA due to unsuccessful cryptographic authentication or integrity issues.<br>○<br>**SWC9018**: Unable to recover the FPGA autorecovery operation due to an internal error.|
|FC Cards|Yes|Yes|Yes|Yes|
|NVMe PCIe SSD<br>drives|Yes|No|Yes|No|
|SAS/SATA hard<br>drives|No|Yes|Yes|No|
|TPM|No|Yes|Yes|Yes|
|Non-SDL Software<br>and Peripherals<br>Application|No|No|No|No|



### Methods for firmware updates

You can perform firmware updates by using the following methods:

- Upload a supported image type from a local system or a network share.
**NOTE:** When updating device firmware using an image file hosted on a local system or a supported network share, a
network speed of at least 5 Mbps is recommended.

- Connect to an FTP, TFTP, HTTP, HTTPS site, or a network repository that contains Windows DUPs and a corresponding
catalog file.

**NOTE:** You can create custom repositories by using the Dell Repository Manager. For more information, see the _Dell_
_Repository Manager Data Center User's Guide_ . iDRAC can provide a difference report between the BIOS and firmware
that is installed on the system and the updates available in the repository. All applicable updates that are contained in
the repository are applied to the system. This feature is available with iDRAC Enterprise or Datacenter license.

**NOTE:** Firmware update using FTP fails if the HTTP proxy used is configured without any authentication. Ensure that
you change the proxy configuration to allow the CONNECT method to use non-SSL ports. For example, while using a
squid proxy, remove the line "http_access deny CONNECT !SSL_ports" that restricts using the CONNECT method on
non-SSL ports.

**NOTE:** HTTP/HTTPS only supports with either digest authentication or no authentication.

- Schedule recurring automated firmware updates by using the catalog file. Custom repository is also supported.



### Considerations for PSU firmware updates

The following are the considerations for firmware updates on a PSU:

**the system during the update to avoid damaging the PSU.**

- Ensure that all servers in the same chassis are powered off before the update.



### iLKM and SEKM considerations

The following are iLKM and SEKM considerations during firmware updates:

- When iLKM mode is enabled on a controller, iDRAC firmware downgrade or upgrade fails when attempted from an iLKM to a
noniLKM iDRAC version. iDRAC firmware upgrade or downgrade passes when performed with the iLKM versions.

- When SEKM mode is enabled on a controller, iDRAC firmware downgrade or upgrade fails when attempted from a SEKM to a
non-SEKM iDRAC version. iDRAC firmware upgrade or downgrade passes when performed with the SEKM versions.

- PERC firmware downgrade fails when SEKM or iLKM is enabled.



### LC logs during firmware updates

The following is the behavior of Lifecycle Controller (LC) logs during firmware updates:

- When a firmware update is tried on a hot plugged disk, a duplicate PR7 message is displayed in the LC logs.
- When the job status is in the **Running** and there is no status update from the update modules, the job times out after 6
hours and it is marked as failed.

- If the job status is in the **Running** state, the firmware update job may be marked as failed after an iDRAC reboot.
- After upgrading the iDRAC firmware, you may notice a difference in the timestamp that is displayed in the LC logs. The time
that is displayed in the LC log may differ from the NTP/BIOS time for a few logs during an iDRAC reset.

- After updating the PERC12 or HBA12 controller firmware using the host operating system, iDRAC may generate the ENC12
and PDR8 messages for drives that are associated with these controllers.

- LC logs are displayed when communication is lost and restored during a GPU firmware update.



### Supported components in MX platforms for firmware updates

The following table provides information about whether a system restart is required when firmware is updated for a particular
component in MX platform.

**NOTE:** When multiple firmware updates are applied through out-of-band methods, the updates are ordered in the most
efficient possible manner to reduce unnecessary system restart.

**Table 13. Firmware update—supported components for MX platforms**

|Component Name|Firmware Rollback<br>Supported? (Yes or<br>No)|Out-of-band—<br>System Restart<br>Required?|In-band—System<br>Restart Required?|Lifecycle<br>Controller UI—<br>Restart Required?|
|---|---|---|---|---|
|Diagnostics|No|No|No|No|
|Operating system Driver<br>Pack|No|No|No|No|
|iDRAC|Yes|No|No*|Yes|
|BIOS|Yes|Yes|Yes|Yes|
|RAID Controller|Yes|Yes|Yes|Yes|
|BOSS|Yes|Yes|Yes|Yes|
|NVDIMM|No|Yes|Yes|Yes|
|Backplanes|Yes|Yes|Yes|Yes|
|Enclosures|Yes|Yes|No|Yes|
|NIC|Yes|Yes|Yes|Yes|
|Power Supply Unit|No|No|No|No|
|CPLD|No|Yes|Yes|Yes|
|FC Cards|Yes|Yes|Yes|Yes|
|NVMe PCIe SSD drives|Yes|No|No|No|
|SAS/SATA hard drives|No|Yes|Yes|No|

- Indicates that though a system restart is not required, iDRAC must be restarted to apply the updates. iDRAC communication
and monitoring may temporarily be interrupted.

When you check for updates, the version that is marked as **Available** does not always indicate that it is the latest version
available. Before you install the update, ensure that the version you choose to install is newer than the version currently
installed. If you want to control the version that iDRAC detects, create a custom repository using Dell Repository Manager
(DRM) and configure iDRAC to use that repository to check for updates.

**NOTE:** For any update requiring iDRAC reset/ reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is
fully ready by waiting for a few seconds of interval with a maximum timeout of 5 minutes before using any other command.

**NOTE:** After you update the PERC or HBA firmware to 12.2 and later versions, perform the Cold Reboot operation instead
of the Warm Reboot operation. The Cold Boot operation ensures that the Try Counter is reset to unlock the drive security
and prevent any Authority-locked-out conditions for in-band updates.

**NOTE:** After updating the PERC12 or HBA12 controller firmware using the host operating system, iDRAC may generate the
ENC12 and PDR8 messages for drives associated with these controllers



### Updating single device firmware using web interface

Use the firmware images available on the local system or from a repository on a network share (CIFS, NFS, HTTP, HTTPS, or
FTP).

Before updating the firmware using single device update method, make sure that you have downloaded the firmware image to a
location on the local system.

**NOTE:** Ensure that the file name for the single component DUP does not have any blank space.

**NOTE:** Before updating the chassis manager, ensure that the iDRAC firmware version supports the corresponding chassis
manager version. For more information about the supported iDRAC version, see the Chassis Manager firmware release
notes.

To update single device firmware using iDRAC web interface:

1. Go to **Maintenance** - **System Update** . The **Firmware Update** page is displayed.
2. On the **Update** tab, select **Local** as the **Location Type** .
**NOTE:** If you select Local, ensure that you download the firmware image to a location on the local system. Select one
file to be staged to iDRAC for update. You can select additional files one file at a time, for uploading to iDRAC. The files
are uploaded to a temporary space on iDRAC and is limited to approximately 300 MB.

3. Click **Browse**, select the firmware image file for the required component, and then click **Upload** . The required firmware is
uploaded to iDRAC.
4. After the upload is complete, the **Update Details** section displays each firmware file that is uploaded to iDRAC and its
status.

**NOTE:** If the firmware image file is valid and was successfully uploaded, the **Contents** column displays a plus icon

( ) icon next to the firmware image file name. Expand the name to view the **Device Name**, **Current**, and **Available**
**firmware version** information.

5. Select the required firmware file and do one of the following:
  - For firmware images that do not require a host system reboot, click **Install** (only available option). For example, the
iDRAC firmware file.

  - For firmware images that require a host system reboot, click **Install and Reboot** or **Install Next Reboot** . Updates that
require a system reboot are staged and committed to run on the next system reboot. Only one system reboot is required
to perform all updates.

  - To cancel the firmware update, click **Cancel** .
**NOTE:** When you click **Install**, **Install and Reboot**, or **Install Next Reboot**, the message `Updating Job Queue` is

displayed.

6. To display the **Job Queue** page, click **Job Queue** . Use this page to view and manage the staged firmware updates or click
**OK** to refresh the current page and view the status of the firmware update.

**NOTE:** If you navigate away from the page without saving the updates, an error message is displayed and all the
uploaded content is lost.

**NOTE:** You cannot proceed further if the session gets expired after uploading the firmware file. This issue can only be
resolved by RACADM `reset` .

**NOTE:** After the firmware update is completed, an error message is displayed - `RAC0508: An unexpected error`
```
    occurred. Wait for few minutes and retry the operation. If the problem persists,
```

`contact service provider.` . This is expected. You can wait for sometime and refresh the browser. Then you

are redirected to the login page.

7. If the job status is **Completed, Virtual AC Pending**, perform the physical AC power cycle or virtual AC power cycle of the
server.

**NOTE:** Use the Redfish URI (redfish/v1/Chassis/System.Embedded.1/Actions/Oem/DellOemChassis.ExtendedReset
with ResetType=PowerCycle and FinalState=On/Off (to either power on the system after the VAC is completed or
leave it in the Off state) to perform the virtual power cycle. If any other method is used to perform the AC power cycle,
then the real-time job may fail. But the updated version still reflects on the AC power cycle.



### Scheduling automatic firmware updates

You can create a periodic recurring schedule for iDRAC to check for new firmware updates. At the scheduled date and time,
iDRAC connects to the specified destination, checks for new updates, and applies or stages all applicable updates. A log file is
created on the remote server, which contains information about server access and staged firmware updates.

It is recommended that you create a repository using Dell Repository Manager (DRM) and configure iDRAC to use this
repository to check for and perform firmware updates. Using an internal repository enables you to control the firmware and
versions available to iDRAC and helps avoid any unintended firmware changes.

**NOTE:** [For more information about DRM, see OpenManage Manuals > Repository Manager.](https://www.dell.com/support/home/en-us/products/software_int/software_ent_systems_mgmt)

You can schedule automatic firmware updates using the iDRAC web interface or RACADM.

**NOTE:** IPv6 address is not supported for scheduling automatic firmware updates.



#### Scheduling automatic firmware update using web interface

To schedule automatic firmware update using web Interface:

**NOTE:** Do not create the next scheduled occurrence of an automatic update job if a job is already Scheduled. It overwrites
the current scheduled job.

1. In the iDRAC web interface, go to **Maintenance** - **System Update** - **Automatic Update** .
The **Firmware Update** page is displayed.

2. Click the **Automatic Update** tab.
3. Select the **Enable Automatic Update** option.
4. Select any of the following options to specify if a system reboot is required after the updates are staged:
  - **Schedule Updates**  - Stage the firmware updates but do not reboot the server.
  - **Schedule Updates and reboot Server**  - Enables server reboot after the firmware updates are staged.
5. Select any of the following to specify the location of the firmware images:
  - **Network**  - Use the catalog file from a network share (CIFS, NFS, HTTP or HTTPS, TFTP). Enter the network share
location details.

**NOTE:** While specifying the network share settings, it is recommended to avoid special characters for user name and
password or percent encode the special characters.

  - **FTP**  - Use the catalog file from the FTP site. Enter the FTP site details.
  - **HTTP** or **HTTPS**  - Allows catalog file streaming and via HTTP and HTTPS file transfer.
6. Based on the selection in step 5, enter the network settings or the FTP settings.

For information about the fields, see the **iDRAC Online Help** .

7. In the **Update Window Schedule** section, specify the start time for the firmware update and the frequency of the updates
(daily, weekly, or monthly).

For information about the fields, see the **iDRAC Online Help** .

8. Click **Schedule Update** .

The next scheduled job is created in the job queue. Five minutes after the first instance of the recurring job starts, the job
for the next time period is created.



#### Scheduling automatic firmware update using RACADM

To schedule automatic firmware update, use the following commands:

- To enable automatic firmware update:

```
  racadm set lifecycleController.lcattributes.AutoUpdate.Enable 1

```

- To view the status of automatic firmware update:

```
  racadm get lifecycleController.lcattributes.AutoUpdate

```

- To schedule the start time and frequency of the firmware update:

```
  racadm AutoUpdateScheduler create -u username –p password –l <location> [-f
  catalogfilename -pu <proxyuser> -pp<proxypassword> -po <proxy port> -pt <proxytype>]
  -time < hh:mm> [-dom < 1 – 28,L,’*’> -wom <1-4,L,’*’> -dow <sun-sat,’*’>] -rp <1-366>
  -a <applyserverReboot (1-enabled | 0-disabled)>

```

For example,

  - To automatically update firmware using a CIFS share:

```
    racadm AutoUpdateScheduler create -u admin -p pwd -l //1.2.3.4/CIFS-share –f
    cat.xml -time 14:30 -wom 1 -dow sun -rp 5 -a 1

```

  - To automatically update firmware using FTP:

```
    racadm AutoUpdateScheduler create -u admin -p pwd -l ftp.mytest.com -pu puser –pp
    puser –po 8080 –pt http –f cat.xml -time 14:30 -wom 1 -dow sun -rp 5 -a 1

```

- To view the current firmware update schedule:

```
  racadm AutoUpdateScheduler view

```

- To disable automatic firmware update:

```
  racadm set lifecycleController.lcattributes.AutoUpdate.Enable 0

```

- To clear the schedule details:

```
  racadm AutoUpdateScheduler clear



### Configuring quick reboot after firmware updates

```

You can use RACADM or Redfish to enable quick reboot to speed up the start of the firmware update.

Before you perform the firmware update, ensure that the value of the attribute `RebootJobType` is set as **`Powercycle`**

Do one of the following to set `RebootJobType` :

- Run the following RACADM commands:

```
  get System.Job.RebootJobType

  set System.Job.RebootJobType Powercycle
```

- Run the GET and PATCH operation of the URI:

```
  /redfish/v1/Managers/iDRAC.Embedded.1/Oem/Dell/DellAttributes/System.Embedded.1?
  $select=Job.1.RebootJobType

  /redfish/v1/Managers/iDRAC.Embedded.1/Oem/Dell/DellAttributes/System.Embedded.1

  BODY:

  {"Attributes":{"Job.1.RebootJobType":"Powercycle"}}



### Updating device firmware using RACADM

```

To update device firmware using RACADM, use the `update` subcommand. For more information, see the **Integrated Dell**
**Remote Access Controller RACADM CLI** [available at iDRAC Manuals.](https://www.dell.com/idracmanuals)

Examples:

- Upload the update file from a remote HTTP share:

```
  racadm update -f <updatefile> -u admin -p mypass -l http://1.2.3.4/share

```

- Upload the update file from a remote HTTPS share:

```
  racadm update -f <updatefile> -u admin -p mypass -l https://1.2.3.4/share

```

- To generate a comparison report using an update repository:

```
  racadm update –f catalog.xml –l //192.168.1.1 –u test –p passwd --verifycatalog

```

- To perform all applicable updates from an update repository using `myfile.xml` as a catalog file and perform a graceful
reboot:

```
  racadm update –f “myfile.xml” –b “graceful” –l //192.168.1.1 –u test –p passwd

```

- To perform all applicable updates from an FTP update repository using `Catalog.xml` as a catalog file:

```
  racadm update –f “Catalog.xml” –t FTP –e 192.168.1.20/Repository/Catalog



### Updating firmware using CMC web interface

```

You can update iDRAC firmware for blade servers using the CMC Web interface.

To update iDRAC firmware using the CMC Web interface:

1. Log in to CMC Web interface.
2. Go to **iDRAC Settings** - **Settings** - **CMC** .

The **Deploy iDRAC** page is displayed.

3. Click **Launch iDRAC** Web interface and perform **iDRAC Firmware Update** .



### Updating firmware using DUP

Before you update firmware using Dell Update Package (DUP), make sure to:

- Install and enable the IPMI and managed system drivers.
- Enable and start the Windows Management Instrumentation (WMI) service if your system is running Windows operating
system,

**NOTE:** While updating the iDRAC firmware using the DUP utility in Linux, if you see error messages such as `usb 5-2:`

`device descriptor read/64, error -71` displayed on the console, ignore them.

- If the system has ESX hypervisor installed, then for the DUP file to run, make sure that the "usbarbitrator" service is stopped
using command: `service usbarbitrator stop`

Some versions of DUPs are constructed in ways that conflict with each other. This happens over time as new
versions of the software are created. A newer version of software may drop support for legacy devices. Support for
new devices may be added. Consider, for example, the two DUPs Network_Firmware_NDT09_WN64_21.60.5.EXE and
Network_Firmware_8J1P7_WN64_21.60.27.50.EXE. The devices supported by these DUPs fit into three groups.

- Group A are legacy devices supported only by NDT09.
- Group B are devices supported by both NDT09 and 8J1P7.
- Group C are new devices supported only by 8J1P7.

Consider a server that has one or more devices from each of Groups A, B, and C. If the DUPs are used one at a time they should
be successful. Using NDT09 by itself updates the devices in group A and group B. Using 8J1P7 by itself updates devices in group
B and group C. However, if you try to use both DUPs at the same time that may attempt to create two updates for the Group B
devices at the same time. That may fail with a valid error: "Job for this device is already present". The update software is unable
to resolve the conflict of two valid DUPs attempting two valid updates on the same devices at the same time. At the same time
both DUPs are required to support Group A and Group C devices. The conflict extends to performing rollbacks on the devices
too. For best practice it is suggested to use each DUP individually.

To update iDRAC using DUP:

1. Download the DUP based on the installed operating system and run it on the managed system.
2. Run the DUP.

The firmware is updated. A system restart is not required after firmware update is complete.



### Updating firmware using remote RACADM

1. Download the firmware image to the TFTP or FTP server. For example, `C:\downloads\firmimg.d9`
2. Run the following RACADM command:

TFTP server:

  - Using `fwupdate` command:

```
    racadm -r <iDRAC IP address> -u <username> -p <password> fwupdate -g -u -a <path>

   path
```

the location on the TFTP server where `firmimg.d9` is stored.

  - Using `update` command:

```
    racadm -r <iDRAC IP address> -u <username> -p <password> update —f <filename>

```

FTP server:

  - Using `fwupdate` command:

```
    racadm -r <iDRAC IP address> -u <username> -p <password> fwupdate –f <ftpserver IP>
    <ftpserver username> <ftpserver password> –d <path>

   path

```

the location on the FTP server where `firmimg.d9` is stored.

  - Using `update` command:

```
    racadm -r <iDRAC IP address> -u <username> -p <password> update —f <filename>

```

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Updating firmware using Lifecycle Controller Remote Services

For information to update the firmware using Lifecycle Controller–Remote Services, see _Lifecycle Controller Remote Services_
_Quick Start Guide_ [available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)



### Updating CMC firmware from iDRAC

In the PowerEdge FX2/FX2s chassis, you can update the firmware for the Chassis Management Controller and any component
that can be updated by CMC and shared by the servers from iDRAC.

Before applying the update, make sure that:

- Servers are not allowed to power-up by CMC.
- Chassis with LCD must display a message indicating “update is in-progress”.
- Chassis without LCD must indicate the update progress using LED blinking pattern.
- During the update, chassis action power commands are disabled.

The updates for components such as Programmable System-on-Chip (PSoC) of IOM that requires all the servers to be idle, the
update is applied on the next chassis power-up cycle.



#### CMC settings to update CMC firmware from iDRAC

In the PowerEdge FX2/FX2s chassis, before performing the firmware update from iDRAC for CMC and its shared components,
do the following:

1. Launch the CMC Web interface
2. Go to **iDRAC Settings** - **Settings** - **CMC** .

The **Deploy iDRAC** page is displayed.

3. From the **Chassis Management at Server Mode**, select **Manage and Monitor**, and the click **Apply** .



#### iDRAC settings to update CMC firmware

In the PowerEdge FX2/FX2s chassis, before updating the firmware for CMC and its shared components from iDRAC, do the
following settings in iDRAC:

1. Go to **iDRAC Settings** - **Settings** - **CMC** .
2. Click on **Chassis Management Controller Firmware Update**

The **Chassis Management Controller Firmware Update Settings** page is displayed.

3. For **Allow CMC Updates Through OS and Lifecycle Controller**, select **Enabled** to enable CMC firmware update from
iDRAC.

4. Under **Current CMC Setting**, make sure that **Chassis Management at Server Mode** option displays **Manage and**
**Monitor** . You can set this in CMC.



### Rebootless updates

From iDRAC release 6.10.00.00, iDRAC supports rebootless updates. This feature enables you to perform firmware update from
iDRAC without rebooting the host server to initiate and perform the update in a pre-OPERATING SYSTEM environment. To
identify whether the DUP supports sideband update, there are tags to identify if the DUP firmware supports sideband direct
update (PLDM, NVMe-MI, so forth) and/or UEFI FMP update method and type of payload present in the DUP.

When iDRAC inventories the components, it decides if the particular component supports direct sideband update or legacy UEFI
FMP-based update, and requires host reboot or not.

**NOTE:** Some devices like Network adapters may need a power cycle for a firmware update.

Two properties specific to PLDM firmware update capabilities are listed in the software inventory **PLDMCapabilitiesDuringUpdate** and **PLDMFDPCapabilitiesDuringUpdate** . These parameters are available only for devices
that support PLDM firmware update.

**NOTE:** The PLDM-based update feature is supported only on Platforms with iDRAC 1GB memory.

The iDRAC/ LC update modules handle the reboot or rebootless methods based on the support. Following are the different
update methods:

- Sideband Direct update reboot identified at runtime
- Sideband Direct updates no reboot.
- SSM (UEFI FMP based)/ SMA-based update
- Redstone FPGA, PDB CPLD update from iDRAC
- CPLD update from iDRAC
**NOTE:** In case of repository updates, the application updates that do not require host reboot must be performed
immediately.

**NOTE:** For direct updates (realtime FW updates) from iDRAC, there is an LCLOG (SUP200, SUP0518, SUP516) with a
device description (friendly FQDD information) instead of the Product description.

**NOTE:** When NVMe drives are behind PERC (in the front) and directly attached in the rear backplane or the opposite way,
then rebootless update does not work for the direct attached drives.

**NOTE:** If you perform firmware updates using LC UI for storage components capable of rebootless updates, the updates
fail. Hence, use iDRAC interfaces for all firmware updates.



## Viewing and managing staged updates

You can view and delete the scheduled jobs including configuration and update jobs. This is a licensed feature. All jobs queued to
run during the next reboot can be deleted.

**NOTE:** When any update or other tasks and jobs are in-progress, do not reboot or shutdown or AC power cycle the
host or iDRAC by any mode (manual or "Ctrl+Alt+Del" keys or other through iDRAC interfaces). The system (host and
iDRAC) should always be rebooted/shutdown gracefully when no tasks or jobs are running in iDRAC or host. Ungraceful
shutdown or interrupting an operation can cause unpredictable results such as firmware corruption, generate core files,
RSODs, YSODs, error events in LCL, so on.

**NOTE:** For any update requiring iDRAC reset/ reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is
fully ready by waiting for few seconds of interval with maximum timeout of 5 minutes before using any other command.



### Viewing and managing staged updates using iDRAC web interface

To view the list of scheduled jobs using iDRAC web interface, go to **Maintenance** - **Job Queue** . The **Job Queue** page displays
the status of jobs in the Lifecycle Controller job queue. For information about the displayed fields, see the **iDRAC Online Help** .

To delete job(s), select the job(s) and click **Delete** . The page is refreshed and the selected job is removed from the Lifecycle
Controller job queue. You can delete all the jobs queued to run during the next reboot. You cannot delete active jobs, that is,
jobs with the status **Running** or **Downloading** .

You must have Server Control privilege to delete jobs.



### Viewing and managing staged updates using RACADM

To view the staged updates using RACADM, use `jobqueue` sub-command. For more information, see the Integrated Dell
Remote Access Controller RACADM CLI Guide.



## Rolling back device firmware

You can roll back the firmware for iDRAC or any device that Lifecycle Controller supports, even if the upgrade was previously
performed using another interface. For example, if the firmware was upgraded using the Lifecycle Controller UI, you can roll
back the firmware using the iDRAC web interface. You can perform firmware rollback for multiple devices with one system
reboot.

The Dell 14 [th] generation PowerEdge servers have a single iDRAC firmware. Rolling back the iDRAC firmware also rolls back the
Lifecycle Controller firmware.

It is recommended to keep the firmware updated to ensure you have the latest features and security updates. Roll back an
update or install an earlier version if you encounter any issues after an update. To install an earlier version, use Lifecycle
Controller to check for updates and select the version that you want to install.

For the details about supported and unsupported components for firmware rollback, see Supported components in MX
platforms for firmware updates.

You can perform firmware rollback for the following components:

- iDRAC with Lifecycle Controller
- BIOS
- Network Interface Card (NIC)
- Power Supply Unit (PSU)
- RAID Controller
- Backplane
**NOTE:** You cannot perform firmware rollback for Diagnostics, Driver Packs, and CPLD.

Before rolling back the firmware, make sure that:

- You have Configure privilege to roll back iDRAC firmware.
- You have Server Control privilege and have enabled Lifecycle Controller to roll back firmware for any other device other than
the iDRAC.

- Change the NIC mode to **Dedicated** if the mode is set as **Shared LOM** .

You can roll back the firmware to the previously installed version using any of the following methods:

- iDRAC web interface
- CMC web interface (not supported on MX platforms)
- OME-Modular web interface (Supported on MX platforms)
- CMC RACADM CLI (not supported on MX platforms)
- iDRAC RACADM CLI
- Lifecycle Controller UI
- Lifecycle Controller-Remote Services
- Redfish API



### Rollback firmware using iDRAC web interface

To roll back device firmware:

1. In the iDRAC Web interface, go to **Maintenance** - **System Update** - **Rollback** .
The **Rollback** page displays the devices for which you can rollback the firmware. You can view the device name, associated
devices, currently installed firmware version, and the available firmware rollback version.

2. Select one or more devices for which you want to rollback the firmware.
3. Based on the selected devices, click **Install and Reboot** or **Install Next Reboot** . If only iDRAC is selected, then click
**Install** .
When you click **Install and Reboot** or **Install Next Reboot**, the message “Updating Job Queue” is displayed.

4. Click **Job Queue** .

The **Job Queue** page is displayed, where you can view and manage the staged firmware updates.

**NOTE:**

   - While in rollback mode, the rollback process continues in the background even if you navigate away from this page.

An error message appears if:

  - You do not have Server Control privilege to rollback any firmware other than the iDRAC or Configure privilege to rollback
iDRAC firmware.

  - Firmware rollback is already in-progress in another session.
  - Updates are staged to run or already in running state.

If Lifecycle Controller is disabled or in recovery state and you try to perform a firmware rollback for any device other than
iDRAC, an appropriate warning message is displayed along with steps to enable Lifecycle Controller.



### Rollback firmware using CMC web interface

To roll back using the CMC Web interface:

1. Log in to CMC Web interface.
2. Go to **iDRAC Settings** - **Settings** - **CMC** .

The **Deploy iDRAC** page is displayed.

3. Click **Launch iDRAC** and perform device firmware rollback as mentioned in the Rollback firmware using iDRAC web

interface.



### Rollback firmware using RACADM

1. Check the rollback status and the FQDD using the `swinventory` command:

```
  racadm swinventory

```

For the device for which you want to rollback the firmware, the `Rollback Version` must be `Available` . Also, note the
FQDD.

2. Rollback the device firmware using:

```
  racadm rollback <FQDD>

```

[For more information, see Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Rollback firmware using Lifecycle Controller

For information, see _Dell Lifecycle Controller User's Guide_ [available at iDRAC manuals .](https://www.dell.com/idracmanuals)



### Rollback firmware using Lifecycle Controller-Remote Services

For information, see _Lifecycle Controller Remote Services Quick Start Guide_ [available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)



### Recovering iDRAC

iDRAC supports two operating system images to make sure a bootable iDRAC. In the event of an unforeseen catastrophic error
and you lose both boot paths:

- iDRAC bootloader detects that there is no bootable image.
- System Health and Identify LED is flashed at ~1/2 second rate. (LED is located on the back of a rack and tower servers and
on the front of a blade server.)

- Bootloader is now polling the SD card slot.
- Format an SD card with FAT using a Windows operating system, or EXT3 using a Linux operating system.
- Copy **firmimg.d9** to the SD card.
- Insert the SD card into the server.
- Bootloader detects the SD card, turns the flashing LED to solid amber, reads the firmimg.d9, reprograms iDRAC, and then
reboots iDRAC.



## Easy Restore

Easy Restore uses the Easy Restore flash memory to back up the data. When you replace the motherboard and power on the
system, the BIOS queries the iDRAC and prompts you to restore the backed-up data. The first BIOS screen prompts you to
restore the Service Tag, licenses, and UEFI diagnostic application. The second BIOS screen prompts you to restore system
configuration settings. If you choose not to restore data on the first BIOS screen and do not set the Service Tag by another
method, then the first BIOS screen is displayed again. The second BIOS screen is displayed only once.

**NOTE:**

  - System configurations settings are backed-up only when Collect System Inventory On Reboot (CSIOR) is enabled.
Ensure that Lifecycle Controller and CSIOR are enabled.

  - Easy Restore does not back up other data such as firmware images, vFlash data, or add-in cards data.
**NOTE:** While replacing the motherboard, you have to manually choose Liquid cooled or Air cooled. Incorrect selection of
these options leads to thermal issues in the platform and in such case reach out to Dell Tech Support for the recovery.

After you replace the system board on your server, Easy Restore allows you to automatically restore the following data:

- System Service Tag
- Asset Tag
- Licenses data
- UEFI Diagnostics application
- System configuration settings—BIOS, iDRAC, and NIC
**NOTE:** In servers with iDRAC release 3.00.00.00 and above, Easy Restore automatically proceeds in 5 minutes if there is no
user interaction.

Following are the time duration details that are required for some restoring actions:

- Restoring system contents like Diagnostics, System Event Log (SEL), and OEM ID Module typically takes less than a minute.
- Restoring system configuration data (iDRAC, BIOS, NIC) may take several minutes (sometimes around 10 min) to complete.
**NOTE:** During this time, there is no indication or progress bar and the server might be rebooted a couple of times to finish
restoring the configuration.



## Monitoring iDRAC using other Systems Management tools

You can discover and monitor iDRAC using Dell Management Console or Dell OpenManage Essentials. You can also use Dell
Remote Access Configuration Tool (DRACT) to discover iDRACs, update firmware, and set up Active Directory. For more
information, see the respective user’s guides.



## Support Server Configuration Profile — Import and Export

Server Configuration Profile (SCP) allows you to import and export server configuration files.

**NOTE:** You need admin privileges to perform Export and Import SCP task.

You can import and export from local management station, and from a Network Share via CIFS, NFS, HTTP or HTTPS. Using
SCP, you can select and import or export component level configurations for BIOS, NIC and RAID. You can import and export
SCP to the local management station or to a CIFS, NFS, HTTP, or HTTPS network share. You can either import and export
individual profiles of iDRAC, BIOS, NIC, and RAID, or all of them together as a single file.

You can specify preview import or export of the SCP where the job is running and configuration result is generated but none of
the configuration has applied.

A job is created once the import or export is initiated through the GUI. The status of the jobs can be viewed on the Job Queue
page.

**NOTE:**

  - Only Host Name or IP Address are accepted for destination address.
  - You can browse to a specific location to import the server configuration files. You need to select the correct server
configuration file that you want to import. For example, import.xml.

  - Depending on the exported file format (that you selected), the extension is added automatically. For example,
`export_system_config.xml` .

  - While exporting, SCP file name may change. For example con.xml to _con.xml.
  - SCP applies the full configuration in a single job with minimal number of reboots. However, in a few system
configurations some attributes change the operation mode of a device or may create subdevices with new attributes.
When this occurs, SCP may be unable to apply all settings during a single job. Review the ConfigResult entries for the
job to resolve any pending configuration settings.

SCP allows you to perform OS deployment (OSD) using a single xml/json file across multiple systems. You can also perform
existing operations such as configurations and repository updates all at once.

SCP also allows to export and import of SSH public keys for all iDRAC users. There are 4 SSH public keys for all users.

Following are the steps for OS deployment using SCP:

1. Export SCP file
2. SCP file contains all the suppressed attributes that are needed to perform OSD.
3. Edit / update the OSD attributes and then perform import operation.
4. These OSD attributes are then validated by SCP orchestrator.
5. SCP orchestrator performs the configuration and repository updates specified in SCP file.
6. After configuration and updates are done, host OS shutdowns.
**NOTE:** Only CIFS and NFS share is supported for hosting OS media.

7. SCP orchestrator initiates the OSD by attaching the drivers for the selected operating system and then initiates one time
boot to the OS media present in NFS / Share.
8. LCL shows the progress of the job.
9. Once BIOS boots to the OS media, SCP job shows as Complete.
10. The attached media and OS media will be automatically detached after 65535 seconds or after the duration specified by

`OSD.1#ExposeDuration` attribute.

For detailed information on the overall feature along with deployment workflow refer to Using Server Configuration Profiles to
Deploy Operating Systems to Dell PowerEdge Servers .



### Importing server configuration profile using iDRAC web interface

Before importing the SCP file, it is recommended to perform the Import Preview operation. This operation identifies any
potential formatting issues or invalid attribute settings without impacting the state of the server.

To import the server configuration profile:

1. Go to **Configuration** - **Server Configuration Profile** .
The **Server Configuration Profile** page is displayed.

2. Select one of the following to specify the location type:
  - **Local** to import the configuration file saved in a local drive.
  - **Network Share** to import the configuration file from CIFS or NFS share.
  - **HTTP or HTTPS** to import the configuration file from a local file using HTTP or HTTPS file transfer.
**NOTE:** Depending on the location type, you must enter the Network Settings or HTTP or HTTPS settings. If the proxy is
configured for HTTP or HTTPS, proxy settings are also required.

3. Select the components listed in **Import Components** option.
4. Select the **Shutdown** type.
5. Select the **Maximum wait time** to specify the wait time before the system shuts down after the import is complete.
6. Click **Import** .



### Exporting server configuration profile using iDRAC web interface

To export the server configuration profile:

1. Go to **Configuration** - **Server Configuration Profile**
The **Server Configuration Profile** page is displayed.

2. Click **Export** .
3. Select one of the following to specify the location type:
  - **Local** to save the configuration file on a local drive.
  - **Network Share** to save the configuration file on a CIFS or NFS share.
  - **HTTP or HTTPS** to save the configuration file to a local file using HTTP/HTTPS file transfer.
**NOTE:** Depending on the location type, you must enter the Network Settings or HTTP/HTTPS settings. If the proxy is
configured for HTTP/HTTPS, proxy settings are also required.

4. Select the components that you must back up the configuration for.
5. Select the **Export type** from the following are the options:
  - **Basic** : Creates a nondestructive snapshot of the configuration.
  - **Replacement Export** : Replaces the server settings with new settings or restores server settings to a known baseline.
  - **Clone Export** : Clones the settings from one server to another server with identical hardware. All settings except I/O
identity are updated. The settings in this export are destructive when uploaded to another system.

6. Select an **Export file format** .
7. Select **Additional export items** .
8. Click **Export** .



## Secure Boot Configuration from BIOS Settings or F2

UEFI Secure Boot is a technology that eliminates a major security void that may occur during a handoff between the UEFI
firmware and UEFI operating system (operating system). In UEFI Secure Boot, each component in the chain is validated and
authorized against a specific certificate before it is allowed to load or run. Secure Boot removes the threat and provides
software identity checking at every step of the boot—Platform firmware, Option Cards, and operating system BootLoader.

The Unified Extensible Firmware Interface (UEFI) Forum—an industry body that develops standards for pre-boot software
—defines Secure Boot in the UEFI specification. Computer system vendors, expansion card vendors, and operating system
providers collaborate on this specification to promote interoperability. As a portion of the UEFI specification, Secure Boot
represents an industry-wide standard for security in the pre-boot environment.

When enabled, UEFI Secure Boot prevents the unsigned UEFI device drivers from being loaded, displays an error message, and
does not allow the device to function. You must disable Secure Boot to load the unsigned device drivers.

On the Dell 14 [th] generation and later versions of PowerEdge servers, you can enable or disable the Secure Boot feature by using
different interfaces (RACADM, WSMAN, REDFISH, and LC-UI).



##### Acceptable file formats

The Secure Boot policy contains only one key in PK, but multiple keys may reside in KEK. Ideally, either the platform
manufacturer or platform owner maintains the private key corresponding to the public PK. Third parties (such as operating
system providers and device providers) maintain the private keys corresponding to the public keys in KEK. In this way, platform
owners or third parties may add or remove entries in the db or dbx of a specific system.

The Secure Boot policy uses db and dbx to authorize pre-boot image file execution. To run an image file, associate it with a key
or hash value in db, and not associate with a key or hash value in dbx. Any attempts to update the contents of db or dbx must
be signed by a private PK or KEK. Any attempts to update the contents of PK or KEK must be signed by a private PK.

**Table 14. Acceptable file formats**

|Policy Component|Acceptable File Formats|Acceptable File Extensions|Max records allowed|
|---|---|---|---|
|**PK**|X.509 Certificate (binary DER<br>format only)|1.<br>`.cer`|One|
|||2.<br>`.der`<br>3. .crt||
|**KEK**|X.509 Certificate (binary DER<br>format only) Public Key Store|1.<br>`.cer`<br>2.<br>`.der`<br>3.<br>`.crt`<br>4.<br>`.pbk`|More than one|
|**DB and DBX**|X.509 Certificate (binary<br>DER format only) EFI image<br>(system BIOS will calculate<br>and import image digest)|1.<br>`.cer`<br>2.<br>`.der`<br>3.<br>`.crt`<br>4.<br>`.efi`|More than one|

The Secure Boot Settings feature can be accessed by clicking System Security under System BIOS Settings. To go to System
BIOS Settings, press F2 when the company logo is displayed during POST.

- By default, Secure Boot is Disabled and the Secure Boot policy is set to Standard. To configure the Secure Boot Policy, you
must enable Secure Boot.

- When the Secure Boot mode is set to Standard, it indicates that the system has default certificates and image digests or
hash loaded from the factory. This caters to the security of standard firmware, drivers, option-roms, and boot loaders.

- To support a new driver or firmware on a server, the respective certificate must be enrolled into the database of Secure
Boot certificate store. Therefore, the Secure Boot Policy must be configured to Custom.

When the Secure Boot Policy is configured as Custom, it inherits the standard certificates and image digests loaded in the
system by default, which you can modify. Secure Boot Policy configured as Custom allows you to perform operations such
as View, Export, Import, Delete, Delete All, Reset, and Reset All. Using these operations, you can configure the Secure Boot
Policies.

Configuring the Secure Boot Policy to Custom enables the options to manage the certificate store by using various actions
such as Export, Import, Delete, Delete All, Reset, and Rest All on PK, KEK, database, and DBX. You can select the policy
(PK/KEK/DB/DBX) on which you want to make the change and perform appropriate actions by clicking the respective link.
Each section has links to perform the Import, Export, Delete, and Reset operations. Links are enabled based on what is
applicable, which depends on the configuration at the time. Delete All and Reset All are the operations that have an impact
on all the policies. Delete All deletes all the certificates and image digests in the Custom policy, and Rest All restores all the
certificates and image digests from the Standard or Default certificate store.



## BIOS recovery

The BIOS recovery feature allows you to manually recover the BIOS from a stored image. The BIOS is checked when the
system is powered-on and if a corrupt or compromised BIOS is detected, an error message is displayed. You can then initiate
the process of BIOS recovery using RACADM. To perform a manual BIOS recovery, see the iDRAC RACADM Command Line
[Interface Reference Guide available at iDRAC Manuals.](https://www.dell.com/idracmanuals)



# 4 Data Processing Unit (DPU)

A Data Processing Unit (DPU) is a system on a chip that consists of ARM cores, a NIC ASIC, and acceleration engines. A
DPU is programmable and potentially capable of running an operating system. DPU support is added to iDRAC from release
6.00.30.00 onwards. DPUs combine network connectivity with CPU cores independent from the Hypervisor or operating
system, allowing acceleration and offload services. DPUs distinguish themselves from traditional offload engines by their
flexibility, programmability, and ability to host a wide variety of services.

**NOTE:** DPUs require an iDRAC9 Enterprise or Datacenter license.

Use of DPU offers the following advantages:

- Isolates infrastructure services from the host operating system and applications.
- Enables an environment to deliver new services independent of the host application environment.
- Enables hardware acceleration to perform data-intensive operations at wire-speed.
- Free up server/x86 CPU cores for enabling customer applications single socket and small form factor edge platforms

After the DPU operating system is booted, additional PCIe Functions can be initialized. So, the BIOS PCIe enumeration (and host
Operating System/Hypervisor boot process) shall happen only after DPU operating system has booted or ready.

iDRAC allows you to configure the DPU operating system Ready Mode (Boot Synchronization) settings against each DPU
capable slot. Possible values are:

- **Enabled:** DPU does participate in holding the BIOS PCIe enumeration and host Operating System/Hypervisor boot process.
- **Disabled:** DPU does not participate in holding the BIOS PCIe enumeration and host Operating System/Hypervisor boot
process.

Points to consider about DPU:

- Only a few slots are DPU capable. iDRAC allows you to configure DPU Boot Synchronization against those slots alone.
- DPU Boot Synchronization settings are Slot-based (Not Identity based). That is, if the DPU device is moved to a different
slot, the device behaves as per the newly inserted Slot configuration.

- DPU Boot Synchronization settings are configurable even without the presence of a DPU device.
- After discovery, if the slot does not have a DPU device that is installed, then DPU Boot Synchronization configurations are
NOT effective.

- Individual DPU operating system Ready and Overall DPU operating system Ready are reported in the LCL.
- On an unsupported DPU platform, while performing a system erase, the DPU LC logs display the SYS560 message ( `some`
`of the DPU devices failed to reset)` . On a supported DPU platform, if the DPU is not present and a system
erase is performed, the logs display the SYS564 message ( `unable to perform system erase of DPU because`
`there is no DPU available in the system` ).

- When the NVIDIA BF3 cards are disabled from the BIOS configuration, the **Status** in the **Network Devices** page. ( **System**
  - **Overview**   - **Network Devices**   - **Summary** ) in iDRAC UI is displayed in Green.
- When the PCIe slots of NVIDIA BF3 DPU cards are **Boot Driver Disabled** in the BIOS configuration ( **System BIOS**
**Settings**  - **Integrated Devices**  - **Slot Disablement)**, PR7 and PR8 logs are displayed in the iDRAC LC logs.

- The device hardware inventory is displayed for the NVIDIA BF3 cards when the PCIe slot is **Boot Drive Disabled** from the
BIOS configuration.

- After you perform the powercycle operation and set the powersavingmode ON on the Nokia card, the BIOS may stop and
the Non-Maskable Interrupt (NMI) message is displayed. In this case, reboot the system.

- When the Nokia RAN DPU card is set to the powersaving mode, critical LC logs are displayed.

Following are the features of DPU:

- You are allowed to configure DPU Boot Synchronization for each DPU capable slot.
- You are allowed to configure the DPU operating system Ready timeout value in minutes (from 0 to 30).
- Based on the user configuration, BIOS PCIe enumeration and host Operating System/Hypervisor boot process happens only
after each **Boot synchronization enabled DPU** has reported that DPU operating system is ready.

- Other PCIe functions that are exposed by DPU operating system are enumerated by BIOS and reported in the iDRAC
Hardware Inventory.

- BIOS displays various DPU-related messages during the POST:
  - **Discovering Data Processing Unit(s) ...** —While discovering the DPU devices
  - **Discovering Data Processing Unit(s) ... Done** —When DPU discovery is completed.
  - **Initializing Data Processing Unit (Do NOT reboot the system)** —At 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100%
completion of boot-synchronization

  - **Initializing Data Processing Unit... Done** —When 100% completion of boot-synchronization and boot-synchronization
is successful.

- Individual and overall DPU operating System Ready messages are reported in LCL.
**NOTE:** The DPU operating system Ready flag persists across the Host reboots, and the DPU operating system Ready
message is logged for each Host reboot.

- If any LC-SSM task is present, then BIOS skips the waiting on DPU boot synchronization.



### Inventory and Monitoring of DPUs

iDRAC system inventory provides the make and model of the DPU while monitoring the health of the DPU cores, peripherals,
and the installed operating system. `GET` is used to retrieve inventory information. This action ensures that no unauthorized
devices are installed maliciously. Using the GET operation, you can periodically check the DPU health. If the system is healthy, it
returns a payload response and status update to provide health updates.

To detect malicious or accidental DPU operating system installations use GET operation. Using the GET operation that you can
retrieve operating system name, vendor name, version, and status of the DPU operating system.

You can view the installed DPU from iDRAC UI ( **System** - **Inventory** - **Firmware) Inventory**

**Redfish**

Using Redfish, you can set a one-time boot configuration which is used to boot the DPU with the configured value once on
reboot. On the next reboot, the DPU boot is based on the Boot Order that is configured. Redfish also allows you ARM-UEFI and
[BMC firmware updates. For more information, see developer.dell.com.](https://developer.dell.com/)

**Serial Console**

To access serial control using RACADM, login to iDRAC SSH - `Racadm> console dpu`

**Co-ordinated Shutdown**

The ESXi operating system shutdown process internally shuts down the DPU ESXio to protect ESXio File corruption.

**Intel Processing Unit**

During part replacement of an Intel Processing Unit (IPU) device, the part replacement (PR) messages are not displayed in the
iDRAC LC logs.



# 5 Plugin Management

Plugins are software components that extend the functionality of iDRAC. Plugins are individually packaged in a DUP. Plugins are
not deleted on iDRAC reboot, reset, or AC cycles. The iDRAC sanitize operation or LC wipe operation is used to remove the
plugins. You can enable or disable the plugins.

To manage plugins from the iDRAC UI, go to **iDRAC Settings** - **Settings** - **Plugins** .

**NOTE:** You must have login, control and configure privileges to install, update, and remove the plugins. You can only view
the installed plugins with login privileges.

**Topics:**

- Installing a plugin
- Uninstalling a plugin
- Restarting a plugin
- Enabling or disabling a plugin
- Viewing the plugin details



## Installing a plugin

Install a plugin if you want to extend the functionality of iDRAC. Some plugins are preinstalled into iDRAC from Dell factory for
17G PowerEdge servers.

**NOTE:** For more information about the Dell Connectivity Client (DCC) plugin, see the Dell Connectivity Client Overview
[document at dell.com/support.](https://www.dell.com/support/home/en-us)

When a Non-Standard Device List (Non-SDL) card is installed, iDRAC cannot detect an SDK plugin. Manually search and install
the SDK plug-in. iDRAC firmware update, downgrade, or rollback does not have an impact on the functionality of plugins.

1. Download the plugin from Dell.com.
2. Go to **iDRAC Settings** - **Settings** - **Plugins** .
3. Click **Add/Update** .
4. Select the **Location Type** and click **Choose File** and select the plugin file.
5. Click **Upload** .

If a plugin is valid, a success message is displayed after the plugin installed. If the hardware is not present, an LC message is
logged indicating that the plugin is not started. If the plugin is invalid, an error message is displayed.



## Uninstalling a plugin

1. Go to **iDRAC Settings** - **Settings** - **Plugins** .
2. Select the plugin and click **Uninstall** .

The selected plugin is uninstalled.



## Restarting a plugin

You can restart a plugin that is installed in iDRAC.

1. Go to **iDRAC Settings** - **Settings** - **Plugins** .
2. Click **Restart** .



## Enabling or disabling a plugin

You can enable or disable a plugin.

1. Go to **iDRAC Settings** - **Settings** - **Plugins** .
2. Select the plugin and click **Enable** or **Disable** .



## Viewing the plugin details

You can view the details of the installed plugins.

1. Go to **iDRAC Settings** - **Settings** - **Plugins** .
2. Select the plugin and click **Details** .

The details of the plugin are displayed.



# 6 Configuring iDRAC

iDRAC enables you to configure iDRAC properties, set up users, and set up alerts to perform remote management tasks.

Before you configure iDRAC, make sure that the iDRAC network settings and a supported browser is configured, and the
required licenses are updated. For more information about the licensable feature in iDRAC, see iDRAC licenses .

You can configure iDRAC using:

- iDRAC Web Interface
- RACADM
- Remote Services (see **Lifecycle Controller Remote Services User’s Guide** )
- IPMITool (see **Baseboard Management Controller Management Utilities User’s Guide** )
**NOTE:** When any task or job is in-progress, do not reboot or shutdown orAC power cycle the host or iDRAC by any
mode (manual or "Ctrl+Alt+Del" keys or options provided through iDRAC interfaces). The system (host and iDRAC) should
always be rebooted or shutdown gracefully when no tasks or jobs are running in iDRAC or host. Ungraceful shutdown or
interrupting an operation can cause unpredictable results such as firmware corruption, generate core files, RSODs, YSODs,
error events in LCL, so on.

To configure iDRAC:

1. Log in to iDRAC.
2. Modify the network settings if required.
**NOTE:** If you have configured iDRAC network settings, using iDRAC Settings utility during iDRAC IP address setup, then
ignore this step.

3. Configure interfaces to access iDRAC.
4. Configure front panel display.
5. Configure System Location if required.
6. Configure time zone and Network Time Protocol (NTP) if required.
7. Establish any of the following alternate communication methods to iDRAC:
  - IPMI or RAC serial
  - IPMI serial over LAN
  - IPMI over LAN
  - SSH
8. Obtain the required certificates.
9. Add and configure iDRAC users with privileges.
10. Configure and enable e-mail alerts, SNMP traps, or IPMI alerts.
11. Set the power cap policy if required.
12. Enable the Last Crash Screen.
13. Configure virtual console and virtual media if required.
14. Configure vFlash SD card if required.
15. Set the first boot device if required.
16. Set the OS to iDRAC Pass-through if required.
**Topics:**

- Viewing iDRAC information
- Modifying network settings
- Cipher suite selection
- FIPS mode
- Configuring services
- Using VNC client to manage remote server
- Configuring front panel display
- Configuring time zone and NTP
- Setting first boot device
- Enabling or disabling OS to iDRAC Pass-through
- Obtaining certificates
- Configuring multiple iDRACs using RACADM
- Disabling access to modify iDRAC configuration settings on host system
- Self Heal



## Viewing iDRAC information

You can view the basic properties of iDRAC.



### Viewing iDRAC information using web interface

In the iDRAC Web interface, go to **iDRAC Settings** - **Overview** to view the following information related to iDRAC. For
information about the properties, see **iDRAC Online Help** .

**iDRAC Details**

- Device Type
- Hardware Version
- Firmware Version
- Firmware Update
- RAC time
- IPMI version
- Number of Possible Sessions
- Number of Current Sessions
- IPMI Version



## iDRAC Service Module

- Status



### Connection View

- State
- Switch Connection ID
- Switch Port Connection ID
**Current Network Settings**

- iDRAC MAC Address
- Active NIC Interface
- DNS Domain Name
**Current IPv4 Setting**

- IPv4 Enabled
- DHCP
- Current IP Address
- Current Subnet Mask
- Current Gateway
- Use DHCP to Obtain DNS Server Address
- Current Preferred DNS Server
- Current Alternate DNS Server
**Current IPv6 Settings**

- IPv6 Enable
- Autoconfiguration
- Current IP Address
- Current IP Gateway
- Link Local Address
- Use DHCPv6 to obtain DNS
- Current Preferred DNS Server
- Current Alternate DNS Server



### Viewing iDRAC information using RACADM

To view iDRAC information using RACADM, see `getsysinfo` or `get` sub-command details provided in the **Integrated Dell**
**Remote Access Controller RACADM CLI Guide** .



## Modifying network settings

After configuring the iDRAC network settings using the iDRAC Settings utility, you can also modify the settings through the
iDRAC Web interface, RACADM, Lifecycle Controller, and Server Administrator (after booting to the operating system). For
more information on the tools and privilege settings, see the respective user’s guides.

To modify the network settings using iDRAC Web interface or RACADM, you must have **Configure** privileges.

**NOTE:** Changing the network settings may terminate the current network connections to iDRAC.



### Modifying network settings using web interface

To modify the iDRAC network settings:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** - **Network** - **Network Settings** .
The **Network** page is displayed.

2. Specify the network settings, common settings, IPv4, IPv6, IPMI, and/or VLAN settings as per your requirement and click
**Apply** .

If you select **Auto Dedicated NIC** under **Network Settings**, when the iDRAC has its NIC Selection as shared LOM (1, 2,
3, or 4) and a link is detected on the iDRAC dedicated NIC, the iDRAC changes its NIC selection to use the dedicated NIC.
If no link is detected on the dedicated NIC, then the iDRAC uses the shared LOM. The switch from shared to dedicated
time-out is five seconds and from dedicated to shared is 30 seconds. You can configure this time-out value using RACADM
or WSMan.

For information about the various fields, see the **iDRAC Online Help** .

**NOTE:** If the iDRAC is using DHCP and has obtained a lease for its IP address, it is released back to the DHCP server's
address pool when NIC or Ipv4 or DHCP is disabled.



### Modifying network settings using local RACADM

To generate a list of available network properties, use the command

```
 racadm get iDRAC.Nic

```

To use DHCP to obtain an IP address, use the following command to write the object `DHCPEnable` and enable this feature.

```
 racadm set iDRAC.IPv4.DHCPEnable 1

```

The following example shows how the command may be used to configure the required LAN network properties:

```
 racadm set iDRAC.Nic.Enable 1
 racadm set iDRAC.IPv4.Address 192.168.0.120
 racadm set iDRAC.IPv4.Netmask 255.255.255.0
 racadm set iDRAC.IPv4.Gateway 192.168.0.120
 racadm set iDRAC.IPv4.DHCPEnable 0
 racadm set iDRAC.IPv4.DNSFromDHCP 0
 racadm set iDRAC.IPv4.DNS1 192.168.0.5
 racadm set iDRAC.IPv4.DNS2 192.168.0.6
 racadm set iDRAC.Nic.DNSRegister 1

```

```
 racadm set iDRAC.Nic.DNSRacName RAC-EK00002
 racadm set iDRAC.Nic.DNSDomainFromDHCP 0
 racadm set iDRAC.Nic.DNSDomainName MYDOMAIN

```

**NOTE:** If `iDRAC.Nic.Enable` is set to **0**, the iDRAC LAN is disabled even if DHCP is enabled.



### Configuring IP filtering

In addition to user authentication, use the following options to provide additional security while accessing iDRAC:

- IP filtering limits the IP address range of the clients accessing iDRAC. It compares the IP address of an incoming login to
the specified range and allows iDRAC access only from a management station whose IP address is within the range. All other
login requests are denied.

- When repeated login failures occur from a particular IP address, it prevents the address from logging in to iDRAC for a
preselected time span. If you unsuccessfully log in up to two times, you are allowed to log in again only after 30 seconds. If
you unsuccessfully log in more than two times, you are allowed to log in again only after 60 seconds.

**NOTE:** This features supports upto 5 IP ranges. You van view / set this feature using RACADM and Redfish.

As login failures accumulate from a specific IP address, they are registered by an internal counter. When the user successfully
logs in, the failure history is cleared and the internal counter is reset.

**NOTE:** When login attempts are prevented from the client IP address, few SSH clients may display the message: `ssh`

`exchange identification: Connection closed by remote host` .



#### Configure IP filtering using iDRAC web interface

You must have Configure privilege to perform these steps.

To configure IP filtering:

1. In iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** - **Network** - **Network Settings** - **Advanced Network**
**Settings** .
The **Network** page is displayed.

2. Click **Advanced Network Settings** .

The **Network Security** page is displayed.

3. Specify the IP filtering settings using **IP Range Address** and **IP Range Subnet Mask** .

For more information about the options, see **iDRAC Online Help** .

4. Click **Apply** to save the settings.
**Federal Information Processing Standards**  - FIPS is a set of standards used by the United States government agencies
and contractors. FIPS Mode is intended to meet the requirements of FIPS 140-2 level 1. For more information about FIPS,
refer to the FIPS User Guide for iDRAC, and CMC for non MX platforms.

**NOTE:** Enabling **FIPS Mode** resets iDRAC to the default settings.



#### Configuring IP filtering using RACADM

You must have Configure privilege to perform these steps.

To configure IP filtering, use the following RACADM objects in the `iDRAC.IPBlocking` group:

- RangeEnable
- RangeAddr
- RangeMask

The `RangeMask` property is applied to both the incoming IP address and to the `RangeAddr` property. If the results are
identical, the incoming login request is allowed to access iDRAC. Logging in from IP addresses outside this range results in an
error.

**NOTE:** Configuring IP filtering supports up to 5 IP ranges.

The login proceeds if the following expression equals zero:

```
 RangeMask & (<incoming-IP-address> ^ RangeAddr)

&
```

Bitwise AND of the quantities

```
^
```

Bitwise exclusive-OR

**Examples for IP Filtering**

The following RACADM commands block all IP addresses except 192.168.0.57:

```
 racadm set iDRAC.IPBlocking.RangeEnable 1
 racadm set iDRAC.IPBlocking.RangeAddr 192.168.0.57
 racadm set iDRAC.IPBlocking.RangeMask 255.255.255.255

```

To restrict logins to a set of four adjacent IP addresses (for example, 192.168.0.212 through 192.168.0.215), select all but the
lowest two bits in the mask:

```
 racadm set iDRAC.IPBlocking.RangeEnable 1
 racadm set iDRAC.IPBlocking.RangeAddr 192.168.0.212
 racadm set iDRAC.IPBlocking.RangeMask 255.255.255.252

```

The last byte of the range mask is set to 252, the decimal equivalent of 11111100b.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Cipher suite selection

Cipher Suite Selection can be used to limit the ciphers in iDRAC or client communications and determine how secure the
connection will be. It provides another level of filtering the effective in-use TLS Cipher Suite. These settings can be configured
through iDRAC web interface, RACADM, and WSMan command line interfaces.



### Configuring cipher suite selection using iDRAC web interface

**CAUTION: Using OpenSSL Cipher command to parse strings with invalid syntax may lead to unexpected errors.**

**NOTE:** This is an advanced security option. Before you configure this option, ensure that you have thorough knowledge of
the following:

  - The OpenSSL Cipher String Syntax and its use.
  - Tools and Procedures to validate the resultant Cipher Suite configuration to ensure that the results align with the
expectations and requirements.

**NOTE:** Before you configure the Advanced Settings for TLS Cipher Suites, ensure that you are using a supported web
browser.

**NOTE:** Irrespective of the TLS version configured in iDRAC, firefox browser in RHEL-8.4 allows you to launch iDRAC GUI.

**NOTE:** To obtain the list of ciphers for a specific port, run the nmap tool.

To add custom cipher strings:

1. In iDRAC web interface, go to **iDRAC Settings** - **Services** - **Web Server** .
2. Click **Set Cipher String** under the **Customer Cipher String** option.

The **Set Custom Cipher String** page is displayed.

3. In the **Custom Cipher String** field, enter a valid string and click **Set Cipher String** .
**NOTE:**

   - [For more information about cipher strings, see the OpenSSLpage.](https://www.openssl.org/docs/man1.0.2/man1/ciphers.html)
   - TLS 1.3 is not supported.
4. Click **Apply** .

Setting the custom cipher string terminates the current iDRAC session. Wait for a few minutes before you open a new
iDRAC session.



### Configuring cipher suite selection using RACADM

To configure cipher suite selection using RACADM, use any one of the following commands:

- `racadm set idraC.webServer.customCipherString ALL:!DHE-RSA-AES256-GCM-SHA384:!DHE-RSA-`
```
  AES256-GCM-SHA384
```

- `racadm set idraC.webServer.customCipherString ALL:-DHE-RSA-CAMELLIA256-SHA`
- `racadm set idraC.webServer.customCipherString ALL:!DHE-RSA-AES256-GCM-SHA384:!DHE-RSA-`
```
  AES256-SHA256:+AES256-GCM-SHA384:-DHE-RSA-CAMELLIA256-SHA

```

For more information about these objects, see **iDRAC RACADM Command Line Interface Reference Guide** available on the
[iDRAC Manualspage.](https://www.dell.com/support/home/us/en/19/products/software_int/software_ent_systems_mgmt/remote_ent_sys_mgmt)



## FIPS mode

FIPS is a computer security standard that United States government agencies and contractors must use. Starting from version
iDRAC 2.40.40.40, iDRAC supports enabling FIPS mode.

iDRAC will be officially certified to support FIPS mode in the future.



##### Difference between FIPS-mode supported and FIPS-validated

Software that has been validated by completing the Cryptographic Module Validation Program is referred to as FIPS-validated.
Because of the time it takes to complete FIPS-validation, not all versions of iDRAC are validated. For information about the
latest status of FIPS-validation for iDRAC, see the Cryptographic Module Validation Program page on the NIST website.



### Enabling FIPS Mode

**CAUTION: Enabling FIPS mode resets iDRAC to factory-default settings. If you want to restore the settings,**
**back up the server configuration profile (SCP) before you enable FIPS mode, and restore the SCP after iDRAC**
**restarts.**

**NOTE:** If you reinstall or upgrade iDRAC firmware, FIPS mode gets disabled. From iDRAC release 6.10.00.00, FIPS mode is
in enabled state even after iDRAC firmware update.



#### Enabling FIPS mode using web interface

1. On the iDRAC web interface, navigate to **iDRAC Settings** - **Connectivity** - **Network** - **Network Settings** - **Advanced**
**Network Settings** .

2. In **FIPS Mode**, select **Enabled** and click **Apply** .
**NOTE:** Enabling FIPS Mode resets iDRAC to the default settings.

3. A message appears prompting you to confirm the change. Click **OK** .

iDRAC restarts in FIPS mode. Wait for at least 60 seconds before you reconnect to iDRAC.

4. Install a trusted certificate for iDRAC.
**NOTE:** The default SSL certificate is not allowed in FIPS mode.

**NOTE:** Some iDRAC interfaces, such as the standards-compliant implementations of IPMI and SNMP, do not support
FIPS-compliance.



#### Enabling FIPS mode using RACADM

Use RACADM CLI to run the following command:

```
 racadm set iDRAC.Security.FIPSMode <Enable>



### Disabling FIPS mode

```

To disable FIPS mode, you must reset iDRAC to the factory-default settings.



## Configuring services

You can configure and enable the following services on iDRAC:

**Local Configuration** Disable access to iDRAC configuration (from the host system) using Local RACADM and iDRAC
Settings utility.

**Web Server** Enable access to iDRAC web interface. If you disable the web interface, remote RACADM also gets
disabled. Use local RACADM to re-enable the web server and remote RACADM.

**SEKM Configuration** Enables secure enterprise key management functionality on iDRAC using a client server architecture.

**SSH** Access iDRAC through firmware RACADM.

**Remote RACADM** Remotely access iDRAC.

**SNMP Agent** Enables support for SNMP queries (GET, GETNEXT, and GETBULK operations) in iDRAC.

**Automated System**
**Recovery Agent**

Enable Last System Crash Screen.

**Redfish** Enables support for Redfish RESTful API.

**VNC Server** Enable VNC server with or without SSL encryption.



### Configuring services using web interface

To configure the services using iDRAC Web interface:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Services** .
The **Services** page is displayed.

2. Specify the required information and click **Apply** .

For information about the various settings, see the **iDRAC Online Help** .

**NOTE:** Do not select the **Prevent this page from creating additional dialogs** check-box. Selecting this option
prevents you from configuring services.

You can configure **SEKM** from iDRAC Settings page. Click **iDRAC Settings**  - **Services**  - **SEKM Configuration** .

**NOTE:** For detailed step by step procedure for configuring SEKM, see the **iDRAC Online Help** .

**NOTE:** When **Security (Encryption)** mode is changed from **None** to **SEKM**, Real-Time job is not available. But it will
be added to Staged job list. However, Real-Time job is successful when the mode is changed from **SEKM** to **None** .

Verify the following when changing the value of the **Username** Field in Client Certificate section on the KeySecure server
(for ex: changing the value from **Common Name (CN)** to **User ID (UID)** )

a. While using an existing account:

   - Verify in the iDRAC SSL certificate that, instead of the **Common Name** field, the **User name** field now matches the
existing username on the KMS. If they don't, then you will have to set the username field and regenerate the SSL
certificate again, get it signed on KMS and re-upload to iDRAC.
b. While using a new user account:

   - Make sure the **User name** string matches the username field in the iDRAC SSL certificate.
   - If they don't match, then you will need to reconfigure the iDRAC KMS attributes Username and Password.
   - Once the certificate is verified to contain the username, then the only change that needs to be made is to change the
key ownership from the old user to the new user to match the newly created KMS username.

While using Vormetric Data Security Manager as KMS, ensure that the Common Name (CN) field in iDRAC SSL certificate
matches with the host name added to Vormetric Data Security Manager. Otherwise, the certificate may not import
successfully.

**NOTE:**

   - **Rekey** option will be disabled when `racadm sekm getstatus` reports as **Failed** .
   - SEKM only supports **Common name**, **User ID**, or **Organization Unit** for **User Name** field under Client certificate.
   - If you are using a third party CA to sign the iDRAC CSR, ensure that the third party CA supports the value **UID** for
**User Name** field in Client certificate. If it is not supported, use **Common Name** as the value for **User Name** field.

   - If you are using Username and Password fields, ensure that KMS server supports those attributes.
**NOTE:** For KeySecure key management server,

   - while creating an SSL certificate request, you must include at least one of the IP addresses or DNS name of the key
management server in **Subject Alternative Name** field.

   - the IP address must be in the following format: IP:xxx.xxx.xxx.xxx.



### Configuring services using RACADM

To enable and configure services using RACADM, use the `set` command with the objects in the following object groups:

- iDRAC.LocalSecurity
- iDRAC.LocalSecurity
- iDRAC.SSH
- iDRAC.Webserver
- iDRAC.Racadm
- iDRAC.SNMP

[For more information about these objects, see Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### SEKM Functionalities

The following are the SEKM functionalities available in iDRAC:

1. **SEKM Key Purge Policy** —iDRAC provides a policy setting that allows you to configure iDRAC to purge old unused keys
at the Key Management Server (KMS) when Rekey operation is performed. You can set the iDRAC read-writable attribute
KMSKeyPurgePolicy to one of the following values:

  - Keep All Keys – This is the default setting and is the existing behavior where iDRAC leaves all the keys on the KMS
untouched while performing Rekey operation.

  - Keep N and N-1 keys – iDRAC deletes all keys at the KMS except the current (N) and previous key (N-1) when
performing Rekey operation.
2. **KMS Key Purge on SEKM Disable** —As part of the Secure Enterprise Key Manager (SEKM) solution, iDRAC allows you
to disable SEKM on the iDRAC. Once SEKM is disabled, the keys that are generated by iDRAC at the KMS are unused and
remain at the KMS. This feature is for allowing iDRAC to delete those keys when SEKM is disabled. iDRAC provides a new
option “-purgeKMSKeys” to existing legacy command “racadm sekm disable” which will let you purge keys at the KMS when
SEKM is disabled on iDRAC.

**NOTE:** If SEKM is already disabled and you want to purge old keys, you must re-enable SEKM, then disable passing in
option -purgeKMSKeys.

3. **Key Creation Policy** —As part of this release, iDRAC has been preconfigured with a Key Creation Policy. Attribute
KeyCreationPolicy is read-only and set to "Key per iDRAC" value.

  - iDRAC read-only attribute iDRAC.SEKM.KeyIdentifierN reports the Key Identifier that is created by the KMS.

```
    racadm get iDRAC.SEKM.KeyIdentifierN

```

  - iDRAC read-only attribute iDRAC.SEKM.KeyIdentifierNMinusOne reports the previous Key Identifier after performing a
Rekey operation.

```
    racadm get iDRAC.SEKM.KeyIdentifierNMinusOne

```

4. **SEKM Rekey** —iDRAC provides the following two options from the UI to rekey your SEKM solution, either Rekey iDRAC or
PERC. It is recommended to rekey the iDRAC since this rekeys all SEKM Secure capable and enabled devices.

  - **SEKM iDRAC Rekey [Rekey on iDRAC.Embedded.1 FQDD]** —When performing `racadm sekm rekey`
`iDRAC.Embedded.1`, all SEKM Secure capable/Enabled devices are Rekeyed with a new key from KMS and this
is common key to all SEKM enabled devices. iDRAC Rekey operation can also be performed from iDRAC UI- **iDRAC**
**Settings**    - **Services**    - **SEKM Configuration**    - **Rekey** . After performing this operation, the change in the Key can be
validated by reading KeyIdentifierN and KeyIdentifierNMinusOne attributes.

  - **SEKM PERC Rekey ( Rekey On Controller [Example RAID.Slot.1-1] FQDD )** —When performing `racadm sekm`
`rekey <controller FQDD>`, the corresponding SEKM enabled controller gets rekeyed to the currently active iDRAC
common key created from KMS. Storage Controller Rekey operation can also be performed from iDRAC UI- **Storage**    **Controllers**    - **<controller FQDD>**    - **Actions**    - **Edit**    - **Security**    - **Security(Encryption)**    - **Rekey** .

**NOTE:** When you run Rekey on PERC while the controller and iDRAC keys are in sync, you may get a **config job**
**failure**, or configuration job may succeed but the key is not changed when you run the job. You can use iDRAC
Rekey option to fix this issue.

5. **SEKM Rekey only from Redfish** : The following two SEKM Rekey options are supported from Redfish:
  - **SEKM iDRAC Schedule Rekey** —Sends a new key generation request from iDRAC for automatic change of the SEKM
keys based on a recurrence interval that is configured by the user.

  - **SEKM iDRAC Periodic Sync with Key Management Server (KMS)** —Enables automatic change of the SEKM keys
based on the recurrence interval configured on the KMS Server. iDRAC polls for any new key that is generated by the
KMS server.

For detailed information about all supported SEKM features and deployment workflow, see the white paper - Enable
[OpenManage Secure Enterprise Key Manager (SEKM) on Dell PowerEdge Servers](https://dl.dell.com/content/manual24526085-enable-openmanage-secure-enterprise-key-manager-on-dell-poweredge-servers.pdf?language=en-us)

**NOTE:** When SEKM is enabled on PERC, a CTL136 log is generated. However, in PERC 12 while performing rekey, the
CTL136 log is not generated. This is because the controller does not create a key request as keys are provided as part of
the rekey command.



### iLKM functionalities

iDRAC Local Key Management (iLKM) is a security solution much like the Secure Enterprise Key Management (SEKM). This
solution is ideal for users who do not plan to use SEKM but would like to secure devices using iDRAC. However, customers can
migrate to SEKM at a later point in time.

When using iLKM, iDRAC acts as key manager and generates authentication keys that are used to secure storage devices. To
use iLKM as key management system, go to **iDRAC Settings** - **Services** - **iDRAC Key Management** and select iLKM from
the drop-down menu.

**NOTE:** iLKM requires a combination of SEKM license and iDRAC Enterprise, or SEKM license and iDRAC data center
license.

Provide a Passphrase and a Key ID to enable iLKM. Both Passphrase and Key ID lengths should be a maximum of 255
characters.

**NOTE:**

  - iLKM can be viewed and configured through iDRAC UI, RACADM, and Redfish interfaces.
  - It is possible to enable or disable security on supported NVMe SED when iDRAC is in the iLKM security mode.
  - It is not possible to enable, disable, or rekey iLKM in the System Lockdown mode.
  - iLKM currently only supports direct-attached NVMe SED that support TCG Opal 2.0 protocol and above. For servers
with PERC controllers, enable LKM on PERC using the existing the PERC LKM feature.

  - iLKM provides a rekey option, where you must provide the passphrase and key ID for authentication.
**Auto Secure Security Capable Drives**

- Option to request iDRAC to auto secure non-PERC attached NVMe SED and SAS SED behind a security enabled SAS HBA.
Drives are auto secured on a host reboot or on a drive hot plug.

- Option does not auto enable security on controllers such as PERC and SAS HBA.
- Option is enabled by default—you can be disable by using the RACADM command.
- Disable the option before repurposing a drive by using the cryptographic erase option (or PSID revert option) if the drive is
no longer required to be secured by iDRAC.

**NOTE:** NVMe direct-attached drives can be encryption capable and encryption not-capable drives. SEKM 044 logs are
generated for encryption not-capable drives because the plug-in status is verified for both the NVMe direct-attached drives
during the autosecure operation.

**NOTE:** PSID based revert operations can be performed only on the locked or foreign drives. PSID based revert operations
cannot be performed on the drives which are connected to PERC controller.

**NOTE:** Do not run power cycle on the host system immediately after enabling the **Auto Secure Security Capable Drives**
option. This may interrupt security enablement on the drives and might put the drives in an undefined security state.

**Transition from iLKM to SEKM**

You must provide an iLKM passphrase to authenticate the transition along with the SEKM configuration details. If the
authentication is successful, SEKM is enabled on iDRAC and the previous iLKM key ID is deleted. To transition from iLKM
to SEKM, do the following:

1. Set up the CSA certificate.
2. Configure SEKM settings.
3. Perform the iLKM to SEKM transition.



### Enabling or disabling HTTPS redirection

If you do not want automatic redirection from HTTP to HTTPs due to certificate warning issue with default iDRAC certificate or
as a temporary setting for debugging purpose, you can configure iDRAC such that redirection from http port (default is 80) to
https port (default is 443) is disabled. By default, it is enabled. You have to log out and log in to iDRAC for this setting to take
effect. When you disable this feature, a warning message is displayed.

You must have Configure iDRAC privilege to enable or disable HTTPS redirection.

An event is recorded in the Lifecycle Controller log file when this feature is enabled or disabled.

To disable the HTTP to HTTPS redirection:

```
 racadm set iDRAC.Webserver.HttpsRedirection Disabled

```

To enable HTTP to HTTPS redirection:

```
 racadm set iDRAC.Webserver.HttpsRedirection Enabled

```

To view the status of the HTTP to HTTPS redirection:

```
 racadm get iDRAC.Webserver.HttpsRedirection



## Using VNC client to manage remote server

```

You can use a standard open VNC client to manage the remote server using both desktop and mobile devices such as Dell Wyse
PocketCloud. When servers in data centers stop functioning, the iDRAC or the operating system sends an alert to the console
on the management station. The console sends an email or SMS to a mobile device with required information and launches
VNC viewer application on the management station. This VNC viewer can connect to OS/Hypervisor on the server and provide
access to keyboard, video, and mouse of the host server to perform the necessary remediation. Before launching the VNC
client, you must enable the VNC server and configure the VNC server settings in iDRAC such as password, VNC port number,
SSL encryption, and the time-out value. You can configure these settings using iDRAC Web interface or RACADM.

**NOTE:** VNC feature is licensed and is available in the iDRAC Enterprise or Datacenter license.

You can choose from many VNC applications or Desktop clients such as the ones from RealVNC or Dell Wyse PocketCloud.

Two VNC client sessions can be activated simultaneously. Second session is in Read-Only mode.

If a VNC session is active, you can only launch the Virtual Media using Launch Virtual Console and not the Virtual Console
Viewer.

If video encryption is disabled, the VNC client starts RFB handshake directly, and an SSL handshake is not required. During VNC
client handshake (RFB or SSL), if another VNC session is active or if a Virtual Console session is open, the new VNC client
session is rejected. After completion of the initial handshake, VNC server disables Virtual Console and allows only Virtual Media.
After termination of the VNC session, VNC server restores the original state of Virtual Console (enabled or disabled).

**NOTE:**

  - While launching a VNC session, if you get an RFB protocol error, change the VNC client settings to High quality and then
relaunch the session.

  - When iDRAC NIC is in shared mode and the host system is power cycled, the network connection is lost for a few
seconds. During this time, if you perform any action in the active VNC client, the VNC session may close. You must
wait for timeout (value configured for the VNC Server settings in the **Services** page in iDRAC Web interface) and then
re-establish the VNC connection.

  - If the VNC client window is minimized for more than 60 seconds, the client window closes. You must open a new VNC
session. If you maximize the VNC client window within 60 seconds, you can continue to use it.



### Configuring VNC server using iDRAC web interface

To configure the VNC server settings:

1. In the iDRAC Web interface, go to **Configuration** - **Virtual Console** .
The **Virtual Console** page is displayed.

2. In the **VNC Server** section, enable the VNC server, specify the password, port number, and enable or disable SSL
encryption.

For information about the fields, see the **iDRAC Online Help** .

3. Click **Apply** .

The VNC server is configured.



### Configuring VNC server using RACADM

To configure the VNC server, use the `set` command with the objects in `VNCserver` .

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Setting up VNC viewer with SSL encryption

While configuring the VNC server settings in iDRAC, if the **SSL Encryption** option was enabled, then the SSL tunnel application
must be used along with the VNC Viewer to establish the SSL encrypted connection with iDRAC VNC server.

**NOTE:** Most of the VNC clients do not have built-in SSL encryption support.

To configure the SSL tunnel application:

1. Configure SSL tunnel to accept connection on `<localhost>:<localport number>` . For example, 127.0.0.1:5930.
2. Configure SSL tunnel to connect to `<iDRAC IP address>:<VNC server port Number>` . For example,
192.168.0.120:5901.

3. Start the tunnel application.

To establish connection with the iDRAC VNC server over the SSL encrypted channel, connect the VNC viewer to the
localhost (link local IP address) and the local port number (127.0.0.1:<local port number>).



### Setting up VNC viewer without SSL encryption

In general, all Remote Frame Buffer (RFB) compliant VNC Viewers connect to the VNC server using the iDRAC IP address and
port number that is configured for the VNC server. If the SSL encryption option is disabled when configuring the VNC server
settings in iDRAC, then to connect to the VNC Viewer do the following:

In the **VNC Viewer** dialog box, enter the iDRAC IP address and the VNC port number in the **VNC Server** field.

The format is `<iDRAC IP address:VNC port number>`

For example, if the iDRAC IP address is 192.168.0.120 and VNC port number is 5901, then enter `192.168.0.120:5901` .



## Configuring front panel display

You can configure the front panel LCD and LED display for the managed system.

For rack and tower servers, two types of front panels are available:

- LCD front panel and System ID LED
- LED front panel and System ID LED

For blade servers, only the System ID LED is available on the server front panel since the blade chassis has the LCD.



### Configuring LCD setting

You can set and display a default string such as iDRAC name, IP, and so on or a user-defined string on the LCD front panel of
the managed system.



#### Configuring LCD setting using web interface

To configure the server LCD front panel display:

1. In iDRAC Web interface, go to **Configurations** - **System Settings** - **Hardware Settings** - **Front Panel configuration** .
2. In **LCD Settings** section, from the **Set Home Message** drop-down menu, select any of the following:
  - Service Tag (default)
  - Asset Tag
  - DRAC MAC Address
  - DRAC IPv4 Address
  - DRAC IPv6 Address
  - System Power
  - Ambient Temperature
  - System Model
  - Host Name
  - User Defined
  - None
**NOTE:** If you select **User Defined**, enter the required message in the text box.

**NOTE:** If you select **None**, home message is not displayed on the server LCD front panel.

3. Enable Virtual Console indication (optional). If enabled, the Live Front Panel Feed section and the LCD panel on the server
displays the `Virtual console session active` message when there is an active Virtual Console session.

4. Click **Apply** .

The server LCD front panel displays the configured home message.



#### Configuring LCD setting using RACADM

To configure the server LCD front panel display, use the objects in the `System.LCD` group.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Configuring LCD setting using iDRAC settings utility

To configure the server LCD front panel display:

1. In the iDRAC Settings utility, go to **Front Panel Security** .
The **iDRAC Settings.Front Panel Security** page is displayed.

2. Enable or disable the power button.
3. Specify the following:
  - Access to the front panel
  - LCD message string
  - System power units, ambient temperature units, and error display
4. Enable or disable the virtual console indication.

For information about the options, see the **iDRAC Settings Utility Online Help** .

5. Click **Back**, click **Finish**, and then click **Yes** .



### Configuring system ID LED setting

To identify a server, enable or disable System ID LED blinking on the managed system.



#### Configuring system ID LED setting using web interface

To configure the System ID LED display:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **Front Panel configuration** .
The **System ID LED Settings** page is displayed.

2. In **System ID LED Settings** section, select any of the following options to enable or disable LED blinking:
  - Blink Off
  - Blink On
  - Blink On 1 Day Timeout
  - Blink On 1 Week Timeout
  - Blink On 1 Month Timeout
3. Click **Apply** .

The LED blinking on the front panel is configured.



#### Configuring system ID LED setting using RACADM

To configure system ID LED, use the `setled` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Configuring time zone and NTP

You can configure the time zone in iDRAC and synchronize the iDRAC time using Network Time Protocol (NTP) instead of BIOS
or host system times. You must have Configure privilege to configure time zone or NTP settings. After you have updated the
NTP settings, log out of all current sessions, and then log in to iDRAC.

When the time zone is changed in iDRAC, the time and time zone offset in the timestamp are automatically adjusted. Select the
same time zone between Real-Time Clock (RTC) and iDRAC because time synchronization issues between BIOS and iDRAC can
lead to unexpected behavior. Enable the NTP settings in iDRAC to ensure timestamp accuracy.

**NOTE:** If NTP is enabled in iDRAC, and different time zones are set for Real-Time Clock (RTC) and iDRAC:

  - iDRAC synchronizes with the NTP server to obtain Coordinated Universal Time (UTC).
  - The timestamp displays `<date><local time><iDRAC time zone offset>` . Where `<local time>` = UTC

with time zone offset

**NOTE:** If NTP is disabled in iDRAC, and different time zones are set for RTC and iDRAC:

  - iDRAC synchronizes with RTC time as is. RTC can be either UTC or local depending on the operating system and its
settings.

  - The timestamp displays `<date><RTC><iDRAC time zone>`



### Configuring time zone and NTP using iDRAC web interface

To configure time zone and NTP using iDRAC web interface:

1. Go to **iDRAC Settings** - **Settings** - **Time zone and NTP Settings** .
The **Time zone and NTP** page is displayed.

2. To configure the time zone, from the **Time Zone** drop-down menu, select the required time zone, and then click **Apply** .
3. To configure NTP, enable NTP, enter the NTP server addresses, and then click **Apply** .

For information about the fields, see **iDRAC Online Help** .



### Configuring time zone and NTP using RACADM

To configure time zone and NTP, use the `set` command with the objects in the `iDRAC.Time` and `iDRAC.NTPConfigGroup`
group.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

**NOTE:** iDRAC syncs the time with the host (local time). Hence it is recommended to configure both iDRAC and host with
the same time zone so that the time sync is proper. If you want to change a time zone, you need to change it on both host
and iDRAC and then the host needs to reboot.



## Setting first boot device

You can set the first boot device for the next boot only or for all subsequent reboots. If you set the device to be used for all
subsequent boots, it remains as the first boot device in the BIOS boot order until it is changed again either from the iDRAC web
interface or from the BIOS boot sequence.

You can set the first boot device to one of the following:

- Normal Boot
- PXE
- BIOS Setup
- Local Floppy/Primary Removable Media
- Local CD/DVD
- Hard Drive
- Virtual Floppy
- Virtual CD/DVD/ISO
- Local SD Card
- Lifecycle Controller
- BIOS Boot Manager
- UEFI Device Path
- UEFI HTTP
- Virtual Network File 1
- Virtual Network File 2
**NOTE:**

  - BIOS Setup (F2), Lifecycle Controller (F10), and BIOS Boot Manager (F11) cannot be set as permanent boot device.
  - The first boot device setting in iDRAC Web Interface overrides the System BIOS boot settings.



### Setting first boot device using web interface

To set the first boot device using iDRAC Web interface:

1. Go to **Configuration** - **System Settings** - **Hardware Settings** - **First Boot Device** .
The **First Boot Device** page is displayed.

2. Select the required first boot device from the drop-down list, and click **Apply** .

The system boots from the selected device for subsequent reboots.

3. To boot from the selected device only once on the next boot, select **Boot Once** . Thereafter, the system boots from the first
boot device in the BIOS boot order.

For more information about the options, see the **iDRAC Online Help** .



### Setting first boot device using RACADM

- To set the first boot device, use the `iDRAC.ServerBoot.FirstBootDevice` object.
- To enable boot once for a device, use the `iDRAC.ServerBoot.BootOnce` object.

[For more information about these objects, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Setting first boot device using virtual console

You can select the device to boot from as the server is being viewed in the Virtual Console viewer before the server runs
through its boot-up sequence. Boot-once is supported by all devices listed in Setting first boot device.

To set the first boot device using Virtual Console:

1. Launch Virtual Console.
2. In the Virtual Console Viewer, from the **Next Boot** menu, set the required device as the first boot device.



### Enabling last crash screen

To troubleshoot the cause of a crash on the managed system, you can capture the system crash image using iDRAC.

**NOTE:** For information about Server Administrator, see the _OpenManage Installation Guide_ available on the OpenManage
manualspage..

The host system should have Windows Operating system to use this feature.

**NOTE:**

  - This feature is not applicable on Linux system.
  - This feature is independent of any agents or attributes.



## Enabling or disabling OS to iDRAC Pass-through

In servers that have Network Daughter Card (NDC) or embedded LAN On Motherboard (LOM) devices, you can enable the OS
to iDRAC Pass-through feature. This feature provides a high-speed bi-directional in-band communication between iDRAC and
the host operating system through a shared LOM, a dedicated NIC, or through the USB NIC. This feature is available for iDRAC
Enterprise or Datacenter license.

**NOTE:** iDRAC Service Module (iSM) provides more features for managing iDRAC through the operating system. For more
[information, see the iDRAC Service Module User's Guide available on the iDRAC Service Modulepage.](https://www.dell.com/support/home/us/en/19/products/software_int/software_ent_systems_mgmt/remote_ent_sys_mgmt/ent_sys_mgmt_idrac_svc_module)

When enabled through dedicated NIC, you can launch the browser in the host operating system and then access the iDRAC
Web interface. The dedicated NIC for the blade servers is through the Chassis Management Controller.

Switching between dedicated NIC or shared LOM does not require a reboot or reset of the host operating system or iDRAC.

You can enable this channel using:

- iDRAC web interface
- RACADM or WSMan (post operating system environment)
- iDRAC Settings utility (pre-operating system environment)

If the network configuration is changed through iDRAC Web interface, you must wait for at least 10 seconds before enabling OS
to iDRAC Pass-through.

If you are configuring the server using a Server Configuration Profile through RACADM, WSMan or Redfish and if the network
settings are changed in this file, then you must wait for 15 seconds to either enable OS to iDRAC Pass-through feature or set
the OS Host IP address.

Before enabling OS to iDRAC Pass-through, make sure that:

- iDRAC is configured to use dedicated NIC or shared mode (that is, NIC selection is assigned to one of the LOMs).
- Host operating system and iDRAC are in the same subnet and same VLAN.
- Host operating system IP address is configured.
- A card that supports OS to iDRAC Pass-through capability is installed.
- You have the Configure privilege.

When you enable this feature:

- In shared mode, the host operating system's IP address is used.
- In dedicated mode, you must provide a valid IP address of the host operating system. If more than one LOM is active, enter
the first LOM’s IP address.

If the OS to iDRAC Pass-through feature does not work after it is enabled, ensure that you check the following:

- The iDRAC dedicated NIC cable is connected properly.
- At least one LOM is active.
**NOTE:** Use the default IP address. Ensure that the IP address of the USB NIC interface is not in the same network subnet
as the iDRAC or host OS IP addresses. If this IP address conflicts with an IP address of other interfaces of the host system
or the local network, you must change it.

**NOTE:** If you launch iDRAC Service Module while USB NIC is in disabled state, the iDRAC Service Module changes the USB
NIC IP address to 169.254.0.1.

**NOTE:** Do not use 169.254.0.3 and 169.254.0.4 IP addresses. These IP addresses are reserved for the USB NIC port on the
front panel when an A/A cable is used.

**NOTE:** iDRAC may not be accessible from the host server using LOM-Passthrough when NIC teaming is enabled. Then,
iDRAC can be accessed from the host server OS using the iDRAC USB NIC or through the external network, via the iDRAC
dedicated NIC.



### Supported cards for OS to iDRAC Pass-through

The following table provides a list of cards that support the OS to iDRAC Pass-through feature using LOM.

**Table 15. OS to iDRAC Pass-through using LOM — supported cards**

|Category|Manufacturer|Type|
|---|---|---|
|NDC|Broadcom|●<br>5720 QP rNDC 1G BASE-T|
|NDC|Intel|●<br>x520/i350 QP rNDC 1G BASE-T|

In-built LOM cards also support the OS to iDRAC pass-through feature.



### Supported operating systems for USB NIC

For list of operating systems supported for USB NIC, see the respective release note at iDRAC Release Versions and Release
notes.

For Linux operating systems, configure the USB NIC as DHCP on the host operating system before enabling USB NIC.

For vSphere, you must install the VIB file before enabling USB NIC.

**NOTE:**

  - If you disable USB-NIC on the iDRAC while iSM is running in the OS, iSM service module status changes to
"Running(limited functionality)".

  - If you install iSM in the OS while USB NIC is disabled in the iDRAC, iSM automatically enables USB NIC in the iDRAC to
finish the installation. If needed, disable USB NIC after the installation is completed.

**NOTE:** To configure USB NIC as DHCP in Linux operating system or XenServer, refer to the operating system or hypervisor
documentation.



#### Installing VIB file

For vSphere operating systems, before enabling the USB NIC, you must install the VIB file.

To install the VIB file:

1. Using Win-SCP, copy the VIB file to `/tmp/` folder of the ESX-i host operating system.
2. Go to the ESXi prompt and run the following command:

```
  esxcli software vib install -v /tmp/ iDRAC_USB_NIC-1.0.0-799733X03.vib --no-sig-check

```

The output is:

```
  Message: The update completed successfully, but the system needs to be rebooted for
  the changes to be effective.
  Reboot Required: true
  VIBs Installed: Dell_bootbank_iDRAC_USB_NIC_1.0.0-799733X03
  VIBs Removed:
  VIBs Skipped:

```

3. Reboot the server.
4. At the ESXi prompt, run the command: `esxcfg-vmknic –l` .

The output displays the usb0 entry.



### Enabling or disabling an operating system to iDRAC Pass-through using web interface

To enable operating system to iDRAC Pass-through using web interface:

1. Go to **iDRAC Settings** - **Connectivity** - **Network** - **OS to iDRAC Pass-through** .
The **OS to iDRAC Pass-through** page is displayed.

2. Change the **State** to **Enabled** .
3. Select any of the following options for Pass-through Mode:
  - **LOM** —The operating system to iDRAC pass-through link between the iDRAC and the host operating system is
established through the LOM or NDC.

  - **USB NIC** —The operating system to iDRAC pass-through link between the iDRAC and the host operating system is
established through the internal USB bus.

**NOTE:** If you set the pass-through mode to LOM, ensure that:

   - The operating system and iDRAC are on the same subnet.
   - NIC selection in Network Settings is set to LOM.
4. If the server is connected in shared LOM mode, then the **OS IP Address** field is disabled.
**NOTE:** If the VLAN is enabled on the iDRAC, the LOM-Passthrough functions only in shared LOM mode with VLAN
taggings that are configured on the host.

**NOTE:**

   - When Pass-through mode is set to LOM, it is not possible to launch iDRAC from the host operating system after cold
boot.

   - The LOM Pass-through is removed using the Dedicated Mode feature.
5. If you select **USB NIC** as the pass-through configuration, enter the IP address of the USB NIC.

The default value is 169.254.1.1. It is recommended to use the default IP address. However, if this IP address conflicts with
an IP address of other interfaces of the host system or the local network, you must change it.

Do not enter 169.254.0.3 and 169.254.0.4 IPs. These IPs are reserved for the USB NIC port on the front panel when an A/A
cable is used.

**NOTE:** If IPv6 is preferred, the default address is fde1:53ba:e9a0:de11::1. If needed, this address can be modified in the
idrac.OS-BMC.UsbNicULA setting. If IPv6 is not wanted on the USB-NIC, it can be disabled by changing the address to
"::"

**NOTE:** When you modify the static IP address of the USB NIC, it automatically adjusts the DHCP address range to align
with the new static IP. For instance, if you set the static IP to 169.250.1.1, the DHCP address updates to 169.250.1.2.
This change is compatible with the network manager, Wicked, which accepts the new DHCP address.

**NOTE:** When the USB NIC is enabled, iDRAC can be accessed using the name idrac.local from either Windows or Linux
[operating system. In Linux, for iDRAC local to work, the avahi, nss-mdns, and dependent packages must be installed.](HTTPS://IDRAC.LOCAL/)

6. Click **Apply** .
7. Click **Test Network Configuration** to check if the IP is accessible and the link is established between the iDRAC and the
host operating system.



### Enabling or disabling OS to iDRAC Pass-through using RACADM

To enable or disable OS to iDRAC Pass-through using RACADM, use the objects in the `iDRAC.OS-BMC` group.

[For more information, see the Integrated Dell Remote Access Controller Attribute Registry available on the iDRAC Manualspage.](https://www.dell.com/idracmanuals)



### Enabling or disabling OS to iDRAC Pass-through using iDRAC settings utility

To enable or disable OS to iDRAC Pass-through using iDRAC Settings Utility:

1. In the iDRAC Settings utility, go to **Communications Permissions** .
The **iDRAC Settings.Communications Permissions** page is displayed.

2. Select any of the following options to enable OS to iDRAC pass-through:
  - **LOM**  - The OS to iDRAC pass-through link between the iDRAC and the host operating system is established through
the LOM or NDC.

  - **USB NIC**  - The OS to iDRAC pass-through link between the iDRAC and the host operating system is established
through the internal USB bus.

**NOTE:** If you set the pass-through mode to LOM, ensure that:

   - OS and iDRAC are on the same subnet
   - NIC selection in Network Settings is set to a LOM

To disable this feature, select **Disabled** .

**NOTE:** The LOM option can be selected only of the card supports OS to iDRAC pass-through capability. Else, this
option is grayed-out.

3. If you select **LOM** as the pass-through configuration, and if the server is connected using dedicated mode, enter the IPv4
address of the operating system.

**NOTE:** If the server is connected in shared LOM mode, then the **OS IP Address** field is disabled.

4. If you select **USB NIC** as the pass-through configuration, enter the IP address of the USB NIC.

The default value is 169.254.1.1. However, if this IP address conflicts with an IP address of other interfaces of the host
system or the local network, you must change it. Do not enter 169.254.0.3 and 169.254.0.4 IPs. These IPs are reserved for
the USB NIC port on the front panel when an A/A cable is used.

**NOTE:** If IPv6 is preferred, the default address is fde1:53ba:e9a0:de11::1. If needed, this address can be modified in the
idrac.OS-BMC.UsbNicULA setting. If IPv6 is not wanted on the USB-NIC, it can be disabled by changing the address to
"::"

5. Click **Back**, click **Finish**, and then click **Yes** .

The details are saved.



## Obtaining certificates

The following table lists the types of certificates based on the login type.

**Table 16. Types of certificate based on login type**

|Login Type|Certificate Type|How to Obtain|Col4|
|---|---|---|---|
|Single Sign-on using Active<br>Directory|Trusted CA certificate|Generate a CSR and get<br>it signed from a Certificate<br>Authority.<br>**NOTE:** SHA-2 certificates<br>are also supported.|Generate a CSR and get<br>it signed from a Certificate<br>Authority.<br>**NOTE:** SHA-2 certificates<br>are also supported.|
|Smart Card login as a local or<br>Active Directory user|●<br>User certificate<br>●<br>Trusted CA certificate|●<br>User Certificate — Export<br>the smart card user<br>certificate as Base64-<br>encoded file using the card<br>management software<br>provided by the smart<br>card vendor.<br>●<br>Trusted CA certificate —<br>This certificate is issued<br>by a CA.<br>**NOTE:** SHA-2 certificates<br>are also supported.|●<br>User Certificate — Export<br>the smart card user<br>certificate as Base64-<br>encoded file using the card<br>management software<br>provided by the smart<br>card vendor.<br>●<br>Trusted CA certificate —<br>This certificate is issued<br>by a CA.<br>**NOTE:** SHA-2 certificates<br>are also supported.|
|Active Directory user login|Trusted CA certificate|This certificate is issued by a<br>CA.<br>**NOTE:** SHA-2 certificates<br>are also supported.|This certificate is issued by a<br>CA.<br>**NOTE:** SHA-2 certificates<br>are also supported.|
|Local User login|SSL Certificate|Generate a CSR and get it<br>signed from a trusted CA<br>**NOTE:** iDRAC ships with<br>a default self-signed SSL<br>server certificate. The<br>iDRAC Web server, Virtual<br>Media, and Virtual Console<br>use this certificate.<br>**NOTE:** SHA-2 certificates<br>are also supported.|Generate a CSR and get it<br>signed from a trusted CA<br>**NOTE:** iDRAC ships with<br>a default self-signed SSL<br>server certificate. The<br>iDRAC Web server, Virtual<br>Media, and Virtual Console<br>use this certificate.<br>**NOTE:** SHA-2 certificates<br>are also supported.|



### SSL server certificates

iDRAC includes a web server that is configured to use the industry-standard SSL security protocol to transfer encrypted data
over a network. An SSL encryption option is provided to disable weak ciphers. Built upon asymmetric encryption technology,
SSL is widely accepted for providing authenticated and encrypted communication between clients and servers to prevent eaves
dropping across a network.

An SSL-enabled system can perform the following tasks:

- Authenticate itself to an SSL-enabled client.
- Allow the two systems to establish an encrypted connection.
**NOTE:** If SSL encryption is set to 256-bit or higher and 168–bit or higher, the cryptography settings for your virtual
machine environment (JVM, IcedTea) may require installing the Unlimited Strength Java Cryptography Extension Policy
Files to permit usage of iDRAC plugins such as vConsole with this level of encryption. For information about installing the
policy files, see the documentation for Java.

iDRAC Web server has a Dell self-signed unique SSL digital certificate by default. You can replace the default SSL certificate
with acertificate that is signed by a well-known Certificate Authority (CA). A Certificate Authority is a business entity that is
recognized in the Information Technology industry for meeting high standards of reliable screening, identification, and other
important security criteria. Examples of CAs include Thawte and VeriSign. To initiate the process of obtaining a CA-signed
certificate, use either iDRAC Web interface or RACADM interface to generate a Certificate Signing Request (CSR) with your

company’s information. Then, submit the generated CSR to a CA such as VeriSign or Thawte. The CA can be a root CA or an
intermediate CA. After you receive the CA-signed SSL certificate, upload this to iDRAC.

You can upload a CA certificate from iDRAC using UI **iDRAC Settings** - **Services** - **Web Server** - **SSL/TLS Certificate**
**Signing Request** . You can also see certificate details from other interfaces.

For each iDRAC to be trusted by the management station, that iDRAC’s SSL certificate must be placed in the management
station’s certificate store. Once the SSL certificate is installed on the management stations, supported browsers can access
iDRAC without certificate warnings.

You can also upload a custom signing certificate to sign the SSL certificate, rather than relying on the default signing certificate
for this function. By importing one custom signing certificate into all management stations, all the iDRACs using the custom
signing certificate are trusted. If a custom signing certificate is uploaded when a custom SSL certificate is already in-use,
then the custom SSL certificate is disabled and a one-time autogenerated SSL certificate, signed with the custom signing
certificate, is used. You can download the custom signing certificate (without the private key). You can also delete an existing
custom signing certificate. After deleting the custom signing certificate, iDRAC resets and autogenerates a new self-signed
SSL certificate. If a self-signed certificate is regenerated, then the trust must be re-established between that iDRAC and the
management workstation. Auto-generated SSL certificates are self-signed and have an expiration date of ten years and one day
and a start date of one day in the past (for different time zone settings on management stations and the iDRAC).

The iDRAC Web server SSL certificate supports the asterisk character (*) as part of the left-most component of the Common
Name when generating a Certificate Signing Request (CSR). For example, *.qa.com, or *.company.qa.com. This is called a
wildcard certificate. If a wildcard CSR is generated outside of iDRAC, you can have a signed single wildcard SSL certificate that
you can upload for multiple iDRACs and all the iDRACs are trusted by the supported browsers. While connecting to iDRAC Web
interface using a supported browser that supports a wildcard certificate, the iDRAC is trusted by the browser. While launching
viewers, the iDRACs are trusted by the viewer clients.

Starting from release 6.10.00.00, you can enable the Certificate Expiry Notification feature and can also configure the
Notification Interval and Notification Frequency. iDRAC provides notification about certificate expiry.

**NOTE:** Perform the `racadm sslresetcfg` command to update the expiry date in the default self-signed certificates.

You can enable Certificate Expiry Notification and the notification interval from - **iDRAC Settings** - **Services** - **Web Server** **Settings** . Als, on the iDRAC login page, you can see the security warning at the bottom of the page about certificate expiry.



### Generating a new certificate signing request

A CSR is a digital request to a Certificate Authority (CA) for a SSL server certificate. SSL server certificates allow clients of the
server to trust the identity of the server and to negotiate an encrypted session with the server.

After the CA receives a CSR, they review and verify the information the CSR contains. If the applicant meets the CA’s
security standards, the CA issues a digitally-signed SSL server certificate that uniquely identifies the applicant’s server when it
establishes SSL connections with browsers running on management stations.

After the CA approves the CSR and issues the SSL server certificate, it can be uploaded to iDRAC. The information used to
generate the CSR, stored on the iDRAC firmware, must match the information contained in the SSL server certificate, that is,
the certificate must have been generated using the CSR created by iDRAC.



#### Generating CSR using web interface

To generate a new CSR:

**NOTE:** Each new CSR overwrites any previous CSR data stored in the firmware. The information in the CSR must match
the information in the SSL server certificate. Else, iDRAC does not accept the certificate.

**NOTE:** From iDRAC release 6.00.02.00, it is also possible to download the generated CSR without having to create a new
one.

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Services** - **Web Server** - **SSL certificate**, select **Generate**
**Certificate Signing Request (CSR)** and click **Next** .
The **Generate a New Certificate Signing Request** page is displayed.

2. Enter a value for each CSR attribute.

For more information, see **iDRAC Online Help** .

3. Click **Generate** .

A new CSR is generated. Save it to the management station.



#### Generating CSR using RACADM

To generate a CSR using RACADM, use the `set` command with the objects in the `iDRAC.Security` group, and then use the
`sslcsrgen` command to generate the CSR.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Automatic Certificate Enrollment

In iDRAC, the Automatic Certificate Enrollment (ACE) feature enables you to automatically install and renew the certificates
that are used by the web server. When this feature is enabled, the existing web server certificate is replaced by a new
certificate. Enter the Certificate Signing Request (CSR) details before you enable ACE.

Automated Certificate Management Environment (ACME) and Simple Certificate Enrollment Protocol (SCEP) serve different
purposes. ACME operates using a public key infrastructure (PKI), whereas SCEP relies on a challenge password for
authentication. Network Device Enrollment Service (NDES) is the Microsoft implementation of SCEP.

**NOTE:**

  - ACE is a licensed feature and requires a Datacenter license.
  - A valid ACE setup is required to issue the server certificate.

iDRAC time must be synchronized with NDES or Certificate Authority.

**NOTE:** If the time is not synchronized, iDRAC may receive invalid or expired certificates during the enrollment and renewal
process.

The following are the ACE configuration parameters:

- Enable and Disable.
- SCEP server URL or ACEM server URL
- Challenge password (SCEP only)
**NOTE:** For more information about these parameters, see **iDRAC Online Help** .

The following are the available status for ACE:

- Enrolled—ACE is enabled. The certificate is monitored, and a new certificate can be issued on expiry.
- Enrolling—Intermediate state after ACE is enabled.
- Error—Problem encountered with ACE server.
- None—Default.
**NOTE:** When you enable ACE, the web server is restarted and all the existing web sessions are logged out.

**NOTE:** To view the success and failure messages, see the life cycle logs.



### Uploading server certificate

After generating a CSR, you can upload the signed SSL server certificate to the iDRAC firmware. iDRAC must be reset to apply
the certificate. iDRAC accepts only X509, Base 64 encoded Web server certificates. SHA-2 certificates are also supported.

**CAUTION: During reset, iDRAC is not available for a few minutes.**



#### Uploading server certificate using web interface

To upload the SSL server certificate:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Services** - **Web Server** - **SSL/TLS Certificate Signing Request**,
select **Upload Server Certificate** and click **Next** .
The **Certificate Upload** page is displayed.

2. Under **File Path**, click **Browse** and select the certificate on the management station.
3. Click **Apply** .

The SSL server certificate is uploaded to iDRAC.

4. A pop-up message is displayed asking you to reset iDRAC immediately or at a later time. Click **Reset iDRAC** or **Reset**
**iDRAC Later** as required.
iDRAC resets and the new certificate is applied. The iDRAC is not available for a few minutes during the reset.

**NOTE:** You must reset iDRAC to apply the new certificate. Until iDRAC is reset, the existing certificate is active.



#### Uploading server certificate using RACADM

To upload the SSL server certificate, use the `sslcertupload` command. For more information, see the Integrated Dell
Remote Access Controller RACADM CLI Guide.

If the CSR is generated outside of iDRAC with a private key available, then to upload the certificate to iDRAC:

1. Send the CSR to a well-known root CA. CA signs the CSR and the CSR becomes a valid certificate.
2. Upload the private key using the remote racadm `sslkeyupload` command.
3. Upload the signed certificate to iDRAC using the remote racadm `sslcertupload` command.

The new certificate is uploaded iDRAC. A message is displayed asking you to reset iDRAC.

4. Run the racadm `racreset` command to reset iDRAC.

iDRAC resets and the new certificate is applied. The iDRAC is not available for a few minutes during the reset.

**NOTE:** You must reset iDRAC to apply the new certificate. Until iDRAC is reset, the existing certificate is active.



### Viewing server certificate

You can view the SSL server certificate that is currently being used in iDRAC.



#### Viewing server certificate using web interface

In the iDRAC Web interface, go to **iDRAC Settings** - **Services** - **Web Server** - **SSL certificate** . The **SSL** page displays the
SSL server certificate that is currently in use at the top of the page.



#### Viewing server certificate using RACADM

To view the SSL server certificate, use the `sslcertview` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Uploading custom signing certificate

You can upload a custom signing certificate to sign the SSL certificate. SHA-2 certificates are also supported.



#### Uploading custom signing certificate using web interface

To upload the custom signing certificate using iDRAC web interface:

1. Go to **iDRAC Settings** - **Services** - **Web Server** - **SSL/TLS Custom Signing Certificate** .
The **SSL** page is displayed.

2. Under **SSL/TLS Custom Signing Certificate**, click **Upload Signing Certificate** .

The **Upload Custom SSL Certificate Signing Certificate** page is displayed.

3. Click **Choose File** and select the custom SSL certificate signing certificate file.

Only Public-Key Cryptography Standards #12 (PKCS #12) compliant certificate is supported.

4. If the certificate is password protected, in the **PKCS#12 Password** field, enter the password.
5. Click **Apply** .

The certificate is uploaded to iDRAC.

6. A pop-up message is displayed asking you to reset iDRAC immediately or at a later time. Click **Reset iDRAC** or **Reset**
**iDRAC Later** as required.
After iDRAC resets, the new certificate is applied. The iDRAC is not available for a few minutes during the reset.

**NOTE:** You must reset iDRAC to apply the new certificate. Until iDRAC is reset, the existing certificate is active.



#### Uploading custom SSL certificate signing certificate using RACADM

To upload the custom SSL certificate signing certificate using RACADM, use the `sslcertupload` command, and then use the
`racreset` command to reset iDRAC.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Downloading custom SSL certificate signing certificate

You can download the custom signing certificate using iDRAC Web interface or RACADM.



#### Downloading custom signing certificate

To download the custom signing certificate using iDRAC Web interface:

1. Go to **iDRAC Settings** - **Connectivity** - **SSL** .
The **SSL** page is displayed.

2. Under **Custom SSL Certificate Signing Certificate**, select **Download Custom SSL Certificate Signing Certificate**

and click **Next** .
A pop-up message is displayed that allows you to save the custom signing certificate to a location of your choice.



#### Downloading custom SSL certificate signing certificate using RACADM

To download the custom SSL certificate signing certificate, use the `sslcertdownload` subcommand. For more information,
[see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Deleting custom SSL certificate signing certificate

You can also delete an existing custom signing certificate using iDRAC Web interface or RACADM.



#### Deleting custom signing certificate using iDRAC web interface

To delete the custom signing certificate using iDRAC web interface:

1. Go to **iDRAC Settings** - **Connectivity** - **SSL** .
The **SSL** page is displayed.

2. Under **Custom SSL Certificate Signing Certificate**, select **Delete Custom SSL Certificate Signing Certificate** and
click **Next** .

3. A pop-up message is displayed asking you to reset iDRAC immediately or at a later time. Click **Reset iDRAC** or **Reset**
**iDRAC Later** as required.
After iDRAC resets, a new self-signed certificate is generated.



#### Deleting custom SSL certificate signing certificate using RACADM

To delete the custom SSL certificate signing certificate using RACADM, use the `sslcertdelete` subcommand. Then, use the
`racreset` command to reset iDRAC.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Configuring multiple iDRACs using RACADM

You can configure one or more iDRACs with identical properties using RACADM. When you query a specific iDRAC using its
group ID and object ID, RACADM creates a configuration file from the retrieved information. Import the file to other iDRACs to
identically configure them.

**NOTE:**

  - The configuration file contains information that is applicable for the particular server. The information is organized under
various object groups.

  - Some configuration files contain unique iDRAC information, such as the static IP address, that you must modify before
you import the file into other iDRACs.

You can also use the System Configuration Profile (SCP) to configure multiple iDRACs using RACADM. SCP file contains the
component configuration information. You can use this file to apply the configuration for BIOS, iDRAC, RAID, and NIC by
importing the file into a target system. For more information, see **XML Configuration Workflow** white paper available at Dell
Manuals page.

To configure multiple iDRACs using the configuration file:

1. Query the target iDRAC that contains the required configuration using the following command:

```
  racadm get -f <file_name>.xml -t xml -c iDRAC.Embedded.1

```

The command requests the iDRAC configuration and generates the configuration file.

**NOTE:** Redirecting the iDRAC configuration to a file using `get -f` is only supported with the local and remote

RACADM interfaces.

**NOTE:** The generated configuration file does not contain user passwords.

The `get` command displays all configuration properties in a group (specified by group name and index) and all configuration
properties for a user.

2. Modify the configuration file using a text editor, if required.
**NOTE:** It is recommended that you edit this file with a simple text editor. The RACADM utility uses an ASCII text parser.
Any formatting confuses the parser, which may corrupt the RACADM database.

3. On the target iDRAC, use the following command to modify the settings:

```
  racadm set -f <file_name>.xml -t xml

```

This loads the information into the other iDRAC. You can use `set` command to synchronize the user and password database
with Server Administrator.

4. Reset the target iDRAC using the command: `racadm racreset`



## Disabling access to modify iDRAC configuration settings on host system

You can disable access to modify the iDRAC configuration settings through Local RACADM or iDRAC Settings utility. However,
you can view these configuration settings. To do this:

1. In iDRAC Web interface, go to **iDRAC Settings** - **Services** - **Local Configurations** .
2. Select one or both of the following:
  - **Disable the iDRAC Local Configuration using iDRAC Settings**  - Disables access to modify the configuration
settings in iDRAC Settings utility.

  - **Disable the iDRAC Local Configuration using RACADM**  - Disables access to modify the configuration settings in
Local RACADM.

3. Click **Apply** .
**NOTE:** If access is disabled, you cannot use Server Administrator or IPMITool to perform iDRAC configurations.
However, you can use IPMI Over LAN.



## Self Heal

The **Self Heal** feature helps you keep your iDRAC firmware up to date by checking the installed version against the latest
version available on the Dell Support site. It provides update recommendations and guidance through QR codes or video links.



### Enable Self Heal in iDRAC web interface

Enable Self Heal to automatically check if the iDRAC firmware version is the latest version.

1. In the iDRAC web interface, go to **iDRAC Settings** - **Services** - **Self Heal** .
2. In the **Self Heal** section, select **Enabled** .
3. Click **Apply** .

If the firmware is up to date, the message `iDRAC Firmware is up to date` is displayed. If an update is required, the
message `iDRAC Firmware needs update` is displayed.



# 7 Delegated Authorization using OAuth 2.0

The Delegated Authorization feature allows a user or console to access iDRAC API using OAuth 2.0 JSON Web Tokens (JWT)
that the user or console first obtains from an Authorization Server. Once an OAuth JWT has been retrieved, the user or console
may use it to invoke iDRAC API. This circumvents the need for specifying username and password to access the API.

**NOTE:** This feature is only available for DataCenter license. You need to have Configure iDRAC or Configure Users privilege
to use this feature.

iDRAC supports configuration of up to 2 Authorization Servers. The configuration requires a user to specify the following
Authorization Server details:

- **Name** - A string to identify the Authorization Server on the iDRAC.
- **Metadata URL** - The OpenID Connect compliant URL as advertised by the server.
- **HTTPS certificate** - The server public key the iDRAC should use to communicate with the server.
- **Offline Key** - The JWK set document for the Authorization Server.
- **Offline Issuer** - The issuer string as used in tokens issued by the Authorization Server.

For Online configuration:

- When configuring an Authorization Server, the iDRAC administrator needs to ensure that the iDRAC has online network
access to the Authorization Server.

- If iDRAC cannot access the Authorization Server, the configuration fails and a subsequent attempt to access the iDRAC API
fails even though a valid token is presented.

For offline configuration:

- iDRAC does not need to communicate with the Auth server, but instead it is configures with the metadata details that it has
downloaded offline. When configured offline, iDRAC has public portion of the signing keys and can validate the token without
a network connection to the Auth server.



# 8 Viewing iDRAC and managed system information

You can view iDRAC and managed system health and properties, hardware and firmware inventory, sensor health, storage
devices, network devices, and view and terminate user sessions. For blade servers, you can also view the Flex Address or
Remote-Assigned Address (applicable only for MX platforms) .

**Topics:**

- Viewing managed system health and properties
- Configuring Asset Tracking
- Viewing system inventory
- Viewing system components
- Monitoring performance index of CPU, memory, and input output modules
- Reading Firmware and Hardware inventories
- Performing and checking firmware update status
- Performing and checking system/ component configuration status
- Idle Server Detection
- GPU (Accelerators) Management
- Checking the system for Fresh Air compliance
- Viewing historical temperature data
- Viewing network interfaces available on host OS
- Viewing network interfaces available on host OS using RACADM
- Viewing FlexAddress mezzanine card fabric connections
- Viewing or terminating iDRAC sessions



## Viewing managed system health and properties

When you log in to the iDRAC web interface, the **System Summary** page allows you to view the managed system's health,
basic iDRAC information, preview the virtual console, add and view work notes, and quickly launch tasks such as power on or
off, power cycle, view logs, update and rollback firmware, switch on or switch off the front panel LED, and reset iDRAC.

To access the **System Summary** page, go to **System** - **Overview** - **Summary** . The **System Summary** page is displayed. For
more information, see the **iDRAC Online Help** .

You can also view the basic system summary information using the iDRAC Settings utility. To do this, in iDRAC Settings utility,
go to **System Summary** . The **iDRAC Settings System Summary** page is displayed. For more information, see the **iDRAC**
**Settings Utility Online Help** .



## Configuring Asset Tracking

The Asset Tracking feature in iDRAC provides you the ability to configure various attributes that are related to your server. This
includes information such as acquisition, warranty, service, and so on.

**NOTE:** Asset Tracking in iDRAC is similar to the Asset Tag feature in OpenManage Server Administrator. However, the
attribute information has to be entered separately in both these tools for them to report the relevant Asset data.

To configure Asset Tracking:

1. In the iDRAC interface, go to **Configuration** - **Asset Tracking** .
2. Click **Add Custom Assets** to add any additional attributes which are not specified by default on this page.
3. Enter all the relevant information of your server asset and click **Apply** .
4. To view the Asset Tracking Report, go to **System** - **Details** - **Asset Tracking** .



## Viewing system inventory

You can view information about the hardware and firmware components that are installed on the managed system. To view the
system inventory in the iDRAC web interface, go to **System** - **Inventory** . For information about the displayed properties, see
**iDRAC Online Help** .

The **Hardware Inventory** section displays the information for the following components available on the managed system:

- iDRAC
- OEM
- RAID controller
- Batteries
- CPUs
- GPU
- DIMMs
- HDDs
- Backplanes
- Network Interface Cards (integrated and embedded)
- Video card
- SD card
- Power Supply Units (PSUs)
- Fans
- Fibre Channel HBAs
- USB
- NVMe PCIe SSD devices
**NOTE:** In hardware Inventory for any GPU, entries BuildDate, GPUGUID, and OEMInfo are supported and populated for
NVIDIA devices only. OEMInfo data is populated only if there is any data given by the NVIDIA device for that field.

**NOTE:** In the iDRAC UI, NVIDIA ConnectX-7 Channel Cards that are configured in InfiniBand (IB) mode are displayed in NIC
Devices and InfiniBand Devices.

The following table list the attributes and the expected values in the **Hardware Inventory** page in iDRAC UI when the
Pensando DPU card does not support HII.

**Table 17. Attributes and expected values**

|Attributes|Expected value|
|---|---|
|CurrentMACAddress|Empty|
|BusNumber|Zero|
|DataBusWidth|Empty|
|PCIDeviceID|Empty|
|PCISubDeviceID|Empty|
|PCISubVendorID|Empty|
|PCIVendorID|Empty|
|SlotLength|Empty|
|SlotType|Empty|
|LastSystemInventoryTime|1970-01-01T00:00:00|
|LastUpdateTime|1970-01-01T00:00:00|
|FCoEOffloadMode|Disabled|
|iScsiOffloadMode|Disabled|
|NicMode|Disabled|
|MaxBandwidth|0|
|MinBandwidth|0|

**NOTE:** Staged inventory is updated only after host boot. Inventories such as PCIe Slots and PCIe devices under hardware
inventory are part of the staged inventory that is generated during the Host boot (after CSIOR). Even Hot plug or removal
of drives does not change the inventory data unless the host is rebooted.

In the UI, **Network Device** - **Partitition State** page, PCI Device ID, Minimum Bandwidth, and Maximum Bandwidth values are
empty.

Under **Network Device** - **Settings and Capabilities** page, Supported Boot Protocol value is empty.

The **Firmware Inventory** section displays the firmware version for the following components:

- BIOS
- Lifecycle Controller
- iDRAC
- Operating system driver pack
- System CPLD
- PERC controllers
- Physical disks
- Power supply
- NIC
- Fibre Channel
- Backplane
- Enclosure
- PCIe SSDs
- TPM
- Operating system Collector
- iSM
**NOTE:** For PowerVault MD 2412, PowerVault MD 2424, or PowerVault MD 2460, the Enclosure firmware version is in the
format - Major Minor and there is no patch version. This is due to the SCSI Inquiry command's 4-byte limitation on the
firmware version field. For example: if the EMM firmware version is 7.3.1, then the enclosure firmware version is 0703.

**NOTE:** Components that lack roll-back capability using iDRAC do not display their Release Date in the software inventory.
When a component is updated from the HOST operating system, it may not populate rollback contents and Release Date
details.

**NOTE:** After performing an in-band operating system firmware update on an external enclosure (JBOD), cold reboot
(power cycle) the server to update the enclosure information and system inventory in iDRAC.

**NOTE:** Firmware inventory may take long or may not show up sometimes. Use the racadm command
`getremoteservicestatus` before running firmware inventory.

**NOTE:**

  - The software inventory displays only the last 4 bytes of the firmware version and the Release date information. For
example, if the firmware version is FLVDL06, the firmware inventory displays DL06.

  - For SATA drives, the firmware version shows four characters always. If any SATA drive has a firmware version more
than four characters, the software inventory displays the last four characters of the firmware version and the storage
page and hardware inventory displays the full version.

  - When you are viewing software inventory using Redfish interface, the Release date information is displayed only for
components that support rollback.

**NOTE:**

  - The firmware version of the GPU bundle is displayed as 00.00.00.00:
   - Until a firmware update is performed using DUP.
   - After the system, erase is performed on the system.
  - If there is a communication failure between the GPU baseboard and iDRAC, the GPU bundle version may not be
displayed in the firmware inventory. To resolve the communication issue, perform the AC cycle. The firmware version is
displayed as 00.00.00.00 when communication is restored.

  - If any device (Example: TPM) is in the OFF state, then the software inventory displays the version as **Not Available** or
**0** . And if the application is not installed, then it shows the version as **Not Installed** .

  - The system displays the default initial system date and time as the **Installed date/time** in the **System Inventory** page
until a new device firmware version is installed using the DUP. Also, BIOS and iDRAC date/ time should be synchronized
for components whose inventory details are obtained from BIOS (example: BIOS, TPM).

  - The installation date does not change if the updated version is the same as the installed version.
  - Sometimes the **LastUpdateTime** field of any component in iDRAC hardware inventory is shown as future/past date.
This can happen when either BIOS or HOST time is set to the wrong date. To fix this issue, correct the BIOS or HOST
date.

**NOTE:** On the Dell PowerEdge FX2/FX2s servers, the naming convention of the CMC version that is displayed in the
iDRAC UI differs from that on the CMC UI. However, the version remains the same.

When you replace any hardware component or update the firmware versions, enable and run the **Collect System Inventory on**
**Reboot** (CSIOR) option to collect the system inventory on reboot. After a few minutes, log in to iDRAC, and go to the **System**
**Inventory** page to view the details. It may take up to 5 minutes for the information to be available depending on the hardware
installed on the server.

**NOTE:** CSIOR option is enabled by default.

**NOTE:** Configuration changes and firmware updates that are made within the operating system may not reflect properly in
the inventory until you perform a server restart.

Click **Export** to export the hardware inventory in an XML format and save it to a location of your choice.



## Viewing system components

The following components in iDRAC UI help you to monitor the health of a managed system:

- **Batteries** —Provides information about the batteries on the system board CMOS and storage RAID on motherboard
(ROMB).

**NOTE:** The storage ROMB battery settings are available only if the system has a ROMB with a battery.

- **CPU** —Indicates the health and state of the CPUs in a managed system. It also reports processor automatic throttling and
predictive failure.

- **Memory** —Indicates the health and state of the Dual In-line memory modules (DIMMs) present in a managed system.
- **Intrusion** —Provides information about the chassis.
- **Power** (available only for rack and tower servers)—Provides information about the power supplies and the power supply
redundancy status.

**NOTE:** If there is only one power supply in the system, the power supply redundancy is set to **Disabled** .

- **Removable Media** —Provides information about the Internal SD Modules; vFlash, and Internal Dual SD Module (IDSDM).
  - When IDSDM redundancy is enabled, the IDSDM sensor status such as IDSDM Redundancy Status, IDSDM SD1, and
IDSDM SD2 are displayed. When redundancy is disabled, only IDSDM SD1 is displayed.

  - If IDSDM redundancy is initially disabled when the system is powered on or after an iDRAC reset, the IDSDM SD1 sensor
status is displayed only after a card is inserted.

  - If IDSDM redundancy is enabled with two SD cards present in the IDSDM, and the status of one SD card is online while
the status of the other card is offline. A system reboot is required to restore redundancy between the two SD cards in
the IDSDM. After the redundancy is restored, the status of both the SD cards in the IDSDM is online.

  - During the rebuilding operation to restore redundancy between two SD cards present in the IDSDM, the IDSDM status is
not displayed since the IDSDM sensors are powered off.

**NOTE:** If the host system is rebooted during IDSDM rebuild operation, the iDRAC does not display the IDSDM
information. To resolve this, rebuild IDSDM again or reset the iDRAC.

  - System Event Logs (SEL) for a write-protected or corrupt SD card in the IDSDM module are not repeated until they are
cleared by replacing the SD card with a writable or good SD card, respectively.

**NOTE:** When iDRAC firmware is updated from versions prior to 3.30.30.30, iDRAC need to be reset to defaults for
IDSDM settings to appear in the Server Administrator's Platform Event Filter.

- **Voltage** —Indicates the status and reading of the voltage sensors on various system components.
- **Cooling** —Provides details about fans and hardware temperatures.
- **Accelerator** —Provides the details of the GPUs and Processing Accelerators. After an iDRAC reboot, it takes approximately
15 to 20 minutes for iDRAC to complete the inventory of all sensors in the Processing Accelerator Controller.

- **PCIe Slots** —Provides details for all PCIe devices including PCIeSSD (NVMe) devices.
- **Network Devices** —Provides details for all network devices including DPUs.

The following table lists the system components that can be monitored:

**NOTE:** The **System Overview** page displays data only for sensors present on your system.

**Table 18. System components monitored from the iDRAC UI**

|System components|Navigation path in iDRAC|
|---|---|
|**Batteries**|**System** >**Overview** >**Batteries**|
|**Cooling**|**System** >**Overview** >**Cooling**|
|**CPU**|**System** >**Overview** >**CPU**|
|**Memory**|**System** >**Overview** >**Memory**|
|**Intrusion**|**System** >**Overview** >**Intrusion**|
|**Power**|**System** >**Overview** >**Power**|
|**Removable Media**|**System** >**Overview** >**Removable Media**|
|**Voltages**|**System** >**Overview** >**Voltages**|
|**Network Devices**|**System** >**Overview** >**Network Devices**|
|**Accelerators**|**System** >**Overview** >**Accelerators**|
|**PCIe Slots**|**System** >**Overview** >**PCIe Slots**|

Use the `racadm getsensorinfo` command to get the details of each of these components.

**NOTE:** For current information of supported properties and their values, see the **iDRAC Online Help** .



## Monitoring performance index of CPU, memory, and input output modules

In Dell’s 14 [th] generation Dell PowerEdge servers, Intel ME supports Compute Usage Per Second (CUPS) functionality. The
CUPS functionality provides real-time monitoring of CPU, memory, and I/O utilization and system-level utilization index for the
system. Intel ME allows out-of-band (OOB) performance monitoring and does not consume CPU resources. The Intel ME has a
system CUPS sensor that provides computation, memory, and I/O resource utilization values as a CUPS Index. iDRAC monitors
this CUPS index for the overall system utilization and also monitors the instantaneous utilization index of the CPU, Memory, and
I/O.

**NOTE:** CUPS functionality is not supported on the following servers:

  - PowerEdge R240
  - PowerEdge R240xd
  - PowerEdge R340
  - PowerEdge R6415
  - PowerEdge R7415
  - PowerEdge R7425
  - PowerEdge T140

The CPU and chipset have dedicated Resource monitoring Counters (RMC). The data from these RMCs is queried to obtain
utilization information of system resources. The data from RMCs is aggregated by the node manager to measure the cumulative
utilization of each of these system resources that is read from iDRAC using existing intercommunication mechanisms to provide
data through out-of-band management interfaces.

The Intel sensor representation of performance parameters and index values is for a complete physical system. Therefore, the
performance data representation on the interfaces is for the complete physical system, even if the system is virtualized and has
multiple virtual hosts.

To display the performance parameters, the supported sensors must be present in the server.

The four system utilization parameters are:

- **CPU Utilization** - Data from RMCs for each CPU core is aggregated to provide cumulative utilization of all the cores in
the system. This utilization is based on time that is spent in active and inactive states. A sample of RMC is taken every six
seconds. To view the current CPU utilization, check the CPU utilization that is displayed in the host Operating System.

- **Memory Utilization** - RMCs measure memory traffic occurring at each memory channel or memory controller instance.
Data from these RMCs is aggregated to measure the cumulative memory traffic across all the memory channels on the
system. This is a measure of memory bandwidth consumption and not the amount of memory utilization. iDRAC aggregates
it for one minute, so it may or may not match the memory utilization that other operating system tools, such as **top** in Linux,
show. Memory bandwidth utilization that the iDRAC shows is an indication of whether the workload is memory intensive or
not.

- **I/O Utilization** - There is one RMC per root port in the PCI Express Root Complex to measure PCI Express traffic
emanating from or directed to that root port and the lower segment. Data from these RMCs is aggregated for measuring PCI
express traffic for all PCI Express segments emanating from the package. This is measure of I/O bandwidth utilization for
the system.

- **System Level CUPS Index** - The CUPS index is calculated by aggregating CPU, Memory, and I/O index considering a
predefined load factor of each system resource. The load factor depends on the nature of the workload on the system.
CUPS Index represents the measurement of the compute headroom available on the server. If the system has a large CUPS
Index, then there is limited headroom to place more workloads on that system. As the resource consumption decreases, the
system’s CUPS index decreases. A low CUPS index indicates that there is a large compute headroom and the server can
receive new workloads and the server is in a lower power state to reduce power consumption. Workload monitoring can then
be applied throughout the data center to provide a high-level and holistic view of the data center’s workload, providing a
dynamic data center solution.

**NOTE:** The CPU, memory, and I/O utilization indexes are aggregated over one minute. Therefore, if there are any
instantaneous spikes in these indexes, they may be suppressed. They are an indication of workload patterns not the amount
of resource utilization.

The IPMI, SEL, and SNMP traps are generated if the thresholds of the utilization indexes are reached and the sensor events are
enabled. The sensor event flags are disabled by default. It can be enabled using the standard IPMI interface.

The required privileges are:

- Login privilege is required to monitor performance data.
- Configure privilege is required for setting warning thresholds and reset historical peaks.
- Login privilege and Enterprise license are required to read historical static data.



### Monitoring performance index of CPU, memory, and input output modules using web interface

To monitor the performance index of CPU, memory, and I/O modules, in the iDRAC web interface, go to **System** **Performance** .

- **System Performance** section — Displays the current reading and the warning reading for CPU, Memory and I/O utilization
index, and system level CUPS index in a graphical view.

- **System Performance Historical Data** section:
  - Provides the statistics for CPU, memory, IO utilization, and the system level CUPS index. If the host system is powered
off, then the graph displays the power off line below 0 percent.

  - You can reset the peak utilization for a particular sensor. Click **Reset Historical Peak** . You must have Configure
privilege to reset the peak value.

- **Performance Metrics** section:
  - Displays status and present reading
  - Displays or specifies the warning threshold utilization limit. You must have server configure privilege to set the threshold
values.

For information about the displayed properties, see the **iDRAC Online Help** .



### Monitoring performance index for of CPU, memory, and input output modules using RACADM

Use the **SystemPerfStatistics** sub command to monitor performance index for CPU, memory, and I/O modules. For more
[information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Reading Firmware and Hardware inventories

**NOTE:** Ensure that you give few seconds of interval while using the command `getremoteservicesstatus` with a

timeout of 5 minutes.

1. Use `getremoteservicesstatus` method/URI/command to check whether Lifecycle Controller (LC) status is ready.
Ensure that system is **ON** at least once and **Collect System Inventory On Restart (CSIOR)** had run at least once to get
the proper details. Based on the requirement for some components like storage and network, you may also need to check if
system is in **Out of POST** and **Real Time (RT)** status.
2. Maximum timeout for LC to be ready should be 5 minutes. Ensure that system is in the following status for LC status to be
ready:

  - Out of POST
  - Job is not already running
  - Not in LC GUI
  - Host struck in POST
3. Once LC status is ready, use the `getinventory` method/ URI/ command.



## Performing and checking firmware update status

**NOTE:** Ensure that you give few seconds of interval while using the command `getremoteservicesstatus` with a

timeout of 5 minutes.

1. Check for firmware inventory (follow the procedure mentioned above).
2. To avoid possible failures later, verify if the component to be updated is present in the system and/or if proper supported
Dell Update Package (DUP) is selected to be uploaded.
3. After initial checks, use `getremoteservicesstatus` method/URI/command to check if LC status is ready.
4. Once LC is ready, use the `firmwareupdate` method/ URI/ command and pass the correct DUP to start the update.
5. If the update requires a host reboot, create reboot job or reboot the host. Power, OSM, and PERC updates requires cold
reboot.
6. Check for job status - **Success/ Failure** . View LifeCycle Log events and job queue status, and check for config results for
more details on the failures.
7. Only after **Collect System Inventory On Restart (CSIOR)** in host if required is completed successfully, the job marks as
completed if not failed, even in case of multiple /catalog updates. Hence, it is recommended that caller do not have its own
timeout or should be more than this timeout.
8. If update is stuck for more than 6 hours (i.e., job module does not get status from update module for 6 hours), then the job
may timeout and fail.
9. The update timeouts are based on device team's recommendation which is read at run-time.
10. Once job is marked as completed and if inventory doesn't report the new changes that was just applied, wait for 30 s and
then check inventory again.



## Performing and checking system/ component configuration status

**NOTE:** Ensure that you give few seconds of interval while using the command `getremoteservicesstatus` with a

timeout of 5 minutes.

1. Check for firmware inventory (follow the procedure mentioned above).
2. To avoid possible failures later, ensure that the required component is present in the system.
3. After initial checks, use `getremoteservicesstatus` method/URI/command to check if LC status is ready. Based on the
requirement for some components like storage and network, other status may need to be checked, for instance, whether
system is **Out of POST** and **Real Time (RT)** status.
4. Once LC is ready, use the system/ component configurations and create the job.
5. Create reboot job or reboot the host if the configuration requires a host reboot. Specific configuration setting might require
a cold reboot.
6. The caller must check for job status to be completed - **Success/ Failure** . View LifeCycle Log events, job queue status and
check config results for more details on the failures.
7. Only after **Collect System Inventory On Restart (CSIOR)** in host if required is completed successfully, the job marks as
completed if not failed. This is applicable if host reboot is required.
8. Once the job is completed, wait for 30 s, and then use `getremoteservicesstatus` method/URI/command to check if
LC status is ready, with other required status and then read the expected values.



## Idle Server Detection

iDRAC provides out-of-band performance monitoring index of server components like CPU, memory, and I/O.

The history data of the server level CUPS index is used to monitor whether the server is utilized or running idle for long time. If
the server is underutilized below certain threshold for a defined span of interval (in hours), then it will be reported as idle server.

This feature is only supported on Intel platforms with CUPS ability. AMD and Intel platforms without CUPS capability do not
support this feature.

**NOTE:**

  - This feature requires Datacenter license.
  - To read the configurations of Idle Server Configuration parameters, you need Login privilege and to modify the
parameters you need iDRAC Configure privilege.

To view or modify the parameters, navigate to **Configuration** - **System Settings** .

Idle server detection is reported based on following parameters:

- Idle Server Threshold (%) - This is set to 20% by default and can be configured from 0 to 50%. The reset operation sets the
threshold to 20%.

- Idle Server Scan Interval (in hours) - This is the time period over which the hourly samples are collected to determine the idle
server. This is set to 240 hours by default and can be configured from 1 to 9000 hours. The reset operation sets the interval
to 240 hours.

- Server Utilization Percentile (%) - The utilization percentile value can be set to 80 to 100%. The default value is 80%. If the
80% of the hourly samples falls below utilization threshold, then it is considered as idle server.



##### Modifying idle Server Detection parameters using RACADM

```
 racadm get system.idleServerDetection



##### Modifying idle Server Detection parameters using Redfish

https://<iDRAC IP>/redfish/v1/Managers/System.Embedded.1/Attributes

```



##### Modifying idle Server Detection parameters using WSMAN

```
 winrm e http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/root/dcim/DCIM_SystemAttribute
 -u:root -p:calvin -r:https://<iDRAC IP>/wsman -SkipCNcheck -SkipCAcheck -encoding:utf-8
 -a:basic

```

**NOTE:** iDRAC GUI doesn't support to view or modify the attributes.



## GPU (Accelerators) Management

Dell PowerEdge servers are shipped with Graphics Processing Unit (GPU). GPU management enables you to view the various
GPUs connected to the system and also monitor power, temperature, and thermal information of the GPUs.

The following are the GPU properties and the license details:

|Table 19. GPU properties and the license details|Col2|
|---|---|
|**GPU Properties**|**License**|
|**Inventory**|**Inventory**|
|Board Part Number|All Licenses|
|OEM Info|All Licenses|
|Serial Number|All Licenses|
|Marketing Name|All Licenses|
|GPU Part Number|All Licenses|
|Build Date.|All Licenses|
|Firmware Version|All Licenses|
|GPU GUID|All Licenses|
|PCI vendorid|All Licenses|
|PCI deviceid|All Licenses|
|PCI Subvendorid|All Licenses|
|PCI Subdeviceid|All Licenses|
|GPU Status|All Licenses|
|GPU Health|All Licenses|
|**Thermal Metrics**|**Thermal Metrics**|
|Primary GPU temperature|All Licenses|
|Secondary GPU temperature|All Licenses|
|Board temperature|All Licenses|
|Memory temperature|All Licenses|
|Minimum GPU HW Slowdown Temperature|Enterprise|
|GPU Shutdown Temperature|Enterprise|
|Maximum Memory Operating temperature|Enterprise|
|Maximum GPU Operating Temperature|Enterprise|
|Thermal Alert State|Enterprise|
|Power Brake State|Enterprise|

**Table 19. GPU properties and the license details (continued)**

|GPU Properties|License|
|---|---|
|**Power Metrics**|**Power Metrics**|
|Power Consumption|All Licenses|
|Power Supply Status|Enterprise|
|Board Power Supply Status|Enterprise|

**NOTE:**

  - Due to platform specificity, some GPU metrics are not collected on all platforms, resulting in Null or N/A values being
displayed for those metrics.

  - GPU properties are not listed for Embedded GPU cards, and the Status is marked as **Unknown** .
  - The operating temperature may be different for AMD-based systems.
  - The number of GPU entries per PCIe slot that is displayed in the host may differ from that in the iDRAC.
  - When a manual AC power cycle is required after performing any component or bundled firmware updates for GPUs or
Power Distribution Board (PDB) CPLDs, SUP0545 event in Lifecycle(LC) logs is displayed. After this event, ensure to
perform a manual AC or virtual AC power cycle to avoid any unexpected behavior in the server.

  - After a GPU firmware update that includes component firmware updates or bundled firmware updates, ensure to
perform an AC power cycle or virtual AC power cycle to complete the update. Doing so avoids any unexpected behavior
in iDRAC related to GPUs.

  - In Persistent Mode, during warm reboot, the GPU Power capping limit values may not be accurate.
  - GPU Power Capping feature is not available in Non-A2 GPU configurations.

GPU has to be in ready state before the command fetches the data. GPUStatus field in Inventory shows the availability of the
GPU and whether the GPU device is responding or not. If the GPU status is ready, GPUStatus shows **OK**, otherwise the status
shows **Unavailable** .

The GPU offers multiple health parameters that can be pulled through the SMBPB interface of the NVIDIA controllers. This
feature is limited only to NVIDIA cards. The following are the health parameters that are retrieved from the GPU device:

- Power
- Temperature
- Thermal
**NOTE:** This feature is only limited to NVIDIA cards. This information is not available for any other GPU that the server may
support. The interval for polling the GPU cards over the PBI is 5 s.

**NOTE:** While updating the GPU firmware, avoid any USB or USB-NIC operations (such as connecting to USB management
port, iDRAC quick sync operation, enabling or disabling USB-NIC port, or similar USB operations) in iDRAC. Any such
operation during the firmware update can result in nondeterministic behavior and may also result in a firmware update
failure.

With warm reboot and Persistent mode is disabled, we can see the following behavior:

- Power Consumption shows as N/A.
- Power Cap limit shows with older inventory Limit Values.

The host system must have the NVIDIA GPU driver that is installed and running for various GPU features to be available.
Some of the GPU features that are available are power consumption, current power cap limit, GPU power capping and limiting,
GPU target temperature, minimum GPU slowdown temperature, GPU shutdown temperature, maximum memory operating
temperature, and maximum GPU operating temperature, GPU utilization, and so on. These values are shown as **N/A** if the
NVIDIA GPU driver is not installed. GPU features that are dependent on the driver that is loaded and running are not limited to
this list.

In Linux, when the card is unused, the driver down-trains the card and unloads to save power. In such cases, the power
consumption, current power cap limit, GPU power capping and limiting, GPU target temperature, minimum GPU slowdown
temperature, GPU shutdown temperature, max memory operating temperature, max memory operating temperature, max GPU
operating temperature, GPU utilization, and other features are not available. Persistent mode should be enabled for the device
to avoid unload. You can use nvidia-smi tool to enable this using the command `nvidia-smi -pm 1` .

You can generate GPU reports using Telemetry. For more information about telemetry features, see Telemetry Streaming.

**NOTE:** In Racadm, You may see dummy GPU entries with empty values. This may happen if the device is not ready to
respond when iDRAC queries the GPU device for the information. Perform an iDRAC `racrest` operation to resolve this

issue.



##### Monitoring Processing Accelerators

Accelerator devices with PCIe class Processing Accelerators need real-time temperature and sensor monitoring because it
generates significant heat when in use.

Perform the following steps to get **Processing Accelerators** ' inventory information:

1. Power off the server.
2. Install the accelerators on the riser card.
3. Power on the server.
4. Wait until POST is complete.
5. Log in to the iDRAC UI.
6. Go to **System** - **Overview** - **Accelerators** . You can see both GPU and Processing Accelerators sections.
7. Expand the specific accelerator to see the following sensor information:
  - Power consumption
  - Temperature details
**NOTE:** Logical temperature sensors are not displayed in the iDRAC interfaces. Only physical temperature sensors are
displayed.

**NOTE:** You must have iDRAC login privilege to access the accelerators' information.

**NOTE:** Power consumption sensors are available only for the supported accelerators and are available only with Datacenter
license.

**NOTE:** iDRAC interfaces may not display the information of power and thermal sensors that are dependent on the host
operating system (operating system). In this case, install the GPU drivers (ROCm package) in the host operating system.

**NOTE:**

  - It is recommended to perform A100 GPU CEC firmware update before updating the Accelerators firmware.
  - Do not perform GPU CEC and Accelerators firmware update simultaneously to avoid failure of updates. Perform an AC
or virtual AC power cycle after the firmware update failures. Doing so avoids further failures of a single update that is
caused by a previous update failure.

  - The firmware update for the HGX A100 8-GPU Baseboard FPGA may take between 60 and 90 minutes to complete.
  - HGX A100 8-GPU Baseboard FPGA and CEC DUP updates must not be triggered simultaneously. It is recommended to
follow these steps:

1. Update the CEC firmware.
2. Perform a virtual AC or a manual AC cycle.
3. Update the FPGA firmware.
4. Perform another virtual AC or manual AC cycle.
  - To update the PDB CPLD from the operating system, start a cold reboot. After the update, a virtual AC cycle is
performed.

**NOTE:** Occasionally, the accelerators send 0 values for power consumption. Therefore, PLDM also uses 0 values and
displays the same in the UI. Although, the values are automatically corrected in subsequent readings.

**NOTE:** PCIe Devices are dependent on the device drivers and firmware to respond to iDRAC requests. These devices log
LC message HWC9053 (communication that is lost with the device) when the required drivers and firmware are not loaded
or when the server is in the Pre-OPERATING SYSTEM environment (UEFI shell and Lifecycle Controller page).



## Checking the system for Fresh Air compliance

Fresh Air cooling directly uses outside air to cool systems in the data center. Fresh Air compliant systems can operate above its
normal ambient operating range (temperatures up to 113 °F (45 °C)).

**NOTE:** Some servers or certain configurations of a server may not be Fresh Air compliant. See the specific server manual
for details related to Fresh Air compliance or contact Dell for more details.

To check the system for Fresh Air compliance:

1. In the iDRAC Web interface, go to **System** - **Overview** - **Cooling** - **Temperature overview** .
The **Temperature overview** page is displayed.

2. See the **Fresh Air** section that indicates whether the server is fresh air compliant or not.



## Viewing historical temperature data

You can monitor the percentage of time the system has operated at ambient temperature that is greater than the normally
supported fresh air temperature threshold. The system board temperature sensor reading is collected over a period of time to
monitor the temperature. The data collection starts when the system is first powered on after it is shipped from the factory.
The data is collected and displayed for the duration when the system is powered on. You can track and store the monitored
temperature for the last seven years.

**NOTE:** You can track the temperature history even for systems that are not Fresh-Air compliant. However, the threshold
limits and fresh air related warnings generated are based on fresh air supported limits. The limits are 42ºC for warning and
47ºC for critical. These values correspond to 40ºC and 45ºC fresh air limits with 2ºC margin for accuracy.

Two fixed temperature bands are tracked that are associated to fresh air limits:

- Warning band — Consists of the duration a system has operated above the temperature sensor warning threshold (42ºC).
The system can operate in the warning band for 10% of the time for 12 months.

- Critical band — Consists of the duration a system has operated above the temperature sensor critical threshold (47ºC). The
system can operate in the critical band for 1% of the time for 12 months which also increments time in the warning band.

The collected data is represented in a graphical format to track the 10% and 1% levels. The logged temperature data can be
cleared only before shipping from the factory.

An event is generated if the system continues to operate above the normally supported temperature threshold for a specified
operational time. If the average temperature over the specified operational time is greater than or equal to the warning level (>
= 8%) or the critical level (> = 0.8%), an event is logged in the Lifecycle Log and the corresponding SNMP trap is generated.
The events are:

- Warning event when the temperature was greater than the warning threshold for duration of 8% or more in the last 12
months.

- Critical event when the temperature was greater than the warning threshold for duration of 10% or more in the last 12
months.

- Warning event when the temperature was greater than the critical threshold for duration of 0.8% or more in the last 12
months.

- Critical event when the temperature was greater than the critical threshold for duration of 1% or more in the last 12 months.

You can also configure iDRAC to generate additional events. For more information, see the Setting alert recurrence event
section.



### Viewing historical temperature data using iDRAC web interface

To view historical temperature data:

1. In the iDRAC Web interface, go to **System** - **Overview** - **Cooling** - **Temperature overview** .
The **Temperature overview** page is displayed.

2. See the **System Board Temperature Historical Data** section that provides a graphical display of the stored temperature
(average and peak values) for the last day, last 30 days, and last year.

For more information, see the **iDRAC Online Help** .

**NOTE:** After an iDRAC firmware update or iDRAC reset, some temperature data may not be displayed in the graph.

**NOTE:** WX3200 AMD GPU card currently doesnot support I2C interface for temperature sensors. Hence, temperature
readings will not be available for this card from iDRAC interfaces.



### Viewing historical temperature data using RACADM

To view historical data using RACADM, use the `inlettemphistory` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

**NOTE:** You may find mismatch in the inlet temperature values in iDRAC UI and RACADM. To compare the data between
these interfaces, please note the following:

  - **iDRAC UI** options from drop-down and their output:
   - Last Day - Hourly data displayed for last 24 hours.
   - Last Month - Daily data displayed for last 30 days.
   - Last Year - Monthly data displayed for last 12 months.
  - **RACADM** output: Displays exact values for hour, day, month, and year for respective RACADM commands.



### Configuring warning threshold for inlet temperature

You can modify the minimum and maximum warning threshold values for the Inlet Temperature sensor. If a reset to the default
action is performed, the temperature thresholds are set to the default values. You must have Configure user privilege to set the
warning threshold values for the Inlet Temperature sensor.



#### Configuring warning threshold for inlet temperature using web interface

To configure warning threshold for inlet temperature:

1. In the iDRAC Web interface, go to **System** - **Overview** - **Cooling** - **Temperature overview** .
The **Temperature overview** page is displayed.

2. In the **Temperature Probes** section, for the **Inlet Temperature**, enter the minimum and maximum values for the **Warning**
**Threshold** in Centigrade or Fahrenheit. If you enter the value in centigrade, the system automatically calculates and displays
the Fahrenheit value. Similarly, if you enter Fahrenheit, the value for Centigrade is displayed.

3. Click **Apply** .

The values are configured.

**NOTE:** Changes to default thresholds are not reflected in the historical data chart since the chart limits are for fresh
air limit values only. Warnings for exceeding the custom thresholds are different from warning associated to exceeding
fresh air thresholds.



## Viewing network interfaces available on host OS

You can view information about all the network interfaces that are available on the host operating system such as the IP
addresses that are assigned to the server. The iDRAC Service Module provides this information to iDRAC. The OS IP address
information includes the IPv4 and IPv6 addresses, MAC address, Subnet mask or prefix length, the FQDD of the network device,
network interface name, network interface description, network interface status, network interface type (Ethernet, tunnel,
loopback, and so on.), Gateway address, DNS server address, and DHCP server address.

**NOTE:** This feature is available with iDRAC Express and iDRAC Enterprise/Datacenter licenses.

To view the OS information, make sure that:

- You have Login privilege.
- iDRAC Service Module is installed and running on the host operating system.
- OS Information option is enabled in the **iDRAC Settings** - **Overview** - **iDRAC Service Module** page.

iDRAC can display the IPv4 and IPv6 addresses for all the interfaces configured on the Host OS.

Depending on how the Host OS detects the DHCP server, the corresponding IPv4 or IPv6 DHCP server address may not be
displayed.



### Viewing network interfaces available on host OS using web interface

To view the network interfaces available on the host OS using Web interface:

1. Go to **System** - **Host OS** - **Network Interfaces** .
The **Network Interfaces** page displays all the network interfaces that are available on the host operating system.

2. To view the list of network interfaces associated with a network device, from the **Network Device FQDD** drop-down menu,
select a network device and click **Apply** .
The OS IP details are displayed in the **Host OS Network Interfaces** section.

3. From the **Device FQDD** column, click on the network device link.

The corresponding device page is displayed from the **Hardware**  - **Network Devices** section, where you can view the device
details. For information about the properties, see the **iDRAC Online Help** .

4. Click the icon to display more details.

Similarly, you can view the host OS network interface information associated with a network device from the **Hardware**  **Network Devices** page. Click **View Host OS Network Interfaces** .



## Viewing network interfaces available on host OS using RACADM

Use the `gethostnetworkinterfaces` command to view the network interfaces available on the host operating systems
[using RACADM. For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Viewing FlexAddress mezzanine card fabric connections

In blade servers, FlexAddress allows the use of persistent, chassis-assigned World Wide Names and MAC addresses (WWN/
MAC) for each managed server port connection.

You can view the following information for each installed embedded Ethernet and optional mezzanine card port:

- Fabrics to which the cards are connected.
- Type of fabric.
- Server-assigned, chassis-assigned, or remotely assigned MAC addresses.

To view the Flex Address information in iDRAC, configure and enable the Flex Address feature in Chassis Management
Controller (CMC). For more information, see the _Chassis Management Controller User's Guide_ [available on the CMC manuals](https://www.dell.com/cmcmanuals)
page.. Any existing Virtual Console or Virtual Media session terminates if the FlexAddress setting is enabled or disabled.

**NOTE:** To avoid errors that may lead to an inability to turn on the managed system, you **must** have the correct type of
mezzanine card installed for each port and fabric connection.

The FlexAddress feature replaces the server–assigned MAC addresses with chassis–assigned MAC addresses and is
implemented for iDRAC along with blade LOMs, mezzanine cards and I/O modules. The iDRAC FlexAddress feature supports
preservation of slot specific MAC address for iDRACs in a chassis. The chassis–assigned MAC address is stored in CMC non–
volatile memory and is sent to iDRAC during an iDRAC boot or when CMC FlexAddress is enabled.

If CMC enables chassis–assigned MAC addresses, iDRAC displays the **MAC address** on any of the following pages:

- **System** - **Details** - **iDRAC Details** .
- **System** - **Server** - **WWN/MAC** .
- **iDRAC Settings** - **Overview** - **Current Network Settings** .
**CAUTION: With FlexAddress enabled, if you switch from a server–assigned MAC address to a chassis–assigned**
**MAC address and vice–versa, iDRAC IP address also changes.**



## Viewing or terminating iDRAC sessions

You can view the number of users currently logged in to iDRAC and terminate the user sessions.



### Terminating iDRAC sessions using web interface

The users who do not have administrative privileges must have Configure iDRAC privilege to terminate iDRAC sessions using
iDRAC Web interface.

To view and terminate the iDRAC sessions:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **users** - **Sessions** .
The **Sessions** page displays the session ID, username, IP address, and session type. For more information about these
properties, see the **iDRAC Online Help** .

2. To terminate the session, under the **Terminate** column, click the Trashcan icon for a session.



#### Terminating iDRAC sessions using RACADM

You must have administrator privileges to terminate iDRAC sessions using RACADM.

To view the current user sessions, use the `getssninfo` command.

To terminate a user session, use the `closessn` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



# 9 Setting up iDRAC communication

You can communicate with iDRAC using any of the following modes:

- iDRAC Web Interface
- Serial connection using DB9 cable (RAC serial or IPMI serial) — For rack and tower servers only
- IPMI Serial Over LAN
- IPMI Over LAN
- Remote RACADM
- Local RACADM
- Remote Services
**NOTE:** To ensure that Local RACADM import or export commands work properly, ensure that the USB mass-storage host
is enabled in the operating system. For information about enabling USB storage host, see the documentation for your
operating system.

The following table provides an overview of the supported protocols, supported commands, and pre-requisites:

**Table 20. Communication modes — summary**

|Mode of Communication|Supported Protocol|Supported Commands|Pre-requisite|
|---|---|---|---|
|**iDRAC Web Interface**|Internet Protocol (https)|N/A|Web Server|
|**Serial using Null modem**<br>**DB9 cable**|Serial Protocol|RACADM and IPMI|Part of iDRAC firmware and<br>RAC Serial or IPMI Serial is<br>enabled|
|**IPMI Serial Over LAN**|Intelligent Platform<br>Management Bus protocol<br>SSH|IPMI|IPMITool is installed and IPMI<br>Serial Over LAN is enabled|
|**IPMI over LAN**|Intelligent Platform<br>Management Bus protocol|IPMI|IPMITool is installed and IPMI<br>Settings is enabled|
|**Remote RACADM**|https|Remote RACADM|Remote RACADM is installed<br>and enabled|
|**Firmware RACADM**|SSH|Firmware RACADM|Firmware RACADM is installed<br>and enabled|
|**Local RACADM**|IPMI|Local RACADM|Local RACADM is installed|
|**Remote Services** 1|WSMan|WinRM (Windows) and<br>OpenWSMan (Linux)|WinRM is installed (Windows)<br>or OpenWSMan is installed<br>(Linux)|
|**Remote Services** 1|Redfish|Various browser plug-ins,<br>CURL (Windows and Linux),<br>Python request and JSON<br>modules|Plug-ins, CURL, Python<br>modules are installed|
|[1] For more information, see the_Dell Lifecycle Controller User's Guide_ available atiDRAC manuals .|[1] For more information, see the_Dell Lifecycle Controller User's Guide_ available atiDRAC manuals .|[1] For more information, see the_Dell Lifecycle Controller User's Guide_ available atiDRAC manuals .|[1] For more information, see the_Dell Lifecycle Controller User's Guide_ available atiDRAC manuals .|

**Topics:**

- Communicating with iDRAC through serial connection using DB9 cable
- Switching between RAC serial and serial console while using DB9 cable
- Communicating with iDRAC using IPMI SOL
- Communicating with iDRAC using IPMI over LAN
- Enabling or disabling remote RACADM
- Disabling local RACADM
- Enabling IPMI on managed system
- Configuring Linux for serial console during boot in RHEL 6
- Configuring serial terminal in RHEL 7
- Supported SSH cryptography schemes



## Communicating with iDRAC through serial connection using DB9 cable

You can use any of the following communication methods to perform systems management tasks through serial connection to
rack and tower servers:

- RAC Serial
- IPMI Serial — Direct Connect Basic mode and Direct Connect Terminal mode
**NOTE:** In case of blade servers, the serial connection is established through the chassis. For more information, see the
_Chassis Management Controller User's Guide_ [available on the CMC manuals page. (not applicable for MX platforms)](https://www.dell.com/cmcmanuals) _Dell_
_OpenManage Enterprise-Modular for PowerEdge MX7000 Chassis User's Guide_ [available on the OpenManage manuals](https://www.dell.com/openmanagemanuals)
page (applicable for MX platforms).

To establish the serial connection:

1. Configure the BIOS to enable serial connection.
2. Connect the Null Modem DB9 cable from the management station’s serial port to the managed system’s external serial
connector.

**NOTE:** Server power cycle is required from vConsole or GUI for any change in Baud-rate.

**NOTE:** If iDRAC serial connection authentication is disabled, then iDRAC racreset is required for any change in BAUDrate.

3. Make sure that the management station’s terminal emulation software is configured for serial connection using any of the
following:

  - Linux Minicom in an Xterm
  - Hilgraeve’s HyperTerminal Private Edition (version 6.3)

Based on where the managed system is in its boot process, you can see either the POST screen or the operating system
screen. This is based on the configuration: SAC for Windows and Linux text mode screens for Linux.

4. Enable RAC serial or IPMI serial connections in iDRAC.



### Configuring BIOS for serial connection

To configure BIOS for Serial Connection:

**NOTE:** This is applicable only for iDRAC on rack and tower servers.

1. Turn on or restart the system.
2. Press F2.
3. Go to **System BIOS Settings** - **Serial Communication** .
4. Select **External Serial Connector** to **Remote Access device** .
5. Click **Back**, click **Finish**, and then click **Yes** .
6. Press Esc to exit **System Setup** .



### Enabling RAC serial connection

After configuring serial connection in BIOS, enable RAC serial in iDRAC.

**NOTE:** This is applicable only for iDRAC on rack and tower servers.



#### Enabling RAC serial connection using web interface

To enable RAC serial connection:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Network** - **Serial** .
The **Serial** page is displayed.

2. Under **RAC Serial**, select **Enabled** and specify the values for the attributes.
3. Click **Apply** .

The RAC serial settings are configured.



#### Enabling RAC serial connection using RACADM

To enable RAC serial connection using RACADM, use the `set` command with the object in the `iDRAC.Serial` group.



### Enabling IPMI serial connection basic and terminal modes

To enable IPMI serial routing of BIOS to iDRAC, configure IPMI Serial in any of the following modes in iDRAC:

**NOTE:** This is applicable only for iDRAC on rack and tower servers.

- IPMI basic mode — Supports a binary interface for program access, such as the IPMI shell (ipmish) that is included with the
Baseboard Management Utility (BMU). For example, to print the System Event Log using ipmish via IPMI Basic mode, run
the following command: `ipmish -com 1 -baud 57600 -flow cts -u <username> -p <password> sel get`

**NOTE:** The default iDRAC user name and password are provided on the system badge.

- IPMI terminal mode — Supports ASCII commands that are sent from a serial terminal. This mode supports limited number of
commands (including power control) and raw IPMI commands that are typed as hexadecimal ASCII characters. It allows you
to view the operating system boot sequences up to BIOS, when you login to iDRAC through SSH. You need to logout from
the IPMI terminal using `[sys pwd -x]`, below are the example for IPMI Terminal mode commands.

  - `[sys tmode]`
  - `[sys pwd -u root calvin]`
  - `[sys health query -v]`
  - `[18 00 01]`
  - `[sys pwd -x]`



#### Enabling serial connection using web interface

Make sure to disable the RAC serial interface to enable IPMI Serial.

To configure IPMI Serial settings:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** - **Serial** .
2. Under **IPMI Serial**, specify the values for the attributes. For information about the options, see the **iDRAC Online Help** .
3. Click **Apply** .



#### Enabling serial connection IPMI mode using RACADM

To configure the IPMI mode, disable the RAC serial interface and then enable the IPMI mode.

```
 racadm set iDRAC.Serial.Enable 0
 racadm set iDRAC.IPMISerial.ConnectionMode <n>

```

n=0 — Terminal Mode

n=1 — Basic Mode



#### Enabling serial connection IPMI serial settings using RACADM

1. Change the IPMI serial-connection mode to the appropriate setting using the command.

```
  racadm set iDRAC.Serial.Enable 0

```

2. Set the IPMI Serial baud rate using the command.

```
  racadm set iDRAC.IPMISerial.BaudRate <baud_rate>

|Parameter|Allowed values (in bps)|
|---|---|
|**`<baud_rate>`**|9600, 19200, 57600, and 115200.|

```

3. Enable the IPMI serial hardware flow control using the command.

```
  racadm set iDRAC.IPMISerial.FlowContro 1

```

4. Set the IPMI serial channel minimum privilege level using the command.

```
  racadm set iDRAC.IPMISerial.ChanPrivLimit <level>

|Parameter|Privilege level|
|---|---|
|**`<level>`** = 2|User|
|**`<level>`** = 3|Operator|
|**`<level>`** = 4|Administrator|

```

5. Ensure that the serial MUX (external serial connector) is set correctly to the remote access device in the BIOS Setup
program to configure BIOS for serial connection.

For more information about these properties, see the IPMI 2.0 specification.



#### Additional settings for ipmi serial terminal mode

This section provides additional configuration settings for IPMI serial terminal mode.



##### Configuring additional settings for IPMI serial terminal mode using web interface

To set the Terminal Mode settings:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** - **Serial** .
The **Serial** page is displayed.

2. Enable IPMI serial.
3. Click **Terminal Mode Settings.**

The **Terminal Mode Settings** page is displayed.

4. Specify the following values:
  - Line editing
  - Delete control
  - Echo Control
  - Handshaking control
  - New line sequence
  - Input new line sequences

For information about the options, see the **iDRAC Online Help** .

5. Click **Apply** .

The terminal mode settings are configured.

6. Make sure that the serial MUX (external serial connector) is set correctly to the remote access device in the BIOS Setup
program to configure BIOS for serial connection.



##### Configuring additional settings for IPMI serial terminal mode using RACADM

To configure the Terminal Mode settings, use the `set` command with the objects in the `idrac.ipmiserial` group.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



## Switching between RAC serial and serial console while using DB9 cable

iDRAC supports Escape key sequences that allow switching between RAC Serial Interface communication and Serial Console on
rack and tower servers.



### Switching from serial console to RAC serial

To switch to RAC Serial Interface communication mode when in Serial Console Mode, press Esc+Shift, 9.

The key sequence directs you to the `iDRAC Login` prompt (if the iDRAC is set to RAC Serial mode) or to the Serial
Connection mode where terminal commands can be issued if iDRAC is set to IPMI Serial Direct Connect Terminal Mode.



### Switching from RAC serial to serial console

To switch to Serial Console Mode when in RAC Serial Interface Communication Mode, press Esc+Shift, Q.

When in terminal mode, to switch the connection to the Serial Console mode, press Esc+Shift, Q.

To go back to the terminal mode use, when connected in Serial Console mode, press Esc+Shift, 9.



## Communicating with iDRAC using IPMI SOL

IPMI Serial Over LAN (SOL) allows a managed system’s text-based console serial data to be redirected over iDRAC’s dedicated
or shared out-of-band ethernet management network. Using SOL you can:

- Remotely access operating systems with no time-out.
- Diagnose host systems on Emergency Management Services (EMS) or Special Administrator Console (SAC) for Windows or
Linux shell.

- View the progress of a servers during POST and reconfigure the BIOS setup program.

To setup the SOL communication mode:

1. Configure BIOS for serial connection.
2. Configure iDRAC to Use SOL.
3. Enable a supported protocol (SSH, IPMItool).



### Configuring BIOS for serial connection

**NOTE:** This is applicable only for iDRAC on rack and tower servers.

1. Turn on or restart the system.
2. Press F2.
3. Go to **System BIOS Settings** - **Serial Communication** .
4. Specify the following values:
  - Serial Communication — On With Console Redirection
  - Serial Port Address — COM2.
**NOTE:** You can set the **serial communication** field to **On with serial redirection via com1** if **serial device2** in
the **serial port address** field is also set to com1.

  - External serial connector — Serial device 2
  - Failsafe Baud Rate — 115200
  - Remote Terminal Type — VT100/VT220
  - Redirection After Boot — Enabled
5. Click **Back** and then click **Finish** .
6. Click **Yes** to save the changes.
7. Press <Esc> to exit **System Setup** .
**NOTE:** BIOS sends the screen serial data in 25 x 80 format. The SSH window that is used to invoke the `console`

`com2` command must be set to 25 x 80. Then, the redirected screen appears correctly.

**NOTE:** If the boot loader or operating system provides serial redirection such as GRUB or Linux, then the BIOS
**Redirection After Boot** setting must be disabled. This is to avoid potential race condition of multiple components
accessing the serial port.



### Configuring iDRAC to use SOL

You can specify the SOL settings in iDRAC using Web interface, RACADM, or iDRAC Settings utility.



#### Configuring iDRAC to use SOL using iDRAC web interface

To configure IPMI Serial over LAN (SOL):

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** - **Serial Over LAN** .
The **Serial over LAN** page is displayed.

2. Enable SOL, specify the values, and click **Apply** .

The IPMI SOL settings are configured.

3. To set the character accumulate interval and the character send threshold, select **Advanced Settings.**

The **Serial Over LAN Advanced Settings** page is displayed.

4. Specify the values for the attributes and click **Apply** .

The IPMI SOL advanced settings are configured. These values help to improve the performance.

For information about the options, see the **iDRAC Online Help** .



#### Configuring iDRAC to use SOL using RACADM

To configure IPMI Serial over LAN (SOL):

1. Enable IPMI Serial over LAN using the command.

```
  racadm set iDRAC.IPMISol.Enable 1

```

2. Update the IPMI SOL minimum privilege level using the command.

```
  racadm set iDRAC.IPMISol.MinPrivilege <level>

|Parameter|Privilege level|
|---|---|
|**`<level>`** = 2|User|
|**`<level>`** = 3|Operator|
|**`<level>`** = 4|Administrator|

```

**NOTE:** To activate IPMI SOL, you must have the minimum privilege defined in IMPI SOL. For more information, see the
IPMI 2.0 specification.

3. Update the IPMI SOL baud rate using the command.

```
  racadm set iDRAC.IPMISol.BaudRate <baud_rate>

```

**NOTE:** To redirect the serial console over LAN, make sure that the SOL baud rate is identical to the managed system’s
baud rate.

|Parameter|Allowed values (in bps)|
|---|---|
|**`<baud_rate>`**|9600, 19200, 57600, and 115200.|

4. Enable SOL for each user using the command.

```
  racadm set iDRAC.Users.<id>.SolEnable 2

|Parameter|Description|
|---|---|
|**`<id>`**|Unique ID of the user|

```

**NOTE:** To redirect the serial console over LAN, ensure that the SOL baud rate is identical to the baud rate of the managed
system.



### Enabling supported protocol

The supported protocols are IPMI and SSH.



#### Enabling supported protocol using web interface

To enable SSH, go to **iDRAC Settings** - **Services** and select **Enabled** for SSH.

To enable IPMI, go to **iDRAC Settings** - **Connectivity** and select **IPMI Settings** . Make sure that the **Encryption Key** value is
all zeroes or press the backspace key to clear and change the value to NULL characters.



#### Enabling supported protocol using RACADM

To enable the SSH, use the following command.

SSH

```
 racadm set iDRAC.SSH.Enable 1

```

To change the SSH port

```
 racadm set iDRAC.SSH.Port <port number>

```

You can use tools such as:

- IPMItool for using IPMI protocol
- Putty/OpenSSH for using SSH protocol



#### SOL using IPMI protocol

The IPMI-based SOL utility and IPMItool use RMCP+ delivered using UDP datagrams to port 623. The RMCP+ provides
improved authentication, data integrity checks, encryption, and the ability to carry multiple types of payloads while using IPMI
2.0. For more information, see **http://ipmitool.sourceforge.net/manpage.html** .

The RMCP+ uses a 40-character hexadecimal string (characters 0-9, a-f, and A-F) encryption key for authentication. The
default value is a string of 40 zeros.

An RMCP+ connection to iDRAC must be encrypted using the encryption key (Key Generator Key). You can configure the
encryption key using the iDRAC web interface or iDRAC Settings utility.

To start SOL session using IPMItool from a management station:

**NOTE:** If required, you can change the default SOL time-out at **iDRAC Settings**  - **Services** .

1. Install IPMITool from the **Dell Systems Management Tools and Documentation** DVD.

For installation instructions, see the **Software Quick Installation Guide** .

2. At the command prompt (Windows or Linux), run the following command to start SOL from iDRAC:

```
  ipmitool -H <iDRAC-ip-address> -I lanplus -U <login name> -P <login password> sol
  activate

```

This command connected the management station to the managed system's serial port.

3. To quit a SOL session from IPMItool, press ~ and then . (period).
**NOTE:** If a SOL session does not terminate, reset iDRAC and allow up to two minutes to complete booting.

**NOTE:** IPMI SOL session may terminate while copying large input text from a client running Windows OS to a host running
Linux OS. To avoid the session from getting terminated abruptly, convert any large text to a UNIX-based line ending.

**NOTE:** If a SOL session created using RACADM tool exists, starting another SOL session using IPMI tool will not show any
notification or error about the existing sessions.

**NOTE:** Due to windows OS settings, SOL session connected through ssh and IPMI tool may go to blank screen after
booting. Disconnect and Re-connect the SOL Session again to get back SAC prompt.



#### SOL using SSH

Secure Shell (SSH) is network protocol used to perform command line communications to iDRAC. You can parse remote
RACADM commands through this interface.

SSH has improved security. iDRAC only supports SSH version 2 with password authentication, and is enabled by default. iDRAC
supports up to two to four SSH sessions at a time.

**NOTE:** Starting iDRAC version 4.40.00.00, telnet feature is removed from iDRAC, so any related attribute registry
properties are obsoleted. While some of these properties are still available in iDRAC to keep backward compatibility with
existing console applications and scripts, the corresponding settings are ignored by iDRAC firmware.

**NOTE:** While establishing SSH connection, a security message is displayed- 'Further Authentication required'. even though
2FA is disabled.

**NOTE:** For MX platforms, one SSH session will be used for iDRAC communication. If all the sessions are in use, then iDRAC
will not launch until one session is free.

Use open-source programs such as PuTTY or OpenSSH that support SSH on a management station to connect to iDRAC.

**NOTE:** Run `OpenSSH` from a VT100 or ANSI terminal emulator on Windows. Running `OpenSSH` at the Windows command

prompt does not result in full functionality (that is, some keys do not respond and no graphics are displayed).

Before using SSH to communicate with iDRAC, make sure to:

1. Configure BIOS to enable Serial Console.
2. Configure SOL in iDRAC.
3. Enable SSH using iDRAC Web interface or RACADM.

SSH (port 22) client <−−> WAN connection <−−> iDRAC

The IPMI-based SOL that uses SSH protocol eliminates the need for an additional utility because the serial to network
translation happens within iDRAC. The SSH console that you use must be able to interpret and respond to the data arriving

from the serial port of the managed system. The serial port usually attaches to a shell that emulates an ANSI- or VT100/
VT220–terminal. The serial console is automatically redirected to the SSH.



##### Using SOL from PuTTY on Windows

**NOTE:** If required, you can change the default SSH time-out at **iDRAC Settings**  - **Services** .

To start IPMI SOL from PuTTY on a Windows management station:

1. Run the following command to connect to iDRAC

```
  putty.exe [-ssh] <login name>@<iDRAC-ip-address> <port number>

```

**NOTE:** The port number is optional. It is required only when the port number is reassigned.

2. Run the command `console com2` or `connect com2` to start SOL and boot the managed system.

A SOL session from the management station to the managed system using the SSH protocol is opened. To access the iDRAC
command-line console, follow the ESC key sequence. Putty and SOL connection behavior:

  - While accessing the managed system through putty during POST, if the Function keys and keypad option on putty is set
to:

   - VT100+ — F2 passes, but F12 cannot pass.
   - ESC[n~ — F12 passes, but F2 cannot pass.
  - In Windows, if the Emergency Management System (EMS) console is opened immediately after a host reboot, the Special
Admin Console (SAC) terminal may get corrupted. Quit the SOL session, close the terminal, open another terminal, and
start the SOL session using the same command.

**NOTE:** Due to windows OS settings, SOL session connected through ssh and IPMI tool may go to blank screen after
booting. Disconnect and Re-connect the SOL Session again to get back SAC prompt.



##### Using SOL from OpenSSH on Linux

To start SOL from OpenSSH on a Linux management station:

**NOTE:** If required, you can change the default SSH session time-out at **iDRAC Settings**  - **Services** .

1. Start a shell.
2. Connect to iDRAC using the following command: ssh **<iDRAC-ip-address>** -l **<login name>**
3. Enter one of the following commands at the command prompt to start SOL:
  - `connect com2`
  - `console com2`

This connects iDRAC to the managed system’s SOL port. Once a SOL session is established, iDRAC command line console
is not available. Follow the escape sequence correctly to open the iDRAC command line console. The escape sequence is
also printed on the screen as soon as a SOL session is connected. When the managed system is off, it takes sometime to
establish the SOL session.

**NOTE:** You can use console com1 or console com2 to start SOL. Reboot the server to establish the connection.

To view history of the SOL interface, enable Serial Data Capture. It writes all serial data received from the host to iDRAC
memory in a 512 KB rolling window. This requires Datacenter license.

4. Quit the SOL session to close an active SOL session.



##### Disconnecting SOL session in iDRAC command line console

The commands to disconnect a SOL session are based on the utility. You can exit the utility only when a SOL session is
completely terminated.

To disconnect a SOL session, terminate the SOL session from the iDRAC command line console.

To quit SOL redirection, press Enter, Esc, T.

The SOL session closes.

If a SOL session is not terminated completely in the utility, other SOL sessions may not be available. To resolve this, terminate
the command line console in the Web interface under **iDRAC Settings** - **Connectivity** - **Serial Over LAN** .



## Communicating with iDRAC using IPMI over LAN

You must configure IPMI over LAN for iDRAC to enable or disable IPMI commands over LAN channels to any external systems. If
IPMI over LAN is not configured, then external systems cannot communicate with the iDRAC server using IPMI commands.

**NOTE:** IPMI also supports IPv6 address protocol for Linux-based operating systems.



### Configuring IPMI over LAN using web interface

To configure IPMI over LAN:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Connectivity** .
The **Network** page is displayed.

2. Under **IPMI Settings**, specify the values for the attributes and click **Apply** .

For information about the options, see the **iDRAC Online Help** .

The IPMI over LAN settings are configured.



### Configuring IPMI over LAN using iDRAC settings utility

To configure IPMI over LAN:

1. In the **iDRAC Settings Utility**, go to **Network** .
The **iDRAC Settings Network** page is displayed.

2. For **IPMI Settings**, specify the values.

For information about the options, see the **iDRAC Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The IPMI over LAN settings are configured.



### Configuring IPMI over LAN using RACADM

1. Enable IPMI over LAN.

```
  racadm set iDRAC.IPMILan.Enable 1

```

**NOTE:** This setting determines the IPMI commands that are performed using IPMI over LAN interface. For more
information, see the IPMI 2.0 specifications at **intel.com** .

2. Update the IPMI channel privileges.

```
  racadm set iDRAC.IPMILan.PrivLimit <level>

|Parameter|Privilege level|
|---|---|
|**`<level>`** = 2|User|
|**`<level>`** = 3|Operator|
|**`<level>`** = 4|Administrator|

```

3. Set the IPMI LAN channel encryption key, if required.

```
  racadm set iDRAC.IPMILan.EncryptionKey <key>

|Parameter|Description|
|---|---|
|**`<key>`**|20-character encryption key in a valid hexadecimal format.|

```

**NOTE:** The iDRAC IPMI supports the RMCP+ protocol. For more information, see the IPMI 2.0 specifications at **intel.com** .



## Enabling or disabling remote RACADM

You can enable or disable remote RACADM using the iDRAC Web interface or RACADM. You can run up to five remote
RACADM sessions in parallel.

**NOTE:** Remote RACADM is enabled by default.



### Enabling or disabling remote RACADM using web interface

1. In iDRAC Web interface, go to **iDRAC Settings** - **Services** .
2. Under **Remote RACADM**, select the desired option and click **Apply** .

The remote RACADM is enabled or disabled based on the selection.



### Enabling or disabling remote RACADM using RACADM

**NOTE:** It is recommended to run these commands using local RACADM or firmware RACADM.

1. To disable remote RACADM:

```
  racadm set iDRAC.Racadm.Enable 0

```

2. To enable remote RACADM:

```
  racadm set iDRAC.Racadm.Enable 1



## Disabling local RACADM

```

The local RACADM is enabled by default. To disable, see Disabling access to modify iDRAC configuration settings on host
system.



## Enabling IPMI on managed system

On a managed system, use the Dell Open Manage Server Administrator to enable or disable IPMI. For more information, see the
_OpenManage Server Administrator User's Guide_ [available on the OpenManage manuals page..](https://www.dell.com/openmanagemanuals)

**NOTE:** From iDRAC v2.30.30.30 or later, IPMI supports IPv6 address protocol for Linux-based operating systems.



## Configuring Linux for serial console during boot in RHEL 6

The following steps are specific to the Linux GRand Unified Bootloader (GRUB). Similar changes are required if a different boot
loader is used.

**NOTE:** When you configure the client VT100 emulation window, set the window or application that is displaying the
redirected Virtual Console to 25 rows x 80 columns to make sure the correct text displays. Else, some text screens may be
garbled.

Edit the **/etc/grub.conf** file as follows:

1. Locate the General Setting sections in the file and add the following:

```
  serial --unit=1 --speed=57600 terminal --timeout=10 serial

```

2. Append two options to the kernel line:

```
  kernel ............. console=ttyS1,115200n8r console=tty1

```

3. Disable GRUB's graphical interface and use the text-based interface. Else, the GRUB screen is not displayed in RAC Virtual
Console. To disable the graphical interface, comment-out the line starting with `splashimage` .

The following example provides a sample **/etc/grub.conf** file that shows the changes described in this procedure.

```
  # grub.conf generated by anaconda
  # Note that you do not have to rerun grub after making changes to this file
  # NOTICE: You do not have a /boot partition. This means that all
  # kernel and initrd paths are relative to /, e.g.
  # root (hd0,0)
  # kernel /boot/vmlinuz-version ro root=/dev/sdal
  # initrd /boot/initrd-version.img
  #boot=/dev/sda
  default=0
  timeout=10
  #splashimage=(hd0,2)/grub/splash.xpm.gz

  serial --unit=1 --speed=57600
  terminal --timeout=10 serial

  title Red Hat Linux Advanced Server (2.4.9-e.3smp) root (hd0,0)
  kernel /boot/vmlinuz-2.4.9-e.3smp ro root=/dev/sda1 hda=ide-scsi console=ttyS0
  console=ttyS1,115200n8r
  initrd /boot/initrd-2.4.9-e.3smp.img
  title Red Hat Linux Advanced Server-up (2.4.9-e.3) root (hd0,00)
  kernel /boot/vmlinuz-2.4.9-e.3 ro root=/dev/sda1 s
  initrd /boot/initrd-2.4.9-e.3.im

```

4. To enable multiple GRUB options to start Virtual Console sessions through the RAC serial connection, add the following line
to all options:

```
  console=ttyS1,115200n8r console=tty1

```

The example shows `console=ttyS1,57600` added to the first option.

**NOTE:** If the boot loader or operating system provides serial redirection such as GRUB or Linux, then the BIOS
**Redirection After Boot** setting must be disabled. This is to avoid potential race condition of multiple components
accessing the serial port.



### Enabling login to the virtual console after boot

In the file **/etc/inittab**, add a new line to configure `agetty` on the COM2 serial port:

```
co:2345:respawn:/sbin/agetty -h -L 57600 ttyS1 ansi

```

The following example shows a sample file with the new line.

```
 #inittab This file describes how the INIT process should set up
 #the system in a certain run-level.
 #Author:Miquel van Smoorenburg
 #Modified for RHS Linux by Marc Ewing and Donnie Barnes
 #Default runlevel. The runlevels used by RHS are:
 #0 - halt (Do NOT set initdefault to this)
 #1 - Single user mode
 #2 - Multiuser, without NFS (The same as 3, if you do not have #networking)
 #3 - Full multiuser mode
 #4 - unused
 #5 - X11
 #6 - reboot (Do NOT set initdefault to this)
 id:3:initdefault:
 #System initialization.
 si::sysinit:/etc/rc.d/rc.sysinit
 l0:0:wait:/etc/rc.d/rc 0
 l1:1:wait:/etc/rc.d/rc 1
 l2:2:wait:/etc/rc.d/rc 2
 l3:3:wait:/etc/rc.d/rc 3
 l4:4:wait:/etc/rc.d/rc 4
 l5:5:wait:/etc/rc.d/rc 5
 l6:6:wait:/etc/rc.d/rc 6
 #Things to run in every runlevel.
 ud::once:/sbin/update
 ud::once:/sbin/update
 #Trap CTRL-ALT-DELETE
 ca::ctrlaltdel:/sbin/shutdown -t3 -r now
 #When our UPS tells us power has failed, assume we have a few
 #minutes of power left. Schedule a shutdown for 2 minutes from now.
 #This does, of course, assume you have power installed and your
 #UPS is connected and working correctly.
 pf::powerfail:/sbin/shutdown -f -h +2 "Power Failure; System Shutting Down"
 #If power was restored before the shutdown kicked in, cancel it.
 pr:12345:powerokwait:/sbin/shutdown -c "Power Restored; Shutdown Cancelled"

 #Run gettys in standard runlevels
 co:2345:respawn:/sbin/agetty -h -L 57600 ttyS1 ansi
 1:2345:respawn:/sbin/mingetty tty1
 2:2345:respawn:/sbin/mingetty tty2
 3:2345:respawn:/sbin/mingetty tty3
 4:2345:respawn:/sbin/mingetty tty4
 5:2345:respawn:/sbin/mingetty tty5
 6:2345:respawn:/sbin/mingetty tty6

 #Run xdm in runlevel 5
 #xdm is now a separate service
 x:5:respawn:/etc/X11/prefdm -nodaemon

```

In the file **/etc/securetty**, add a new line with the name of the serial tty for COM2:

```
ttyS1

```

The following example shows a sample file with the new line.

**NOTE:** Use the Break Key Sequence (~B) to perform the Linux **Magic SysRq** key commands on the serial console using
IPMI Tool.

```
 vc/1
 vc/2
 vc/3
 vc/4
 vc/5
 vc/6
 vc/7
 vc/8
 vc/9

```

```
 vc/10
 vc/11
 tty1
 tty2
 tty3
 tty4
 tty5
 tty6
 tty7
 tty8
 tty9
 tty10
 tty11
 ttyS1



## Configuring serial terminal in RHEL 7

```

To configure serial terminal in RHEL 7:

1. Add, or update the following lines to `/etc/default/grub` :

```
  GRUB_CMDLINE_LINUX_DEFAULT="console=tty0 console=ttyS0,115200n8"

  GRUB_TERMINAL="console serial"

  GRUB_SERIAL_COMMAND="serial --speed=115200 --unit=0 --word=8 --parity=no --stop=1"

```

`GRUB_CMDLINE_LINUX_DEFAULT` applies this configuration only to the default menu entry, use `GRUB_CMDLINE_LINUX`
to apply it to all the menu entries.

Each line should only appear once within the `/etc/default/grub` . If the line already exists, then modify it to avoid
another copy. Therefore, only one `GRUB_CMDLINE_LINUX_DEFAULT` line is allowed.

2. Rebuild the `/boot/grub2/grub.cfg` configuration file by running the `grub2-mkconfig -o` command as follows:
  - on BIOS-based systems:

```
    ~]# grub2-mkconfig -o /boot/grub2/grub.cfg

```

  - on UEFI-based systems:

```
    ~]# grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg

```

For more information, see the RHEL 7 System Administrator's Guide at redhat.com.



### Controlling GRUB from serial console

You can configure GRUB to use the serial console instead of the VGA console. This allows you to interrupt the boot process and
choose a different kernel or add kernel parameters, for example, to boot into single user mode.

To configure GRUB to use serial console, comment out the splash image and add the `serial` and `terminal` options to
`grub.conf` :

```
 [root@localhost ~]# cat /boot/grub/grub.conf

 # grub.conf generated by anaconda

 #

 # Note that you do not have to rerun grub after making changes to this file

 # NOTICE: You have a /boot partition. This means that

 #     all kernel and initrd paths are relative to /boot/, eg.

 #     root (hd0,0)

 #     kernel /vmlinuz-version ro root=/dev/hda2

 #     initrd /initrd-version.img

 #boot=/dev/hda

 default=0

 timeout=10

 #splashimage=(hd0,0)/grub/splash.xpm.gz

 serial --unit=0 --speed=1152001

```

**NOTE:** Restart the system for the settings to take effect.



## Supported SSH cryptography schemes

To communicate with iDRAC using SSH protocol, it supports multiple cryptography schemes listed in the following table.

|Table 21. SSH cryptography schemes|Col2|
|---|---|
|**Scheme Type**|**Algorithms**|
|**Asymmetric Cryptography**|**Asymmetric Cryptography**|
|Public key|●<br>curve25519-sha256<br>●<br>curve25519-sha256@libssh.org<br>●<br>ssh-rsa<br>●<br>ecdsa-sha2-nistp256<br>●<br>diffie-hellman-group16-sha512<br>●<br>diffie-hellman-group18-sha512<br>●<br>diffie-hellman-group14-sha256|
|**Symmetric Cryptography**|**Symmetric Cryptography**|
|Key Exchange|●<br>rsa-sha2-512<br>●<br>rsa-sha2-256|

**Table 21. SSH cryptography schemes (continued)**

|Scheme Type|Algorithms|
|---|---|
||●<br>ssh-rsa<br>●<br>ecdsa-sha2-nistp256<br>●<br>ssh-ed25519<br>●<br>ecdh-sha2-nistp256<br>●<br>ecdh-sha2-nistp384<br>●<br>ecdh-sha2-nistp521<br>●<br>diffie-hellman-group-exchange-sha256|
|Encryption|●<br>chacha20-poly1305@openssh.com<br>●<br>aes128-ctr<br>●<br>aes192-ctr<br>●<br>aes256-ctr<br>●<br>aes128-gcm@openssh.com<br>●<br>aes256-gcm@openssh.com|
|MAC|●<br>umac-64@openssh.com<br>●<br>umac-128-etm@openssh.com<br>●<br>hmac-sha2-256-etm@openssh.com<br>●<br>hmac-sha2-512-etm@openssh.com<br>●<br>umac-128@openssh.com<br>●<br>hmac-sha2-256<br>●<br>hmac-sha2-512|
|Compression|None|

**NOTE:** If you enable OpenSSH 7.0 or later, DSA public key support is disabled. To ensure better security for iDRAC, Dell
recommends not enabling DSA public key support.



### Using public key authentication for SSH

iDRAC supports the Public Key Authentication (PKA) over SSH. This is a licensed feature. When the PKA over SSH is set up
and used correctly, you must enter the user name while logging into iDRAC. This is useful for setting up automated scripts that
perform various functions. The uploaded keys must be in RFC 4716 or OpenSSH format. Else, you must convert the keys into
that format.

In any scenario, a pair of private and public key must be generated on the management station. The public key is uploaded to
iDRAC local user and private key is used by the SSH client to establish the trust relationship between the management station
and iDRAC.

You can generate the public or private key pair using:

- **PuTTY Key Generator** application for clients running Windows
- **ssh-keygen** CLI for clients running Linux.
**CAUTION: This privilege is normally reserved for users who are members of the Administrator user group on**
**iDRAC. However, users in the ‘Custom’ user group can be assigned this privilege. A user with this privilege can**
**modify any user’s configuration. This includes creation or deletion of any user, SSH Key management for users,**
**and so on. For these reasons, assign this privilege carefully.**

**CAUTION: The capability to upload, view, and/ or delete SSH keys is based on the ’Configure Users’ user**
**privilege. This privilege allows user(s) to configure another user's SSH key. You should grant this privilege**
**carefully.**



#### Generating public keys for Windows

To use the **PuTTY Key Generator** application to create the basic key:

1. Start the application and select RSA for the key type.
2. Enter the number of bits for the key. The number of bits must be between 2048 and 4096 bits.
3. Click **Generate** and move the mouse in the window as directed.

The keys are generated.

4. You can modify the key comment field.
5. Enter a passphrase to secure the key.
6. Save the public and private key.



#### Generating public keys for Linux

To use the **ssh-keygen** application to create the basic key, open a terminal window and at the shell prompt, enter `ssh-`
```
keygen –t rsa –b 2048 –C testing

```

Where:

- `-t` is **rsa** .
- `–b` specifies the bit encryption size between 2048 and 4096.
- `–C` allows modifying the public key comment and is optional.
**NOTE:** The options are case-sensitive.

Follow the instructions. After the command is performed, upload the public file.

**CAUTION: Keys that are generated from the Linux management station using ssh-keygen are in the non-4716**
**format. Convert the keys into the 4716 format using** **`ssh-keygen -e -f /root/.ssh/id_rsa.pub >`**

**`std_rsa.pub`** **. Do not change the permissions of the key file. The conversion must be done using default**

**permissions.**

**NOTE:** iDRAC does not support ssh-agent forward of keys.



#### Uploading SSH keys

You can upload up to four public keys **per user** to use over an SSH interface. Before adding the public keys, make sure that you
view the keys if they are set up, so that a key is not accidentally overwritten.

When adding new public keys, make sure that the existing keys are not at the index where the new key is added. iDRAC does
not perform checks to make sure previous key(s) are deleted before a new key(s) are added. When a new key is added, it is
usable if the SSH interface is enabled.



##### Uploading SSH keys using web interface

To upload the SSH keys:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Users** - **Local Users** .
The **Local Users** page is displayed.

2. In the **User ID** column, click a user ID number.

The **Users Main Menu** page is displayed.

3. Under **SSH Key Configurations**, select **Upload SSH Key(s)** and click **Next** .

The **Upload SSH Key(s)** page is displayed.

4. Upload the SSH keys in one of the following ways:
  - Upload the key file.
  - Copy the contents of the key file into the text box

For more information, see iDRAC Online Help.

5. Click **Apply** .



##### Uploading SSH keys using RACADM

To upload the SSH keys, run the following command:

**NOTE:** You cannot upload and copy a key at the same time.

- For local RACADM: `racadm sshpkauth -i <2 to 16> -k <1 to 4> -f <filename>`
- From remote RACADM using or SSH: `racadm sshpkauth -i <2 to 16> -k <1 to 4> -t <key-text>`

For example, to upload a valid key to iDRAC User ID 2 in the first key space using a file, run the following command:

```
 $ racadm sshpkauth -i 2 -k 1 -f pkkey.key

```

**NOTE:** The `-f` option is not supported on ssh/serial RACADM.



#### Viewing SSH keys

You can view the keys that are uploaded to iDRAC.



##### Viewing SSH keys using web interface

To view the SSH keys:

1. In Web interface, go to **iDRAC Settings** - **Users** .
The **Local Users** page is displayed.

2. In the **User ID** column, click a user ID number.

The **Users Main Menu** page is displayed.

3. Under **SSH Key Configurations**, select **View/Remove SSH Key(s)** and click **Next** .

The **View/Remove SSH Key(s)** page is displayed with the key details.



#### Deleting SSH keys

Before deleting the public keys, make sure that you view the keys if they are set up, so that a key is not accidentally deleted.



##### Deleting SSH keys using web interface

To delete the SSH key(s):

1. In Web interface, go to **iDRAC Settings** - **Users** .
The **Local Users** page is displayed.

2. In the **ID** column, select a user ID number, click **Edit** .

The **Edit User** page is displayed.

3. Under **SSH Key Configurations**, select a SSH Key and click **Edit** .

The **SSH Key** page displays the **Edit From** details.

4. Select **Remove** for the key(s) you want to delete, and click **Apply** .

The selected key(s) is deleted.



##### Deleting SSH keys using RACADM

To delete the SSH key(s), run the following commands:

- Specific key — `racadm sshpkauth -i <2 to 16> -d -k <1 to 4>`
- All keys — `racadm sshpkauth -i <2 to 16> -d -k all`



# 10 Configuring user accounts and privileges

You can setup user accounts with specific privileges ( **role-based authority** ) to manage your system using iDRAC and maintain
system security. By default iDRAC is configured with a local administrator account. The default iDRAC user name and password
are provided with the system badge. As an administrator, you can setup user accounts to allow other users to access iDRAC.
For more information see the documentation for the server.

You can setup local users or use directory services such as Microsoft Active Directory or LDAP to setup user accounts. Using a
directory service provides a central location for managing authorized user accounts.

iDRAC supports role-based access to users with a set of associated privileges. The roles are administrator, operator, read only,
or none. The role defines the maximum privileges available.

**Topics:**

- iDRAC user roles and privileges
- Recommended characters in user names and passwords
- Configuring local users
- Configuring Active Directory users
- Configuring generic LDAP users



## iDRAC user roles and privileges

The iDRAC role and privilege names have changed from earlier generation of servers. The role names are:

**Table 22. iDRAC roles**

|Current Generation|Prior Generation|Privileges|
|---|---|---|
|Administrator|Administrator|Login, Configure, Configure Users, Logs, System Control, Access Virtual<br>Console, Access Virtual Media, System Operations, Debug|
|Operator|Power User|Login, Configure, System Control, Access Virtual Console, Access<br>Virtual Media, System Operations, Debug|
|Read Only.|Guest User|Login|
|None|None|None|

The following table describes the user privileges:

**Table 23. iDRAC user privileges**

|User Privilege|Description|
|---|---|
|Login to iDRAC|Enables the user to log in to iDRAC.|
|Configure iDRAC|Enables the user to configure iDRAC. With this privilege, a user can also configure power<br>management, virtual console, virtual media, licenses, system settings, storage devices, BIOS<br>settings, SCP, and so on.|
|**NOTE:** The administrator role overrides all the privileges from the other components such as BIOS setup password.|**NOTE:** The administrator role overrides all the privileges from the other components such as BIOS setup password.|
|Configure Users|Enables the user to allow specific users to access the system.|
|Clear Logs|Enables the user to clear only the System Event Log (SEL).|
|Control and Configure System|Enables power cycling of the host system. Enables the users to configure iDRAC, power<br>management, virtual console, virtual media, licenses, system settings, storage devices, BIOS<br>settings, SCP, and so on. With this privilege, the users can also generate Technical Support<br>Reports (TSRs).|
|Access Virtual Console|Enables the users to run Virtual Console.|
|Access Virtual Media|Enables the user to run and use Virtual Media.|
|Test Alerts|Allows user initiated and generated events, and information is sent as an asynchronous<br>notification and logged.|
|Execute Debug Commands|Enables the user to run diagnostic commands.|



## Recommended characters in user names and passwords

This section provides details about the recommended characters while creating and using user names and passwords.

**NOTE:** The password must include one uppercase and one lower case letter, one number and a special character.

Use the following characters while creating user names and passwords:

**Table 24. Recommended characters for user names**

|Characters|Length|
|---|---|
|●<br>0-9<br>●<br>A-Z<br>●<br>a-z<br>●<br>- ! # $ % & ( ) * ; ? [\] ^ _ ` { | } ~ + < = >|1–16|

**Table 25. Recommended characters for passwords**

|Characters|iDRAC9 versions|Length|
|---|---|---|
|●<br>0-9<br>●<br>A-Z<br>●<br>a-z<br>●<br>' - ! " # $ % & ( ) *, . / : ; ? @<br>[\] ^ _ ` { | } ~ + < = >|7.00.00.00 and later|1–127|
|●<br>0-9<br>●<br>A-Z<br>●<br>a-z<br>●<br>' - ! " # $ % & ( ) *, . / : ; ? @<br>[\] ^ _ ` { | } ~ + < = >|●<br>4.00.00.00<br>●<br>Between 4.00.00.00 and 7.00.00.00|1-40|
|●<br>0-9<br>●<br>A-Z<br>●<br>a-z<br>●<br>' - ! " # $ % & ( ) *, . / : ; ? @<br>[\] ^ _ ` { | } ~ + < = >|Earlier than 4.00.00.00|1-20|

**NOTE:** You may be able to create user names and passwords that include other characters. However, to ensure
compatibility with all interfaces, Dell recommends using only the characters listed here.

**NOTE:** The characters allowed in user names and passwords for network shares are determined by the network-share type.
iDRAC supports valid characters for network share credentials as defined by the share type, except <, >, and, (comma).

**NOTE:** To improve security, it is recommended to use complex passwords that have eight or more characters and include
lowercase alphabets, uppercase alphabets, numbers, and special characters. It is also recommended to regularly change the
passwords, if possible.



## Configuring local users

You can configure up to 16 local users in iDRAC with specific access permissions. Before you create an iDRAC user, verify if
any current users exist. You can set user names, passwords, and roles with the privileges for these users. The user names and
passwords can be changed using any of the iDRAC secured interfaces (that is, web interface, RACADM or WSMan). You can
also enable or disable SNMPv3 authentication for each user.



### Configuring local users using iDRAC web interface

To add and configure local iDRAC users:

**NOTE:** You must have Configure Users permission to create an iDRAC user.

1. In the iDRAC Web interface, go to **iDRAC Settings** - **User** .
The **Local Users** page is displayed.

2. In the User **ID** column, select a user ID number and click **Edit** .
**NOTE:** User 1 is reserved for the IPMI anonymous user and you cannot change this configuration.

The **User Configuration** page is displayed.

3. Add **User Account Settings** and **Advanced Settings** details to configure the user account.
**NOTE:** Enable the user ID and specify the user name, password, and user role (access privileges) for the user. You can
also enable LAN privilege level, Serial port privilege level, serial over LAN status, SNMPv3 authentication, authentication
type and the privacy type for the user. For more information about the options, see the **iDRAC Online Help** .

4. Click **Save** . The user is created with the required privileges.



### Configuring local users using RACADM

**NOTE:** You must be logged in as user **root** to perform RACADM commands on a remote Linux system.

You can configure single or multiple iDRAC users using RACADM.

To configure multiple iDRAC users with identical configuration settings, follow these procedures:

- Use the RACADM examples in this section as a guide to create a batch file of RACADM commands, and then perform the
batch file on each managed system.

- Create the iDRAC configuration file and perform the `racadm set` command on each managed system using the same
configuration file.

If you are configuring a new iDRAC or if you have used the `racadm racresetcfg` command, then check for the default
iDRAC user name and password on the system badge. The `racadm racresetcfg` command resets the iDRAC to the default
values.

**NOTE:** If SEKM is enabled on the server, then disable SEKM using the `racadm sekm disable` command before using

this command. This can avoid any storage devices being locked out which are secured by iDRAC, if SEKM settings are
erased from iDRAC by performing this command.

**NOTE:** Users can be enabled and disabled over time. As a result, a user may have a different index number on each iDRAC.

To verify if a user exists, type the following command once for each index (1–16):

```
 racadm get iDRAC.Users.<index>.UserName

```

Several parameters and object IDs are displayed with their current values. The key field is `iDRAC.Users.UserName=` . If a
user name is displayed after =, that index number is taken.

To enable SNMP v3 authentication for a user, use **SNMPv3AuthenticationType**, **SNMPv3Enable**, **SNMPv3PrivacyType**
objects. For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.

If you use the Server Configuration Profile file to configure users, use the **AuthenticationProtocol**, **ProtocolEnable**, and
**PrivacyProtocol** attributes to enable SNMPv3 authentication.



#### Adding iDRAC user using RACADM

1. Set the index and user name.

```
  racadm set idrac.users.<index>.username <user_name>

|Parameter|Description|
|---|---|
|**`<index>`**|Unique index of the user|
|**`<user_name>`**|User name|

```

2. Set the password.

```
  racadm set idrac.users.<index>.password <password>

```

3. Set the user privileges.
4. Enable the user.

```
  racadm set idrac.users.<index>.enable 1

```

To verify, use the following command:

```
 racadm get idrac.users.<index>

```

[For more information, see the Integrated Dell Remote Access Controller 9 RACADM CLI guide.](https://www.dell.com/support/home/en-us/product-support/product/idrac9-lifecycle-controller-v7.x-series/docs)



#### Enabling iDRAC user with permissions

To enable a user with specific administrative permissions (role-based authority):

1. Locate an available user index.

```
  racadm get iDRAC.Users <index>

```

2. Type the following commands with the new user name and password.

```
  racadm set iDRAC.Users.<index>.Privilege <user privilege bit mask value>

```

**NOTE:** The default privilege value is 0, which indicates the user has no privileges enabled. For a list of valid bit-mask
[values for specific user privileges, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Configuring Active Directory users

If your company uses the Microsoft Active Directory software, you can configure the software to provide access to iDRAC,
allowing you to add and control iDRAC user privileges to your existing users in your directory service. This is a licensed feature.

You can configure user authentication through Active Directory to log in to the iDRAC. You can also provide role-based
authority, which enables an administrator to configure specific privileges for each user.

**NOTE:** StartTLS on Port 389 is supported. By default, LDAPS on Port 636 is configured. The connection protocol can be
reconfigured to StartTLS using Redfish or RACADM command `racadm set iDRAC.ActiveDirectory.Connection`

`StartTLS` .

**NOTE:** For any deployment done using MX Template and CA validation is enabled within the template, the user must upload
CA certificates at first login or before changing Authentication Service from LDAP to Active Directory or vice versa.



### Prerequisites for using Active Directory authentication for iDRAC

To use the Active Directory authentication feature of iDRAC, make sure that you have:

- Deployed an Active Directory infrastructure. See the Microsoft website for more information.
- Integrated PKI into the Active Directory infrastructure. iDRAC uses the standard Public Key Infrastructure (PKI) mechanism
to authenticate securely into the Active Directory. See the Microsoft website for more information.

- Enabled the Secure Socket Layer (SSL) on all domain controllers that iDRAC connects to for authenticating to all the domain
controllers.



#### Enabling SSL on domain controller

When iDRAC authenticates users with an Active Directory domain controller, it starts an SSL session with the domain controller.
At this time, the domain controller must publish a certificate signed by the Certificate Authority (CA)—the root certificate of
which is also uploaded into iDRAC. For iDRAC to authenticate to **any** domain controller—whether it is the root or the child
domain controller—that domain controller must have an SSL-enabled certificate signed by the domain’s CA.

If you are using Microsoft Enterprise Root CA to **automatically** assign all your domain controllers to an SSL certificate, you
must:

1. Install the SSL certificate on each domain controller.
2. Export the Domain Controller Root CA Certificate to iDRAC.
3. Import iDRAC Firmware SSL Certificate.



#### Installing SSL certificate for each domain controller

To install the SSL certificate for each controller:

1. Click **Start** - **Administrative Tools** - **Domain Security Policy** .
2. Expand the **Public Key Policies** folder, right-click **Automatic Certificate Request Settings** and click **Automatic**
**Certificate Request** .
The **Automatic Certificate Request Setup Wizard** is displayed.

3. Click **Next** and select **Domain Controller** .
4. Click **Next** and click **Finish** . The SSL certificate is installed.



#### Exporting domain controller root CA certificate to iDRAC

To export the domain controller root CA certificate to iDRAC:

1. Locate the domain controller that is running the Microsoft Enterprise CA service.
2. Click **Start** - **Run** .
3. Enter `mmc` and click **OK** .
4. In the **Console 1** (MMC) window, click **File (** or **Console )** and select **Add/Remove Snap-in** .
5. In the **Add/Remove Snap-In** window, click **Add** .
6. In the **Standalone Snap-In** window, select **Certificates** and click **Add** .
7. Select **Computer** and click **Next** .
8. Select **Local Computer**, click **Finish**, and click **OK** .
9. In the **Console 1** window, go to **Certificates** **Personal** **Certificates** folder.
10. Locate and right-click the root CA certificate, select **All Tasks**, and click **Export...** .
11. In the **Certificate Export Wizard**, click **Next**, and select **No do not export the private key** .
12. Click **Next** and select **Base-64 encoded X.509 (.cer)** as the format.
13. Click **Next** and save the certificate to a directory on your system.
14. Upload the certificate you saved in step 13 to iDRAC.



#### Importing iDRAC firmware SSL certificate

iDRAC SSL certificate is the identical certificate used for iDRAC Web server. All iDRAC controllers are shipped with a default
self-signed certificate.

If the Active Directory Server is set to authenticate the client during an SSL session initialization phase, you need to upload
iDRAC Server certificate to the Active Directory Domain controller. This additional step is not required if the Active Directory
does not perform a client authentication during an SSL session’s initialization phase.

**NOTE:** If iDRAC firmware SSL certificate is CA-signed and the certificate of that CA is already in the domain controller's
Trusted Root Certificate Authority list, do not perform the steps in this section.

To import iDRAC firmware SSL certificate to all domain controller trusted certificate lists:

1. Download iDRAC SSL certificate using the following RACADM command:

```
  racadm sslcertdownload -t 1 -f <RAC SSL certificate>

```

2. On the domain controller, open an **MMC Console** window and select **Certificates** - **Trusted Root Certification**
**Authorities** .

3. Right-click **Certificates**, select **All Tasks** and click **Import** .
4. Click **Next** and browse to the SSL certificate file.
5. Install iDRAC SSL Certificate in each domain controller’s **Trusted Root Certification Authority** .

If you have installed your own certificate, make sure that the CA signing your certificate is in the **Trusted Root**
**Certification Authority** list. If the Authority is not in the list, you must install it on all your domain controllers.

6. Click **Next** and select whether you want Windows to automatically select the certificate store based on the type of
certificate, or browse to a store of your choice.

7. Click **Finish** and click **OK** . The iDRAC firmware SSL certificate is imported to all domain controller trusted certificate lists.



### Supported Active Directory authentication mechanisms

You can use Active Directory to define iDRAC user access using two methods:

- **Standard schema** solution, which uses Microsoft’s default Active Directory group objects only.
- **Extended schema** solution, which has customized Active Directory objects. All the access control objects are maintained in
Active Directory. It provides maximum flexibility to configure user access on different iDRACs with varying privilege levels.



### Standard schema Active Directory overview

As shown in the following figure, using standard schema for Active Directory integration requires configuration on both Active
Directory and iDRAC.

**Figure 1. Configuration of iDRAC with active directory standard schema**

In Active Directory, a standard group object is used as a role group. A user who has iDRAC access is a member of the role group.
To provide this user access to a specific iDRAC, the role group name and its domain name must be configured on the specific
iDRAC. The role and the privilege level are defined on each iDRAC and not in the Active Directory. You can configure up to 15
role groups in each iDRAC. Table reference no shows the default role group privileges.

**Table 26. Default role group privileges**

|Role Groups|Default Privilege Level|Permissions Granted|Bit Mask|
|---|---|---|---|
|Role Group 1|None|Log in to iDRAC, Configure<br>iDRAC, Configure Users, Clear<br>Logs, perform Server Control<br>Commands, Access Virtual<br>Console, Access Virtual<br>Media, Test Alerts, perform<br>Diagnostic Commands.|0x000001ff|
|Role Group 2|None|Log in to iDRAC,<br>Configure iDRAC, perform<br>Server Control Commands,<br>Access Virtual Console,<br>Access Virtual Media, Test<br>Alerts, perform Diagnostic<br>Commands.|0x0000001f3|
|Role Group 3|None|Log in to iDRAC|0x00000001|
|Role Group 4|None|No assigned permissions|0x00000000|
|Role Group 5|None|No assigned permissions|0x00000000|

**NOTE:** The Bit Mask values are used only when setting Standard Schema with the RACADM.



#### Single domain versus multiple domain scenarios

If all the login users and role groups, including the nested groups, are in the same domain, then only the domain controllers’
addresses must be configured on iDRAC. In this single domain scenario, any group type is supported.

If all the login users and role groups, or any of the nested groups, are from multiple domains, then Global Catalog server
addresses must be configured on iDRAC. In this multiple domain scenario, all the role groups and nested groups, if any, must be
a Universal Group type.



### Configuring Standard schema Active Directory

Before configuring the standard schema Active Directory, ensure that:

- You have the iDRAC Enterprise or Datacenter license.
- The configuration is performed on a server that is used as the Domain Controller.
- The dat, time and time zone on the server are correct.
- The iDRAC network settings are configured, or in iDRAC web interface go to **iDRAC Settings > Connectivity > Network >**
**Common Settings** to configure the network settings.

To configure iDRAC for an Active Directory login access:

1. On an Active Directory server (domain controller), open the Active Directory Users and Computers Snap-in.
2. Create the iDRAC groups and users.
3. Configure the group name, domain name, and the role privileges on iDRAC using the iDRAC web interface or RACADM.



#### Configuring Active Directory with Standard schema using iDRAC web interface

**NOTE:** For information about the various fields, see the **iDRAC Online Help** .

1. In the iDRAC web interface, go to **iDRAC Settings** - **Users** - **Directory Services** .
The **Directory Service** page is displayed.

2. Select the **Microsoft Active Directory** option and then click **Edit** .

The **Active Directory Configuration and Management** page is displayed.

3. Click **Configure Active Directory** .

The **Active Directory Configuration and Management Step 1 of 4** page is displayed.

4. Optionally, enable certificate validation and upload the CA-signed digital certificate used during initiation of SSL connections
when communicating with the Active Directory (AD) server. For this, the Domain Controllers and Global Catalog FQDN must
be specified. This is done in the next steps. And hence the DNS should be configured properly in the network settings.

5. Click **Next** .

The **Active Directory Configuration and Management Step 2 of 4** page is displayed.

6. Enable Active Directory and specify the location information about Active Directory servers and user accounts. Also, specify
the time iDRAC must wait for responses from Active Directory during iDRAC login.

**NOTE:** If certificate validation is enabled, specify the Domain Controller Server addresses and the Global Catalog FQDN.
Make sure that DNS is configured correctly under **iDRAC Settings**     - **Network** .

7. Click **Next** . The **Active Directory Configuration and Management Step 3 of 4** page is displayed.
8. Select **Standard Schema** and click Next.

The **Active Directory Configuration and Management Step 4a of 4** page is displayed.

9. Enter the location of Active Directory global catalog server(s) and specify privilege groups used to authorize users.
10. Click a **Role Group** to configure the control authorization policy for users under the standard schema mode.

The **Active Directory Configuration and Management Step 4b of 4** page is displayed.

11. Specify the privileges and click **Apply** .

The settings are applied and the **Active Directory Configuration and Management Step 4a of 4** page is displayed.

12. Click **Finish** . The Active Directory settings for standard schema are configured.



#### Configuring Active Directory with Standard schema using RACADM

1. Use the following commands:

```
  racadm set iDRAC.ActiveDirectory.Enable 1
  racadm set iDRAC.ActiveDirectory.Schema 2
  racadm set iDRAC.ADGroup.Name <common name of the role group>
  racadm set iDRAC.ADGroup.Domain <fully qualified domain name>
  racadm set iDRAC.ADGroup.Privilege <Bit-mask value for specific RoleGroup permissions>
  racadm set iDRAC.ActiveDirectory.DomainController1 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.DomainController2 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.DomainController3 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.GlobalCatalog1 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.GlobalCatalog2 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.GlobalCatalog3 <fully qualified domain name or IP
  address of the domain controller>

```

  - Enter the Fully Qualified Domain Name (FQDN) of the domain controller, not the FQDN of the domain. For example, enter
`servername.dell.com` instead of `dell.com` .

  - For bit-mask values for specific Role Group permissions, see Default role group privileges.
  - You must provide at least one of the three domain controller addresses. iDRAC attempts to connect to each of the
configured addresses one-by-one until it makes a successful connection. With Standard Schema, these are the addresses
of the domain controllers where the user accounts and the role groups are located.

  - The Global Catalog server is only required for standard schema when the user accounts and role groups are in different
domains. In multiple domain case, only the Universal Group can be used.

  - If certificate validation is enabled, the FQDN or IP address that you specify in this field must match the Subject or
Subject Alternative Name field of your domain controller certificate.

  - To disable the certificate validation during SSL handshake, use the following command:

```
    racadm set iDRAC.ActiveDirectory.CertValidationEnable 0

```

In this case, no Certificate Authority (CA) certificate needs to be uploaded.

  - To enforce the certificate validation during SSL handshake (optional), use the following command:

```
    racadm set iDRAC.ActiveDirectory.CertValidationEnable 1

```

In this case, you must upload the CA certificate using the following command:

```
    racadm sslcertupload -t 0x2 -f <ADS root CA certificate>

```

**NOTE:** If certificate validation is enabled, specify the Domain Controller Server addresses and the Global Catalog
FQDN. Ensure that DNS is configured correctly under **Overview**      - **iDRAC Settings**      - **Network** .

Using the following RACADM command may be optional.

```
    racadm sslcertdownload -t 1 -f <RAC SSL certificate>

```

2. If DHCP is enabled on iDRAC and you want to use the DNS provided by the DHCP server, enter the following command:

```
  racadm set iDRAC.IPv4.DNSFromDHCP 1

```

3. If DHCP is disabled on iDRAC or you want manually enter the DNS IP address, enter the following RACADM command:

```
  racadm set iDRAC.IPv4.DNSFromDHCP 0
  racadm set iDRAC.IPv4.DNSFromDHCP.DNS1 <primary DNS IP address>
  racadm set iDRAC.IPv4.DNSFromDHCP.DNS2 <secondary DNS IP address>

```

4. If you want to configure a list of user domains so that you only need to enter the user name when logging in to the web
interface, use the following command:

```
  racadm set iDRAC.UserDomain.<index>.Name <fully qualified domain name or IP Address
  of the domain controller>

```

You can configure up to 40 user domains with index numbers between 1 and 40.



### Extended schema Active Directory overview

Using the extended schema solution requires the Active Directory schema extension.



###### Best practices for extended schema

The extended schema uses Dell association objects to join iDRAC and permission. This allows you to use iDRAC based on
the overall permissions granted. The default Access Control List (ACL) of Dell Association objects allows Self and Domain
Administrators to manage the permissions and scope of iDRAC objects.

By default, the Dell Association objects do not inherit all permissions from the parent Active Directory objects. If you enable
inheritance for the Dell Association object, the inherited permissions for that association object are granted to the selected
users and groups. This may result in unintended privileges being provided to the iDRAC.

To use the Extended Schema securely, Dell recommends not enabling inheritance on Dell Association objects within the
extended schema implementation.



#### Active directory schema extensions

The Active Directory data is a distributed database of **attributes** and **classes** . The Active Directory schema includes the rules
that determine the type of data that can be added or included in the database. The user class is one example of a **class** that
is stored in the database. Some example user class attributes can include the user’s first name, last name, phone number,

and so on. You can extend the Active Directory database by adding your own unique **attributes** and **classes** for specific
requirements. Dell has extended the schema to include the necessary changes to support remote management authentication
and authorization using Active Directory.

Each **attribute** or **class** that is added to an existing Active Directory Schema must be defined with a unique ID. To maintain
unique IDs across the industry, Microsoft maintains a database of Active Directory Object Identifiers (OIDs) so that when
companies add extensions to the schema, they can be guaranteed to be unique and not to conflict with each other. To extend
the schema in Microsoft's Active Directory, Dell received unique OIDs, unique name extensions, and uniquely linked attribute IDs
for the attributes and classes that are added into the directory service:

- Extension is: `dell`
- Base OID is: `1.2.840.113556.1.8000.1280`
- RAC LinkID range is: `12070 to 12079`



#### Overview of iDRAC schema extensions

Dell has extended the schema to include an **Association**, **Device**, and **Privilege** property. The **Association** property is used
to link together the users or groups with a specific set of privileges to one or more iDRAC devices. This model provides an
administrator maximum flexibility over the different combinations of users, iDRAC privileges, and iDRAC devices on the network
without much complexity.

For each physical iDRAC device on the network that you want to integrate with Active Directory for authentication and
authorization, create at least one association object and one iDRAC device object. You can create multiple association objects,
and each association object can be linked to as many users, groups of users, or iDRAC device objects as required. The users and
iDRAC user groups can be members of any domain in the enterprise.

However, each association object can be linked (or, may link users, groups of users, or iDRAC device objects) to only one
privilege object. This example allows an administrator to control each user’s privileges on specific iDRAC devices.

iDRAC device object is the link to iDRAC firmware for querying Active Directory for authentication and authorization. When
iDRAC is added to the network, the administrator must configure iDRAC and its device object with its Active Directory name so
that users can perform authentication and authorization with Active Directory. Additionally, the administrator must add iDRAC
to at least one association object for users to authenticate.

The following figure shows that the association object provides the connection that is needed for the authentication and
authorization.

**Figure 2. Typical setup for active directory objects**

You can create as many or as few association objects as required. However, you must create at least one Association Object,
and you must have one iDRAC Device Object for each iDRAC device on the network that you want to integrate with Active
Directory for Authentication and Authorization with iDRAC.

The Association Object allows for as many or as few users and/or groups as well as iDRAC Device Objects. However, the
Association Object only includes one Privilege Object per Association Object. The Association Object connects the Users who
have Privileges on iDRAC devices.

The Dell extension to the ADUC MMC Snap-in only allows associating the Privilege Object and iDRAC Objects from the same
domain with the Association Object. The Dell extension does not allow a group or an iDRAC object from other domains to be
added as a product member of the Association Object.

When adding Universal Groups from separate domains, create an Association Object with Universal Scope. The Default
Association objects created by the Dell Schema Extender Utility are Domain Local Groups and they do not work with Universal
Groups from other domains.

Users, user groups, or nested user groups from any domain can be added into the Association Object. Extended Schema
solutions support any user group type and any user group nesting across multiple domains allowed by Microsoft Active
Directory.



#### Accumulating privileges using Extended Schema

The Extended Schema Authentication mechanism supports Privilege Accumulation from different privilege objects associated
with the same user through different Association Objects. In other words, Extended Schema Authentication accumulates
privileges to allow the user the super set of all assigned privileges corresponding to the different privilege objects associated
with the same user.

The following figure provides an example of accumulating privileges using Extended Schema.

**Figure 3. Privilege accumulation for a user**

The figure shows two Association Objects—A01 and A02. User1 is associated to iDRAC2 through both association objects.

Extended Schema Authentication accumulates privileges to allow the user the maximum set of privileges possible considering
the assigned privileges of the different privilege objects associated to the same user.

In this example, User1 has both Priv1 and Priv2 privileges on iDRAC2. User1 has Priv1 privileges on iDRAC1 only. User2 has Priv1
privileges on both iDRAC1 and iDRAC2. In addition, this figure shows that User1 can be in a different domain and can be a
member of a group.



### Configuring Extended schema Active Directory

To configure Active Directory to access iDRAC:

1. Extend the Active Directory schema.
2. Extend the Active Directory Users and Computers Snap-in.
3. Add iDRAC users and their privileges to Active Directory.
4. Configure iDRAC Active Directory properties using iDRAC Web interface or RACADM.



#### Extending Active Directory schema

Extending your Active Directory schema adds a Dell organizational unit, schema classes and attributes, and example privileges
and association objects to the Active Directory schema. Before you extend the schema, make sure that you have the Schema
Admin privileges on the Schema Master FSMO-Role-Owner of the domain forest.

**NOTE:** The schema extension for this product is different from the previous generations. The earlier schema does not work
with this product.

**NOTE:** Extending the new schema has no impact on previous versions of the product.

You can extend your schema using one of the following methods:

- Dell Schema Extender utility
- LDIF script file

If you use the LDIF script file, the Dell organizational unit is not added to the schema.

The LDIF files and Dell Schema Extender are on your **Dell Systems Management Tools and Documentation** DVD in the
following respective directories:

- DVDdrive `:\SYSMGMT\ManagementStation\support\OMActiveDirectory_Tools\Remote_Management_Adv`
```
  anced\LDIF_Files
```

- <DVDdrive>:
```
  \SYSMGMT\ManagementStation\support\OMActiveDirectory_Tools\Remote_Management_Advanced\Sch
  ema Extender

```

To use the LDIF files, see the instructions in the readme included in the **LDIF_Files** directory.

You can copy and run the Schema Extender or LDIF files from any location.



##### Using Dell Schema Extender

**CAUTION: The Dell Schema Extender uses the SchemaExtenderOem.ini file. To make sure that the Dell Schema**
**Extender utility functions properly, do not modify the name of this file.**

1. In the **Welcome** screen, click **Next.**
2. Read and understand the warning and click **Next** .
3. Select **Use Current Log In Credentials** or enter a user name and password with schema administrator rights.
4. Click **Next** to run the Dell Schema Extender.
5. Click **Finish** .

The schema is extended. To verify the schema extension, use the MMC and the Active Directory Schema Snap-in to verify
that the Classes and attributes exist. See the Microsoft documentation for details about using the MMC and the Active
Directory Schema Snap-in.



###### Classes and attributes

**Table 27. Class definitions for classes added to the active directory schema**

|Class Name|Assigned Object Identification Number (OID)|
|---|---|
|delliDRACDevice|1.2.840.113556.1.8000.1280.1.7.1.1|
|delliDRACAssociation|1.2.840.113556.1.8000.1280.1.7.1.2|
|dellRAC4Privileges|1.2.840.113556.1.8000.1280.1.1.1.3|
|dellPrivileges|1.2.840.113556.1.8000.1280.1.1.1.4|
|dellProduct|1.2.840.113556.1.8000.1280.1.1.1.5|

**Table 28. DelliDRACdevice class**

|OID|1.2.840.113556.1.8000.1280.1.7.1.1|
|---|---|
|Description|Represents the Dell iDRAC device. iDRAC must be configured<br>as delliDRACDevice in Active Directory. This configuration<br>enables iDRAC to send Lightweight Directory Access Protocol<br>(LDAP) queries to Active Directory.|
|Class Type|Structural Class|
|SuperClasses|dellProduct|
|Attributes|dellSchemaVersion dellRacType|

**Table 29. delliDRACAssociationObject class**

|OID|1.2.840.113556.1.8000.1280.1.7.1.2|
|---|---|
|Description|Represents the Dell Association Object. The Association<br>Object provides the connection between the users and the<br>devices.|
|Class Type|Structural Class|
|SuperClasses|Group|
|Attributes|dellProductMembers dellPrivilegeMember|

**Table 30. dellRAC4Privileges class**

|OID|1.2.840.113556.1.8000.1280.1.1.1.3|
|---|---|
|Description|Defines the privileges (Authorization Rights) for iDRAC|
|Class Type|Auxiliary Class|
|SuperClasses|None|
|Attributes|●<br>dellIsLoginUser<br>●<br>dellIsCardConfigAdmin<br>●<br>dellIsUserConfigAdmin<br>●<br>dellIsLogClearAdmin<br>●<br>dellIsServerResetUser<br>●<br>dellIsConsoleRedirectUser<br>●<br>dellIsVirtualMediaUser<br>●<br>dellIsTestAlertUser<br>●<br>dellIsDebugCommandAdmin|

**Table 31. dellPrivileges class**

|OID|1.2.840.113556.1.8000.1280.1.1.1.4|
|---|---|
|Description|Used as a container Class for the Dell Privileges (Authorization<br>Rights).|
|Class Type|Structural Class|
|SuperClasses|User|
|Attributes|dellRAC4Privileges|

**Table 32. dellProduct class**

|OID|1.2.840.113556.1.8000.1280.1.1.1.5|
|---|---|
|Description|The main class from which all Dell products are derived.|
|Class Type|Structural Class|
|SuperClasses|Computer|
|Attributes|dellAssociationMembers|

**Table 33. List of attributes added to the active directory schema**

|Attribute Name/Description|Assigned OID/Syntax Object Identifier|Single Valued|
|---|---|---|
|**dellPrivilegeMember** —List of<br>dellPrivilege Objects that belong to<br>this Attribute.|●<br>1.2.840.113556.1.8000.1280.1.1.2.1<br>●<br>Distinguished Name (LDAPTYPE_DN<br>1.3.6.1.4.1.1466.115.121.1.12)|FALSE|
|**dellProductMembers** —List of<br>dellRacDevice and DelliDRACDevice<br>Objects that belong to this role.|●<br>1.2.840.113556.1.8000.1280.1.1.2.2<br>●<br>Distinguished Name (LDAPTYPE_DN<br>1.3.6.1.4.1.1466.115.121.1.12)|FALSE|
|This attribute is the forward<br>link to the dellAssociationMembers<br>backward link. Link ID: 12070|||
|**dellIsLoginUser** —TRUE if the user<br>has Login rights on the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.3<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsCardConfigAdmin** —TRUE if<br>the user has Card Configuration<br>rights on the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.4<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsUserConfigAdmin** —TRUE if<br>the user has User Configuration rights<br>on the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.5<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**delIsLogClearAdmin** —TRUE if the<br>user has Log Clearing rights on the<br>device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.6<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsServerResetUser** —TRUE if<br>the user has Server Reset rights on<br>the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.7<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsConsoleRedirectUser** —TRUE<br>if the user has Virtual Console rights<br>on the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.8<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsVirtualMediaUser** —TRUE if<br>the user has Virtual Media rights on<br>the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.9<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsTestAlertUser** —TRUE if the<br>user has Test Alert User rights on the<br>device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.10<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellIsDebugCommandAdmin** —<br>TRUE if the user has Debug<br>Command Admin rights on the device.|●<br>1.2.840.113556.1.8000.1280.1.1.2.11<br>●<br>Boolean (LDAPTYPE_BOOLEAN<br>1.3.6.1.4.1.1466.115.121.1.7)|TRUE|
|**dellSchemaVersion** —The Current<br>Schema Version is used to update the<br>schema.|●<br>1.2.840.113556.1.8000.1280.1.1.2.12<br>●<br>Case Ignore String<br>(LDAPTYPE_CASEIGNORESTRING<br>1.2.840.113556.1.4.905)|TRUE|
|**dellRacType** —This attribute<br>is the Current RAC Type<br>for the delliDRACDevice object<br>and the backward link to<br>the dellAssociationObjectMembers<br>forward link.|●<br>1.2.840.113556.1.8000.1280.1.1.2.13<br>●<br>Case Ignore String<br>(LDAPTYPE_CASEIGNORESTRING<br>1.2.840.113556.1.4.905)|TRUE|
|**dellAssociationMembers** —List of<br>dellAssociationObjectMembers that<br>belong to this Product. This attribute<br>is the backward link to the<br>dellProductMembers linked attribute.<br>Link ID: 12071|●<br>1.2.840.113556.1.8000.1280.1.1.2.14<br>●<br>Distinguished Name (LDAPTYPE_DN<br>1.3.6.1.4.1.1466.115.121.1.12)|FALSE|



#### Installing Dell extension to the Active Directory users and computers snap-in

When you extend the schema in Active Directory, you must also extend the Active Directory Users and Computers Snap-in so
the administrator can manage iDRAC devices, users and user groups, iDRAC associations, and iDRAC privileges.

When you install your systems management software using the **Dell Systems Management Tools and Documentation** DVD,
you can extend the Snap-in by selecting the **Active Directory Users and Computers Snap-in** option during the installation
procedure. See the Dell OpenManage Software Quick Installation Guide for additional instructions about installing systems
management software. For 64-bit Windows Operating Systems, the Snap-in installer is located under:

**<DVDdrive>:\SYSMGMT\ManagementStation\support\OMActiveDirectory_SnapIn64**

For more information about the Active Directory Users and Computers Snap-in, see Microsoft documentation.



#### Adding iDRAC users and privileges to Active Directory

Using the Dell-extended Active Directory Users and Computers Snap-in, you can add iDRAC users and privileges by creating
device, association, and privilege objects. To add each object, perform the following:

- Create an iDRAC device Object
- Create a Privilege Object
- Create an Association Object
- Add objects to an Association Object



##### Creating iDRAC device object

To create iDRAC device object:

1. In the MMC **Console Root** window, right-click a container.
2. Select **New** - **Dell Remote Management Object Advanced** .

The **New Object** window is displayed.

3. Enter a name for the new object. The name must be identical to iDRAC name that you enter while configuring Active
Directory properties using iDRAC Web interface.

4. Select iDRAC **Device Object** and click OK.



##### Creating privilege object

To create a privilege object:

**NOTE:** You must create a privilege object in the same domain as the related association object.

1. In the **Console Root** (MMC) window, right-click a container.
2. Select **New** - **Dell Remote Management Object Advanced** .

The **New Object** window is displayed.

3. Enter a name for the new object.
4. Select **Privilege Object** and click OK.
5. Right-click the privilege object that you created, and select **Properties** .
6. Click the **Remote Management Privileges** tab and assign the privileges for the user or group.



##### Creating association object

To create association object:

**NOTE:** iDRAC association object is derived from the group and its scope is set to Domain Local.

1. In the **Console Root** (MMC) window, right-click a container.
2. Select **New** - **Dell Remote Management Object Advanced** .

This **New Object** window is displayed.

3. Enter a name for the new object and select **Association Object** .
4. Select the scope for the **Association Object** and click OK.
5. Provide access privileges to the authenticated users for accessing the created association objects.



##### Providing user access privileges for association objects

To provide access privileges to the authenticated users for accessing the created association objects:

1. Go to **Administrative Tools** - **ADSI Edit** . The **ADSI Edit** window is displayed.
2. In the right-pane, navigate to the created association object, right-click and select **Properties** .
3. In the **Security** tab, click **Add** .
4. Type `Authenticated Users`, click **Check Names**, and click **OK** . The authenticated users is added to the list of **Groups**
**and user names** .

5. Click **OK** .



##### Adding objects to association object

Using the **Association Object Properties** window, you can associate users or user groups, privilege objects, and iDRAC
devices or iDRAC device groups.

You can add groups of users and iDRAC devices.



##### Adding users or user groups

To add users or user groups:

1. Right-click the **Association Object** and select **Properties** .
2. Select the **Users** tab and click **Add** .
3. Enter the user or user group name and click **OK** .



##### Adding privileges

To add privileges:

Click the **Privilege Object** tab to add the privilege object to the association that defines the user’s or user group’s privileges
when authenticating to an iDRAC device. Only one privilege object can be added to an Association Object.

1. Select the **Privileges Object** tab and click **Add** .
2. Enter the privilege object name and click **OK** .
3. Click the **Privilege Object** tab to add the privilege object to the association that defines the user’s or user group’s privileges
when authenticating to an iDRAC device. Only one privilege object can be added to an Association Object.



##### Adding iDRAC devices or iDRAC device groups

To add iDRAC devices or iDRAC device groups:

1. Select the **Products** tab and click **Add** .
2. Enter iDRAC devices or iDRAC device group name and click **OK** .
3. In the **Properties** window, click **Apply** and click **OK** .
4. Click the **Products** tab to add one iDRAC device connected to the network that is available for the defined users or user
groups. You can add multiple iDRAC devices to an Association Object.



#### Configuring Active Directory with Extended schema using iDRAC web interface

To configure Active Directory with extended schema using Web interface:

**NOTE:** For information about the various fields, see the **iDRAC Online Help** .

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Users** - **Directory Services** - **Microsoft Active Directory** . Click
**Edit**

The **Active Directory Configuration and Management Step 1 of 4** page is displayed.

2. Optionally, enable certificate validation and upload the CA-signed digital certificate used during initiation of SSL connections
when communicating with the Active Directory (AD) server.

3. Click **Next** .

The **Active Directory Configuration and Management Step 2 of 4** page is displayed.

4. Specify the location information about Active Directory (AD) servers and user accounts. Also, specify the time iDRAC must
wait for responses from AD during login process.

**NOTE:**

   - If certificate validation is enabled, specify the Domain Controller Server addresses and the FQDN. Make sure that
DNS is configured correctly under **iDRAC Settings**      - **Network**

   - If the user and iDRAC objects are in different domains, then do not select the **User Domain from Login** option.
Instead select **Specify a Domain** option and enter the domain name where the iDRAC object is available.

5. Click **Next** . The **Active Directory Configuration and Management Step 3 of 4** page is displayed.
6. Select **Extended Schema** and click **Next** .

The **Active Directory Configuration and Management Step 4 of 4** page is displayed.

7. Enter the name and location of the iDRAC device object in Active Directory (AD) and click **Finish** .
The Active Directory settings for extended schema mode is configured.



#### Configuring Active Directory with Extended schema using RACADM

To configure Active Directory with Extended Schema using the RACADM:

1. Use the following commands:

```
  racadm set iDRAC.ActiveDirectory.Enable 1
  racadm set iDRAC.ActiveDirectory.Schema 2
  racadm set iDRAC.ActiveDirectory.RacName <RAC common name>
  racadm set iDRAC.ActiveDirectory.RacDomain <fully qualified rac domain name>
  racadm set iDRAC.ActiveDirectory.DomainController1 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.DomainController2 <fully qualified domain name or IP
  address of the domain controller>
  racadm set iDRAC.ActiveDirectory.DomainController3 <fully qualified domain name or IP
  address of the domain controller>

```

  - Enter the Fully Qualified Domain Name (FQDN) of the domain controller, not the FQDN of the domain. For example, enter
`servername.dell.com` instead of `dell.com` .

  - You must provide at least one of the three addresses. iDRAC attempts to connect to each of the configured addresses
one-by-one until it makes a successful connection. With Extended Schema, these are the FQDN or IP addresses of the
domain controllers where this iDRAC device is located.

  - To disable the certificate validation during SSL handshake, use the following command:

```
    racadm set iDRAC.ActiveDirectory.CertValidationEnable 0

```

In this case, you do not have to upload a CA certificate.

  - To enforce the certificate validation during SSL handshake (optional):

```
    racadm set iDRAC.ActiveDirectory.CertValidationEnable 1

```

In this case, you must upload a CA certificate using the following command:

```
    racadm sslcertupload -t 0x2 -f <ADS root CA certificate>

```

**NOTE:** If certificate validation is enabled, specify the Domain Controller Server addresses and the FQDN. Ensure
that DNS is configured correctly under **iDRAC Settings**      - **Network** .

Using the following RACADM command may be optional:

```
    racadm sslcertdownload -t 1 -f <RAC SSL certificate>

```

2. If DHCP is enabled on iDRAC and you want to use the DNS provided by the DHCP server, enter the following command:

```
  racadm set iDRAC.IPv4.DNSFromDHCP 1

```

3. If DHCP is disabled in iDRAC or you want to manually input your DNS IP address, enter the following command:

```
  racadm set iDRAC.IPv4.DNSFromDHCP 0
  racadm set iDRAC.IPv4.DNSFromDHCP.DNS1 <primary DNS IP address>
  racadm set iDRAC.IPv4.DNSFromDHCP.DNS2 <secondary DNS IP address>

```

4. If you want to configure a list of user domains so that you only need to enter the user name during log in to iDRAC web
interface, use the following command:

```
  racadm set iDRAC.UserDomain.<index>.Name <fully qualified domain name or IP Address
  of the domain controller>

```

You can configure up to 40 user domains with index numbers between 1 and 40.



### Testing Active Directory settings

You can test the Active Directory settings to verify whether your configuration is correct, or to diagnose the problem with a
failed Active Directory log in.



#### Testing Active Directory settings using iDRAC web interface

To test the Active Directory settings:

1. In iDRAC Web Interface, go to **iDRAC Settings** - **Users** - **Directory Services** - **Microsoft Active Directory**, click **Test** .
The **Test Active Directory Settings** page is displayed.

2. Click **Test** .
3. Enter a test user's name (for example, **username@domain.com** ) and password and click **Start Test** . A detailed test results
and the test log displays.

If there is a failure in any step, examine the details in the test log to identify the problem and a possible solution.

**NOTE:** When testing Active Directory settings with Enable Certificate Validation checked, iDRAC requires that the
Active Directory server be identified by the FQDN and not an IP address. If the Active Directory server is identified by an
IP address, certificate validation fails because iDRAC is not able to communicate with the Active Directory server.



## Configuring generic LDAP users

iDRAC provides a generic solution to support Lightweight Directory Access Protocol (LDAP)-based authentication. This feature
does not require any schema extension on your directory services.

To make iDRAC LDAP implementation generic, the commonality between different directory services is used to group users and
then map the user-group relationship. The directory service-specific action is the schema. For example, they may have different
attribute names for the group, user, and the link between the user and the group. These actions can be configured in iDRAC.

**NOTE:** StartTLS on Port 389 is supported. By default, LDAPS on Port 636 is configured. The connection protocol
can be reconfigured to StartTLS using Redfish or the RACADM command `racadm set iDRAC.LDAP.Connection`

`StartTLS` .

**NOTE:** The Smart Card-based Two-Factor Authentication (TFA) and the Single Sign-On (SSO) logins are not supported for
generic LDAP Directory Service.



### Configuring generic LDAP directory service using iDRAC web- based interface

To configure the generic LDAP directory service using Web interface:

**NOTE:** For information about the various fields, see the **iDRAC Online Help** .

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Users** - **Directory Services** - **Generic LDAP Directory Service**,
click **Edit** .
The **Generic LDAP Configuration and Management Step 1 of 3** page displays the current generic LDAP settings.

2. Optionally, enable certificate validation and upload the digital certificate used during initiation of SSL connections when
communicating with a generic LDAP server.

3. Click **Next** .

The **Generic LDAP Configuration and Management Step 2 of 3** page is displayed.

4. Enable generic LDAP authentication and specify the location information about generic LDAP servers and user accounts.
**NOTE:** If certificate validation is enabled, specify the LDAP Server’s FQDN and make sure that DNS is configured
correctly under **iDRAC Settings**     - **Network** .

**NOTE:** In this release, nested group is not supported. The firmware searches for the direct member of the group to
match the user DN. Also, only single domain is supported. Cross domain is not supported.

5. Click **Next** .

The **Generic LDAP Configuration and Management Step 3a of 3** page is displayed.

6. Click **Role Group** .

The **Generic LDAP Configuration and Management Step 3b of 3** page is displayed.

7. Specify the group distinguished name, the privileges associated with the group, and click **Apply** .
**NOTE:** If you are using Novell eDirectory and if you have used these characters—#(hash), "(double quotes), ;(semi
colon), > (greater than),, (comma), or <(lesser than)—for the Group DN name, they must be escaped.

The role group settings are saved. The **Generic LDAP Configuration and Management Step 3a of 3** page displays the
role group settings.

8. If you want to configure additional role groups, repeat steps 7 and 8.
9. Click **Finish** . The generic LDAP directory service is configured.



### Configuring generic LDAP directory service using RACADM

To configure the LDAP directory service, use the objects in the `iDRAC.LDAP` and `iDRAC.LDAPRole` groups.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Testing LDAP directory service settings

You can test the LDAP directory service settings to verify whether your configuration is correct, or to diagnose the problem
with a failed LDAP log in.



#### Testing LDAP directory service settings using iDRAC web interface

To test the LDAP directory service settings:

1. In iDRAC Web Interface, go to **iDRAC Settings** - **Users** - **Directory Services** - **Generic LDAP Directory Service** .
The **Generic LDAP Configuration and Management** page displays the current generic LDAP settings.

2. Click **Test** .
3. Enter the user name and password of a directory user that is chosen to test the LDAP settings. The format depends on the
**Attribute of User Login** is used and the user name entered must match the value of the chosen attribute.

**NOTE:** When testing LDAP settings with **Enable Certificate Validation** checked, iDRAC requires that the LDAP server
be identified by the FQDN and not an IP address. If the LDAP server is identified by an IP address, certificate validation
fails because iDRAC is not able to communicate with the LDAP server.

**NOTE:** When generic LDAP is enabled, iDRAC first tries to login the user as a directory user. If it fails, local user lookup
is enabled.

The test results and the test log are displayed.



# 11 System Configuration Lockdown mode

System Configuration Lockdown mode helps in preventing unintended changes after a system is provisioned. Lockdown mode
is applicable to both configuration and firmware updates. When the system is locked down, any attempt to change the system
configuration is blocked. If any attempts are made to change the critical system settings, an error message is displayed. Enabling
System lockdown mode blocks the firmware update of third-party I/O cards using the vendor tools.

System Lockdown mode is only available for Enterprise licensed customers.

In the 4.40.00.00 release, System lockdown functionality is extended to NICs also.

**NOTE:** Enhanced Lockdown for NICs only includes firmware lockdown to prevent firmware updates. Configuration (x-UEFI)
lockdown is not supported.

**NOTE:** After the System Lockdown mode is enabled, you cannot change any configuration settings. System settings fields
are disabled.

Lockdown mode can be enabled or disabled using the following interfaces:

- iDRAC web interface
- RACADM
- WSMan
- System Configuration Profile (SCP)
- Redfish
- Using F2 during POST and selecting iDRAC Settings
- Factory System Erase
**NOTE:** To enable Lockdown mode, you must have an iDRAC Enterprise or Datacenter license, and Control and Configure
system privileges.

**NOTE:** You may be able to access vMedia while system is in the Lockdown mode but configuring remote file share is not
enabled.

**NOTE:** The interfaces such as OMSA, SysCfg, and USC can only check the settings but cannot modify the configurations.

**NOTE:** When the Lockdown mode is enabled, you cannot configure any alert settings. However, you can trigger a test
email.

The following table lists the functional and nonfunctional features, interfaces, and utilities that are affected by Lockdown mode:

**NOTE:** Changing the boot order using iDRAC is not supported when Lockdown mode is enabled. However, a boot-control
option is available in the vConsole menu, which has no effect when iDRAC is in the Lockdown mode.

**Table 34. Items affected by Lockdown mode**

|Disabled|Remains functional|
|---|---|
|●<br>Deleting Licenses<br>●<br>DUP updates<br>●<br>SCP import<br>●<br>Reset to defaults<br>●<br>OMSA/OMSS<br>●<br>IPMI<br>●<br>DRAC/LC<br>●<br>DTK-Syscfg<br>●<br>Redfish<br>●<br>OpenManage Essentials<br>●<br>BIOS (F2 settings become read-only)<br>●<br>Group manager|●<br>Power Operations - Power ON/OFF, Reset<br>●<br>Power cap setting<br>●<br>Power priority<br>●<br>Identify devices (Chassis or PERC)<br>●<br>Part replacement, Easy Restore, and System Board replacement<br>●<br>Running diagnostics<br>●<br>Modular operations (FlexAddress or Remote-Assigned Address)<br>●<br>Group Manager passcode<br>●<br>All vendor tools that have direct access to the device (excludes<br>selected NICs)<br>●<br>License export<br>●<br>PERC|
|●<br>Select network cards.<br>●<br>iLKM/SEKM|○<br>PERC CLI<br>○<br>DTK-RAIDCFG<br>○<br>F2/Ctrl+R<br>●<br>All Vendor tools that have direct access to the device.<br>●<br>NVMe<br>○<br>DTK-RAIDCFG<br>○<br>F2/Ctrl+R<br>●<br>BOSS-S1<br>○<br>Marvell CLI<br>○<br>F2/Ctrl+R<br>●<br>ISM/OMSA settings (OS BMC enable, watchdog ping, operating<br>system name, operating system version)|

**NOTE:** When lockdown mode is enabled, the OpenID Connect login option is not displayed in the iDRAC login page.



# 12 Configuring iDRAC for Single Sign-On or smart card login

This section provides information to configure iDRAC for Smart Card login (for local users and Active Directory users), and
Single Sign-On (SSO) login (for Active Directory users.) SSO and smart card login are licensed features.

iDRAC supports Kerberos based Active Directory authentication to support Smart Card and SSO logins. For information on
Kerberos, see the Microsoft website.

**Topics:**

- Prerequisites for Active Directory Single Sign-On or Smart Card login
- Configuring iDRAC SSO login for Active Directory users
- Enabling or disabling smart card login
- Configuring Smart Card Login
- Log in using Smart Card



## Prerequisites for Active Directory Single Sign-On or Smart Card login

The prerequisites to Active Directory based SSO or Smart Card logins are:

- Synchronize iDRAC time with the Active Directory domain controller time. If not, kerberos authentication on iDRAC fails. You
can use the Time zone and NTP feature to synchronize the time. To do this, see Configuring time zone and NTP.

- Register iDRAC as a computer in the Active Directory root domain.
**NOTE:** iDRAC does not support Personal Identity Verification (PIV) or Common Access Card (CAC) smart card users
on a child or subdomain in a forest or collection of domains. To overcome this limitation, it is recommended to deploy all
smart card users on the root domain instead of the child domains within the forest.

- Generate a keytab file using the ktpass tool.
- To enable Single Sign-On for Extended schema, make sure that the **Trust this user for delegation to any service**
**(Kerberos only)** option is selected on the **Delegation** tab for the keytab user. This tab is available only after creating the
keytab file using ktpass utility.

- Configure the browser to enable SSO login.
- Create the Active Directory objects and provide the required privileges.
- For SSO, configure the reverse lookup zone on the DNS servers for the subnet where iDRAC resides.
**NOTE:** If the hostname does not match the reverse DNS lookup, Kerberos authentication fails.

- Configure the browser to support SSO login. For more information, see Single Sign-On.
**NOTE:** Google Chrome and Safari do not support Active Directory for SSO login.



### Registering iDRAC on Domain name System

To register iDRAC in Active Directory root domain:

1. Click **iDRAC Settings** - **Connectivity** - **Network** .
The **Network** page is displayed.

2. You can select **IPv4 Settings** or **IPv6 Settings** based on the IP settings.
3. Provide a valid **Preferred/Alternate DNS Server** IP address. This value is a valid DNS server IP address that is part of the
root domain.

4. Select **Register iDRAC on DNS** .
5. Provide a valid **DNS Domain Name** .
6. Verify that network DNS configuration matches with the Active Directory DNS information.

For more information about the options, see the **iDRAC Online Help** .



### Creating Active Directory objects and providing privileges





###### Logging in to Active Directory Standard schema based SSO

Perform the following steps for Active Directory Standard schema based SSO login:

1. Create a User Group.
2. Create a User for Standard schema.
**NOTE:** Use the existing AD User Group & AD User.



###### Logging in to Active Directory Extended schema based SSO

Perform the following steps for Active Directory Extended schema based SSO login:

1. Create the device object, privilege object, and association object in the Active Directory server.
2. Set access privileges to the created privilege object.
**NOTE:** It is recommended not to provide administrator privileges as this could bypass some security checks.

3. Associate the device object and privilege object using the association object.
4. Add the preceding SSO user (login user) to the device object.
5. Provide access privilege to **Authenticated Users** for accessing the created association object.



###### Logging in to Active Directory SSO

Perform the following steps for Active Directory SSO login:

1. Create a Kerberos key-tab user which is used for the creation of the key-tab file.
**NOTE:** Create new KERBROS key for every iDRAC IP.



## Configuring iDRAC SSO login for Active Directory users

Before configuring iDRAC for Active Directory SSO login, make sure that you have completed all the prerequisites.

You can configure iDRAC for Active Directory SSO when you setup an user account based on Active Directory.



### Creating a User in Active Directory for SSO

To create a user in Active Directory for SSO:

1. Create a new user in the organization unit.
2. Go to **Kerberos User>Properties>Account>Use Kerberos AES Encryption types for this account**
3. Use the following command to generate a Kerberos keytab in the Active Directory server:

```
  C:\> ktpass.exe -princ HTTP/idrac7name.domainname.com@DOMAINNAME.COM -mapuser
  DOMAINNAME\username -mapop set -crypto AES256-SHA1 -ptype KRB5_NT_PRINCIPAL -pass
  [password] -out c:\krbkeytab



###### Note for Extended Schema

```

- Change the Delegation setting of the Kerberos user.
- Go to **Kerberos User>Properties>Delegation>Trust this user for delegation to any service (Kerberos only)**
**NOTE:** Log-off and Log-in from the Management Station Active Directory user after changing the above setting.



### Generating Kerberos keytab file

To support the SSO and smart card login authentication, iDRAC supports the configuration to enable itself as a kerberized
service on a Windows Kerberos network. The Kerberos configuration on iDRAC involves the same steps as configuring a non–
Windows Server Kerberos service as a security principal in Windows Server Active Directory.

The **ktpass** tool (available from Microsoft as part of the server installation CD/DVD) is used to create the Service Principal
Name (SPN) bindings to a user account and export the trust information into a MIT–style Kerberos **keytab** file, which
enables a trust relation between an external user or system and the Key Distribution Center (KDC). The keytab file contains
a cryptographic key, which is used to encrypt the information between the server and the KDC. The ktpass tool allows UNIX–
based services that support Kerberos authentication to use the interoperability features provided by a Windows Server Kerberos
KDC service. For more information about the **ktpass** utility, see the Microsoft website at: **technet.microsoft.com/en-us/**
**library/cc779157(WS.10).aspx**

Before generating a keytab file, you must create an Active Directory user account for use with the **-mapuser** option of the
`ktpass` command. Also, you must have the same name as iDRAC DNS name to which you upload the generated keytab file.

To generate a keytab file using the ktpass tool:

1. Run the **ktpass** utility on the domain controller (Active Directory server) where you want to map iDRAC to a user account in
Active Directory.

2. Use the following ktpass command to create the Kerberos keytab file:

```
  C:\> ktpass.exe -princ HTTP/idrac7name.domainname.com@DOMAINNAME.COM -mapuser
  DOMAINNAME\username -mapop set -crypto AES256-SHA1 -ptype KRB5_NT_PRINCIPAL -pass
  [password] -out c:\krbkeytab

```

The encryption type is AES256-SHA1. The principal type is KRB5_NT_PRINCIPAL. The properties of the user account to
which the Service Principal Name is mapped to must have **Use AES 256 encryption types for this account** property
enabled.

**NOTE:** Use lowercase letters for the **iDRACname** and **Service Principal Name** . Use uppercase letters for the domain
name as shown in the example.

A keytab file is generated.

**NOTE:** If you find any issues with the iDRAC user for which the keytab file is created, create a user and a new keytab
file. If the same keytab file that was initially created is again run, it does not configure correctly.



### Configuring iDRAC SSO login for Active Directory users using web interface

To configure iDRAC for Active Directory SSO login:

**NOTE:** For information about the options, see the **iDRAC Online Help** .

1. Verify whether the iDRAC DNS name matches the iDRAC Fully Qualified Domain Name. To do this, in iDRAC Web interface,
go to **iDRAC Settings**   - **Network**   - **Common Settings** and refer to **DNS iDRAC Name** property.

2. While configuring Active Directory to setup a user account based on standard schema or extended schema, perform the
following two additional steps to configure SSO:

  - Upload the keytab file on the **Active Directory Configuration and Management Step 1 of 4** page.
  - Select **Enable Single Sign-On** option on the **Active Directory Configuration and Management Step 2 of 4** page.



### Configuring iDRAC SSO login for Active Directory users using RACADM

To enable SSO, complete the steps to configure Active Directory, and run the following command:

```
 racadm set iDRAC.ActiveDirectory.SSOEnable 1



### Management Station Settings

```

Perform the following steps after configuring SSO login for Active Directory users:
1. Set the DNS Server IP in Network properties and mention the preferred DNS Server IP.
2. Go to My Computer and add the ***domain.tld** domain.
3. Add the Active Directory User to Administrator by navigating to: **My Computer** - **Manage** - **Local User and Groups**
**Groups**  - **Administrator** and add the Active Directory User.
4. Logoff the system and login using the Active Directory User credential.
5. In Internet Explorer Setting, add *domain.tld domain as below:

a. Go to **Tools**   - **Internet Options**   - **Security**   - **Local Internet**   - **Sites** and clear the **Automatically detect intranet**
**network setting** selection. Select the remaining three options and click **Advanced** to add *domain.tld.
b. Open a new window in IE and use the iDRAC hostname to launch the iDRAC GUI.
6. In Mozilla Firefox Setting, add *domain.tld domain:
  - Launch Firefox browser and type about:config in the URL.
  - Use negotiate in the filter textbox. Double click the result consisting of **auth.trusted.uris** . Type the domain, save the
settings and close the browser.

  - Open a new window in Firefox and use the iDRAC hostname to launch the iDRAC GUI.



## Enabling or disabling smart card login

Before enabling or disabling smart card login for iDRAC, make sure that:

- You have configure iDRAC permissions.
- iDRAC local user configuration or Active Directory user configuration with the appropriate certificates is complete.
**NOTE:** If smart card login is enabled, then SSH, IPMI Over LAN, Serial Over LAN, and remote RACADM are disabled. Again,
if you disable smart card login, the interfaces are not enabled automatically.



### Enabling or disabling smart card login using web interface

To enable or disable the Smart Card logon feature:

1. In the iDRAC web interface, go to **iDRAC Settings** - **Users** - **Smart Card** .
The **Smart Card** page is displayed.

2. From the **Configure Smart Card Logon** drop-down menu, select **Enabled** to enable smart card logon or select **Enabled**
**With Remote RACADM** . Else, select **Disabled** .

For more information about the options, see the **iDRAC Online Help** .

3. Click **Apply** to apply the settings.

You are prompted for a Smart Card login during any subsequent logon attempts using the iDRAC web interface.



### Enabling or disabling smart card login using RACADM

To enable smart card login, use the `set` command with objects in the `iDRAC.SmartCard` group.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



### Enabling or disabling smart card login using iDRAC settings utility

To enable or disable the Smart Card logon feature:

1. In the iDRAC Settings utility, go to **Smart Card** .
The **iDRAC Settings Smart Card** page is displayed.

2. Select **Enabled** to enable smart card logon. Else, select **Disabled** . For more information about the options, see **iDRAC**
**Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The smart card logon feature is enabled or disabled based on the selection.



## Configuring Smart Card Login

**NOTE:** For Active Directory Smart Card Configuration, iDRAC must be configured either with Standard or Extended
Schema SSO Login.



### Configuring iDRAC smart card login for Active Directory users

Before configuring iDRAC Smart Card login for Active Directory users, make sure that you have completed the required
prerequisites.

To configure iDRAC for smart card login:

1. In iDRAC Web interface, while configuring Active Directory to set up an user account based on standard schema or extended
schema, on the **Active Directory Configuration and Management Step 1 of 4** page:

  - Enable certificate validation.
  - Upload a trusted CA-signed certificate.
  - Upload the keytab file.
2. Enable smart card login. For information about the options, see the **iDRAC Online Help** .



### Configuring iDRAC smart card login for local users

To configure iDRAC local user for smart card login:

1. Upload the smart card user certificate and trusted CA certificate to iDRAC.
2. Enable smart card login.



#### Uploading smart card user certificate

Before you upload the user certificate, make sure that the user certificate from the smart card vendor is exported in Base64
format. SHA-2 certificates are also supported.



##### Uploading smart card user certificate using web interface

To upload smart card user certificate:

1. In iDRAC web interface, go to **iDRAC Settings** - **Users** - **Smart Card** .
**NOTE:** The Smart Card login feature requires the configuration of the local and/or Active Directory user certificate.

2. Under **Configure Smart Card Logon**, select **Enabled With Remote RACADM** to enable the configuration..
3. Set the option to **Enable CRL Check for Smart Card Logon** .
4. Click **Apply** .



##### Uploading smart card user certificate using RACADM

To upload smart card user certificate, use the **usercertupload** object. For more information, see the Integrated Dell Remote
Access Controller RACADM CLI Guide.



#### Requesting Certificate for smart card enrollment

Follow these steps to request certificate for smart card enrollment:
1. Connect the smart card in the client system and install the required drivers & software.
2. Verify the driver status in the Device Manager.
3. Launch the smart card enrollment agent in the browser.
4. Enter the **Username** & **Password** and click **OK** .
5. Click **Request Certificate** .
6. Click **Advanced Certificate Request** .
7. Click **Request a certificate** for a smart card on behalf of another user by using the smart card certificate enrollment
station.
8. Select user to enroll by clicking **Select User** button.
9. Click **Enroll** and enter the smart card credential.
10. Enter the smart card PIN and click on **Submit** .



#### Uploading trusted CA certificate for smart card

Before you upload the CA certificate, make sure that you have a CA-signed certificate.



##### Uploading trusted CA certificate for smart card using web interface

To upload trusted CA certificate for smart card login:

1. In iDRAC Web interface, go to **iDRAC Settings** - **Network** - **User Authentication** - **Local Users** .
The **Users** page is displayed.

2. In the **User ID** column, click a user ID number.

The **Users Main Menu** page is displayed.

3. Under **Smart Card Configurations**, select **Upload Trusted CA Certificate** and click **Next** .

The **Trusted CA Certificate Upload** page is displayed.

4. Browse and select the trusted CA certificate, and click **Apply** .



##### Uploading trusted CA certificate for smart card using RACADM

To upload trusted CA certificate for smart card login, use the **usercertupload** object. For more information, see the _Integrated_
_Dell Remote Access Controller RACADM CLI Guide_ .



## Log in using Smart Card

**NOTE:** Smart Card log in is supported in Edge, Chrome, and Firefox..

**NOTE:** Smart Card log in is supported only with TLS 1.2.

1. Log out from the iDRAC GUI after enabling the smart card.
2. Launch iDRAC by using http://IP or launch using the FQDN http://FQDN.
3. Click **Install** after the smart card plug-in downloads.
4. Enter the smart card PIN and click **Submit** . iDRAC logs in successfully using Smart Card
5. .



# 13 Configuring iDRAC to send alerts

You can set alerts and actions for certain events that occur on the managed system. An event occurs when the status of a
system component is greater than the pre-defined condition. If an event matches an event filter and you have configured this
filter to generate an alert (e-mail, SNMP trap, IPMI alert, remote system logs, Redfish event, or WS events), then an alert is
sent to one or more configured destinations. If the same event filter is also configured to perform an action (such as reboot,
power cycle, or power off the system), the action is performed. You can set only one action for each event.

To configure iDRAC to send alerts:

1. Enable alerts.
2. Optionally, you can filter the alerts based on category or severity.
3. Configure the e-mail alert, IPMI alert, SNMP trap, remote system log, Redfish event, operating system log, and/or WS-event
settings.

4. Enable event alerts and actions such as:
  - Send an email alert, IPMI alert, SNMP traps, remote system logs, Redfish event, operating system log, or WS events to
configured destinations.

  - Perform a reboot, power off, or power cycle the managed system.
**NOTE:** For any update requiring iDRAC reset/ reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is
fully ready by waiting for few seconds of interval with maximum timeout of 5 minutes before using any other command.

**Topics:**

- Enabling or disabling alerts
- Setting event alerts
- Setting alert recurrence event
- Setting event actions
- Configuring email alert, SNMP trap, or IPMI trap settings
- Configuring WS Eventing
- Configuring Redfish Eventing
- Configuring Remote System Logging
- Monitoring chassis events
- Alerts message IDs
- Liquid cooling leak detection



## Enabling or disabling alerts

For sending an alert to configured destinations or to perform an event action, you must enable the global alerting option. This
property overrides individual alerting or event actions that is set.



### Enabling or disabling alerts using web interface

To enable or disable generating alerts:

1. In the iDRAC web interface, go to **Configuration** - **System Settings** - **Alert Configuration** .
The **Alerts** page is displayed.

2. Under **Alerts** section:
  - Select **Enable** to enable alert generation or perform an event action.
  - Select **Disable** to disable alert generation or disable an event action.
3. Click **Apply** to save the setting.



#### Quick Alert Configuration

To configure alerts in bulk:

1. Go to **Quick Alert Configuration** under **Alert Configuration** page.
2. Under **Quick Alert Configuration** section:
  - Select the alert category.
  - Select the issue severity notification.
  - Select the location where you would like to receive these notifications.
3. Click **Apply** to save the settings.

All the alerts that are configured are displayed in total under **Alerts Configuration Summary** .

**NOTE:** You must select at least one category, one severity, and one destination type to apply the configuration.

**NOTE:** After the alerts are configured using the **Quick Alerts** tab, and when you go to the **Alert Configuration** tab, the
configured alerts are not enabled in the respective alert categories. To enable the respective alert categories:

1. Select one of the other category tabs ( **System Health**, **Audit**, **Updates**, and **Configuration** ) in the **Alert**
**Configuration** page.

2. Revert to the category that was originally used for alert configuration.



### Enabling or disabling alerts using RACADM

Use the following command:

```
 racadm set iDRAC.IPMILan.AlertEnable <n>

```

n=0 — Disabled

n=1 — Enabled



### Enabling or disabling alerts using iDRAC settings utility

To enable or disable generating alerts or event actions:

1. In the iDRAC Settings utility, go to **Alerts** .
The **iDRAC Settings Alerts** page is displayed.

2. Under **Platform Events**, select **Enabled** to enable alert generation or event action. Else, select **Disabled** . For more
information about the options, see **iDRAC Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The alert settings are configured.



## Setting event alerts

You can set event alerts such as e-mail alerts, IPMI alerts, SNMP traps, remote system logs, operating system logs, and WS
events to be sent to configured destinations.



### Setting event alerts using web interface

To set an event alert using the web interface:

1. Make sure that you have configured the e-mail alert, IPMI alert, SNMP trap settings, and/or remote system log settings.
2. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Alerts and Remote System Log Configuration** .
3. Under **Category**, select one or all of the following alerts for the required events:
  - Email
  - SNMP Trap
  - IPMI Alert
  - Remote System Log
  - WS Eventing
  - OS Log
  - Redfish Event
4. Select **Action** .

The setting is saved.

5. Optionally, you can send a test event. In the **Message ID to Test Event** field, enter the message ID to test if the alert is
generated and click **Test** . For more information about the event and error messages generated by the system firmware and
agents that monitor system components, see the **Event and Error Message Reference Guide** [at iDRACmanuals](https://www.dell.com/support/home/us/en/19/product-support/product/idrac9-lifecycle-controller-v3.30.30.30/docs)



### Setting event alerts using RACADM

To set an event alert, use the **eventfilters** command. For more information, see the Integrated Dell Remote Access Controller
RACADM CLI Guide.



## Setting alert recurrence event

You can configure iDRAC to generate additional events at specific intervals if the system continues to operate at a temperature
which is greater than the inlet temperature threshold limit. The default interval is 30 days. The valid range is 0 to 366 days. A
value of ‘0’ indicates no event recurrence.

**NOTE:** You must have Configure iDRAC privilege to set the alert recurrence value.



### Setting alert recurrence events using RACADM

To set the alert recurrence event using RACADM, use the **eventfilters** command. For more information, see the Integrated Dell
Remote Access Controller RACADM CLI Guide.



### Setting alert recurrence events using iDRAC web interface

To set the alert recurrence value:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Alert Recurrence** .
2. In the **Recurrence** column, enter the alert frequency value for the required category, alert, and severity type(s).

For more information, see the **iDRAC Online help** .

3. Click **Apply** .

The alert recurrence settings are saved.



## Setting event actions

You can set event actions such as perform a reboot, power cycle, power off, or perform no action on the system.



### Setting event actions using web interface

To set an event action:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Alert and Remote System Log Configuration** .
2. From the **Actions** drop-down menu, for each event select an action:
  - Reboot
  - Power Cycle
  - Power Off
  - No Action
3. Click **Apply** .

The setting is saved.



### Setting event actions using RACADM

To configure an event action, use the `eventfilters` command. For more information, see the Integrated Dell Remote Access
Controller RACADM CLI Guide.



## Configuring email alert, SNMP trap, or IPMI trap settings

The management station uses Simple Network Management Protocol (SNMP) and Intelligent Platform Management Interface
(IPMI) traps to receive data from iDRAC. For systems with large number of nodes, it may not be efficient for a management
station to poll each iDRAC for every condition that may occur. For example, event traps can help a management station with
load balancing between nodes or by issuing an alert if an authentication failure occurs. SNMP v1, v2, and v3 formats are
supported.

You can configure the IPv4 and IPv6 alert destinations, email settings, and SMTP server settings, and test these settings. You
can also specify the SNMP v3 user to whom you want to send the SNMP traps.

Before configuring the email, SNMP, or IPMI trap settings, make sure that:

- You have Configure RAC permission.
- You have configured the event filters.



### Configuring IP alert destinations

You can configure the IPv6 or IPv4 addresses to receive the IPMI alerts or SNMP traps.

For information about the iDRAC MIBs required to monitor the servers using SNMP, see the _Dell OpenManage SNMP Reference_
_Guide_ [available on the OpenManage manualspage..](https://www.dell.com/openmanagemanuals)



#### Configuring IP alert destinations using web interface

To configure alert destination settings using Web interface:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **SNMP and E-mail Settings** .
2. Select the **State** option to enable an alert destination (IPv4 address, IPv6 address, or Fully Qualified Domain Name (FQDN))
to receive the traps.

You can specify up to eight destination addresses. For more information about the options, see the **iDRAC Online Help** .

3. Select the SNMP v3 user to whom you want to send the SNMP trap.
4. Enter the iDRAC SNMP community string (applicable only for SNMPv1 and v2) and the SNMP alert port number.

For more information about the options, see the **iDRAC Online Help** .

**NOTE:** The Community String value indicates the community string to use in a Simple Network Management Protocol
(SNMP) alert trap sent from iDRAC. Make sure that the destination community string is the same as the iDRAC
community string. The default value is Public.

5. To test whether the IP address is receiving the IPMI or SNMP traps, click **Send** under **Test IPMI Trap** and **Test SNMP**
**Trap** respectively.

6. Click **Apply** .

The alert destinations are configured.

7. In the **SNMP Trap Format** section, select the protocol version to be used to send the traps on the trap destination(s) —
**SNMP v1**, **SNMP v2**, or **SNMP v3** and click **Apply** .

**NOTE:** The **SNMP Trap Format** option applies only for SNMP Traps and not for IPMI Traps. IPMI Traps are always
sent in SNMP v1 format and is not based on the configured **SNMP Trap Format** option.

The SNMP trap format is configured.



#### Configuring IP alert destinations using RACADM

To configure the trap alert settings:

1. To enable traps:

```
  racadm set idrac.SNMP.Alert.<index>.Enable <n>

```

|Parameter|Description|
|---|---|
|**`<index>`**|Destination index. Allowed values are 1 through 8.|
|**`<n>`**=0<br>**`<n>`**=1|Disable the trap<br>Enable the trap|
|**`<index>`**|Destination index. Allowed values are 1 through 8.|
|**`<Address>`**|A valid IPv4, IPv6, or FQDN address|

```

3. Configure the SNMP community name string:

```
  racadm set idrac.ipmilan.communityname <community_name>

|Parameter|Description|
|---|---|
|**`<community_name>`**|The SNMP Community Name.|

```

4. To configure SNMP destination:
  - Set the SNMP trap destination for SNMPv3:

```
    racadm set idrac.SNMP.Alert.<index>.DestAddr <IP address>

```

  - Set SNMPv3 users for trap destinations:

```
    racadm set idrac.SNMP.Alert.<index>.SNMPv3Username <user_name>

```

  - Enable SNMPv3 for a user:

```
    racadm set idrac.users.<index>.SNMPv3Enable Enabled

```

5. To test the trap, if required:

```
  racadm testtrap -i <index>

```

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Configuring IP alert destinations using iDRAC settings utility

You can configure alert destinations (IPv4, IPv6, or FQDN) using the iDRAC Settings utility. To do this:

1. In the **iDRAC Settings utility**, go to **Alerts** .
The **iDRAC Settings Alerts** page is displayed.

2. Under **Trap Settings**, enable the IP address(es) to receive the traps and enter the IPv4, IPv6, or FQDN destination
address(es). You can specify up to eight addresses.

3. Enter the community string name.

For information about the options, see the **iDRAC Settings Utility Online Help** .

4. Click **Back**, click **Finish**, and then click **Yes** .

The alert destinations are configured.



### Configuring email alert settings

You can configure the sender email address and receiver (destination) email address to receive the email alerts. Also, configure
the SMTP server address settings.

**NOTE:** Email alerts support both IPv4 and IPv6 addresses. The iDRAC DNS Domain Name must be specified when using
IPv6.

**NOTE:** If you are using an external SMTP server, ensure that iDRAC can communicate with that server. If the server is
unreachable, the error RAC0225 is displayed while trying to send a test mail.



#### Configuring email alert settings using web interface

To configure the email alert settings using Web interface:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **SMTP (E-mail) Configuration** .
2. Type a valid email address.
3. Click **Send** under **Test Email** to test the configured email alert settings.
4. Click **Apply** .
5. For SMTP (Email) Server Settings provide the following details:
  - SMTP (Email) Server IP Address or FQDN/DNS Name
  - Custom Sender Address—This field has the following options:
   - **Default** —Address field is not editable.
   - **Custom** —You can enter the email ID from which you can receive the email alerts.
  - Custom Message Subject Prefix—This field has the following options:
   - **Default** —Default message is not editable.
   - **Custom** —You can choose the message to appear in the **Subject** line of the email.
  - SMTP Port Number—The connection can be encrypted and emails can be sent over secure ports:
   - **No Encryption** —Port 25 (default)
   - **SSL**   - Port 465
  - Connection Encryption—When you do not have an email server in your premises, you can use cloud-based email servers
or SMTP Relays. To configure a cloud email server, you can set this feature to any of the following values from the
drop-down:

   - **None** —No encryption on the connection to the SMTP server. It is the default value.
   - **SSL** —Runs SMTP protocol over SSL
**NOTE:**

    - This feature is not configurable using Group Manager.
    - This is a licensed feature and is not available in the iDRAC Basic License.
    - You must have Configure iDRAC privilege to use this feature.
  - Authentication
  - Username

For Server settings, the port usage depends on `connectionencryptiontype` and this can be configured only using
RACADM.

6. Click **Apply** . For more information about the options, see the **iDRAC Online Help** .



#### Configuring email alert settings using RACADM

1. To enable email alert:

```
  racadm set iDRAC.EmailAlert.Enable.[index] [n]

```

|Parameter|Description|
|---|---|
|**`index`**|Email destination index. Allowed values are 1 through 4.|
|**`n`**=0<br>**`n`**=1|Disables email alerts.<br>Enables email alerts.|
|**`index`**|Email destination index. Allowed values are 1 through 4.|
|**`email-address`**|Destination email address that receives the platform event alerts.|

```

3. To configure sender email settings:

```
  racadm set iDRAC.RemoteHosts.[index] [email-address]

|Parameter|Description|
|---|---|
|**`index`**|Sender Email index.|
|**`email-address`**|Sender email address that sends the platform event alerts.|
|**`index`**|Email destination index. Allowed values are 1 through 4.|
|**`custom-message`**|Custom message|

```

5. To test the configured email alert, if required:

```
  racadm testemail -i [index]

|Parameter|Description|
|---|---|
|**`index`**|Email destination index to be tested. Allowed values are 1 through 4.|

```

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Configuring SMTP email server address settings

You must configure the SMTP server address for email alerts to be sent to specified destinations.



##### Configuring SMTP email server address settings using iDRAC web interface

To configure the SMTP server address:

1. In iDRAC Web interface, go to **Configuaration** - **System Settings** - **Alert Configuration** - **SNMP (E-mail**
**Configuration)** .

2. Enter the valid IP address or fully qualified domain name (FQDN) of the SMTP server to be used in the configuration.
3. Select the **Enable Authentication** option and then provide the user name and password (of a user who has access to
SMTP server).

4. Enter the SMTP port number.

For more information about the fields, see the **iDRAC Online Help** .

5. Click **Apply** .

The SMTP settings are configured.



##### Configuring SMTP email server address settings using RACADM

To configure the SMTP email server:

```
 racadm set iDRAC.RemoteHosts.SMTPServerIPAddress <SMTP E-mail Server IP Address>



## Configuring WS Eventing

```

The WS Eventing protocol is used for a client service (subscriber) to register interest (subscription) with a server (event
source) for receiving messages containing the server events (notifications or event messages). Clients interested in receiving
the WS Eventing messages can subscribe with iDRAC and receive Lifecycle Controller job related events.

The steps required to configure WS Eventing feature to receive WS Eventing messages for changes related to Lifecycle
Controller jobs are described in the Web service Eventing Support for iDRAC 1.30.30 specification document. In addition to this
specification, see the DSP0226 (DMTF WS Management Specification), Section 10 Notifications (Eventing) document for the
complete information on the WS Eventing protocol. The Lifecycle Controller related jobs are described in the DCIM Job Control
Profile document.



## Configuring Redfish Eventing

The Redfish eventing protocol is used for a client service (subscriber) to register interest (subscription) with a server (event
source) for receiving messages containing the Redfish events (notifications or event messages). Clients interested in receiving
the Redfish eventing messages can subscribe with iDRAC and receive Lifecycle Controller job related events.



## Configuring Remote System Logging

You can send lifecycle logs to a remote system. Before doing this, ensure that:

- There is network connectivity between iDRAC and the remote system.
- The remote system and iDRAC are on the same network.
**NOTE:** This feature is available with iDRAC Enterprise and Datacenter licenses.

Remote Syslog identity certificate can be generated within the company's internal certificate signing server setup. TLS based
Remote Syslog servers and clients use the same CA certificate in the configuration settings, which is obtained from a CA server.
iDRAC provides a user interface to upload this CA certificate and add it to its configuration file and restart the Remote Syslog
service.



### Configuring remote system logging using web interface

To configure the remote syslog server settings:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Alert Configuration** - **Remote Syslog** **Settings** .
2. The following settings are available. Select the required setting:
  - **Basic Settings** —For legacy solutions
  - **Secure Settings** —For new Implementation (Encrypt Remote Syslog traffic with TLS). For
  - **None** —For disabling Remote Syslog alerts

For information about the field values of these options, see the **iDRAC Online Help** .

3. Click **Apply** .

The settings are saved. All logs written to the lifecycle log are also simultaneously written to configured remote server(s).



### Configuring remote system logging using RACADM

To configure the remote system-logging settings, use the `set` command with the objects in the `iDRAC.SysLog` group.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Enabling Secure Remote System Logs in RACADM

Run the **set iDRAC.syslog.Securesyslogenable** to enable secure remote system logs in iDRAC. To run this command
successfully, upload the Syslog CA Certificate before you enable the Secure Syslog Server.



## Monitoring chassis events

On the PowerEdge FX2/FX2s chassis, you can enable the **Chassis Management and Monitoring** setting in iDRAC to perform
chassis management and monitoring tasks such as monitoring chassis components, configuring alerts, using iDRAC RACADM to
pass CMC RACADM commands, and updating the chassis management firmware. This setting allows you to manage the servers
in the chassis even if the CMC is not on the network. You can set the value to **Disabled** to forward the chassis events. By
default, this setting is set as **Enabled** .

**NOTE:** For this setting to take effect, you must ensure that in CMC, the **Chassis Management at Server** setting must be
set to **Monitor** or **Manage and Monitor** .

When the **Chassis Management and Monitoring** option is set to **Enabled**, iDRAC generates and logs chassis events. The
events generated are integrated into the iDRAC event subsystem and alerts are generated similar to the rest of the events.

CMC also forwards the events generated to iDRAC. In case the iDRAC on the server is not functional, CMC queues the first 16
events and logs the rest in the CMC log. These 16 events are sent to iDRAC as soon as **Chassis monitoring** is set to enabled.

In instances where iDRAC detects that a required CMC functionality is absent, a warning message is displayed informing you
that certain features may not be functional without a CMC firmware upgrade.

**NOTE:** iDRAC doesnot support the following Chassis attributes:

  - `ChassisBoardPartNumber`
  - `ChassisBoardSerialNumber`



### Monitoring chassis events using the iDRAC web interface

To monitor chassis events using the iDRAC web interface, perform the following steps:

**NOTE:** This section appears only for PowerEdge FX2/FX2s chassis and if **Chassis Management at Server** mode is set to
**Monitor** or **Manage and Monitor** in CMC.

1. On the CMC interface, click **Chassis Overview** - **Setup** - **General** .
2. From the **Chassis Management at Server Mode** drop-down menu, select **Manage and Monitor**, and click **Apply** .
3. Launch the iDRAC web interface, click **Overview** - **iDRAC Settings** - **CMC** .
4. Under the **Chassis Management at Server** section, ensure that **Capability from iDRAC** drop-down box is set to
**Enabled** .



### Monitoring chassis events using RACADM

This setting is applicable only for PowerEdge FX2/FX2s servers and if **Chassis Management at Server** mode is set to
**Monitor** or **Manage and Monitor** in CMC.

To monitor chassis events using iDRAC RACADM:

```
 racadm get system.chassiscontrol.chassismanagementmonitoring

```

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Alerts message IDs

The following table provides the list of message IDs that are displayed for the alerts.

**Table 35. Alert message IDs**

|Message ID|Description|Description (For MX platforms)|
|---|---|---|
|AMP|Amperage|Amperage|
|ASR|Auto Sys Reset|Auto Sys Reset|
|BAT|Battery Event|Battery Event|
|BIOS|BIOS Management|BIOS Management|
|BOOT|BOOT Control|BOOT Control|
|CBL|Cable|Cable|
|CPU|Processor|Processor|
|CPUA|Proc Absent|Proc Absent|
|CTL|Storage Contr|Storage Contr|
|DH|Cert Mgmt|Cert Mgmt|
|DIS|Auto-Discovery|Auto-Discovery|
|ENC|Storage Enclosr|Storage Enclosr|
|FAN|Fan Event|Fan Event|
|FSD|Debug|Debug|
|HWC|Hardware Config|Hardware Config|
|IPA|DRAC IP Change|DRAC IP Change|
|ITR|Intrusion|Intrusion|
|JCP|Job Control|Job Control|
|LC|Lifecycle Controller|Lifecycle Controller|
|LIC|Licensing|Licensing|
|LNK|Link Status|Link Status|
|LOG|Log event|Log event|
|MEM|Memory|Memory|
|NDR|NIC OS Driver|NIC OS Driver|
|NIC|NIC Config|NIC Config|
|OSD|OS Deployment|OS Deployment|
|OSE|OS Event|OS Event|
|PCI|PCI Device|PCI Device|
|PDR|Physical Disk|Physical Disk|
|PR|Part Exchange|Part Exchange|
|PST|BIOS POST|BIOS POST|
|PSU|Power Supply|Power Supply|
|PSUA|PSU Absent|PSU Absent|
|PWR|Power Usage|Power Usage|
|RAC|RAC Event|RAC Event|
|RDU|Redundancy|Redundancy|
|RED|FW Download|FW Download|
|RFL|IDSDM Media|IDSDM Media|
|RFLA|IDSDM Absent|IDSDM Absent|
|RFM|FlexAddress SD|Not Applicable|
|RRDU|IDSDM Redundancy|IDSDM Redundancy|
|RSI|Remote Service|Remote Service|
|SEC|Security Event|Security Event|
|SEL|Sys Event Log|Sys Event Log|
|SRD|Software RAID|Software RAID|
|SSD|PCIe SSD|PCIe SSD|
|STOR|Storage|Storage|
|SUP|FW Update Job|FW Update Job|
|SWC|Software Config|Software Config|
|SWU|Software Change|Software Change|
|SYS|System Info|System Info|
|TMP|Temperature|Temperature|
|TST|Test Alert|Test Alert|
|UEFI|UEFI Event|UEFI Event|
|USR|User Tracking|User Tracking|
|VDR|Virtual Disk|Virtual Disk|
|VF|vFlash SD card|vFlash SD card|
|VFL|vFlash Event|vFlash Event|
|VFLA|vFlash Absent|vFlash Absent|
|VLT|Voltage|Voltage|
|VME|Virtual Media|Virtual Media|
|VRM|Virtual Console|Virtual Console|
|WRK|Work Note|Work Note|



## Liquid cooling leak detection

iDRAC detects liquid cooling leaks in the CPU and GPU through critical, warning, and information signals received from the
respective OEM IPMI sensors. The leaks are notified as System Event Logs (SELs), LC logs, WS events, Emails, and SNMP
traps based on the configured alert settings. iDRAC performs appropriate actions according to the alert configuration settings.

By default, servers are configured to perform an automatic **Ungraceful Power Off** when any leak is detected. If you want to
change the default configuration ( **Ungraceful Power Off** ) to other options, see Configuring leak detection.

If iDRAC detects a leak while accessing the LC UI or pre-boot environment (BIOS or boot manager), or during the booting
process, the server may trigger an immediate shutdown.



### Configuring leak detection

**Liquid Cooling System Deafult Action Ungraceful Power Off** is the alert group that is applicable to liquid cooling leak alerts
and actions. By default the alert group is configured for ungraceful **Power Off** action. If there is a leak in the system, the
ungraceful power off is initiated. You can configure the options according to your requirements.

1. Go to **Configuration** - **System Settings** - **Alert Configuration** - **Alerts** - **Alert Configuration** - **Liquid Cooling**
**System Default Action UnGraceful Power Off** .

**NOTE:** In the iDRAC9 7.10.90.00 version, the servers are configured to perform an automatic graceful power off when
a GPU leak is detected. Hence, the alert **Liquid Cooling System Default Action power off** is configured as **Graceful**
**power off** by default. The users have to configure the alert **Liquid cooling system** for the system to detect CPU
leaks with critical severity. The alert group configuration is updated when the iDRAC9 firmware is upgraded to the latest
version.

2. Click **+** .

The **Severity** and **SNMP trap** check boxes are selected. In the **Actions** list, **Power Off** is selected by default.

3. If you want to change the default **Power Off** action, select **No action** or **Graceful Power Off** from the **Action** list.
**NOTE:** If **No action** is selected, the system does not power off when there is a liquid leak.

**NOTE:** If the server fails to perform a **Graceful Power Off** within 15 minutes, perform a force power off.

**CAUTION: If iDRAC is rebooting and the Graceful Power Off is also in progress simultaneously, the system**
**takes more than 20 minutes to power off. It is recommended to force power off the server and not wait for**
**the Graceful Power Off operation to complete.**

4. If you want to include more notifications, select **Email**, **SNMP Trap**, **IPMI Alert**, **Remote System Log**, **WS Event**, **OS**
**Log**, and **Redfish Event** check boxes.

5. To change the power action for small leaks, modify the **Action** for Warning severity (yellow ⚠).
6. To change the power action for large leaks, modify the **Action** for Critical severity (red X).



# 14 iDRAC9 Group Manager

Group Manager enables user to have multiple console experience and offers simplified basic iDRAC management.

iDRAC Group Manager feature is available for Dell 14th generation servers. It offers simplified basic management of iDRAC
and associated servers on the local network using the iDRAC GUI. Group Manager allows 1XMany console experience without
involving a separate application. It allows the users to view the details of a set of servers by permitting more powerful
management than by inspecting servers visually for faults and other manual methods.

Group manager is a licensed feature and part of the Enterprise license. Only iDRAC admin users can access the Group Manager
functionality.

**NOTE:** For better user experience Group Manager supports up to 250 server nodes.

**NOTE:** Following PowerEdge platforms provides functionality of the Group Manager through the Management Module/
Console.

  - PowerEdge MX740C
  - PowerEdge MX750C
  - PowerEdge MX840C

For these particular platforms, it is not recommended to use group manager as it may cause iDRAC sluggishness, slowness,
and failures in iDRAC updates. Instead you can use iDRAC Management Module console or MX 7000 Chassis Management
Module Console.

**Topics:**

- Group Manager
- Summary View
- Network Configuration requirements
- Manage Logins
- Configure Alerts
- Export
- Discovered Servers View
- Jobs View
- Jobs Export
- Group Information Panel
- Group Settings
- Actions on a selected Server
- iDRAC Group Firmware Update



## Group Manager

To use **Group Manager** feature, you must enable the **Group Manager** from iDRAC index page or on the Group Manager
Welcome screen. The group manager welcome screen provides options listed in the below table.

|Table 36. Options in Group Manager|Col2|
|---|---|
|**Option**|**Description**|
|Join Existing Group|Allows you to join an existing group, you must know the<br>**GroupName** and**Passcode** to join a specific group.<br>**NOTE:** Passwords are associated to iDRAC user<br>credentials. Whereas, a passcode is associated to a group<br>to establish authenticated device communication between<br>different iDRACs in the same group.|

**Table 36. Options in Group Manager (continued)**

|Option|Description|
|---|---|
|Create New Group|Allows you to create a new group. The specific iDRAC<br>which has created the group would be the master (primary<br>controller) of the group.|
|Disable Group Manager for this System|You can select this option in case you do not want to join any<br>group from a specific system. However, you can access Group<br>Manager at any time by selecting Open Group Manager from<br>the iDRAC index page. Once you disable the group manager,<br>user must wait for 60 s to perform any further group manager<br>operations.|

Once the group manager feature is enabled, that iDRAC allows you the option to create or join an iDRAC local group. More
than one iDRAC group can be set up in the local network but an individual iDRAC can only be a member of one group at
a time. To change group (join a new group) the iDRAC must first leave its current group and then join the new group. The
iDRAC from where the group was created gets chosen as the primary controller of the group by default. The user does not
define a dedicated group manager primary controller to control that group. The primary controller hosts the group manager web
interface and provides the GUI-based work flows. The iDRAC members self-select a new primary controller for the group if the
current primary goes offline for a prolonged duration, but that does not have any impact on the end user. You can normally
access the group manager from all iDRAC members by clicking group manager from the iDRAC index page.



## Summary View

You need to have administrator privileges to access group manager pages. If a non-administrator user logs onto the iDRAC,
the group manager section does not appear with their credentials. The group manager home page (summary view) is broadly
categorized as three sections. The first section shows rollup summary with aggregated summary details.

- Total number of servers in the local group.
- Chart showing number of servers per server model.
- Doughnut chart showing the servers per their health status (clicking on a chart section filters the server list to show only the
servers with selected health).

- Warning box if there is a duplicate group detected in the local network. Duplicate group is typically the group with the same
name but with a different passcode. This warning box does not appear if there is no duplicate group.

- Displays the iDRACs, that are controlling the group (Primary and Secondary controller).

The second section provides buttons for actions that are taken on the group as whole and the third section displays the list of
all iDRACs in the group.

It shows all the systems in the group and their current health status and allows the user to take corrective action as needed.
Server attributes specific to a server is described in the below table.

**Table 37. Server Attributes**

|Server Attribute|Description|
|---|---|
|Health|Indicates the health status of that specific server.|
|Host Name|Displays the Server name.|
|iDRAC IP Address|Displays the exact IPV4 and IPV6 addresses.|
|Service Tag|Displays the Service Tag information.|
|Model|Displays the Model number of the Dell Server.|
|iDRAC|Displays the iDRAC version.|
|Last Status Update|Displays the time stamp when the server Status was last<br>updated.|

The System Information panel provides further details on the server like iDRAC network connectivity status, server host
power state, express service code, operating system, asset tag, node ID, IDRAC DNS name, Server BIOS version, Server CPU
information, System memory and location information. You may double click on a row or click on the launch iDRAC button to

perform a single sign on redirect to the selected iDRAC index page. On the selected server, virtual console can be accessed or
server power actions can be performed from More Actions dropped down list.

Manage iDRAC user logins, Alert configuration and group inventory export are the group actions supported.



## Network Configuration requirements

Group Manager uses IPv6 link local networking to communicate between iDRACs (excluding the web browser GUI). Link local
communication is defined as non-routed packets which means any iDRAC separated by a router cannot be joined in a local
group. If the iDRAC-dedicated port or shared LOM is assigned to a vLAN, the vLAN limits the number of iDRACs that can be
joined in a group (iDRACs must be on same vLAN and traffic must not pass through a router).

When Group Manager is enabled, iDRAC enables an IPv6 Link Local address regardless of the iDRAC's current user defined
network configuration. Group Manager can be used when iDRAC is configured for IPv4 or IPv6 IP addresses.

Group Manager uses mDNS to discover other iDRACs on the network and sends encrypted packets for normal inventorying,
monitoring and management of the group using the link local IP address. Using IPv6 link local networking means that the Group
Manager ports and packets will never leave the local network or be accessible to external networks.

Ports (Specific to Group Manager unique functionality does not include all iDRAC ports) are:

- 5353 (mDNS)
- 443 (webserver) - configurable
- 5670 (Multicast group communication)
- C000 -> F000 dynamically identifies one free port for each member to communicate in the group



##### Best networking practices

- Groups are intended to be small and on the same physical link local network.
- It is recommended to use the dedicated iDRAC network port for enhanced security. Shared LOM is also supported.



##### Additional network considerations

Two iDRACs that are separated by a router in the network topology are considered to be on separate local networks and cannot
be joined in the same iDRAC local group. Meaning, if the iDRAC is configured for dedicated NIC settings, the network cable
connected to iDRAC dedicated port in the rear of the server must be under a local network for all relevant servers.

If the iDRAC is configured for shared LOM network settings, the shared network connection used by both server host and
IDRAC need to be connected under a local network for Group Manager to detect and onboard those servers into a common
group. IDRACs configured with a mix of dedicated and shared LOM mode NIC settings could also be on-boarded into a common
group, if all the network connections do not pass through a router.



##### Effect of MLD snooping in VLAN environments on Group Manager Discovery

Since Group Manager uses IPv6 multicast addressing for node-initiated discovery, a feature called MLD Snooping can prevent
Group Manager-enabled devices from discovering each other if not configured properly. MLD Snooping is a common ether
switch feature intended to reduce the amount of unnecessary IPv6 multicast traffic on a network.

If MLD Snooping is active in any network, ensure there is an MLD querier enabled so that the ether switches are kept up to
date with the active Group Manager devices on the network. Alternatively, if MLD Snooping is not needed, it can be disabled.
Note that some network switches have MLD Snooping enabled by default. And it is same for switching modules in the MX7000
chassis.

**NOTE:**

For example

  - To disable MLD snooping on a VLAN on a MX5108n IOM:
   - MX5108N-B1# configure terminal
   - MX5108N-B1(config)# interface vlan 194
   - MX5108N-B1(conf-if-vl-194)#no ipv6 mld snooping
  - To enable an MLD querier in a VLAN on the MX5108n IOM:
   - MX5108N-B1# configure terminal
   - MX5108N-B1(config)# interface vlan 194
   - MX5108N-B1(conf-if-vl-194)#ipv6 mld snooping querier



## Manage Logins

Use this section to **Add New User**, **Change User Password** and **Delete User** from the Group.

Group jobs including Manage Logins are one time configurations of the servers. Group manager uses SCP and jobs to make any
changes. Every iDRAC in the group owns an individual job in its job queue for each Group Manager job. Group Manager does not
detect changes on member iDRACs or lock member configurations.

**NOTE:** Group jobs does not configure or override the lockdown mode for any specific iDRAC.

Leaving a group does not change local user or change settings on a member iDRAC.



### Add a New User

Use this section to create and add a new user profile on all the servers in that group. A group job would be created to add the
user to all servers in that group. The status of group job can be found at **GroupManager** - **Jobs** page.

**NOTE:** By default iDRAC is configured with a local administrator account. You can access further information for each
parameter with local administrator account.

For more information see, Configuring user accounts and privileges.

**Table 38. New User Options**

|Option|Description|
|---|---|
|New User Information|Allows you to provide the new user's information details.|
|iDRAC Permissions|Allows you to define the user's role for future usage.|
|Advanced User Settings|Allows you to set (IPMI) user privileges and helps you to<br>enable SNMP.<br>**NOTE:** From 6.00.02.00 release onwards, iDRAC<br>allows for unique Authentication Passphrase & Privacy<br>Passphrase.|

**NOTE:** Any member iDRAC with system lockdown enabled, that is part of the same group returns an error that the user
password was not updated.



### Change User Password

Use this section to change the password information for the user. You can see the **Users** detail with the **User Name**, **Role** and
**Domain** information for individual user. A group job would be created to change the user password on all the servers in that
group. The status of group job can be found at **GroupManager** - **Jobs** page.

If user already exists then the password can be updated. Any member iDRAC with system lockdown enabled, that is part of the
group returns an error that the user password was not updated. If the user does not exist, then an error is returned to group
manager indicating that the user does not exist on the system. The list of users shown in Group Manager GUI is based on the
current user list on the iDRAC that is acting as the primary controller. It does not show all users for all iDRACs.



### Delete User

Use this section to delete users from all the group servers. A group job would be created to delete users from all the group
servers. The status of group job can be found at **GroupManager** - **Jobs** page.

If user already exists on a member iDRAC then the user can be deleted. Any member iDRAC with system lockdown enabled that
is part of the group returns an error that the user is not deleted. If the user does not exist then it shows a successful deletion
for that iDRAC. The list of users shown in Group Manager GUI is based on the current user list on the iDRAC which is acting as
the primary controller. It does not show all users for all iDRACs.



## Configure Alerts

Use this section to configure e-mail alerts. By default alerting is disabled. However, you can enable the alerting anytime. A
group job would be created to apply the e-mail alert configuration to all the group servers. The status of group job can be
monitored at **GroupManager** - **Jobs** page. Group manager email alert configures email alerts on all members. It sets the SMTP
server settings on all members in the same group. Each iDRAC is configured separately. Email configuration is not globally saved.
Current values are based on the iDRAC that is acting as a primary controller. Leaving a group does not reconfigure email alerts.

For more information on Configuring Alerts, see Configuring iDRAC to send alerts.

**Table 39. Configuring alerts options**

|Option|Description|
|---|---|
|SMTP (Email) Server Address Settings|Allows you to configure Server IP Address, SMTP Port<br>Number and enable the authentication. In case you are<br>enabling authentication, you need to provide username and<br>password.|
|Email Addresses|Allows you to configure multiple Email IDs to receive email<br>notifications about system status change. You can send one<br>test email to the configured account from the system.|
|Alert Categories|Allows you to select multiple alert categories to receive email<br>notifications.|

**NOTE:** Any member iDRAC with system lockdown enabled, that is part of the same group returns an error that the user
password was not updated.



## Export

Use this section to export the Group Summary to the local system. The information can be exported to a csv file format. It
contains data related to each individual system in the group. Export includes the following information in csv format. Server
details:

- Health
- Host Name
- iDRAC IPV4 Address
- iDRAC IPV6 Address
- Asset Tag
- Model
- iDRAC Firmware Version
- Last Status Update
- Express Service Code
- iDRAC Connectivity
- Power State
- Operating System
- Service Tag
- Node ID
- iDRAC DNS Name
- BIOS Version
- CPU Details
- System Memory(MB)
- Location Details
**NOTE:** In case, you are using Internet Explorer, disable the Enhanced Security settings to successfully download the csv
file.



## Discovered Servers View

After creating the local group, iDRAC group manager notifies all other iDRACs on the local network that a new group has
been created. For iDRACs to be displayed under Discovered Servers, group manager feature should be enabled in each iDRAC.
Discovered Servers View displays the list of the iDRACs detected on the same network, which can be part of any group. If an
iDRAC does not show up in the discovered systems list then the user must logon to the specific iDRAC and join the group.
The iDRAC that created the group will be shown as the only member in the essentials view until more iDRACs are joined to the
group.

**NOTE:** Discovered servers view at the Group manager console allows you to onboard one or more servers listed in the view
in to that group. The progress of the activity can be tracked from **GroupManager**   - **Jobs** . Alternatively you can logon to
the iDRAC and select the group you would like to onboard from the drop down list to join that group. You can access the
GroupManager welcome screen from iDRAC index page.

|Table 40. Group onboard options|Col2|
|---|---|
|**Option**|**Description**|
|Onboard and Change Login|Select a specific row and select the Onboard and Change<br>Login option to get the newly discovered systems to the<br>group. You must provide the admin logon credentials for the<br>new systems to join the group. If the system has the default<br>password, you need to change it while onboarding it to a<br>group.<br>**NOTE:** Group onboarding allows you to apply the same<br>group alert settings to the new systems.|
|Ignore|Allows you to ignore the systems from the discovered servers<br>list, in case you do not want to add them in any group.|
|Un-Ignore|Allows you to select the systems that you would like to<br>reinstate in the discovered servers list.|
|Rescan|Allows you to scan and generate the list of discovered servers<br>at any time.|



## Jobs View

Jobs view allows the user to track the progress of a group job, helps with simple recovery steps to correct connectivity induced
failures. It also shows the history of the last group actions that were performed as an audit log. The user can use the jobs view
to track the progress of the action across the group or to cancel an action that is schedule to occur in the future. The Jobs view
allows the user to view the status of the last 50 jobs that have been run and any success or failures that has occurred.

**Table 41. Jobs View**

|Option|Description|
|---|---|
|Status|Shows the job's status and the state of the ongoing job.|
|Job|Displays the Job's name.|
|ID|Displays the Job's ID.|
|Start Time|Displays the start time.|
|End Time|Displays the end time.|
|Actions|●<br>Cancel — A scheduled job can be cancelled, before it<br>moves to running state. A running job can be stopped by<br>using the stop button.<br>●<br>Rerun — Allows the user to rerun the job in case the job is<br>in failure state.<br>●<br>Remove — Allows the user to remove the completed old<br>jobs.|
|Export|You can export the group job information to the local system<br>for future references. The jobs list can be exported to csv file<br>format. It contains data related to individual job.|

**NOTE:** For each job entry, the list of systems provide details up to 100 systems. Each system entry contains Hostname,
Service Tag, Member Job Status and Message if in case the job failed.

All Group actions that create jobs are performed on all the group members with immediate effect. You can perform the following
tasks:

- Add/Edit/Remove users
- Configure email alerts
- Change group passcode and name
**NOTE:** Group jobs complete quickly as long as all members are online and accessible. It may take 10 minutes from job start
to job complete. A job will wait and retry for up to 10 hours for the systems that are not accessible.

**NOTE:** While an onboarding job is running no other Job can be scheduled. Jobs include:

  - Add New User
  - Change User Password
  - Delete User
  - Configure Alerts
  - Onboard additional systems
  - Change Group Passcode
  - Change Group Name

Attempting to invoke another Job while an Onboarding task is active, consequences GMGR0039 error code. Once the
onboarding task has made its first attempt to onboard all the new systems, Jobs can be created at any point in time.



## Jobs Export

You can export the log to the local system for further references. The jobs list can be exported to a csv file format. It contains
all the data related to each job.

**NOTE:** Exported CSV files are available only in English.



## Group Information Panel

Group Information panel in the top right of group manager summary view shows a consolidated group summary. Current group
configuration can be edited from the Group Settings page accessible by clicking Group Settings button. It shows how many
systems are there in the group. It also provides the information about the Primary and the Secondary controller of the Group.



## Group Settings

Group settings page provides a listing of selected group attributes.

**Table 42. Group setting attributes**

|Group Attribute|Description|
|---|---|
|Group Name|Displays the name of that Group.|
|Number of Systems|Displays the total number of systems in that group.|
|Created on|Displays the time stamp details.|
|Created by|Displays the details of Group admin.|
|Controlling System|Displays the Service Tag of the system, that acts as the<br>controlling system and coordinates the group management<br>tasks.|
|Backup System|Displays the Service Tag of the system, that acts as the<br>backup system. In case the controlling system is unavailable, it<br>takes up roles of the controlling system.|

Allows the user to perform actions listed on the table below on the group. A group configuration job would be created for these
actions (change group name, change group passcode, remove the members and delete the group). The status of group job can
be viewed or modified from **GroupManager** - **Jobs** page.

|Table 43. Group setting actions|Col2|
|---|---|
|**Actions**|**Description**|
|Change Name|Allows you to change the**Current Group Name** with a**New**<br>**Group Name**.|
|Change Passcode|Allows you to change the existing group password by entering<br>a **New Group Passcode** and validating that password by<br>**Reenter New Group Passcode**.|
|Remove Systems|Allows you to remove multiple systems from the group at a<br>time.|
|Delete Group|Allows you to delete the group. To use any feature of group<br>manager, the user should have administrator privileges. Any<br>pending jobs will be stopped in case the group is deleted.|



## Actions on a selected Server

On the Summary page, you can double click on a row to launch iDRAC for that server through a single sign on redirect. Ensure
to turn off the popup blocker in the browser settings. You can perform following actions on the selected server by clicking
appropriate item from the **More Actions** drop down list.



## Table 44. Actions on a selected Server

|Option|Description|
|---|---|
|Graceful Shutdown|Shuts down the operating system and powers off the system.|
|Cold Reboot|Powers off, then reboots the system.|
|Virtual Console|Launches Virtual Console with single sign on a new browser<br>window.<br>**NOTE:** Disable Popup blocker from the browser to use<br>this functionality.|



##### Group Manager Single Sign On

All iDRACs in the group trust each other based on the shared passcode secret and shared group name. As a result an
administrator user at a group member IDRAC is grant administrator level privileges at any group member iDRAC when accessed

through Group Manager web interface single sign on. iDRACs logs <user>-<SVCTAG> as the user that logged on into peer
members. <SVCTAG> is the service tag of the iDRAC where the user first logged in.



##### Group Manager Concepts — Controlling System

- Automatically selected — by default the first iDRAC configured for Group Manager.
- Provides Group Manager GUI workflow.
- Keeps track of all members.
- Coordinates tasks.
- If a user logs in to any member and clicks on Open Group Manager the browser will be redirected to the primary controller.



##### Group Manager Concepts — Backup System

- Primary controller automatically selects a secondary controller to take over if the primary goes offline for an extended period
of time (10 mins or more).

- If both primary and secondary goes offline for an extended duration (for more than 14 mins) a new primary and secondary
controller gets elected.

- Keeps a copy of the group manager cache of all the groups members and tasks.
- The controlling system and backup system are automatically determined by group manager.
- No user configuration or involvement required.



## iDRAC Group Firmware Update

For iDRAC group firmware update, from the DUP file from a local directory, perform the following steps:

1. Access the group manager console essential view and click **Update iDRAC Firmware** under summary view.
2. From the firmware update dialog box displayed, browse and select the local iDRAC DUP file to be installed. Click **Upload** .
The file is uploaded to iDRAC and verified for integrity.
3. Confirm the firmware update. The Group iDRAC firmware update job is scheduled to run immediately. If the Group Manager
has other group jobs running, then it is performed after the previous job is completed.
4. Track the iDRAC update job progress from the group jobs view.
**NOTE:** This feature is supported on only iDRAC version 3.50.50.50 and later.

**NOTE:** Avoid rebooting, shutting down, or power cycling the host or iDRAC during ongoing updates or tasks. The system
(host and iDRAC) must be rebooted or shutdown gracefully when no tasks or jobs are running in iDRAC or host. Ungraceful
shutdown or interrupting an operation can cause unpredictable results such as firmware corruption, core file generation,
RSODs, YSODs, error events in LCL, and so on.



# 15 Managing logs

iDRAC provides Lifecycle log that contains events related to system, storage devices, network devices, firmware updates,
configuration changes, license messages, and so on. However, the system events are also available as a separate log called
System Event Log (SEL). The lifecycle log is accessible through iDRAC Web interface, RACADM, and WSMan interface.

When the size of the lifecycle log reaches 800 KB, the logs are compressed and archived. You can only view the non-archived
log entries, and apply filters and comments to non-archived logs. To view the archived logs, you must export the entire lifecycle
log to a location on your system.

**Topics:**

- Viewing System Event Log
- Viewing Lifecycle log
- Exporting Lifecycle Controller logs
- Prevent Lifecycle Log Overflow
- Adding work notes



## Viewing System Event Log

When a system event occurs on a managed system, it is recorded in the System Event Log (SEL). The same SEL entry is also
available in the LC log.

**NOTE:** SEL and LC logs may have mismatch in timestamp when iDRAC is rebooting.



### Viewing System Event Log using web interface

To view the SEL, in iDRAC Web interface, go to **Maintenance** - **System Event Log** .

The **System Event Log** page displays a system health indicator, a time stamp, and a description for each event logged. For
more information, see the **iDRAC Online Help** .

Click **Save As** to save the **SEL** to a location of your choice.

**NOTE:** If you are using Internet Explorer and if there is a problem when saving, download the Cumulative Security Update
for Internet Explorer. You can download it from the Microsoft Support website at **support.microsoft.com** .

To clear the logs, click **Clear Log** .

**NOTE:** **Clear Log** only appears if you have Clear Logs permission.

After the SEL is cleared, an entry is logged in the Lifecycle Controller log. The log entry includes the user name and the IP
address from where the SEL was cleared.



### Viewing System Event Log using RACADM

To view the SEL:

```
racadm getsel <options>

```

If no arguments are specified, the entire log is displayed.

To display the number of SEL entries: `racadm getsel -i`

To clear the SEL entries: `racadm clrsel`

[For more information, see Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Viewing System Event Log using iDRAC settings utility

You can view the total number of records in the System Event Log (SEL) using the iDRAC Settings Utility and clear the logs. To
do this:

1. In the iDRAC Settings Utility, go to **System Event Log** .
The **iDRAC Settings.System Event Log** displays the **Total Number of Records** .

2. To clear the records, select **Yes** . Else, select **No** .
3. To view the system events, click **Display System Event Log** .
4. Click **Back**, click **Finish**, and then click **Yes** .



## Viewing Lifecycle log

Lifecycle Controller logs provide the history of changes related to components installed on a managed system. You can also add
work notes to each log entry.

The following events and activities are logged:

- All
- System Health—System Health category represents all the alerts that are related to hardware within the system chassis.
- Storage—Storage Health category represents alerts that are related to the storage subsystem.
- Updates—Update category represents alerts that are generated due to firmware/Driver upgrades/downgrades.
- Audit—Audit category represents the audit log.
- Configuration—Configuration category represents alerts that are related to hardware, firmware, and software configuration
changes.

- Work Notes

When you log in to or log out of iDRAC using any of the following interfaces, the log-in, log-out, or login failure events are
recorded in the Lifecycle logs:

- SSH
- Web interface
- RACADM
- Redfish
- IPMI over LAN
- Serial
- Virtual console
- Virtual media

You can view, and filter logs based on the category and severity level. You can also export and add a work note to a log event.

**NOTE:** Lifecycle logs for Personality Mode change is generated only during the warm boot of the host.

If you initiate configuration jobs using RACADM CLI or iDRAC web interface, the Lifecycle log contains information about the
user, interface used, and the IP address of the system from which you initiate the job.

**NOTE:** On the MX platform, Lifecycle Controller logs multiple job IDs for configuration or installation jobs created using
OME-Modular. For more information about the jobs performed, see the OME-Modular logs.

**NOTE:** When an event occurs multiple times, a single event log is displayed in the LC logs. An additional log
(L0G007) is also displayed indicating the number of times this event has occurred. By default, duplicate event logs
are disabled in iDRAC. If you want all the events to be displayed in the LC logs, run the RACADM command `set`

`idrac.logging.LCDuplicateEventEnable enabled` .



### Viewing Lifecycle log using web interface

To view the Lifecycle Logs, click **Maintenance** - **Lifecycle Log** . The **Lifecycle Log** page is displayed. For more information
about the options, see the **iDRAC Online Help** .



#### Filtering Lifecycle logs

You can filter logs based on category, severity, keyword, or date range.

To filter the lifecycle logs:

1. In the **Lifecycle Log** page, under the **Log Filter** section, do any or all of the following:
  - Select the **Log Type** from the drop-down list.
  - Select the severity level from the **Severity** drop-down list.
  - Enter a keyword.
  - Specify the date range.
2. Click **Apply** .

The filtered log entries are displayed in **Log Results** .



#### Adding comments to Lifecycle logs

To add comments to the Lifecycle logs:

1. In the **Lifecycle Log** page, click the + icon for the required log entry.
The Message ID details are displayed.

2. Enter the comments for the log entry in the **Comment** box.

The comments are displayed in the **Comment** box.



### Viewing Lifecycle log using RACADM

To view Lifecycle logs, use the `lclog` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Exporting Lifecycle Controller logs

You can export the entire Lifecycle Controller log (active and archived entries) in a single zipped XML file to a network share
or to the local system. The zipped XML file extension is `.xml.gz` . The file entries are ordered sequentially based on their
sequence numbers, ordered from the lowest sequence number to the highest.



### Exporting Lifecycle Controller logs using web interface

To export the Lifecycle Controller logs using the Web interface:

1. In the **Lifecycle Log** page, click **Export** .
2. Select any of the following options:
  - **Network**  - Export the Lifecycle Controller logs to a shared location on the network.
  - **Local**  - Export the Lifecycle Controller logs to a location on the local system.
**NOTE:** While specifying the network share settings, it is recommended to avoid special characters for user name and
password or percent encode the special characters.

For information about the fields, see the **iDRAC Online Help** .

3. Click **Export** to export the log to the specified location.



### Exporting Lifecycle Controller logs using RACADM

To export the Lifecycle Controller logs, use the `lclog export` command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Prevent Lifecycle Log Overflow

Starting with release version 6.00.00, it is possible to prevent Lifecycle Log overflow from consoles due to high frequency of
logins from consoles.

- The USR0030/USR0032 events are logged in the lifecycle log for every successful login/logout respectively.
- These events can be aggregated into a new single log, based on an attribute setting.
- A new USR0036 event is displayed in the lifecycle log, aggregating the login-logout events that occur within the time that
is specified by the `LCLoggingAggregationTimeout` attribute. If more than 320 login-logout events occur within this
timeout period, multiple USR0036 events are logged.

**NOTE:**

  - By default, the feature attribute LCLogAggregation is disabled.
  - By default, the timeout is set to 60 minutes and is applicable only if LCLogAggregation is Enabled.
- USR0030 and USR0032 shall not be logged in the lifecycle log, but continues to be sent individual alerts if the corresponding
alerts are enabled (SNMP/Email/Redfish Event/WS-Event and so on).



## Adding work notes

Each user who logs in to iDRAC can add work notes and this is stored in the lifecycle log as an event. You must have iDRAC logs
privilege to add work notes. A maximum of 255 characters are supported for each new work note.

**NOTE:** You cannot delete a work note.

To add a work note:

1. In the iDRAC Web interface, go to **Dashboard** - **Notes** - **add note** .
The **Work Notes** page is displayed.

2. Under **Work Notes**, enter the text in the blank text box.
**NOTE:** It is recommended not to use too many special characters.

3. Click **Save** .

The work note is added to the log. For more information, see the **iDRAC Online Help** .



# 16 Monitoring and managing power in iDRAC

You can use iDRAC to monitor and manage the power requirements of the managed system. This helps to protect the system
from power outages by appropriately distributing and regulating the power consumption on the system.

The key features are:

- **Power Monitoring** - View the power status, history of power measurements, the current averages, peaks, and so on for
the managed system.

- **Power Capping** - View and set the power cap for the managed system, including displaying the minimum and maximum
potential power consumption. This is a licensed feature.

- **Power Control** - Enables you to remotely perform power control operations (such as, power on, power off, system reset,
power cycle, and graceful shutdown) on the managed system.

- **Power Supply Options** - Configure the power supply options such as redundancy policy, hot spare, and power factor
correction.
**Topics:**

- Monitoring power
- Setting warning threshold for power consumption
- Performing power control operations
- Power capping
- Configuring power supply options
- Enabling or disabling power button
- Multi-Vector Cooling



## Monitoring power

iDRAC monitors the power consumption in the system continuously and displays the following power values:

- Power consumption warning and critical thresholds.
- Cumulative power, peak power, and peak amperage values.
- Power consumption over the last hour, last day or last week.
- Average, minimum, and maximum power consumption.
- Historical peak values and peak timestamps.
- Peak headroom and instantaneous headroom values (for rack and tower servers).
**NOTE:** The histogram for the system power consumption trend (hourly, daily, weekly) is maintained only while iDRAC is
running. If iDRAC is restarted, the existing power consumption data is lost and the histogram is restarted.

**NOTE:** In HBM-only mode, HBM memory power is counted as part of the package power, hence memory power telemetry
reading is reported as 0 for this mode.

**NOTE:** After iDRAC firmware update or reset, the power consumption graph will be wiped / reset.



### Monitoring performance index of CPU, memory, and input output modules using web interface

To monitor the performance index of CPU, memory, and I/O modules, in the iDRAC web interface, go to **System** **Performance** .

- **System Performance** section — Displays the current reading and the warning reading for CPU, Memory and I/O utilization
index, and system level CUPS index in a graphical view.

- **System Performance Historical Data** section:
  - Provides the statistics for CPU, memory, IO utilization, and the system level CUPS index. If the host system is powered
off, then the graph displays the power off line below 0 percent.

  - You can reset the peak utilization for a particular sensor. Click **Reset Historical Peak** . You must have Configure
privilege to reset the peak value.

- **Performance Metrics** section:
  - Displays status and present reading
  - Displays or specifies the warning threshold utilization limit. You must have server configure privilege to set the threshold
values.

For information about the displayed properties, see the **iDRAC Online Help** .



### Monitoring performance index for of CPU, memory, and input output modules using RACADM

Use the **SystemPerfStatistics** sub command to monitor performance index for CPU, memory, and I/O modules. For more
[information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Setting warning threshold for power consumption

You can set the warning threshold value for the power consumption sensor in the rack and tower systems. The warning/critical
power threshold for rack and tower systems may change, after the system is power-cycled, based on PSU capacity and
redundancy policy. However, the warning threshold must not exceed the critical threshold even if Power Supply Unit capacity of
the redundancy policy is changed.

The warning power threshold for blade systems is set to power allocation of CMC(for non-MX platforms) or OME Modular (for
MX platforms).

If reset to default action is performed, the power thresholds will be set to default.

You must have Configure user privilege to set the warning threshold value for power consumption sensor.

**NOTE:** The Warning Threshold value is reset to the default value after performing a racreset or an iDRAC update.



### Setting warning threshold for power consumption using web interface

1. In the iDRAC Web interface, go to **System** - **Overview** - **Present Power Reading and Thresholds** .
2. In the **Present Power Reading and Thresholds** section, click **Edit Warning Threshold** .

The **Edit Warning Threshold** page is displayed.

3. In the **Warning Threshold** column, enter the value in **Watts** or **BTU/hr** .

The values must be lower than the **Failure Threshold** values. The values are rounded off to the nearest value that is
divisible by 14. If you enter **Watts**, the system automatically calculates and displays the **BTU/hr** value. Similarly, if you enter
BTU/hr, the value for **Watts** is displayed.

4. Click **Save** . The values are configured.



## Performing power control operations

iDRAC enables you to remotely perform a power on, power off, reset, graceful shut down, Non-Masking Interrupt (NMI), or
power cycle using the Web interface or RACADM.

You can also perform these operations using Lifecycle Controller Remote Services or WSMan. For more information, see the
_Lifecycle Controller Remote Services Quick Start Guide_ [available on the iDRAC manuals page. and the](https://www.dell.com/idracmanuals) **Dell Power State**
**Management Profile** [document available at Dell Support page.](https://www.dell.com/support)

Server power-control operations that are initiated from iDRAC are independent of the power-button behavior that is configured
in the BIOS. You can use the PushPowerButton function to gracefully shut down the system, or power it on, even if the BIOS is
configured to do nothing when the physical power button is pressed.

**NOTE:** Some issues are expected with the NMI functionality from iDRAC UI on systems running SUSE Linux Server (SLES)
with SPDM configuration. To resolve this issue, try the following resolution:Configure the kernel parameters to allow core
dump on NMI.

1. Edit /etc/sysctl.conf and add the following parameters:
   - `# vi /etc/sysctl.conf`
   - `kernel.panic_on_io_nmi = 1`
   - `kernel.panic_on_unrecovered_nmi = 1`
   - `kernel.unknown_nmi_panic = 1`
2. Reboot the server or run sysctl -p to apply the changes.



### Performing power control operations using web interface

To perform power control operations:

1. In the iDRAC web interface, go to **Configuration** - **Power Management** - **Power Control** . The **Power Control** options
are displayed.

2. Select the required power operation:
  - Power On System
  - Power Off System
  - Non-Masking Interrupt (NMI)
  - Graceful Shutdown
  - Reset System (warm boot)
  - Power Cycle System (cold boot)
3. Click **Apply** . For more information, see the **iDRAC Online Help** .



### Performing power control operations using RACADM

To perform power actions, use the **serveraction** command.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Power capping

You can view the power threshold limits that covers the range of AC and DC power consumption that a system under heavy
workload presents to the datacenter. This is a licensed feature.



### Power capping in Blade servers

Before a blade server turns on, based on limited hardware inventory, iDRAC provides the power requirements of the blade
server to the chassis manager. If the power consumption increases over time and if the server consumes power to its maximum
allocation, iDRAC requests CMC (for non-MX platforms) or OME Modular (for MX platforms) to increase the maximum potential
power. This results in an increase in the power delivery, however, the power delivery does not reduce if the consumption
decreases.

After the system is powered on and initialized, iDRAC calculates a new power requirement based on the actual hardware
configuration. The system stays powered on even if the CMC (not for MX platforms) or OME Modular (not for MX platforms)
fails to allocate new power request.

CMC or OME Modular reclaims any unused power from lower priority servers and allocates that power to a higher-priority
infrastructure module or a server.



### Viewing and configuring power cap policy

When power cap policy is enabled, it enforces a user-defined power limits on the system. If power-capping is not enabled, the
default hardware power-protection policy is used. This power-protection policy is independent of the user-defined policy. The
system performance is dynamically adjusted to maintain power consumption close to the specified threshold.

Actual power consumption depends on the workload. It may momentarily exceed the threshold until performance adjustments
are completed. For example, consider a system that has a minimum and maximum Potential Power Consumption values of 500
W and 700 W respectively. You can specify a Power Budget Threshold to reduce consumption to 525 W. When this power
budget is configured, the performance of the system is dynamically adjusted to maintain power consumption of 525 W or less.

If you set a very low power cap or if the ambient temperature is unusually high, power consumption may temporarily exceed the
power-cap while the system is powering up or being reset.

If the power cap value is set lower than the minimum recommended threshold, iDRAC may not be able maintain the requested
power cap.

You can specify the value in Watts, BTU/hr, or as a percentage of the recommended maximum power limit.

When setting the power cap threshold in BTU/hr, the conversion to Watts is rounded off to the nearest integer. When the
power cap threshold are read from the system, the Watts to BTU/hr conversion is also rounded off. Because of the rounding
off, the actual values may slightly differ.

**NOTE:** Setting a power cap limit to a value below the recommended range may cause varied performance including
increased boot time.



#### Configuring power cap policy using web interface

To view and configure the power policies:

1. In iDRAC Web interface, go to **Configuration** - **Power Management** - **Power Cap Policy** .
The current power policy limit is displayed under the **Power Cap Limits** section.

2. Select **Enable** under **Power Cap** .
3. Under **Power Cap Limits** section, enter the power limit within recommended range in Watts and BTU/hr or the maximum %
of recommended system limit.

4. Click **Apply** to apply the values.



#### Configuring power cap policy using RACADM

To view and configure the current power cap values, use the following objects with the `set` command:

- System.Power.Cap.Enable
- System.Power.Cap.Watts
- System.Power.Cap.Btuhr
- System.Power.Cap.Percent

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Configuring power cap policy using iDRAC settings utility

To view and configure power policies:

1. In iDRAC Settings utility, go to **Power Configuration** .
**NOTE:** The **Power Configuration** link is available only if the server power supply unit supports power monitoring.

The **iDRAC Settings Power Configuration** page is displayed.

2. Select **Enabled** to enable the **Power Cap Policy** Else, select **Disabled** .
3. Use the recommended settings, or under **User Defined Power Cap Policy**, enter the required limits.

For more information about the options, see the **iDRAC Settings Utility Online Help** .

4. Click **Back**, click **Finish**, and then click **Yes** .

The power cap values are configured.



## Configuring power supply options

You can configure the power supply options such as redundancy policy, hot spare, and power factor correction.

**NOTE:** Hot spare and Power factor correction features may not be available on some of the platforms/releases.

Hot spare is a power supply feature that configures redundant Power Supply Units (PSUs) to turn off depending on the server
load. This allows the remaining PSUs to operate at a higher load and efficiency. This requires PSUs that support this feature, so
that it quickly powers ON when needed.

In a two PSU system, either PSU1 or PSU2 can be configured as the primary PSU.

After Hot Spare is enabled, PSUs can become active or go to sleep based on load. If Hot Spare is enabled, asymmetric electrical
current sharing between the two PSUs is enabled. One PSU is **awake** and provides the majority of the current; the other PSU is
in sleep mode and provides a small amount of the current. This is often called 1 + 0 with two PSUs and hot spare enabled. If all
PSU-1s are on Circuit-A and all PSU-2s are on Circuit-B, then with hot spare enabled (default hot spare factory configuration),
Circuit-B has much less load and triggers the warnings. If hot spare is disabled, the electrical current sharing is 50-50 between
the two PSUs, the Circuit-A and Circuit-B normally has the same load.

Power factor is the ratio of real power consumed to the apparent power. When power factor correction is enabled, the server
consumes a small amount of power when the host is OFF. By default, power factor correction is enabled when the server is
shipped from the factory.



### Configuring power supply options using web interface

To configure the power supply options:

1. In iDRAC Web interface, go to **Configuration** - **Power Management** - **Power Configuration** .
2. Under **Power Redundancy Policy**, select the required options. For more information, see **iDRAC Online Help** .
**CAUTION: Do not select A/B Grid Redundant on PowerEdge XE96xx series platforms. Selecting A/B Grid**
**Redundant can cause iDRAC connectivity issues.**

3. Click **Apply** . The power supply options are configured.



### Configuring power supply options using RACADM

To configure the power supply options, use the following objects with the `get/set` command:

- System.Power.RedundancyPolicy
- System.Power.Hotspare.Enable
- System.Power.Hotspare.PrimaryPSU
- System.Power.PFC.Enable

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Configuring power supply options using iDRAC settings utility

To configure the power supply options:

1. In iDRAC Settings utility, go to **Power Configuration** .
**NOTE:** The **Power Configuration** link is available only if the server power supply unit supports power monitoring.

The **iDRAC Settings Power Configuration** page is displayed.

2. Under **Power Supply Options** :
  - Enable or disable power supply redundancy.
  - Enable or disable hot spare.
  - Set the primary power supply unit.
  - Enable or disable power factor correction. For more information about the options, see the **iDRAC Settings Utility**
**Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The power supply options are configured.



## Enabling or disabling power button

To enable or disable the power button on the managed system:

1. In iDRAC Settings utility, go to **Front Panel Security** .
The **iDRAC Settings Front Panel Security** page is displayed.

2. Select **Enabled** to enable the power button or **Disabled** to disable it.
3. Click **Back**, click **Finish**, and then click **Yes** .

The settings are saved.



## Multi-Vector Cooling

Multi-Vector Cooling implements a multiprong approach to Thermal Controls in Dell Server Platforms. You can configure
multivector cooling options through iDRAC web interface ( **Configuration** - **System Settings** - **Hardware Settings** **Cooling Configuration** ). It includes (but not limited to):

- Large set of sensors (thermal, power, inventory so on) that allows accurate interpretation of real-time system thermal state
at various locations within the server. It displays only a small subset of sensors that are relevant to users needs based on the
configuration.

- Intelligent and adaptive closed loop control algorithm optimizes fan response to maintain component temperatures. It also
conserves fan power, airflow consumption, and acoustics.

**NOTE:** When a third-party PCIe card is present and AC cycle is performed, the information message `PCI3030-New`
```
    PCI card(s) have been detected in the system. Fan speeds may have changed to add
```

`additional cooling to the cards` may appear in the LC logs.

**NOTE:** During a cold boot, it is expected that the drivers cannot be loaded immediately. Therefore, until the drivers are
fully loaded, PLDM cannot retrieve sensor details, resulting in the fans operating at 100 percent.If the drivers are not
installed, it is expected that the fans operate at 100 percent.

- Using fan zone mapping, cooling can be initiated for the components when it requires. Thus, it results in maximum
performance without compromising the efficiency of power utilization.

- Accurate representation of slot by slot PCIe airflow in terms of LFM metric (Linear Feet per Minute - an accepted industry
standard on how PCIe card airflow requirement is specified). Display of this metric in various iDRAC interfaces allows user
to:

  - Know the maximum LFM capability of each slot within the server.
  - Know what approach is being taken for PCIe cooling for each slot (airflow that is controlled, temperature that is
controlled).

  - Know the minimum LFM being delivered to a slot, if the card is a third-party Card (user-defined custom card).
  - Dial-in custom minimum LFM value for the third-party Card allowing more accurate definition of the card cooling needs
for which the user is better aware of through their custom card specification.

- Displays real-time system airflow metric (CFM, cubic feet per minute) in various iDRAC interfaces to the user to enable data
center airflow balancing based on aggregation of per server CFM consumption.

- Allows custom thermal settings like Thermal Profiles (Maximum Performance vs. Maximum Performance per Watt, Sound
Cap), custom fan speed options (minimum fan speed, fan speed offsets) and custom Exhaust Temperature settings.

  - Most of these settings allow additional cooling over the baseline cooling generated by thermal algorithms and do not
allow fan speeds to go below system cooling requirements.

**NOTE:** One exception to the above statement is for fan speeds that are added for third-party PCIe cards. The
thermal algorithm provision airflow for third-party cards may be more or less than the actual card cooling needs, and
the customers may fine-tune the response for the card by entering the LFM corresponding to the third-party card.

  - The custom Exhaust Temperature option limits exhaust temperature to customer wanted settings.
**NOTE:** For certain configurations and workloads, it may not be physically possible to reduce exhaust below a wanted
set point (for example Custom exhaust setting of 45C with a high inlet temp (for example 30C) and a loaded
configuration {high system power consumption, low airflow}).

  - The sound Cap option is new in the 14th generation of PowerEdge server. It limits CPU power consumption and
controls fan speed and acoustical ceiling. This is unique for acoustical deployments and may result in reduced system
performance.

- System layout and design enable increased airflow capability (by allowing high power) and dense system configurations. It
provides less system restrictions and increased feature density.

  - Streamlined airflow permits efficient airflow to fan power consumption ratio.
- Custom fans are designed for higher efficiency, better performance, longer life, and less vibration. It also delivers a better
acoustic outcome.

  - The average life expectancy of a server fan varies according to the platform specification.
  - If a fan is hot removed or inserted, it may take up to 90 seconds for iDRAC interfaces to reflect the changes in the
**Cooling** page ( **System**    - **Overview**    - **Cooling**    - **Fans** )

- Custom heat sinks are designed for optimized component cooling at minimum (required) airflow yet support highperformance CPUs.



# 17 iDRAC Direct Updates

iDRAC provides out of band ability to update the firmware of various components of a PowerEdge server. iDRAC direct
update helps in eliminating staged jobs during updates. This is supported only for iDRAC releases 5.00.00.00 and above. Only
SEP(passive) backplanes are supported for direct updates.

iDRAC used to have staged updates to initiate firmware update of the components. From this release, Direct updates have been
applied to PSU and Backplane. With the use of Direct Updates and Backplane can have quicker updates. In case of PSU, one
reboot (for initializing the updates) is avoided and the update can happen in single reboot.

With Direct update feature in iDRAC, you can eliminate the first reboot to initiate the updates. The second reboot will be
controlled by the device itself and iDRAC notifies the user if there is need for a separate reset via job status.

**NOTE:** For any update requiring iDRAC reset/ reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is
fully ready by waiting for few seconds of interval with maximum timeout of 5 minutes before using any other command.



# 18 Inventorying, monitoring, and configuring network devices

You can inventory, monitor, and configure the following network devices:

- Network Interface Cards (NICs)
- Converged Network Adapters (CNAs)
- LAN On Motherboards (LOMs)
- Network Daughter Cards (NDCs)
- Mezzanine cards (only for blade servers)

Before you disable NPAR or an individual partition on CNA devices, ensure that you clear all I/O identity attributes (Example:
IP address, virtual addresses, initiator, and storage targets) and partition-level attributes (Example: Bandwidth allocation). You
can disable a partition either by changing the VirtualizationMode attribute setting to NPAR or by disabling all personalities on a
partition.

Depending on the type of installed CNA device, the settings of partition attributes may not be retained from the last time the
partition was active. Set all I/O identity attributes and partition-related attributes when enabling a partition. You can enable a
partition by either changing the VirtualizationMode attribute setting to NPAR or by enabling a personality (Example: NicMode)
on the partition.

**NOTE:** iDRAC behavior may not be consistent when used with Non-Dell cards. These cards may only report in hardware
inventory and report some FRU data.

**Topics:**

- Inventorying and monitoring network devices
- Inventorying and monitoring FC HBA devices
- Inventorying and monitoring SFP Transceiver devices
- Telemetry Streaming
- Serial Data Capture
- Dynamic configuration of virtual addresses, initiator, and storage target settings



## Inventorying and monitoring network devices

You can remotely monitor the health and view the inventory of the network devices in the managed system.

For each device, you can view the following information of the ports and enabled partitions:

- Link Status
- Properties
- Settings and Capabilities
- Receive and Transmit Statistics
- iSCSI, FCoE initiator, and target information
**NOTE:** In case of Embedded NIC device, BIOS representation of each LOM port is considered as individual NIC device so
that the FQDD string is shown as **Embedded NIC 1 Port 1 Partition 1** and **Embedded NIC 2 Port 1 Partition 1** .



### Monitoring network devices using web interface

To view the network device information using Web interface, go to **System** - **Overview** - **Network Devices** . The **Network**
**Devices** page is displayed. For more information about the displayed properties, see **iDRAC Online Help** .

**NOTE:** **Wake On LAN** Port property for the Network Devices in iDRAC GUI may contain stale data as it is updated during
CSIOR. Refer to RACADM output for the correct data of this property.

**Inventorying, monitoring, and configuring network devices** **215**



### Monitoring network devices using RACADM

To view information about network devices, use the `hwinventory` and `nicstatistics` commands.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .

Additional properties may be displayed when using RACADM or WSMan in addition to the properties displayed in the iDRAC web
interface.



### Connection View

Manually checking and troubleshooting the servers’ networking connections is unmanageable in a datacenter environment.
iDRAC streamlines the job with iDRAC Connection View. This feature allows you to remotely check and troubleshoot network
connections from the same centralized GUI that you are using for deploying, updating, monitoring, and maintaining the servers.
Connection View in iDRAC provide details of the physical mapping of switch ports to server’s network ports and iDRAC
(integrated Dell Remote Access Controller) dedicated port connections. All supported network cards are visible in Connection
View, irrespective of the brand.

Instead of manually checking and troubleshooting the server's networking connections, you can view and manage network cable
connections remotely.

The Connection View provides the information of the switch ports which are connected to the server ports, and iDRAC
dedicated port. The server network ports include those on PowerEdge LOM, NDC, Mezz cards, and PCIe add-in cards.

To View network devices connection view, navigate to **System** - **Overview** - **Network Device** - **Connection View** to view
the Connection View.

Also, you can click **iDRAC Settings** - **Connectivity** - **Network** - **Common Settings** - **Connection View** to enable or disable
the connection view.

Connection View can be explored with racadm `SwitchConnection View` command and it can also be viewed with command.

**Enabled** Select **Enabled**, to enable Connection View. By default the **Enabled** option is selected.

**State** Displays **Enabled**, if you enable the connection view option from the **Connection View** from iDRAC
settings.

**Switch Connection**
**ID**

**Switch Port**



### Connection ID

Displays the LLDP chassis ID of the switch through which the device port is connected.

Displays the LLDP port ID of the switch port to which the device port is connected.

**NOTE:** Switch Connection ID and Switch Port Connection ID are available once the Connection View is enabled and the
Link is connected. The associated network card needs to be compatible with the Connection View. Only users with iDRAC
Configure privilege can modify the Connection View settings.

From iDRAC9 4.00.00.00 and later versions, iDRAC supports to send standard LLDP packets to external switches. This provides
options to discover iDRACs on the network. iDRAC sends two types of LLDP packets to the outbound network:

- **Topology LLDP** - In this feature, the LLDP packet goes through all the supported server NIC ports so that an external
switch can locate the originating server, NDC port[NIC FQDD], IOM location in the chassis, blade chassis service tag etc.
From iDRAC9 4.00.00.00 and later versions, Topology LLDP is available as an option for all PowerEdge servers. The LLDP
packets contain server network device connectivity information and are used by I/O modules and external switches to
update their configuration.

**NOTE:**

   - The Topology LLDP must be enabled for the MX chassis configuration to function properly.
   - The Topology LLDP is not supported on 1GbE controllers and select 10GbE controllers (Intel X520, QLogic 578xx).
- **Discovery LLDP** - In this feature, the LLDP packet goes only through the active iDRAC NIC port in use (dedicated NIC or
shared LOM), so an adjacent switch can locate iDRAC connection port in the switch. Discovery LLDP is specific only to the
active iDRAC network port and not will not be seen in all the Network ports in the server. Discovery LLDP will have some
details of the idrac like IP address, MAC address, service tag etc., so that a switch can automatically discover iDRAC devices
connected to it and some data of iDRAC.

**NOTE:** If Virtual MAC Address is cleared on a port/partition, then Virtual MAC Address would be same as MAC Address.

**216** **Inventorying, monitoring, and configuring network devices**

To enable or disable the Topology LLDP, navigate to **iDRAC Settings** - **Connectivity** - **Network** - **Common Settings** **Topology LLDP** to enable or disable the Topology LLDP. By default, it is enabled for MX servers and disabled for all other
servers.

To enable or disable the iDrac Discovery LLDP, navigate to **iDRAC Settings** - **Connectivity** - **Network** - **Common Settings**

- **iDrac Discovery LLDP** . By default, the Enabled option is selected.

LLDP packet originated from idrac can be viewed from switch using the command: `show lldp neighbors` .



###### Refresh Connection View

Use **Refresh Connection View** to get the latest information of Switch Connection ID and Switch Port Connection ID.

**NOTE:** If iDRAC has switch connection and switch port connection information for server network port or iDRAC network
port and due to some reason, the switch connection and switch port connection information is not refreshed for 5min, then
the switch connection and switch port connection information is shown as stale (last known good data) data for all user
interfaces. In the UI, you see yellow bang which is a natural representation and it does not indicate any warning.



###### Connection View Possible Values

**Feature Disabled** Connection view feature is disabled, to view the connection view data enable the feature.

**No Link** Indicates that the link associated with network controller port is down.

**Not Available** LLDP is not enabled on the switch. Check whether LLDP is enabled on the switch port.

**Not Supported** Network controller does not support Connection view feature.

**Stale Data** Last known good data, either the Network controller port link is down or the system is powered off.
Use the refresh option to refresh the connection view details to get the latest data.

**Valid Data** Displays the Valid Switch Connection ID and the Switch Port Connection ID information.



###### Connection View Supported Network Controllers

Following cards or controllers support Connection View feature.

**Broadcom** - 57414 rNDC 25GE

          - 57416/5720 rNDC 10GbE
          - 57412/5720 rNDC 10GbE
          - 57414 PCIe FH/LP 25GE
          - 57412 PCIe FH/LP 10GbE
          - 57416 PCIe FH/LP 10GbE
**Intel** - X710 bNDC 10Gb

          - X710 DP PCIe 10Gb
          - X710 QP PCIe 10Gb
          - X710 + I350 rNDC 10Gb+1Gb
          - X710 rNDC 10Gb
          - X710 bNDC 10Gb
          - XL710 PCIe 40Gb
          - XL710 OCP Mezz 10Gb
          - X710 PCIe 10Gb
**Mellanox** - MT27710 rNDC 40Gb

          - MT27710 PCIe 40Gb
          - MT27700 PCIe 100Gb
**QLogic** - QL41162 PCIe 10GE 2P

          - QL41112 PCIe 10GE 2P
          - QL41262 PCIe 25GE 2P
**Inventorying, monitoring, and configuring network devices** **217**



## Inventorying and monitoring FC HBA devices

You can remotely monitor the health and view the inventory of the Fibre Channel Host Bus Adapters (FC HBA) devices in
the managed system. The Emulex and QLogic FC HBAs are supported. For each FC HBA device, you can view the following
information for the ports:

- FC storage target information
- NVMe storage target information
- Port Properties
- Receive and Transmit Statistics
**NOTE:** Emulex FC8 HBAs are not supported.



### Monitoring FC HBA devices using web interface

To view the FC HBA device information using Web interface, go to **System** - **Overview** - **Network Devices** - **Fibre Channel** .
For more information about the displayed properties, see **iDRAC Online Help** .

The page name also displays the slot number where the FC HBA device is available and the type of FC HBA device.



### Monitoring FC HBA devices using RACADM

To view the FC HBA device information using RACADM, use the `hwinventory` command.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



## Inventorying and monitoring SFP Transceiver devices

You can remotely monitor the health and view the inventory of SFP transceiver devices connected to the system. Following are
the supported transceivers:

- SFP
- SFP+
- SFP28
- SFP-DD
- QSFP
- QSFP+
- QSFP28
- QSFP-DD
- Base-T modules
- AOC & DAC cables
- RJ-45 Base-T connected with Ethernet
- Fiber channel
- IB adapter ports

Most useful transceiver information are Serial number and Part number from transceiver EPROM. These would allow to verify
the remotely installed transceivers, when troubleshooting connectivity issues. For each SFP Transceiver device, you can view
the following information for the ports:

- Vendor Name
- Part Number
- Revision
- Serial Number
- Device Identifier
- Interface Type
**218** **Inventorying, monitoring, and configuring network devices**



### Monitoring SFP Transceiver devices using web interface

To view the SFP Transceiver device information using Web interface, go to **System** - **Overview** - **Network Devices** and click
on particular device. For more information about the displayed properties, see **iDRAC Online Help** .

The page name also displays the slot number where the transceiver device is available under Port statistics.

Monitoring data for SFP devices is only available for active SFPs. Following are the information displayed:

- TX Output Power
- TX Bias Current
- RX Input Power
- Vcc Voltage
- Temperature



### Monitoring SFP Transceiver devices using RACADM

To view the SFP Transceiver device information using RACADM, use the `networktransceiverstatistics` command.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



## Telemetry Streaming

Telemetry enables users to collect and stream real-time device metrics, events, and data logs from a PowerEdge server to a
subscribed external client or server application. Using Telemetry, you can set the type and frequency of reports that needs to be
generated.

**NOTE:**

  - The feature is supported on all the platforms, and it requires an iDRAC Datacenter license.
  - The remote Syslog option for telemetry streaming is removed in 7.00.00.00 and higher versions of firmware.

Telemetry is a one-to-many solution for collecting and streaming the live system data from one or more PowerEdge servers
(iDRAC) to a centralized 'Remote Server Monitoring, Analysis, and Alerting service'. The feature also supports on-demand data
collection of the data.

The Telemetry data includes metrics/inventory and logs/events. The data can be streamed (pushed out) or collected (pulled)
from iDRAC to or by remote consumers like Redfish client and Remote Syslog Server. The telemetry data is also provided to the
iDRAC SupportAssist data collector on demand. The data collection and report is based on predefined Redfish telemetry metrics,
trigger, and report definitions. The telemetry streaming settings can be configured using iDRAC web interface, RACADM,
Redfish, and Server Configuration Profile (SCP).

To enable Telemetry, go to **Configuration** - **System Settings** - **Telemetry Screening**, and select **Enabled** in the **Telemetry**
**Data Stream** list. Data streaming is automatic until Telemetry is enabled.

The following table describes the metric reports that can be generated using telemetry:

**Table 45. Metric report**

|Type|Metric Group|Inventory|Sensor|Statistics|Configuration|Metrics|
|---|---|---|---|---|---|---|
|I/O Devices|NICs|No|Yes|Yes|No|No|
|I/O Devices|FC HBAs|No|Yes|Yes|No|No|
|Server Devices|CPUs|No|Yes|No|No|Yes|
|Server Devices|Memory|No|Yes|No|No|Yes|
|Server Devices|Fans|No|Yes|No|No|No|
|Server Devices|PSUs|No|No|No|No|Yes|
|Server Devices|Sensors|No|Yes|No|No|No|
|Environmental|Thermal|No|Yes|No|No|Yes|
|Environmental|Power|No|No|Yes|No|Yes|
||Performance|No|No|Yes|No|No|
|Accelerators|GPUs|No|No|Yes|No|Yes|

To know more about the field descriptions of Telemetry section, see **iDRAC Online Help** .

**NOTE:**

  - When SAS/SATA backplane is connected to onboard SATA controller then it is expected that the backplane may not
show as Enclosure in the system and may not be shown in hardware inventory as well.

  - StorageDiskSMARTDATA is only supported on SSD drives with SAS/SATA bus protocol and behind the BOSS controller.
  - StorageSensor data is reported only for the drives in Ready/Online/Non-RAID mode and not behind the BOSS
controller.

  - NVMeSMARTData is only supported for SSD (PCIeSSD/NVMe Express) drives with PCIe bus protocol (not behind
SWRAID) and also behind the BOSS-N1 controller.

  - GPGPUStatistics data is only available in specific GPGPU models that support ECC memory capability.
  - PSUMetrics is not available on modular platforms.
  - Fan Power and PCIe Power Metrics may be displayed as 0 for some platforms.
  - CUPS report has been renamed to SystemUsage in the 4.40.00.00 release and it is supported on both INTEL and AMD
platforms.

**Telemetry Workflow:**

1. Install Datacenter license, if not installed already.
2. Configure global Telemetry settings including Enabling the telemetry and Rsyslog server network address and port using
RACADM, Redfish, SCP, or iDRAC UI.
3. Configure the following Telemetry report streaming parameters on the required device report or log using either RACADM or
Redfish interface:

  - EnableTelemetry
  - ReportInterval
  - ReportTriggers
**NOTE:** Enable iDRAC Alerts and Redfish events for the specific hardware for which you need telemetry reports.

4. Redfish client makes a subscription request to the Redfish EventService on iDRAC.
5. iDRAC generates and pushes the metric report or log/event data to the subscribed client when the predefined trigger
conditions are met.

**Feature Constraints:**

1. For security reasons, iDRAC supports only HTTPS-based communication to the client.
2. For stability reasons, iDRAC supports up to eight subscriptions.
3. Deletion of subscriptions is supported through Redfish interface only, even for the manual deletion by the Admin.
**Behavior of Telemetry feature:**

- iDRAC generates and pushes (HTTP POST) the Metric Report or log/event data to all the subscribed clients to the
destination specified in the subscription when the predefined trigger conditions are met. The clients receive new data only
upon successful subscription creation.

- The metric data includes the timestamp in ISO format, UTC time (ends in 'Z'), at the time of data collection from the source.
- Clients can terminate a subscription by sending an HTTP DELETE message to the URI of the subscription resource through
the Redfish interface.

- If the subscription is deleted either by iDRAC or the client, then iDRAC does not send (HTTP POST) reports. If the number
of delivery errors exceeds predefined thresholds, then iDRAC may delete a subscription.

- If a user has Admin privilege, they can delete the subscriptions but only through Redfish interface.
- The client is notified about the termination of a subscription by iDRAC by sending the 'Subscription terminated' event as the
last message.

- Subscriptions are persistent and can remain even after iDRAC restarts. However, you can delete the subscriptions by
performing `racresetcfg` or `racadm systemerase idrac` operations.

- User interfaces like RACADM, Redfish, SCP, and iDRAC display the current status of the client subscriptions.
**220** **Inventorying, monitoring, and configuring network devices**

- TelemetryService readiness can be checked using a new attribute `TelemetryServiceStatus` added under
`GetRemoteServiceAPIStatus` API call. This attribute is added to the existing list of LTStatus, RTStatus, ServerStatus,
and Status.



### Metric Report Definition

A Metric Report Definition provides a means to define the set of metrics that must be in a telemetry report and how the report
must be generated and streamed.

iDRAC telemetry streaming provides metrics that can provide data on server status with no performance impact on the main
server. These metrics include various system parameters such as CPU usage, memory usage, power consumption, temperature
readings, fan speed, and more.



#### Import and edit the Metric Report Definition

If you want to customize a Metric Report Definition for your specific needs, import the Metric Report Definition and edit the
properties.

1. Go to **Configuration** - **System Settings** - **Telemetry Configuration** - **Metric Report Definition** .
2. Select the **Location Type** .
3. Click **Choose File** and select the file.
4. Click **Import** .

The metrics report file is imported. The report is displayed in the **Telemetry reports** list.

5. If you want to edit a specific metrics report, click **Actions** - **Edit Report Properties** for that specific report.

The **Report Settings** dialog box is displayed.

6. Edit the report settings and click **Save** .



#### Export Metric Report Definition

Export the metric report definition if you want to compare the performance of servers or to use the metric report as a template
for other servers.

1. Go to **Configuration** - **System Settings** - **Telemetry Configuration** - **Metric Report Definition** .
2. Select the **Location Type** .
3. Select the **Metric Report Definition** .
4. Click **Save** .

The metrics report file is saved.



### Triggers

Telemetry Triggers define a set of conditions. Based on these conditions, the associated Metric Reports are generated and
streamed. The conditions can include a system event or a user-defined condition, such as a metric value crossing a threshold
limit or reaching equal to a discrete value.

Triggers can be configured to monitor a wide range of conditions, such as hardware failures, changes in system performance, or
other significant events. iDRAC sends the associated Metric Report by using one of the configured streaming methods. These
methods are Server-Sent Events (SSE) or Post to Subscription.



#### Import triggers

If you want to customize a trigger for your specific needs, import the trigger.

1. Go to **Configuration** - **System Settings** - **Telemetry Configuration** - **Triggers**
2. Select the **Location Type** .
3. Click **Choose File** and select the file.
4. Click **Import** .

The trigger file is imported. The trigger is displayed in the **Triggers** list.

**Inventorying, monitoring, and configuring network devices** **221**



#### Export triggers

Export the triggers if you want to compare the triggers of servers or to use the trigger as a template for other servers.

1. Go to **Configuration** - **System Settings** - **Telemetry Configuration** - **Triggers** .
2. Select the **Location Type** .
3. Select the trigger from the **File Name** list.
4. Click **Export** .

The triggers file is displayed in the **Triggers** list.



## Serial Data Capture

iDRAC allows you to capture console redirection serial for later retrieval with the use of the Serial Data Capture feature. This
feature requires an iDRAC Datacenter license.

The purpose of the Serial Data Capture feature is to capture the system serial data and store it so that the customer can later
retrieve it for debugging purpose.

You can enable or disable a serial data capture using RACADM, Redfish, and iDRAC interfaces. When this attribute is enabled,
iDRAC captures serial traffic received on Host Serial Device2 irrespective of serial Mux mode settings.

To enable or disable Serial Data Capture using iDRAC UI, go to **Maintainance** - **Diagnostics** - **Serial Data Logs** page, and
select the check box to enable or disable.

**NOTE:**

  - This attribute is persistent over iDRAC reboot.
  - Firmware reset to default disables this feature.
  - While Serial Data capture is enabled, the buffer keeps getting appended with recent data. If the user disables Serial
capture and enables it again, iDRAC starts appending from last update.

The System serial data capture starts when the user enables the serial data capture flag from any of the interfaces. If serial
data capture is enabled after the system has booted, you have to reboot the system, so BIOS can see the new setting (console
redirection Enabled requested by iDRAC) to get the serial data. iDRAC will start the data capture continuously and stores to the
shared memory with a limit of 512 KB. This buffer is circular.

**NOTE:**

  - For this feature to be functional, one must have Login privilege and System control privilege.
  - This feature requires an iDRAC Datacenter license.



## Dynamic configuration of virtual addresses, initiator, and storage target settings

You can dynamically view and configure the virtual address, initiator and storage target settings, and apply a persistence policy.
It allows the application to apply the settings based on power state changes (that is, operating system restart, warm reset,
cold reset, or AC cycle) and also based on persistence policy setting for that power state. This provides more flexibility in
deployments that need rapid re-configuration of system workloads to another system.

The virtual addresses are:

- Virtual MAC Address
- Virtual iSCSI MAC Address
- Virtual FIP MAC Address
- Virtual WWN
- Virtual WWPN
**NOTE:** When you clear the persistence policy, all the virtual addresses are reset to the default permanent address set at
the factory.

**NOTE:** Some cards with the virtual FIP, virtual WWN, and virtual WWPN MAC attributes, the virtual WWN and virtual
WWPN MAC attributes are automatically configured when you configure virtual FIP.

**222** **Inventorying, monitoring, and configuring network devices**

Using the IO Identity feature, you can:

- View and configure the virtual addresses for network and fibre channel devices (for example, NIC, CNA, FC HBA).
- Configure the initiator (for iSCSI and FCoE) and storage target settings (for iSCSI, FCoE, and FC).
- Specify persistence or clearance of the configured values over a system AC power loss, cold, and warm system resets.

The values configured for virtual addresses, initiator and storage targets may change based on the way the main power is
handled during system reset and whether the NIC, CNA, or FC HBA device has auxiliary power. The persistence of IO identity
settings can be achieved based on the policy setting made using iDRAC.

Only if the I/O identity feature is enabled, the persistence policies take effect. Each time the system resets or powers on, the
values are persisted or cleared based on the policy settings.

**NOTE:** After the values are cleared, you cannot re-apply the values before running the configuration job.



### Supported cards for I/O Identity Optimization

The following table provides the cards that support the I/O Identity Optimization feature.



### Table 46. Supported cards for I/O Identity Optimization

|Manufacturer|Type|
|---|---|
|Broadcom|●<br>5719 Mezz 1GB<br>●<br>5720 PCIe 1 GB<br>●<br>5720 bNDC 1 GB<br>●<br>5720 rNDC 1 GB<br>●<br>57414 PCIe 25 GbE<br>●<br>57504 PCIe 25 GbE<br>●<br>57504 OCP 25 GbE|
|Intel|●<br>i350 DP FH PCIe 1GB<br>●<br>i350 QP PCIe 1GB<br>●<br>i350 QP rNDC 1GB<br>●<br>i350 Mezz 1GB<br>●<br>i350 bNDC 1GB<br>●<br>x520 PCIe 10GB<br>●<br>x520 bNDC 10GB<br>●<br>x520 Mezz 10GB<br>●<br>x520 + i350 rNDC 10GB+1GB<br>●<br>X710 bNDC 10GB<br>●<br>X710 QP bNDC 10GB<br>●<br>X710 PCIe 10 GB<br>●<br>X710 + I350 rNDC 10GB+1GB<br>●<br>X710 rNDC 10GB<br>●<br>XL710 QSFP DP LP PCIe 40GE<br>●<br>XL710 QSFP DP FH PCIe 40GE<br>●<br>X550 DP BT PCIe 2 x 10 Gb<br>●<br>X550 DP BT LP PCIe 2 x 10 Gb<br>●<br>XXV710 Fab A/B Mezz 25 Gb (**for MX platforms** )|
|Mellanox|●<br>ConnectX-3 Pro 10G Mezz 10GB<br>●<br>ConnectX-4 LX 25GE SFP DP rNDC 25GB<br>●<br>ConnectX-4 LX 25GE DP FH PCIe 25GB<br>●<br>ConnectX-4 LX 25GE DP LP PCIe 25GB<br>●<br>ConnectX-4 LX Fab A/B Mezz 25GB (**for MX platforms** )|
|Qlogic|●<br>57810 PCIe 10GB<br>●<br>57810 bNDC 10GB<br>●<br>57810 Mezz 10GB<br>●<br>57800 rNDC 10GB+1GB|
||●<br>57840 rNDC 10GB<br>●<br>57840 bNDC 10GB<br>●<br>QME2662 Mezz FC16<br>●<br>QLE 2692 SP FC16 Gen 6 HBA FH PCIe FC16<br>●<br>SP FC16 Gen 6 HBA LP PCIe FC16<br>●<br>QLE 2690 DP FC16 Gen 6 HBA FH PCIe FC16<br>●<br>DP FC16 Gen 6 HBA LP PCIe FC16<br>●<br>QLE 2742 DP FC32 Gen 6 HBA FH PCIe FC32<br>●<br>DP FC32 Gen 6 HBA LP PCIe FC32<br>●<br>QLE2740 PCIe FC32<br>●<br>QME2692-DEL Fab C Mezz FC16 (**for MX platforms**)<br>●<br>QME2742-DEL Fab C Mezz FC32 (**for MX platforms** )<br>●<br>QL41262HMKR-DE Fab A/B Mezz 25 Gb (**for MX platforms** )<br>●<br>QL41232HMKR-DE Fab A/B Mezz 25 Gb (**for MX platforms** )<br>●<br>QLogic 1x32Gb QLE2770 FC HBA<br>●<br>QLogic 2x32Gb QLE2772 FC HBA|
|Emulex|●<br>LPe15002B-M8 (FH) PCIe FC8<br>●<br>LPe15002B-M8 (LP) PCIe FC8<br>●<br>LPe15000B-M8 (FH) PCIe FC8<br>●<br>LPe15000B-M8 (LP) PCIe FC8<br>●<br>LPe31000-M6-SP PCIe FC16<br>●<br>LPe31002-M6-D DP PCIe FC16<br>●<br>LPe32000-M2-D SP PCIe FC32<br>●<br>LPe32002-M2-D DP PCIe FC32<br>●<br>LPe31002-D Fab C Mezz FC16 (**for MX platforms** )<br>●<br>LPe32002-D Fab C Mezz FC32 (**for MX platforms** )<br>●<br>LPe35002-M2 FC32 2-Port<br>●<br>LPe35000-M2 FC32 1-Port|



### Supported NIC firmware versions for IO Identity Optimization

In 14th generation Dell PowerEdge servers, the required NIC firmware is available by default.

The following table provides the NIC firmware versions for the I/O identity optimization feature.



### Virtual or Remote assigned Address and Persistence Policy behavior when iDRAC is set to Remote-Assigned Address mode or Console mode

The following table describes the Virtual Address Management (VAM) configuration and Persistence Policy behavior, and the
dependencies.

**Table 47. Virtual/Remote-Assigned Address and Persistence Policy behavior**

|Remote assigned<br>Address Feature<br>State in OME<br>Modular|Mode set in<br>iDRAC|IO Identity<br>Feature State in<br>iDRAC|SCP|Persistence<br>Policy|Clear Persistence<br>Policy—Virtual<br>Address|
|---|---|---|---|---|---|
|Remote-Assigned<br>Address enabled|RemoteAssignedAd<br>dress Mode|Enabled|Virtual address<br>management<br>(VAM) configured|Configured VAM<br>persists|Set to Remote<br>assigned Address|
|Remote-Assigned<br>Address enabled|RemoteAssignedAd<br>dress Mode|Enabled|VAM not<br>configured|Set to Remote<br>assigned Address|No persistence—Is<br>set to Remote<br>assigned Address|
|Remote-Assigned<br>Address enabled|RemoteAssignedAd<br>dress Mode|Disabled|Configured using<br>the path provided<br>in Lifecycle<br>Controller|Set to Remote<br>assigned Address<br>for that cycle|No persistence—Is<br>set to Remote<br>assigned Address|
|Remote-Assigned<br>Address enabled|RemoteAssignedAd<br>dress Mode|Disabled|VAM not<br>configured|Set to Remote<br>assigned Address|Set to Remote<br>assigned Address|
|Remote-Assigned<br>Address disabled|RemoteAssignedAd<br>dress Mode|Enabled|VAM configured|Configured VAM<br>persists|Persistence only—<br>clear is not possible|
|Remote-Assigned<br>Address disabled|RemoteAssignedAd<br>dress Mode|Enabled|VAM not<br>configured|Set to hardware<br>MAC address|No persistence<br>supported.<br>Depends on card<br>behavior|
|Remote-Assigned<br>Address disabled|RemoteAssignedAd<br>dress Mode|Disabled|Configured using<br>the path provided<br>in the Lifecycle<br>Controller|Lifecycle Controller<br>configuration<br>persists for that<br>cycle|No persistence<br>supported.<br>Depends on card<br>behavior|
|Remote-Assigned<br>Address disabled|RemoteAssignedAd<br>dress Mode|Disabled|VAM not<br>configured|Set to hardware<br>MAC address|Set to hardware<br>MAC address|
|Remote-Assigned<br>Address enabled|Console Mode|Enabled|VAM configured|Configured VAM<br>persists|Both persistence<br>and clear must<br>work|
|Remote-Assigned<br>Address enabled|Console Mode|Enabled|VAM not<br>configured|Set to hardware<br>MAC address|Set to hardware<br>MAC address|
|Remote-Assigned<br>Address enabled|Console Mode|Disabled|Configured using<br>the path provided<br>in the Lifecycle<br>Controller|Lifecycle Controller<br>configuration<br>persists for that<br>cycle|No persistence<br>supported.<br>Depends on card<br>behavior|
|Remote-Assigned<br>Address disabled|Console Mode|Enabled|VAM configured|Configured VAM<br>persists|Both persistence<br>and clear must<br>work|
|Remote-Assigned<br>Address disabled|Console Mode|Enabled|VAM not<br>configured|Set to hardware<br>MAC address|Set to hardware<br>MAC address|
|Remote-Assigned<br>Address disabled|Console Mode|Disabled|Configured using<br>the path provided<br>in the Lifecycle<br>Controller|Lifecycle Controller<br>configuration<br>persists for that<br>cycle|No persistence<br>supported.<br>Depends on card<br>behavior|
|Remote-Assigned<br>Address enabled|Console Mode|Disabled|VAM not<br>configured|Set to hardware<br>MAC address|Set to hardware<br>MAC address|

**NOTE:**

- Part replacement configuration for Partition capable cards works fine when VirtualizationMode (the attribute to enable
number of partitions) is the same as the replaced card and the NIC card present in the server.

- Part replacement configuration does not trigger when replaced card VirtualizationMode (number of partitions) are not
matching with the NIC card present in the server.

**Inventorying, monitoring, and configuring network devices** **225**

  - During the Part Replacement window before CSIOR, the Lifecycle Controller restores the NIC configuration. It involves a
cold boot followed by warm boot. After both are rebooted, NIC has the same firmware which is installed during restore
process.

  - Persistence policy applies for every reboot based on policy. Here on cold boot, virtual identities are not applied due to
firmware version mismatch and persistence data being deleted.

  - The persistence policy feature checks the PCI IDs and firmware version of the current and previous NIC of the same
vendor which is replaced. In case these fields are not matched, virtual identities are not applied and persistence data
(virtual identities) are also deleted from iDRAC.

  - For part replacement, the vendor should maintain the same PCI ids and firmware version or you must perform VAM job/
template deployment.



### System behavior for FlexAddress and IO Identity





### Table 48. System behavior for FlexAddress and I/O Identity

|Type|FlexAddress<br>Feature State in<br>CMC|IO Identity<br>Feature State in<br>iDRAC|Availability of<br>Remote Agent VA<br>for the Reboot<br>Cycle|VA Programming<br>Source|Reboot Cycle<br>VA Persistence<br>Behavior|
|---|---|---|---|---|---|
|Server with<br>FA-equivalent<br>Persistence|Enabled|Disabled|NA|FlexAddress from<br>CMC|Per FlexAddress<br>spec|
|Server with<br>FA-equivalent<br>Persistence|N/A, Enabled, or<br>Disabled|Enabled|Yes - New or<br>Persisted|Remote Agent<br>Virtual Address|Per FlexAddress<br>spec|
|Server with<br>FA-equivalent<br>Persistence|N/A, Enabled, or<br>Disabled|Enabled|No|Virtual Address<br>Cleared|Virtual Address<br>Cleared|
|Server with<br>FA-equivalent<br>Persistence|Disabled|Disabled|NA|NA|NA|
|Server with VAM<br>Persistence Policy<br>Feature|Enabled|Disabled|NA|FlexAddress from<br>CMC|Per FlexAddress<br>spec|
|Server with VAM<br>Persistence Policy<br>Feature|Enabled|Enabled|Yes — New or<br>Persisted|Remote Agent<br>Virtual Address|Per Remote Agent<br>Policy Setting|
|Server with VAM<br>Persistence Policy<br>Feature|Enabled|Enabled|No|FlexAddress from<br>CMC|Per FlexAddress<br>spec|
|Server with VAM<br>Persistence Policy<br>Feature|Disabled|Enabled|Yes — New or<br>Persisted|Remote Agent<br>Virtual Address|Per Remote Agent<br>Policy Setting|
|Server with VAM<br>Persistence Policy<br>Feature|Disabled|Enabled|No|Virtual Address<br>Cleared|Virtual Address<br>Cleared|
|Server with VAM<br>Persistence Policy<br>Feature|Disabled|Disabled|NA|NA|NA|



### Enabling or disabling IO Identity Optimization

Normally, after the system boots, the devices are configured and then after a reboot the devices are initialized. You can enable
the I/O Identity Optimization feature to achieve boot optimization. If it is enabled, it sets the virtual address, initiator, and
storage target attributes after the device is reset and before it is initialized, thus eliminating a second BIOS restart. The device
configuration and boot operation occur in a single system start and is optimized for boot time performance.

Before enabling I/O identity optimization, make sure that:

- You have the Login, Configure, and System Control privileges.
- BIOS, iDRAC, and network cards are updated to the latest firmware.

After enabling I/O Identity Optimization feature, export the Server Configuration Profile file from iDRAC, modify the required
I/O Identity attributes in the SCP file, and import the file back to iDRAC.

**NOTE:** I/O Identity attributes should only be set using SCP to make them persistent across reboots. Using other methods
to set them is not persistent.

**226** **Inventorying, monitoring, and configuring network devices**

For the list of I/O Identity Optimization attributes that you can modify in the SCP file, see the **NIC Profile** document available
[at Dell Support page.](https://www.dell.com/support)

**NOTE:** Do not modify non- I/O identity Optimization attributes.



#### Enabling or disabling IO Identity Optimization using web interface

To enable or disable I/O Identity Optimization:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **I/O Identity**
**Optimization** .
The **I/O Identity Optimization** page is displayed.

2. Click the **I/O Identity Optimization** tab, select the **Enable** option to enable this feature. To disable, clear this option.
3. Click **Apply** to apply the setting.



#### Enabling or disabling IO Identity Optimization using RACADM

To enable I/O Identity Optimization, use the command:

```
 racadm set idrac.ioidopt.IOIDOptEnable Enabled

```

After enabling this feature, you must restart the system for the settings to take effect.

To disable I/O Identity Optimization, use the command:

```
 racadm set idrac.ioidopt.IOIDOptEnable Disabled

```

To view the I/O Identity Optimization setting, use the command:

```
 racadm get iDRAC.IOIDOpt



### SSD Wear Threshold

```

iDRAC provides you with the ability to configure thresholds of Remaining Rated Write Endurance for all SSDs and Available
Spare of NVMe PCIe SSDs.

When SSD Remaining Rated Write Endurance and NVMe PCIe SSD Available Spare values are less than the threshold, then
iDRAC logs this event in the LC log and depending on the alert type selection, iDRAC also performs Email alert, SNMP Trap,
IPMI Alert, Logging in Remote Syslog, WS Eventing and operating system log.

iDRAC alerts the user when the SSD Remaining Rated Write Endurance goes below the set threshold, so that the system admin
can take a backup of the SSD or replace it.

For only NVMe PCIe SSDs, iDRAC displays **Available Spare** and provide a threshold to warn. The **Available Spare** is not
available for SSDs which are connected behind PERC and HBA. **Capable Speed** is not available for drives (SAS, SATA) that are
connected behind HBA465e controllers.



#### Configuring SSD Wear Threshold alert features using web interface

To configure Remaining Rated Write Endurance and Available Spare Alert Threshold using web interface:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **SSD Wear Thresholds** .
The **SSD Wear Thresholds** page is displayed.

2. **Remaining Rated Write Endurance** - You can set the value between 1-99%. The default value is 10%.

Alert type for this feature is **SSD Wear Write Endurance** and security alert is **Warning** as a result of threshold event..

3. **Available Spare Alert Threshold** - You can set the value between 1-99%. The default value is 10%.

Alert type for this feature is **SSD Wear Available Spare** and security alert is **Warning** as a result of threshold event.

**Inventorying, monitoring, and configuring network devices** **227**



#### Configuring SSD Wear Threshold alert features using RACADM

To configure Remaining Rated Write Endurance, use the command:

```
 racadm set System.Storage.RemainingRatedWriteEnduranceAlertThreshold n

```

, where n= 1 to 99%.

To configure Available Spare Alert Threshold, use the command:

```
 racadm System.Storage.AvailableSpareAlertThreshold n

```

, where n= 1 to 99%.



### Configuring persistence policy settings

Using IO identity, you can configure policies specifying the system reset and power cycle behaviors that determine the
persistence or clearance of the virtual address, initiator, and storage target settings. Each individual persistence policy attribute
applies to all ports and partitions of all applicable devices in the system. The device behavior changes between auxiliary powered
devices and non-auxiliary powered devices.

**NOTE:** The **Persistence Policy** feature may not work when set to default, if the **VirtualAddressManagement** attribute
is set to **FlexAddress** (not for MX platforms) or **RemoteAssignedAddress** (for MX platforms) mode on iDRAC and if
the FlexAddress or Remote-Assigned Address feature is disabled in CMC (not for MX platforms) or OME Modular (for
MX platforms), ensure that you set the **VirtualAddressManagement** attribute to **Console** mode in iDRAC or enable the
FlexAddress or Remote-Assigned Address feature in CMC or OME Modular.

You can configure the following persistence policies:

- Virtual Address: Auxiliary powered devices
- Virtual Address: Non-Auxiliary powered devices
- Initiator
- Storage target

Before applying the persistence policy, make sure to:

- Inventory the network hardware at least once, that is, enabled Collect System Inventory On Restart.
- Enable I/O Identity Optimization.

Events are logged to the Lifecycle Controller log when:

- I/O Identity Optimization is enabled or disabled.
- Persistence policy is changed.
- Virtual address, initiator and target values are set based on the policy. A single log entry is logged for the configured devices
and the values that are set for those devices when the policy is applied.

Event actions are enabled for SNMP, email, or WS-eventing notifications. Logs are also included in the remote syslogs.



###### Default values for persistence policy

**Table 49. Default values for persistence policy**

|Persistence Policy|AC Power Loss|Cold Boot|Warm Boot|
|---|---|---|---|
|Virtual Address: Auxiliary<br>Powered Devices|Not selected|Selected|Selected|
|Virtual Address: Non-Auxiliary<br>Powered Devices|Not selected|Not selected|Selected|
|Initiator|Selected|Selected|Selected|
|Storage Target|Selected|Selected|Selected|

**228** **Inventorying, monitoring, and configuring network devices**

**NOTE:** When a persistent policy is disabled and when you perform the action to lose the virtual address, re-enabling the
persistent policy does not retrieve the virtual address. You must set the virtual address again after you enable the persistent
policy.

**NOTE:** If there is a persistence policy in effect and the virtual addresses, initiator, or storage targets are set on a
CNA-device partition, do not reset or clear the values configured for virtual addresses, initiator, and storage targets before
changing the VirtualizationMode or the personality of the partition. The action is performed automatically when you disable
the persistence policy. You can also use a configuration job to explicitly set the virtual address attributes to 0s and the
initiator and storage targets values as defined in iSCSI initiator and storage target default values.



#### Configuring persistence policy settings using iDRAC web interface

To configure the persistence policy:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **I/O Identity**
**Optimization** .

2. Click **I/O Identity Optimization** tab.
3. In the **Persistence Policy** section, select one or more of the following for each persistence policy:
  - **Warm Reset**  - The virtual address or target settings persist when warm reset condition occurs.
  - **Cold Reset**  - The virtual address or target settings persist when cold reset conditions occur.
  - **AC Power Loss**  - The virtual address or target settings persist when AC power loss conditions occur.
4. Click **Apply** .

The persistence policies are configured.



#### Configuring persistence policy settings using RACADM

To set persistence policy, use the following racadm object with the **set** sub command:

- For virtual addresses, use **iDRAC.IOIDOpt.VirtualAddressPersistencePolicyAuxPwrd** and
**iDRAC.IOIDOpt.VirtualAddressPersistencePolicyNonAuxPwrd** objects.

- For initiator, use **iDRAC.IOIDOPT.InitiatorPersistencePolicy** object.
- For storage targets, use **iDRAC.IOIDOpt.StorageTargetPersistencePolicy** object.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



#### iSCSI initiator and storage target default values

The following tables provide the list of default values for iSCSI initiator and storage targets when the persistence policies are
cleared.

**Table 50. iSCSI initiator —default values**

|iSCSI Initiator|Default Values in IPv4 mode|Default Values in IPv6 mode|
|---|---|---|
|IscsiInitiatorIpAddr|0.0.0.0|::|
|IscsiInitiatorIpv4Addr|0.0.0.0|0.0.0.0|
|IscsiInitiatorIpv6Addr|::|::|
|IscsiInitiatorSubnet|0.0.0.0|0.0.0.0|
|IscsiInitiatorSubnetPrefix|0|0|
|IscsiInitiatorGateway|0.0.0.0|::|
|IscsiInitiatorIpv4Gateway|0.0.0.0|0.0.0.0|
|IscsiInitiatorIpv6Gateway|::|::|
|IscsiInitiatorPrimDns|0.0.0.0|::|
|IscsiInitiatorIpv4PrimDns|0.0.0.0|0.0.0.0|
|IscsiInitiatorIpv6PrimDns|::|::|
|IscsiInitiatorSecDns|0.0.0.0|::|
|IscsiInitiatorIpv4SecDns|0.0.0.0|0.0.0.0|
|IscsiInitiatorIpv6SecDns|::|::|
|IscsiInitiatorName|Value Cleared|Value Cleared|
|IscsiInitiatorChapId|Value Cleared|Value Cleared|
|IscsiInitiatorChapPwd|Value Cleared|Value Cleared|
|IPVer|Ipv4|Ipv6|

**Table 51. ISCSI storage target attributes — default values**

|iSCSI Storage Target Attributes|Default Values in IPv4 mode|Default Values in IPv6 mode|
|---|---|---|
|ConnectFirstTgt|Disabled|Disabled|
|FirstTgtIpAddress|0.0.0.0|::|
|FirstTgtTcpPort|3260|3260|
|FirstTgtBootLun|0|0|
|FirstTgtIscsiName|Value Cleared|Value Cleared|
|FirstTgtChapId|Value Cleared|Value Cleared|
|FirstTgtChapPwd|Value Cleared|Value Cleared|
|FirstTgtIpVer|Ipv4|NA|
|ConnectSecondTgt|Disabled|Disabled|
|SecondTgtIpAddress|0.0.0.0|::|
|SecondTgtTcpPort|3260|3260|
|SecondTgtBootLun|0|0|
|SecondTgtIscsiName|Value Cleared|Value Cleared|
|SecondTgtChapId|Value Cleared|Value Cleared|
|SecondTgtChapPwd|Value Cleared|Value Cleared|
|SecondTgtIpVer|Ipv4|NA|

**230** **Inventorying, monitoring, and configuring network devices**



# 19 Managing storage devices

Beginning with iDRAC 4.30.30.30 release, iDRAC supports PERC 11, HBA 11, and BOSS 1.5 on AMD systems.

Starting with iDRAC 6.10.85.00 release, iDRAC supports PERC 12.1.

**NOTE:** The hardware caches erase operation fails on a configured external PERC 12 controller. Run the reset configuration
operation before performing Hardware cache erase.

**NOTE:**

  - BOSS controllers support only RAID level 1.
  - Any Foreign Virtual Disks that are detected behind BOSS controllers should be cleared either from BIOS HII or by using
reset controller operation.

  - For BOSS Controllers, the complete VD information may not be available when both PDs are plugged out and plugged in
again.

  - PERC 11 and later controllers support Hardware root of Trust (RoT).
  - For any update requiring iDRAC reset/reboot or in case iDRAC is rebooted, it is recommended to check if iDRAC is fully
ready by waiting for a few seconds of interval with a maximum timeout of 5 minutes before using any other command.

  - For PERC12, Online Capacity Expansion (OCE) with drive addition is possible only on a virtual disk with full size. OCE
with drive addition is not performed on sliced virtual disks.

  - To avoid any unpredictable error, it is recommended not to perform any storage-related operation when a storage job is
in progress.

iDRAC has expanded its agent-free management to include direct configuration of the PERC controllers. This enables you to
remotely configure the storage components that are attached to your system at run-time. These components include RAID and
non-RAID controllers and the channels, ports, enclosures, and disks attached to them. PERC 11 is supported on PowerEdge
Rx5xx/Cx5xx AMD platform servers.

The complete storage subsystem discovery, topology, health monitoring, and configuration are accomplished in the
Comprehensive Embedded Management (CEM) framework by interfacing with the internal and external PERC controllers
through the MCTP protocol over I2C interface.

**NOTE:** The Software RAID (SWRAID) is not supported by CEM and thus is not supported in the iDRAC UI. SWRAID can be
managed using either RACADM, WS-MAN, or Redfish.

Using iDRAC, you can perform most of the functions that are available in OpenManage Storage Management including real-time
(no reboot) configuration commands (for example, create virtual disk). You can completely configure RAID before installing the
operating system.

You can configure and manage the controller functions without accessing the BIOS. These functions include configuring virtual
disks and applying RAID levels and hot spares for data protection. You can initiate many other controller functions such as
rebuild and troubleshooting. You can protect your data by configuring data-redundancy or assigning hot spares.

**NOTE:** If the Volume Management Device (VMD) BIOS setting is enabled (with ID module support) on a PowerEdge server,
avoid configuring CPU-attached NVMe drives to prevent unpredictable behavior.

The storage devices are:

- Controllers—Most operating systems do not read and write data directly from the disks, but instead send read and write
instructions to the controller. The controller is the hardware in your system that interacts directly with the disks to write
and retrieve data. A controller has connectors (channels or ports) which are attached to one or more physical disks or an
enclosure containing physical disks. RAID controllers can span the boundaries of the disks to create an extended amount
of storage space or a virtual disk using the capacity of more than one disk. Controllers also perform other tasks, such as
initiating rebuilds, initializing disks, and more. To complete their tasks, controllers require special software known as firmware
and drivers. To function properly, the controller must have the minimum required version of the firmware and the drivers
installed. Different controllers have different characteristics in the way that they read and write data and perform tasks.
Understanding these features is helpful to most efficiently manage the storage.

**NOTE:** The ControllerDrivesDecommission operation may take more than 1 hour to complete on a fully populated
system.

- Physical disks or physical devices—Reside within an enclosure or are attached to the controller. On a RAID controller,
physical disks or devices are used to create virtual disks.

- Virtual disk—It is storage that is created by a RAID controller from one or more physical disks. Although a virtual disk may be
created from several physical disks, it is viewed by the operating system as a single disk. Depending on the RAID level used,
the virtual disk may retain redundant data if there is a disk failure or have particular performance attributes. Virtual disks can
only be created on a RAID controller.

**NOTE:** Physical disks that are removed from virtual disks are still displayed in the Hardware Inventory. The details are
updated only after the host or iDRAC reboots.

- Enclosure—It is attached to the system externally while the backplane and its physical disks are internal. If the enclosures
are connected in multipath configuration, ensure that the following port combinations are used to connect to the controllers:

  - Port 0 and Port 2
  - Port 1 and Port 3
- Backplane—It is similar to an enclosure. In a Backplane, the controller connector and physical disks are attached to the
enclosure, but it does not have the management features (temperature probes, alarms, and so on) associated with external
enclosures. Physical disks can be contained in an enclosure or attached to the backplane of a system.

**NOTE:** A maximum configuration setup with around 192 physical drives may take up to minimum 30 minutes to complete
the inventory.

**NOTE:** When a system has an extensive array of storage components, such as 240 Virtual Disks and 60 Drives, it
is expected that certain pending storage operations or Discard Pending operations may encounter failures that are
accompanied by the RAC0508 error.

**NOTE:** When one or more backplanes are connected to an expander, then enclosure position is displayed as **Unknown** .

**NOTE:** In any MX chassis which contains storage sleds and compute sleds, iDRAC pertaining to any of the compute sleds in
that chassis report all storage sleds (both assigned and unassigned). If any one of the assigned or unassigned blades are in
Warning or Critical heath state, the blade controller also reports the same status.

**NOTE:** In some platforms, hot removal/insertion of SLED is not supported and you may see some unexpected errors. It
needs to be powered off before hot removal/insertion.

In addition to managing the physical disks contained in the enclosure, you can monitor the status of the fans, power supply, and
temperature probes in an enclosure. You can hot-plug enclosures. Hot-plugging is defined as adding of a component to a system
while the operating system is still running.

**NOTE:** The status for the drives that are hot removed is indicated as **Removed** and the drive information is available within
the hardware and firmware inventories until the next host reboot.

The physical devices connected to the controller must have the latest firmware. For the latest supported firmware, contact your
service provider.

**NOTE:**

  - If you perform drive firmware update on hot-plugged drives, the PR36 log may get missed in the LifeCycle logs even
though the update is successful. To avoid this, perform a host reboot before the firmware update.

  - PR36 is not logged for Battery Backup Units (BBUs) and Data processing Units (DPUs) after firmware updates.
Storage events from PERC are mapped to SNMP traps and WSMan events as applicable. Any changes to the storage
configurations are logged in the Lifecycle Log.

  - After performing a server warm reboot, iDRAC may report PDR8 LC log for drives that are connected behind PERC
controllers.

  - In iDRAC, you can see backplane/enclosure associated with your systems PERC controller. This enclosure reports 16
slots (even though your system does not support that many drives).

  - When drives of the same model but with different firmware versions are hot-swapped or hot-plugged behind a
controller, PR36 logs (version changed) are displayed in the Lifecycle Controller (LC) logs.

In systems where drives are cabled directly to the RAID controller there is an entry that is created for each possible drive
connection to PERC. PERC supports up to 16 cable-connected drives so you see that 16 slots are reported.

|Table 52. PERC capability|Col2|
|---|---|
|**PERC Capability**|**CEM configuration Capable Controller**|
|Real-time|If there are pending or scheduled jobs for any controller, then<br>the jobs have to be cleared or you must wait for the jobs to<br>be completed before applying the configuration at run-time. A<br>reboot is not required for Run-time or real-time jobs.<br>**NOTE:** PERC 11 and above are supported for PowerEdge<br>Rx5xx/Cx5xx servers.|
|Staged|N/A|

**Topics:**

- Understanding RAID concepts
- Supported controllers
- Supported enclosures
- Summary of supported features for storage devices
- Inventorying and monitoring storage devices
- Viewing storage device topology
- Managing physical disks
- Managing virtual disks
- RAID Configuration Features
- Managing controllers
- Managing PCIe SSDs
- Managing enclosures or backplanes
- Choosing operation mode to apply settings
- Viewing and applying pending operations
- Storage devices — apply operation scenarios
- Blinking or unblinking component LEDs
- Warm reboot



## Understanding RAID concepts

Storage Management uses the Redundant Array of Independent Disks (RAID) technology to provide Storage Management
capability. Understanding Storage Management requires an understanding of RAID concepts, as well as some familiarity with
how the RAID controllers and operating system view disk space on your system.



### What is RAID

RAID is a technology for managing the storage of data on the physical disks that reside or are attached to the system. A key
aspect of RAID is the ability to span physical disks so that the combined storage capacity of multiple physical disks can be
treated as a single, extended disk space. Another key aspect of RAID is the ability to maintain redundant data which can be
used to restore data in the event of a disk failure. RAID uses different techniques, such as striping, mirroring, and parity, to
store and reconstruct data. There are different RAID levels that use different methods for storing and reconstructing data. The
RAID levels have different characteristics in terms of read/write performance, data protection, and storage capacity. Not all
RAID levels maintain redundant data, which means for some RAID levels lost data cannot be restored. The RAID level you choose
depends on whether your priority is performance, protection, or storage capacity.

**NOTE:** The RAID Advisory Board (RAB) defines the specifications used to implement RAID. Although RAB defines the RAID
levels, commercial implementation of RAID levels by different vendors may vary from the actual RAID specifications. An
implementation of a particular vendor may affect the read and write performance and the degree of data redundancy.



#### Hardware and software RAID

RAID can be implemented with either hardware or software. A system using hardware RAID has a RAID controller that
implements the RAID levels and processes data reads and writes to the physical disks. When using software RAID provided

by the operating system, the operating system implements the RAID levels. For this reason, using software RAID by itself can
slow the system performance. You can, however, use software RAID along with hardware RAID volumes to provide better
performance and variety in the configuration of RAID volumes. For example, you can mirror a pair of hardware RAID 5 volumes
across two RAID controllers to provide RAID controller redundancy.



#### RAID concepts

RAID uses particular techniques for writing data to disks. These techniques enable RAID to provide data redundancy or better
performance. These techniques include:

- Mirroring — Duplicating data from one physical disk to another physical disk. Mirroring provides data redundancy by
maintaining two copies of the same data on different physical disks. If one of the disks in the mirror fails, the system can
continue to operate using the unaffected disk. Both sides of the mirror contain the same data always. Either side of the
mirror can act as the operational side. A mirrored RAID disk group is comparable in performance to a RAID 5 disk group in
read operations but faster in write operations.

- Striping — Disk striping writes data across all physical disks in a virtual disk. Each stripe consists of consecutive virtual
disk data addresses that are mapped in fixed-size units to each physical disk in the virtual disk using a sequential pattern.
For example, if the virtual disk includes five physical disks, the stripe writes data to physical disks one through five without
repeating any of the physical disks. The amount of space consumed by a stripe is the same on each physical disk. The portion
of a stripe that resides on a physical disk is a stripe element. Striping by itself does not provide data redundancy. Striping in
combination with parity does provide data redundancy.

- Stripe size — The total disk space consumed by a stripe not including a parity disk. For example, consider a stripe that
contains 64KB of disk space and has 16KB of data residing on each disk in the stripe. In this case, the stripe size is 64KB and
the stripe element size is 16KB.

- Stripe element — A stripe element is the portion of a stripe that resides on a single physical disk.
- Stripe element size — The amount of disk space consumed by a stripe element. For example, consider a stripe that contains
64KB of disk space and has 16KB of data residing on each disk in the stripe. In this case, the stripe element size is 16KB and
the stripe size is 64KB.

- Parity — Parity refers to redundant data that is maintained using an algorithm in combination with striping. When one of the
striped disks fails, the data can be reconstructed from the parity information using the algorithm.

- Span — A span is a RAID technique used to combine storage space from groups of physical disks into a RAID 10, 50, or 60
virtual disk.



#### RAID levels

Each RAID level uses some combination of mirroring, striping, and parity to provide data redundancy or improved read and write
performance. For specific information on each RAID level, see Choosing raid levels.



### Organizing data storage for availability and performance

RAID provides different methods or RAID levels for organizing the disk storage. Some RAID levels maintain redundant data so
that you can restore data after a disk failure. Different RAID levels also entail an increase or decrease in the I/O (read and write)
performance of a system.

Maintaining redundant data requires the use of additional physical disks. The possibility of a disk failure increases with an
increase in the number of disks. Since the differences in I/O performance and redundancy, one RAID level may be more
appropriate than another based on the applications in the operating environment and the nature of the data being stored.

When choosing a RAID level, the following performance and cost considerations apply:

- **Availability or fault-tolerance** - Availability or fault-tolerance refers to the ability of a system to maintain operations
and provide access to data even when one of its components has failed. In RAID volumes, availability or fault-tolerance
is achieved by maintaining redundant data. Redundant data includes mirrors (duplicate data) and parity information
(reconstructing data using an algorithm).

- **Performance** - Read and write performance can be increased or decreased depending on the RAID level you choose.
Some RAID levels may be more appropriate for particular applications.

- **Cost efficiency** - Maintaining the redundant data or parity information associated with RAID volumes requires additional
disk space. In situations where the data is temporary, easily reproduced, or non-essential, the increased cost of data
redundancy may not be justified.

- **Mean Time Between Failure (MTBF)** - Using additional disks to maintain data redundancy also increases the chance
of disk failure at any given moment. Although this option cannot be avoided in situations where redundant data is a
requirement, it does have implications on the workload of the system support staff within your organization.

- **Volume** - Volume refers to a single disk non-RAID virtual disk. You can create volumes using external utilities like the
O-ROM <Ctrl> <r>. Storage Management does not support the creation of volumes. However, you can view volumes and
use drives from these volumes for creation of new virtual disks or Online Capacity Expansion (OCE) of existing virtual disks,
provided free space is available.



### Choosing RAID levels

You can use RAID to control data storage on multiple disks. Each RAID level or concatenation has different performance and
data protection characteristics.

**NOTE:** The H3xx PERC controllers do not support RAID levels 6 and 60.

The following topics provide specific information on how each RAID level store data as well as their performance and protection
characteristics:

- Raid level 0 (striping)
- Raid level 1 (mirroring)
- Raid level 5 (striping with distributed parity)
- Raid level 6 (striping with additional distributed parity)
- Raid level 50 (striping over raid 5 sets)
- Raid level 60 (striping over raid 6 sets)
- Raid level 10 (striping over mirror sets)



#### RAID level 0 - striping

RAID 0 uses data striping, which is writing data in equal-sized segments across the physical disks. RAID 0 does not provide data
redundancy.

**RAID 0 characteristics:**

- Groups **n** disks as one large virtual disk with a capacity of (smallest disk size) * **n** disks.
- Data is stored to the disks alternately.
- No redundant data is stored. When a disk fails, the large virtual disk fails with no means of rebuilding the data.
- Better read and write performance.



#### RAID level 1 - mirroring

RAID 1 is the simplest form of maintaining redundant data. In RAID 1, data is mirrored or duplicated on one or more physical
disks. If a physical disk fails, data can be rebuilt using the data from the other side of the mirror.

**RAID 1 characteristics:**

- Groups **n** + **n** disks as one virtual disk with the capacity of **n** disks. The controllers currently supported by Storage
Management allow the selection of two disks when creating a RAID 1. Because these disks are mirrored, the total storage
capacity is equal to one disk.

- Data is replicated on both the disks.
- When a disk fails, the virtual disk still works. The data is read from the mirror of the failed disk.
- Better read performance, but slightly slower write performance.
- Redundancy for protection of data.
- RAID 1 is more expensive in terms of disk space since twice the number of disks are used than required to store the data
without redundancy.



#### RAID level 5 or striping with distributed parity

RAID 5 provides data redundancy by using data striping in combination with parity information. Rather than dedicating a physical
disk to parity, the parity information is striped across all physical disks in the disk group.

**RAID 5 characteristics:**

- Groups **n** disks as one large virtual disk with a capacity of ( **n** -1) disks.
- Redundant information (parity) is alternately stored on all disks.
- When a disk fails, the virtual disk still works, but it is operating in a degraded state. The data is reconstructed from the
surviving disks.

- Better read performance, but slower write performance.
- Redundancy for protection of data.



#### RAID level 6-striping with additional distributed parity

RAID 6 provides data redundancy by using data striping in combination with parity information. Similar to RAID 5, the parity is
distributed within each stripe. RAID 6, however, uses an additional physical disk to maintain parity, such that each stripe in the
disk group maintains two disk blocks with parity information. The additional parity provides data protection in the event of two
disk failures. In the following image, the two sets of parity information are identified as **P** and **Q** .

**RAID 6 characteristics:**

- Groups **n** disks as one large virtual disk with a capacity of ( **n** -2) disks.
- Redundant information (parity) is alternately stored on all disks.
- The virtual disk remains functional with up to two disk failures. The data is reconstructed from the surviving disks.
- Better read performance, but slower write performance.
- Increased redundancy for protection of data.
- Two disks per span are required for parity. RAID 6 is more expensive in terms of disk space.



#### RAID level 50 - striping over RAID 5 sets

RAID 50 is striping over more than one span of physical disks. For example, a RAID 5 disk group that is implemented with three
physical disks and then continues on with a disk group of three more physical disks would be a RAID 50.

It is possible to implement RAID 50 even when the hardware does not directly support it. In this case, you can implement more
than one RAID 5 virtual disks and then convert the RAID 5 disks to dynamic disks. You can then create a dynamic volume that is
spanned across all RAID 5 virtual disks.

**RAID 50 characteristics:**

- Groups **n** - **s** disks as one large virtual disk with a capacity of **s** *( **n** -1) disks, where **s** is the number of spans and **n** is the
number of disks within each span.

- Redundant information (parity) is alternately stored on all disks of each RAID 5 span.
- Better read performance, but slower write performance.
- Requires as much parity information as standard RAID 5.
- Data is striped across all spans. RAID 50 is more expensive in terms of disk space.



#### RAID level 60 - striping over RAID 6 sets

RAID 60 is striping over more than one span of physical disks that are configured as a RAID 6. For example, a RAID 6 disk group
that is implemented with four physical disks and then continues on with a disk group of four more physical disks would be a
RAID 60.

**RAID 60 characteristics:**

- Groups **n** - **s** disks as one large virtual disk with a capacity of **s** *( **n** -2) disks, where **s** is the number of spans and **n** is the
number of disks within each span.

- Redundant information (parity) is alternately stored on all disks of each RAID 6 span.
- Better read performance, but slower write performance.
- Increased redundancy provides greater data protection than a RAID 50.
- Requires proportionally as much parity information as RAID 6.
- Two disks per span are required for parity. RAID 60 is more expensive in terms of disk space.



#### RAID level 10 - striped with mirrors

The RAB considers RAID level 10 to be an implementation of RAID level 1. RAID 10 combines mirrored physical disks (RAID 1)
with data striping (RAID 0). With RAID 10, data is striped across multiple physical disks. The striped disk group is then mirrored
onto another set of physical disks. RAID 10 can be considered a **mirror of stripes** .

**RAID 10 characteristics:**

- Groups **n** disks as one large virtual disk with a capacity of ( **n** /2) disks, where **n** is an even integer.
- Mirror images of the data are striped across sets of physical disks. This level provides redundancy through mirroring.
- When a disk fails, the virtual disk still works. The data is read from the surviving mirrored disk.
- Improved read performance and write performance.
- Redundancy for protection of data.



### Comparing RAID level performance

The following table compares the performance characteristics associated with the more common RAID levels. This table
provides general guidelines for choosing a RAID level. Evaluate your specific environment requirements before choosing a RAID
level.

**Table 53. RAID level performance comparison**

|RAID Level|Data<br>Redundancy|Read<br>Performance|Write<br>Performance|Rebuild<br>Performance|Minimum Disks<br>Required|Suggested<br>Uses|
|---|---|---|---|---|---|---|
|RAID 0|None|Very Good|Very Good|N/A|N|Noncritical data.|
|RAID 1|Excellent|Very Good|Good|Good|2N (N = 1)|Small<br>databases,<br>database logs,<br>and critical<br>information.|
|RAID 5|Good|Sequential<br>reads: good.<br>Transactional<br>reads: Very<br>good|Fair, unless<br>using writeback<br>cache|Fair|N + 1 (N = at<br>least two disks)|Databases and<br>other read<br>intensive<br>transactional<br>uses.|
|RAID 10|Excellent|Very Good|Fair|Good|2N x X|Data intensive<br>environments<br>(large records).|
|RAID 50|Good|Very Good|Fair|Fair|N + 2 (N = at<br>least 4)|Medium sized<br>transactional or<br>data intensive<br>uses.|
|RAID 6|Excellent|Sequential<br>reads: good.<br>Transactional<br>reads: Very<br>good|Fair, unless<br>using writeback<br>cache|Poor|N + 2 (N = at<br>least two disks)|Critical<br>information.<br>Databases and<br>other read<br>intensive<br>transactional<br>uses.|
|RAID 60|Excellent|Very Good|Fair|Poor|X x (N + 2) (N =<br>at least 2)|Critical<br>information.<br>Medium sized<br>transactional or<br>data intensive<br>uses.|
|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|N = Number of physical disks and X = Number of RAID sets|



## Supported controllers





## Supported RAID controllers

The iDRAC interfaces support the following PERC12 controllers:

- PERC H965i Front
- PERC H965i Adapter
- PERC H965i MX
- PERC H965e

The iDRAC interfaces support the following BOSS controllers:

- BOSS-S1 Adapter
- BOSS-S1 Modular (for blade servers)
- BOSS-S2 Adapter
- BOSS-N1
- BOSS-N1 Monolithic
- BOSS-N1 Modular
- ROR-N1
The iDRAC interfaces support the following PERC11 controllers:

- PERC H350 Adapter
- PERC H355 Front
- PERC H355 Adapter
- PERC H750 Adapter
- PERC H755 Adapter
- PERC H755 Front
- PERC H755N Front
- PERC H755 MX
The iDRAC interfaces support the following PERC10 controllers:

- PERC H345 Front
- PERC H345 Adapter
- PERC H740P Mini
- PERC H740P Adapter
- PERC H745 Front
- PERC H745 Adapter
- PERC H840 Adapter
- PERC H745P MX



## Supported non-RAID controllers

iDRAC supports the following controllers:

- HBA330 MMZ
- HBA355i Front
- HBA355i Adapter
- HBA350i MX
- HBA355e Adapter
- 12 Gbps SAS HBA Adapter
- HBA465i Front
- HBA465i Adapter



## Supported enclosures

iDRAC supports MD1400 and MD1420 enclosures.

**NOTE:** Redundant Array of Inexpensive Disks (RBODS) that are connected to HBA controllers are not supported.

**NOTE:** PERC H480 with version 10.1 or greater, firmware supports up to 4 enclosures per port.



## Summary of supported features for storage devices

The following tables provide the features supported by the storage devices through iDRAC.

**Table 54. Supported features for storage controllers - PERC 11**

|Features|H355 Front<br>H355<br>Adapter|H350<br>Adapter|H750 Adapter|H755 Front<br>H755<br>Adapter|H755N Front|H840 Adapter|
|---|---|---|---|---|---|---|
|Assign or<br>unassign<br>physical disk<br>as a global<br>hot spare|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Convert to<br>RAID|Not applicable|Not applicable|Not applicable|Not<br>applicable|Not applicable|Not applicable|
|Convert to<br>RAID/Non<br>RAID,|Real-time<br>(converts<br>drive to non-<br>RAID volume)|Real-time<br>(converts<br>drive to non-<br>RAID volume)|Real-time<br>(converts drive to<br>non-RAID volume)|Real-time<br>(converts<br>drive to<br>non-RAID<br>volume)|Real-time<br>(converts drive<br>to non-RAID<br>volume)|Real-time (converts drive<br>to non-RAID volume)|
|Rebuild|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Cancel<br>Rebuild|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Create virtual<br>disks|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Rename<br>virtual disks|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Edit virtual<br>disks cache<br>policies|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Check virtual<br>disk<br>consistency|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Cancel check<br>consistency|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Initialize<br>virtual disks|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Cancel<br>initialization|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Encrypt<br>virtual disks|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Assign or<br>unassign<br>dedicated hot<br>spare|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Delete virtual<br>disks|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Cancel<br>Background<br>Initialization|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Online<br>Capacity<br>Expansion|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|RAID Level<br>Migration|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Discard<br>Preserved<br>Cache|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Set Patrol<br>Read Mode|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Manual Patrol<br>Read Mode|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Patrol Read<br>Unconfigured<br>Areas|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Check<br>Consistency<br>Mode|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Copyback<br>Mode|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Load Balance<br>Mode|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Check<br>Consistency<br>Rate|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|

**Table 54. Supported features for storage controllers - PERC 11 (continued)**

|Features|H355 Front<br>H355<br>Adapter|H350<br>Adapter|H750 Adapter|H755 Front<br>H755<br>Adapter|H755N Front|H840 Adapter|
|---|---|---|---|---|---|---|
|Rebuild Rate|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|BGI Rate|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Reconstruct<br>Rate|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Import foreign<br>configuration|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Auto-import<br>foreign<br>configuration|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Clear foreign<br>configuration|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Reset<br>controller<br>configuration|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Create or<br>change<br>security keys|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Secure<br>Enterprise<br>Key Manger|Staged|Staged|Staged|Staged|Staged|Staged|
|Inventory and<br>remotely<br>monitor the<br>health of PCIe<br>SSD devices|Not applicable|Not applicable|Not applicable|Not<br>applicable|Not applicable|Not applicable|
|Prepare the<br>PCIe SSD to<br>be removed|Not applicable|Not applicable|Not applicable|Not<br>applicable|Not applicable|Not applicable|
|Securely<br>erase the<br>data for PCIe<br>SSD|Not applicable|Not applicable|Not applicable|Not<br>applicable|Real-time|Not applicable|
|Configure<br>Backplane<br>mode (split/<br>unified)|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Blink or<br>unblink<br>component<br>LEDs|Real-time|Real-time|Real-time|Real-time|Real-time|Real-time|
|Switch<br>controller<br>mode|Not applicable|Not applicable|Not applicable|Not<br>applicable|Not applicable|Not applicable|
|T10PI support<br>for Virtual<br>Disks|Not applicable|Not applicable|Not applicable|Not<br>applicable|Not applicable|Not applicable|

**NOTE:** Added support for

  - eHBA mode for PERC 10.2 or greater firmware which supports converting to Non-RAID disks.
  - convert controller to HBA mode.
  - RAID 10 uneven span.
**Table 55. Supported features for storage controllers - PERC 12**

|Features|H965i Front and<br>H965i Adapter|H965e Adapter|H965i MX|HBA465i Front and H465i<br>Adapter|
|---|---|---|---|---|
|Assign or unassign<br>physical disk as a<br>global hot spare|Real-time|Real-time|Real-time|Not applicable|
|Convert to RAID|Not applicable|Not applicable|Not applicable|Not applicable|
|Convert to<br>RAID/Non RAID,|Real-time (converts<br>drive to non-RAID<br>volume)|Real-time<br>(converts drive to<br>non-RAID volume)|Real-time (converts drive<br>to non-RAID volume)|Real-time|
|Rebuild|Real-time|Real-time|Real-time|Not applicable|
|Cancel Rebuild|Real-time|Real-time|Real-time|Not applicable|
|Create virtual disks|Real-time|Real-time|Real-time|Not applicable|
|Rename virtual disks|Real-time|Real-time|Real-time|Not applicable|
|Edit virtual disks<br>cache policies|Real-time|Real-time|Real-time|Not applicable|
|Check virtual disk<br>consistency|Real-time|Real-time|Real-time|Not applicable|
|Cancel check<br>consistency|Not applicable|Not applicable|Not applicable|Not applicable|
|Initialize virtual disks|Real-time|Real-time|Real-time|Not applicable|
|Cancel initialization|Real-time|Real-time|Real-time|Not applicable|
|Encrypt virtual disks|Real-time|Real-time|Real-time|Not applicable|
|Assign or unassign<br>dedicated hot spare|Real-time|Real-time|Real-time|Not applicable|
|Delete virtual disks|Real-time|Real-time|Real-time|Not applicable|
|Cancel Background<br>Initialization|Real-time|Real-time|Real-time|Not applicable|
|Online Capacity<br>Expansion|Not applicable|Not applicable|Not applicable|Not applicable|
|RAID Level Migration|Not applicable|Not applicable|Not applicable|Not applicable|
|Discard Preserved<br>Cache|Real-time|Real-time|Real-time|Real-time|
|Set Patrol Read<br>Mode|Not applicable|Not applicable|Not applicable|Not applicable|
|Manual Patrol Read<br>Mode|Real-time|Real-time|Real-time|Not applicable|
|Patrol Read<br>Unconfigured Areas|Real-time|Real-time|Real-time|Not applicable|
|Check Consistency<br>Mode|Not applicable|Not applicable|Not applicable|Not applicable|
|Copyback Mode|Not applicable|Not applicable|Not applicable|Not applicable|
|Load Balance Mode|Not applicable|Not applicable|Not applicable|Real-time|
|Check Consistency<br>Rate|Real-time|Real-time|Real-time|Not applicable|
|Boot VD|Not applicable|Not applicable|Not applicable|Not applicable|
|Change PD State|Not applicable|Not applicable|Not applicable|Real-time|
|Rebuild Rate|Real-time|Real-time|Real-time|Not applicable|
|BGI Rate|Real-time|Real-time|Real-time|Not applicable|
|Reconstruct Rate|Real-time|Real-time|Real-time|Not applicable|
|Import foreign<br>configuration|Real-time|Real-time|Real-time|Not applicable|
|Auto-import foreign<br>configuration|Not applicable|Not applicable|Not applicable|Not applicable|
|Clear foreign<br>configuration|Real-time|Real-time|Real-time|Not applicable|
|Reset controller<br>configuration|Real-time|Real-time|Real-time|Not applicable|
|Create or change<br>security keys|Real-time|Real-time|Real-time|Real-time|
|Secure Enterprise<br>Key Manger|Real-time|Real-time|Real-time|Real-time|
|Inventory and<br>remotely monitor the<br>health of PCIe SSD<br>devices|Not applicable|Not applicable|Not applicable|Not applicable|
|Prepare the PCIe<br>SSD to be removed|Not applicable|Not applicable|Not applicable|Not applicable|
|Securely erase the<br>data for PCIe SSD|Not applicable|Not applicable|Not applicable|Real-time|
|Configure Backplane<br>mode (split/unified)|Real-time|Real-time|Real-time|Not applicable|
|Blink or unblink<br>component LEDs|Real-time|Real-time|Real-time|Real-time|
|Switch controller<br>mode|Not applicable|Not applicable|Not applicable|Not applicable|
|T10PI support for<br>Virtual Disks|Not applicable|Not applicable|Not applicable|Not applicable|



## Table 56. Supported features for storage devices

|Feature|PCIe SSD|BOSS S1|BOSS S2|BOSS-N1|ROR-N1|
|---|---|---|---|---|---|
|Create Virtual Disks|Not applicable|Staged|Staged|Staged|Staged|
|Reset Controller<br>Configuration|Not applicable|Staged|Staged|Staged|Staged|
|Fast Initialization|Not applicable|Staged|Staged|Staged|Staged|
|Delete Virtual Disks|Not applicable|Staged|Staged|Staged|Staged|
|Full Initialization|Not applicable|Not applicable|Not applicable|Not applicable|Not applicable|
|Inventory and<br>remotely monitor the<br>health of PCIe SSD<br>devices|Real-time|Not applicable|Not applicable|Not applicable|Not applicable|
|Prepare the PCIe SSD<br>to be removed|Real-time|Not applicable|Not applicable|Not applicable|Not applicable|
|Securely erase the<br>data for PCIe SSD|Staged|Not applicable|Not applicable|Not applicable|Not applicable|
|Blink or unblink<br>component LEDs|Real-time|Not applicable|Real-time|Real-time|Real-time|
|Hot plugging of drives|Real-time|Not applicable|Real-time|Real-time|Real-time|
|SEKM|Staged|Staged|Staged|Staged|Staged|
|Supported RAID levels|RAID 1|RAID 1|RAID 1|RAID 0 and RAID 1|RAID 0 and RAID 1|



## Inventorying and monitoring storage devices

You can remotely monitor the health and view the inventory of the following Comprehensive Embedded Management (CEM)
enabled storage devices in the managed system using iDRAC web interface:

- RAID controllers, non-RAID controllers, BOSS controllers and PCIe extenders
- Enclosures that include Enclosure Management Modules (EMMs), power supply, fan probe, and temperature probe.
- Physical disks
- Virtual disks
- Batteries
**NOTE:** On a system with more Virtual disks, hardware inventory may show empty physical drive data for some of the
Virtual drives.

**NOTE:**

  - For external enclosures connected to PERC or HBA, if you perform hot plug or remove of any of the enclosure
components such as SAS cables, PSU, or EMM, the iDRAC storage inventory data may not be updated or incorrect
Lifecycle Log entries may be generated. It is recommended to perform iDRAC reset after any such operation.

  - If you connect SAS cables to the EMM module or reconnect the EMM module during runtime on maximum configuration
of PowerVault MD 2412, PowerVault MD 2424, or PowerVault MD 2460, the values and states of enclosure components
such as temperature probe, fan, EMM, and PSU may not be updated accurately. Therefore, it is recommended to
perform `racreset` after connecting the SAS cable to the EMM module or after reconnecting the EMM module.

  - The display of the Physical Disks inventory is significantly delayed when EMM is connected to HBA465e. To expedite the
retrieval of the Physical Disks inventory, run the racreset command.

  - Enclosure ID may not change in UI accordingly when the EMM SAS4 cables are removed from H965e and HBA355e
controllers.

The recent storage events and topology of storage devices are also displayed.

Alerts and SNMP traps are generated for storage events. The events are logged in the Lifecycle Log.

**NOTE:**

  - If you try to delete completed jobs from a job queue when a job is in progress, then job which is in progress may fail.
Hence it is recommended to wait for the ongoing job to complete before deleting the job.

  - If you select all the scheduled configuration jobs in the **Storage Job Queue** page, and delete them, a RAC0519 error
is displayed. To avoid this, select one job at a time and delete it. Alternately, you can select all the jobs from the **Job**
**Queue** page, and delete them.

  - If you enumerate the enclosure view's WSMan command on a system while one PSU-cable is removed, the primary
status of the enclosure view is reported as **Healthy** instead of **Warning** .

  - For an accurate inventory of BOSS controllers, ensure that Collect System Inventory On Reboot Operation (CSIOR) is
completed. CSIOR is enabled by default.

  - The storage health rollup follows the same convention of the Dell OpenManage product. For more information, see the
_OpenManage Server Administrator User's Guide_ [available on the OpenManage manuals page.](https://www.dell.com/openmanagemanuals)

  - Physical disks in a system with multiple backplanes may be listed under a different backplane. Use the blink function to
identify the disks.

  - FQDD of certain Backplanes may not be the same in Software Inventory and Hardware Inventory.
  - The lifecycle log for the PERC controller is not available when the past PERC controller events are being processed and
this does not affect the functionality. Past event processing can vary depending on the configuration.

  - During hot removal of M.2 drive for BOSS N-1 controller, iDRAC dashboard health status turns amber, but server front/
back health indicator LED stays blue.

**NOTE:** You can see SRV015 error in two cases- when the device does not support TSR collection like AHCI controllers or if
the device supports TSR collection but not yet inventoried on sideband yet.



### Monitoring storage devices using web interface

To view the storage device information using web interface:

- Go to **Storage** - **Overview** - **Summary** to view the summary of the storage components and the recently logged events.
This page is automatically refreshed every 30 seconds.

- Go to **Storage** - **Overview** - **Controllers** to view the RAID controller information. The **Controllers** page is displayed.
- Go to **Storage** - **Overview** - **Physical Disks** to view physical disk information. The **Physical Disks** page is displayed.
- Go to **Storage** - **Overview** - **Virtual Disks** to view virtual disk information. The **Virtual Disks** page is displayed.
- Go to **Storage** - **Overview** - **Enclosures** to view the enclosure information. The **Enclosures** page is displayed.
**NOTE:** If there are odd number of slots in the server, an empty slot row is added in the **Summary of Slots** list in the
**Enclosure** page.

**NOTE:** For current information of supported properties and their values, see the **iDRAC Online Help** .

You can also use filters to view specific device information.

**NOTE:**

  - The storage hardware list is not displayed in case the system does not have storage devices with CEM support.
  - Behavior of non-Dell certified or 3rd party NVMe devices may not be consistent in iDRAC.
  - If the NVMe SSDs in the backplane slots support NVMe-MI commands and the I2C connection to backplane slots are
fine, the iDRAC discovers these NVMe SSDs and reports them in the interfaces irrespective of the PCI connections to
the respective backplane slots.

|NOTE:<br>Table 57. GUI and other interfaces support|Col2|Col3|
|---|---|---|
|**Type**|**Web GUI Support**|**Other Interfaces support**|
|SATA|Not available|Inventory and RAID configuration|
|NVMe|Physical disk inventory only|Inventory and RAID configuration|

For more information about the displayed properties and to use the filter options, see the iDRAC Online Help.

iDRAC web interface has graphical view of storage devices, which depicts details and status on specific PowerEdge servers.
Following servers offer this feature:

- With release 6.10.00.00 - PowerEdge R640, PowerEdge R740, PowerEdge R740xd, PowerEdge R650, PowerEdge R750,
and PowerEdge R7525.

- With release 7.00.00.00 - PowerEdge R660, PowerEdge R760, PowerEdge R760xd, and PowerEdge R7625.



### Monitoring storage devices using RACADM

To view the storage device information, use the `storage` command.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



### Monitoring backplane using iDRAC settings utility

In the iDRAC Settings utility, go to **System Summary** . The **iDRAC Settings.System Summary** page is displayed. The
**Backplane Inventory** section displays the backplane information. For information about the fields, see the **iDRAC Settings**
**Utility Online Help** .



## Viewing storage device topology

You can view the hierarchical physical containment view of the key storage components, that is, a list of controllers, enclosures
connected to the controller and a link to the physical disk contained in each enclosure. The physical disks attached directly to
the controller are also displayed.

To view the storage device topology, go to **Storage** - **Overview** . The **Overview** page displays the hierarchical representation
of the storage components in the system. The available options are:

- Controllers
- Physical Disks
- Virtual Disks
- Enclosures

Click the links to view the respective component details.



## Managing physical disks

You can perform the following for physical disks:

- View physical disk properties.
- Assign or unassign physical disk as a global hot-spare.
- Convert to RAID capable disk.
- Convert to non-RAID disk.
- Blink or unblink the LED.
- Rebuild physical disk
- Cancel rebuild physical disk
- Cryptographic erase
**NOTE:** If any of the SEKM secured drives that are directly attached to server or behind a controller are not seen or
accessible by the operating system, then it is recommended to review the lifecycle logs and ensure that all the secured
drives are unlocked. Otherwise take recommended actions mentioned in lifecycle logs.



### Assigning or unassigning physical disk as global hot spare

A global hot spare is an unused backup disk that is part of the disk group. Hot spares remain in standby mode. When a physical
disk that is used in a virtual disk fails, the assigned hot spare is activated to replace the failed physical disk without interrupting
the system or requiring your intervention. When a hot spare is activated, it rebuilds the data for all redundant virtual disks that
were using the failed physical disk.

You can change the hot spare assignment by unassigning a disk and choosing another disk as needed. You can also assign more
than one physical disk as a global hot spare.

Global hot spares must be assigned and unassigned manually. They are not assigned to specific virtual disks. If you want to
assign a hot spare to a virtual disk (it replaces any physical disk that fails in the virtual disk), then see Assigning or unassigning
dedicated hot spares.

When deleting virtual disks, all assigned global hot spares may be automatically unassigned when the last virtual disk associated
with the controller is deleted.

If you reset the configuration, the virtual disks are deleted and all the hot spares are unassigned.

You must be familiar with the size requirements and other considerations associated with hot spares.

Before assigning a physical disk as a global hot spare:

- Make sure that Lifecycle Controller is enabled.
- If there are no disk drives available in ready state, insert additional disk drives and make sure that the drives are in ready
state.

- If physical disks are in non-RAID mode convert them to RAID mode using iDRAC interfaces such as iDRAC web interface,
RACADM, Redfish or WSMan, or <CTRL+R>.

**NOTE:** During POST, press F2 to enter System Setup or Device Setup.

If you have assigned a physical disk as a global hot spare in Add to Pending Operation mode, the pending operation is created
but a job is not created. Then, if you try to unassign the same disk as global hot spare, the assign global hot spare pending
operation is cleared.

If you have unassigned a physical disk as a global hot spare in Add to Pending Operation mode, the pending operation is created
but a job is not created. Then, if you try to assign the same disk as a global hot spare, the unassign global hot spare pending
operation is cleared.

If the last VD is deleted, the global hot spares also returns to ready state.

If a PD is already a global hot spares, user can still assign it again as a global hot spares.



#### Assigning or unassigning global hot spare using web interface

To assign or unassign a global hot spare for a physical disk drive:

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Physical Disk** .
2. All the physical disks are displayed.
3. To assign as a global hotspare, from the drop-down menus in the **Action** column, select **Assign Global Hotspare** for one or
more physical disks.

4. To unassign a hot spare, from the drop-down menus in the **Action** column, select **Unassign Hotspare** for one or more
physical disks.

5. Click **Apply Now** .

Depending on your requirement, you can also choose to apply **At Next Reboot** or **At Scheduled Time** . Based on the
selected operation mode, the settings are applied.



#### Assigning or unassigning global hot spare using RACADM

Use the `storage` command and specify the type as global hot spare.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



### Converting a physical disk to RAID or non-RAID mode

Converting a physical disk to RAID mode enables the disk for all RAID operations. When a disk is in a non-RAID mode, the disk is
exposed to the operating system unlike unconfigured good disks and is used in a direct pass-through mode.

You can convert the physical disk drives to RAID or non-RAID mode by:

- Using iDRAC interfaces such as iDRAC web interface, RACADM, Redfish or WSMan.
- Pressing <Ctrl+R> while restarting the server and selecting the required controller.
**NOTE:** If the physical drives connected to a PERC controller are in non-RAID mode, the size of the disk displayed in the
iDRAC interfaces, such as iDRAC GUI, RACADM, Redfish and WSMan, may be slightly less than the actual size of the disk.
However, you can use the full capacity of the disk to deploy operating systems.

**NOTE:** Hot plugged disks in PERC 11 are either ready or non-RAID depending on the current auto configure behavior
setting.



#### Converting physical disks to RAID capable or non-RAID mode using the iDRAC web interface

To convert the physical disks to RAID mode or non-RAID mode, perform the following steps:

1. In the iDRAC web interface, click **Storage** - **Overview** - **Physical Disks** .
2. Click **Filter options** . Two options are displayed - **Clear All Filters** and **Advanced Filter** . Click **Advanced Filter** option.

An elaborated list is displayed that allows you to configure different parameters.

3. From the **Group By** drop-down menu, select an enclosure or virtual disks.

The parameters associated with the enclosure or the VD are displayed.

4. Click **Apply**, once you select all the desired parameters. For more information about the fields, see the **iDRAC Online Help** .

The settings are applied based on the option selected in the operation mode.



#### Converting physical disks to RAID capable or non-RAID mode using RACADM

Depending on whether you want to convert to RAID or Non-RAID mode, use the following RACADM commands:

- To convert to RAID mode, use the `racadm storage converttoraid` command.
- To convert to Non-RAID mode, use the `racadm storage converttononraid` command.
**NOTE:** On the S140 controller, you can only use the RACADM interface to convert the drives from non-RAID to RAID mode.
The supported Software RAID modes are Windows or Linux Mode.

[For more information about the commands, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Erasing physical disks

The System Erase feature allows you to erase the contents of the physical drives. This feature is accessible using RACADM or
the LC UI. Physical drives on the server are grouped into two categories.

- Secure erase drives—Includes drives that provide cryptographic erase such as ISE and SED SAS and SATA drives, and PCIe
SSDs.

**NOTE:** ISE drives follow the NIST SP 800-88r1 standard and are NIST purge compliant. This means that all **old data** is
irretrievable upon erasure.

- Overwrite erase drives—Includes all drives that do not support cryptographic erase.
**NOTE:** Before erasing vFlash, you must first detach all partitions using iDRAC interfaces before performing the operation.

**NOTE:** The system erase option only applies to drives within the server. iDRAC is not able to erase drives in an external
enclosure such as a JBOD.

The RACADM SystemErase subcommand includes options for the following categories:

- The **SecureErasePD** option cryptographically erases all the secure erase drives.
- The **OverwritePD** option overwrites data on all drives.
**NOTE:** Cryptographic erase of BOSS and HBA 11 physical disks can be performed using the `SystemErase` method. This

operation is supported through LCUI, WSMAN, and RACADM interfaces.

**NOTE:** Cryptographic Erase is not supported individually on M.2 drives. It is supported only in LC-UI as part of System
retire or system erase. This limitation is applicable for BOSS-S1/S2 controllers. Although, Cryptographic Erase on M.2 drives
that are connected to BOSS-N1 works normally.

Before performing SystemErase, use the following command to check the erase capability of all physical disks for a server:

```
 # racadm storage get pdisks –o –p SystemEraseCapability

```

**NOTE:** If SEKM is enabled on the server, then disable SEKM using the `racadm sekm disable` command before using

this command. This can avoid any storage devices being locked out which are secured by iDRAC, if SEKM settings are
erased from iDRAC by performing this command.

To erase ISE and SED drives, use this command:

```
 # racadm systemerase –secureerasepd

```

To erase overwrite erase drives, use the following command:

```
 # racadm systemerase -overwritepd

```

**NOTE:** RACADM SystemErase removes all the virtual disks from the physical disks that are erased by the above commands.

**NOTE:** RACADM SystemErase causes the server to restart in order to perform the erase operations.

**NOTE:** Individual PCIe SSD or SED devices can be erased using the iDRAC UI or RACADM. For more information, see the
Erasing PCIe SSD device data and the Erasing SED device data section.

For information about the System Erase function within the Lifecycle Controller UI, see the _Dell Lifecycle Controller User's_
_Guide_ [available at iDRAC manuals .](https://www.dell.com/idracmanuals)



### Erasing SED/ISE device data

**NOTE:** This operation is not supported when the supported device is a part of a Virtual Disk. The target-supported device
must be removed from the virtual disk prior to performing device erase.

Cryptographic Erase permanently erases all data present on the disk. Performing a Cryptographic Erase on an SED/ISE
overwrites all blocks and results in permanent loss of all data on the supported devices. During Cryptographic Erase, the
host is unable to access the supported device. SED/ISE device erase can be performed either in real time (drives behind RAID
Controller and PSID erase) or be applied after a system reboot.

If the system reboots or experiences a power loss during cryptographic erase, the operation is canceled. You must reboot the
system and restart the process.

Before erasing SED/ISE device data, ensure that:

- Lifecycle Controller is enabled.
- You have Server Control and Login privileges.
- Selected supported drive is not part of a virtual disk.
**NOTE:**

  - Erasing SED/ISE can be performed either as a real time (drives behind RAID Controller and PSID erase) or as a staged
operation.

  - After the drive is erased, it may still be displayed as active within the operating system due to data caching. If this
occurs, reboot the operating system and the erased drive will no longer be displayed or report any data.

  - Reboot the server before starting the operation. If the operation continues to fail, ensure that CSIOR is enabled and that
the NVMe disks qualified by Dell Technologies.

  - Cryptographic erase can also be performed using PSID.



#### Erasing SED/ISE device data using web interface

To erase the data on the supported device:

1. In the iDRAC Web interface, go to **Storage** - **Overview** - **Physical Disks** .
The **Physical Disk** page is displayed.

2. From the **Controller** drop-down menu, select the controller to view the associated devices.
3. From the drop-down menus, select **Cryptographic Erase** for one or more SED/ISEs.

If you have selected **Cryptographic Erase** and you want to view the other options in the drop-down menu, then select
**Action** and then click the drop-down menu to view the other options.

4. From the **Apply Operation Mode** drop-down menu, select one of the following options:
  - **Apply Now**  - Select this option to apply the actions immediately with no system reboot required.
  - **At Next Reboot**  - Select this option to apply the actions during the next system reboot.
  - **At Scheduled Time**  - Select this option to apply the actions at a scheduled day and time:
   - **Start Time** and **End Time**   - Click the calendar icons and select the days. From the drop-down menus, select the
time. The action is applied between the start time and end time.

   - From the drop-down menu, select the type of reboot:
￭ No Reboot (Manually Reboot System)
￭ Graceful Shutdown
￭ Force Shutdown
￭ Power Cycle System (cold boot)

5. Click **Apply** .

If the job is not created, a message indicating that the job creation was not successful is displayed. Also, the message ID and
the recommended response action is displayed.

If the job is created successfully, a message indicating that the job ID is created for the selected controller is displayed. Click
**Job Queue** to view the progress of the job in the Job Queue page.

If pending operation is not created, an error message is displayed. If pending operation is successful and job creation is not
successful, then an error message is displayed.



#### Erasing SED device data using RACADM

To securely erase an SED device:

```
 racadm storage cryptographicerase:<SED FQDD>

```

To create the target job after performing the `cryptographicerase psid` command:

```
 racadm jobqueue create <SED FQDD> -s TIME_NOW -realtime

```

To create the target staged job after performing the `cryptographic erase` command (non-PSID):

```
 racadm jobqueue create <SED FQDD> -s TIME_NOW -e <start_time>

```

To query the job ID returned:

```
 racadm jobqueue view -i <job ID>

```

To perform cryptographic erase:

```
 racadm storage cryptographicerase:<SED FQDD> -psid<PSID>

```

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



### Rebuild Physical Disk

Rebuild Physical Disk is the ability to reconstruct the contents of a failed disk. This is true only when auto rebuild option is set
to false. If there is a redundant virtual disk, the rebuild operation can reconstruct the contents of a failed physical disk. A rebuild
can take place during normal operation, but it degrades performance.

Cancel Rebuild can be used to cancel a rebuild that is in progress. If you cancel a rebuild, the virtual disk remains in a degraded
state. The failure of an additional physical disk can cause the virtual disk to fail and may result in data loss. It is recommended to
perform a rebuild on the failed physical disk at the earliest.

In case, you cancel the rebuild of a physical disk that is assigned as a hot spare, reinitiate the rebuild on the same physical disk
in order to restore the data. Canceling the rebuild of a physical disk and then assigning another physical disk as a hot spare does
not cause the newly assigned hot spare to rebuild the data.



## Managing virtual disks

You can perform the following operations for the virtual disks:

- Create
- Delete
- Edit policies
- Initialize
- Check consistency
- Cancel check consistency
- Encrypt virtual disks
- Assign or unassign dedicated hot spares
- Blink and unblink virtual disk
- Cancel background initialization
- Online capacity expansion
- RAID level migration
**NOTE:** You can manage and monitor 240 virtual disks using iDRAC interface. To create VDs, use either Device Setup (F2),
PERCCLI command line tool, or Dell OpenManage Server Administrator (OMSA).



### Creating virtual disks

To implement RAID functions, you must create a virtual disk. A virtual disk refers to storage created by a RAID controller from
one or more physical disks. Although a virtual disk may be created from several physical disks, it is seen by the operating system
as a single disk.

Before creating a virtual disk, you should be familiar with the information in Considerations Before Creating Virtual Disks.

You can create a Virtual Disk using the Physical Disks that are attached to the PERC controller. To create a Virtual Disk, you
must have the Server Control user privilege. You can create a maximum of 64 virtual drives and a maximum of 16 virtual drives in
the same drive group.

You cannot create a virtual disk if:

- Physical disk drives are not available for virtual disk creation. Install additional physical disk drives.
- The maximum number of virtual disks that can be created on the controller has been reached. You must delete at least one
virtual disk and then create a new virtual disk.

- The maximum number of virtual disks that are supported by a drive group has been reached. You must delete one virtual disk
from the selected group and then create a new virtual disk.

- A job is running or scheduled on the selected controller. You must wait for this job to complete, or you can delete the job
before attempting a new operation. You can view and manage the status of the scheduled job in the Job Queue page.

- Physical disk is in non-RAID mode. You must convert to RAID mode using iDRAC interfaces such as iDRAC web interface,
RACADM, Redfish, WSMan, or <CTRL+R>.

**NOTE:** If you create a virtual disk in Add to Pending Operation mode and a job is not created, and then if you delete the
Virtual disk, then the create pending operation for the virtual disk is cleared.

**NOTE:** RAID 6 and RAID 60 are not supported in PERC H330.

**NOTE:** BOSS controller allows you to create virtual disk only of size equal to the full size of the M.2 physical storage media.
Ensure that you set the virtual disk size to zero when using the Server Configuration Profile to create a BOSS virtual disk.
For other interfaces such as RACADM, WSMan, and Redfish, the virtual disk size should not be specified.

**NOTE:** Creating virtual disks is not allowed on drives that are already secured.



#### Considerations before creating virtual disks

Before creating virtual disks, consider the following:

- Virtual disk names not stored on controller—The names of the virtual disks that you create are not stored on the controller.
This means that if you reboot using a different operating system, the new operating system may rename the virtual disk
using its own naming conventions.

- Disk grouping is a logical grouping of disks attached to a RAID controller on which one or more virtual disks are created, such
that all virtual disks in the disk group use all of the physical disks in the disk group. The current implementation supports the
blocking of mixed disk groups during the creation of logical devices.

- Physical disks are bound to disk groups. Therefore, there is no RAID level mixing on one disk group.
- There are limitations on the number of physical disks that can be included in the virtual disk. These limitations depend on the
controller. When creating a virtual disk, controllers support a certain number of stripes and spans (methods for combining

the storage on physical disks). Because the number of total stripes and spans is limited, the number of physical disks that
can be used is also limited. The limitations on stripes and spans affect the RAID levels as follows:

  - Maximum number of spans affects RAID 10, RAID 50, and RAID 60.
  - Maximum number of stripes affects RAID 0, RAID 5, RAID 50, RAID 6, and RAID 60.
  - Number of physical disks in a mirror is always 2. This affects RAID 1 and RAID 10.
**NOTE:**

   - RAID 1 is only supported for BOSS controllers.
   - SWRAID controller only supports RAID 0, 1, 5 and 10.
- Cannot create virtual disks on PCIe SSDs. But PERC 11 and later controllers support creating virtual disks using PCIe SSDs.
**NOTE:** Some actions can result in boot target ID not being reset to ffff when no VD or EPD-PT is configured.



#### Creating virtual disks using web interface

To create virtual disk:

1. In the iDRAC Web interface, go to **Storage** - **Overview** - **Virtual DisksAdvanced Filter** .
2. In the **Virtual Disk** section, do the following:

a. From the **Controller** drop-down menu, select the controller for which you want to create the virtual disk.
b. From the **Layout** drop-down menu, select the RAID level for the Virtual Disk.

Only those RAID levels supported by the controller appear in the drop-down menu and it is based on the RAID levels are
available based on the total number of physical disks available.
c. Select the **Media Type**, **Stripe Size**, **Read Policy**, **Write Policy**, **Disk Cache Policy**, .

Only those values supported by the controller appear in the drop-down menus for these properties.
d. In the **Capacity** field, enter the size of the virtual disk.

The maximum size is displayed and then updated as disks are selected.
e. The **Span Count** field is displayed based on the selected physical disks (step 3). You cannot set this value. It is
automatically calculated after selecting disks for multi-raid level. **Span Count** field is applicable to RAID 10, RAID 50, and
RAID 60. If you have selected RAID 10 and if the controller supports uneven RAID 10, then the span count value is not
displayed. The controller automatically sets the appropriate value. For RAID 50 and RAID 60, this field is not displayed
when minimum number of disks are used to create RAID. It can be changed if more disks are used.

3. In the **Select Physical Disks** section, select the number of physical disks.

For more information about the fields, see the **iDRAC Online Help** .

4. From the **Apply Operation Mode** drop-down menu, select when you want to apply the settings.
5. Click **Create Virtual Disk** .

Based on the selected **Apply Operation Mode**, the settings are applied.

**NOTE:** You can use alphanumeric characters, dashes, and underscores in the disk name.



#### Creating virtual disks using RACADM

Use the `racadm storage createvd` command.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .

**NOTE:** Disk slicing or configuring partial VDs is not supported using RACADM on the drives managed by S140 controller.



### Editing virtual disk cache policies

You can change the read, write, or disk cache policy of a virtual disk.

**NOTE:** Some of the controllers do not support all read or write policies. Therefore, when a policy is applied, an error
message is displayed.

The read policies indicate whether the controller must read sequential sectors of the virtual disk searching for data:

- **Adaptive Read Ahead** - The controller initiates read ahead only if the two most recent reads requests accessed sequential
sectors of the disk. If subsequent read requests access random sectors of the disk, the controller reverts to no read ahead
policy. The controller continues to evaluate whether read requests are accessing sequential sectors of the disk, and initiates
read ahead if necessary.

- **Read Ahead** - The controller reads sequential sectors of the virtual disk when seeking data. Read ahead policy may
improve system performance if the data is written to the sequential sectors of the virtual disk.

- **No Read Ahead** - Selecting no read ahead policy indicates that the controller should not use read ahead policy.

The write policies specify if the controller sends a write-request completion signal when the data is in the cache or after it has
been written to the disk.

- **Write Through** - The controller sends a write-request completion signal only after the data is written to the disk.
Write-through caching provides better data security than write-back caching, since the system assumes that the data is
available only after it has been safely written to the disk.

- **Write Back** - The controller sends a write-request completion signal as soon as the data is in the controller cache but has
not yet been written to disk. Write back caching may provide improved performance since subsequent read requests can
retrieve data quickly from the cache then from the disk. However, data loss may occur in the event of a system failure which
prevents that data from being written on a disk. Other applications may also experience problems when actions assume that
the data is available on the disk.

- **Force Write Back** - The write cache is enabled regardless of whether the controller has a battery. If the controller does
not have a battery and force write-back caching is used, data loss may occur in the event of a power failure.

The Disk Cache policy applies to readings on a specific virtual disk. These settings do not affect the read-ahead policy.

**NOTE:**

  - Controller non-volatile cache and battery backup of controller cache affects the read-policy or the write policy that a
controller can support. All PERCs do not have battery and cache.

  - Read ahead and write back requires cache. Therefore, if the controller does not have cache, it does not allow you to set
the policy value.

   - Similarly, if the PERC has cache but not battery and the policy is set that requires accessing cache, then data loss
may occur if base of power off. So few PERCs may not allow that policy.

   - Therefore, depending upon the PERC, the policy value is set.



### Deleting virtual disks

Deleting a virtual disk destroys all information including file systems and volumes on the virtual disk and removes the virtual disk
from the controller’s configuration. When deleting virtual disks, all assigned global hot spares may be automatically unassigned
when the last virtual disk associated with the controller is deleted. When deleting the last virtual disk of a disk group, all
assigned dedicated hot spares automatically become global hot spares.

If you delete all the VDs for a global hot spare, then the global hot spare is automatically deleted.

You must have the Login and Server Control privilege to perform delete virtual disks.

When this operation is allowed, you can delete a boot virtual drive. It is done from the sideband and the independent of the
operating system. Hence, a warning message appears before you delete the virtual drive.

If you delete a virtual disk, and then immediately create a new virtual disk with all the same characteristics as the one that was
deleted, the controller recognizes the data as if the first virtual disk were never deleted. In this situation, if you do not want the
old data after re-creating a new virtual disk, reinitialize the virtual disk.

**NOTE:** Reset configuration and delete Virtual Disk operations cannot be stacked with a maximum 240 virtual disk creation
operations. This results in the failure of the operation. These two operations can be run as separate jobs with a minimum
2-minute gap.



### Checking virtual disk consistency

This operation verifies the accuracy of the redundant (parity) information. This task only applies to redundant virtual disks.
When necessary, the check consistency task rebuilds the redundant data. If the virtual drive has a degraded status, running a
check consistency may be able to return the virtual drive to ready status. You can perform a consistency check using the web
interface or RACADM.

You can also cancel the check consistency operation. The cancel check consistency is a real-time operation.

You must have Login and Server Control privilege to check consistency of virtual disks.

**NOTE:** Consistency check is not supported when the drives are set up in RAID0 mode.

**NOTE:** If you perform Cancel Consistency operation when there is no consistency check operation is in progress, then the
pending operation in GUI is shown as Cancel BGI instead of Cancel Consistency check.



### Initializing virtual disks

Initializing virtual disks erases the all the data on the disk but does not change the virtual disk configuration. You must initialize a
virtual disk that is configured before it is used.

**NOTE:** Do not initialize virtual disks when attempting to recreate an existing configuration.

You can perform a fast initialization, a full Initialization, or cancel the initialization operation.

**NOTE:** The cancel initialization is a real-time operation. You can cancel the initialization using only the iDRAC Web interface
and not RACADM.



#### Fast initialization

The fast initialize operation initializes all physical disks included in the virtual disk. It updates the metadata on the physical disks
so that all disk space is available for future write operations. The initialize task can be completed quickly because the existing
information on the physical disks is not erased, although future write operations overwrite any information that remains on the
physical disks.

Fast initialization only deletes the boot sector and stripe information. Perform a fast initialize only if you are constrained for time
or the hard drives are new or unused. Fast Initialization takes less time to complete (usually 30-60 seconds).

**CAUTION: Performing a fast initialize causes existing data to be inaccessible.**

The fast initialize task does not write zeroes to the disk blocks on the physical disks. It is because the Fast Initialize task does
not perform a write operation, it causes less degradation to the disk.

A fast initialization on a virtual disk overwrites the first and last 8 MB of the virtual disk, clearing any boot records or partition
information. The operation takes only 2-3 seconds to complete and is recommended when you are recreating virtual disks.

A background initialization starts five minutes after the Fast Initialization is completed.



###### Full or slow initialization

The full initialization (also called slow initialize) operation initializes all physical disks included in the virtual disk. It updates the
metadata on the physical disks and erases all existing data and file systems. You can perform a full initialization after creating
the virtual disk. In comparison with the fast initialize operation, you may want to use the full initialize if you have trouble with a
physical disk or suspect that it has bad disk blocks. The full initialize operation remaps bad blocks and writes zeroes to all disk
blocks.

If full initialization of a virtual disk is performed, background initialization is not required. During full initialization, the host is
not able to access the virtual disk. If the system reboots during a full initialization, the operation terminates and a background
initialization process starts on the virtual disk.

It is always recommended to do a full initialization on drives that previously contained data. Full initialization can take up to 1-2
minutes per GB. The speed of initialization depends on the controller model, speed of hard drives, and the firmware version.

The full initialize task initializes one physical disk at a time.

**NOTE:** Full initialize is supported only in real-time. Only few controllers support full initialization.



### Encrypting virtual disks

When encryption is disabled on a controller (that is, the security key is deleted), manually enable encryption for virtual disks
created using SED drives. If the virtual disk is created after encryption is enabled on a controller, the virtual disk is automatically

encrypted. It is automatically configured as an encrypted virtual disk unless the enabled encryption option is disabled during the
virtual disk creation.

You must have Login and Server Control privilege to manage the encryption keys.

**NOTE:** Though encryption is enabled in the controllers, user needs to manually enable encryption on the VD if VD is created
from iDRAC. Only if the VD is created from OMSA, it would be automatically encrypted.



### Assigning or unassigning dedicated hot spares

A dedicated hot spare is an unused backup disk that is assigned to a virtual disk. When a physical disk in the virtual disk fails, the
hot spare is activated to replace the failed physical disk without interrupting the system or requiring your intervention.

You must have Login and Server Control privilege to run this operation.

You can assign only 4K drives as hot spare to 4K virtual disks.

If you have assigned a physical disk as a dedicated hot spare in Add to Pending Operation mode, the pending operation is
created but a job is not created. Then, if you try to unassign the dedicated hot spare, the assign dedicated hot spare pending
operation is cleared.

If you have unassigned a physical disk as a dedicated hot spare in Add to Pending Operation mode, the pending operation is
created but a job is not created. Then, if you try to assign the dedicated hot spare, the unassign dedicated hot spare pending
operation is cleared.

**NOTE:** While the log export operation is in progress, you cannot view information about dedicated hot spares on the
**Manage Virtual Disks** page. After the log export operation is complete, reload or refresh the **Manage Virtual Disks** page
to view the information.



#### Rename VD

To change the name of a Virtual Disk, the user must have System Control privilege. The virtual disk name can contain only
alphanumeric characters, dashes, and underscores. The maximum length of the name depends on the individual controller. In
most cases, the maximum length is 15 characters. Every time a virtual disk is renamed, an LC Log gets created.



#### Edit Disk capacity

Online Capacity Expansion (OCE) allows you to increase the storage capacity of selected RAID levels while the system remains
online. The controller redistributes the data on the array(called Reconfiguration), placing new space available at the end of each
RAID array.

Online Capacity Expansion (OCE) can be achieved in two ways:

- If free space is available on the smallest physical drive on the virtual disks group after starting LBA of Virtual disks, the
virtual disk´s capacity can be expanded within that free space. This option allows you to enter the new increased virtual disk
size. If disk group in a virtual disk has space available only before starting LBA, then Edit Disk Capacity in same disk group is
not permitted even though there is Available Space on a physical drive.

- A virtual disk's capacity can also be expanded by adding additional compatible physical disks to the existing virtual disk group.
This option does not allow you to enter the new increased virtual disk size. New increased virtual disk size is calculated and
displayed to the user based on the used disk space of existing physical disk group on a particular virtual disk, existing raid
level of the virtual disk and the number of new drives added to the virtual disk.

Capacity Expansion allows user to specify the final VD size. Internally final VD size is conveyed to PERC in percentage (this
percentage is the space user would like to use from empty space left in the array for the local disk to expand). Because of this
percentage logic final VD size after reconfiguration completes may be different from what user provided for scenario where user
is not giving maximum VD size possible as the final VD size (percentage turns out to be less than 100%). User does not see
difference in this entered VD size and final VD size after reconfiguration, if maximum possible VD size is entered by user.



#### Raid Level Migration

RAID Level Migration (RLM) refers to changing a virtual disk´s RAID level. iDRAC9 provides an option to increase the VD size
using RLM. In a way, RLM allows migrating the RAID level of a virtual disk which in turn may increase the size of virtual disk.

RAID level migration is the process of converting a VD with one RAID Level to another. When you migrate a VD to a different
Raid Level, the user data on it is redistributed to the format of the new configuration.

This configuration is supported by both staged and realtime.

The below table describes possible reconfigurable VD layouts while reconfiguring (RLM) a VD with addition of disks and without
addition of disks.

**Table 58. Possible VD Layout**

|Source VD Layout|Possible target VD Layout with Disk<br>Add|Possible target VD Layout Without<br>disk addition|
|---|---|---|
|R0 (single disk)|R1|NA|
|R0|R5/R6|NA|
|R1|R0/R5/R6|R0|
|R5|R0/R6|R0|
|R6|R0/R5|R0/R5|



#### Permitted operations when OCE or RLM is going on

The following operations are allowed when OCE/RLM is going on:

**Table 59. Permitted operations**

|From Controller End behind<br>which a VD is going<br>through OCE/RLM|From VD End (which is<br>going through OCE/RLM)|From any other Ready<br>State Physical Disk on the<br>same controller|From any other VD (which<br>is not going through OCE/<br>RLM) End on the same<br>controller|
|---|---|---|---|
|Reset Configuration|Delete|Blink|Delete|
|Export Log|Blink|Unblink|Blink|
|Set Patrol Read Mode|Unblink|Assign Global Hot Spare|Unblink|
|Start Patrol Read|N/A|Convert to non-RAID Disks|Rename|
|Change Controller Properties|N/A|N/A|Change Policy|
|Manage Physical Disk Power|N/A|N/A|Slow Initialize|
|Convert to RAID Capable<br>Disks|N/A|N/A|Fast Initialize|
|Convert to Non-RAID Disks|N/A|N/A|Replace Member Disk|
|Change Controller Mode|N/A|N/A|N/A|



#### OCE and RLM Restrictions or Limitations

Following are the common limitations for OCE and RLM:

- OCE/RLM is restricted to the scenario where the disk group contains only one VD.
- OCE is not supported on RAID50 and RAID60. RLM is not supported on RAID10,RAID50 and RAID60.
- If the controller already contains the maximum number of virtual disks, you cannot perform a RAID level migration or capacity
expansion on any virtual disk.

- The controller changes the write cache policy of all virtual disks undergoing a RLM/OCE to Write-Through until RLM/OCE is
complete.

- Reconfiguring Virtual Disks typically impacts disk performance until the reconfiguration operation is complete.
- The total number of physical disks in a disk group cannot exceed 32.
- If any background operation (like BGI/rebuild/copyback/patrol read ) is already running on the corresponding VD/PD then
Reconfiguration (OCE/RLM) is not allowed at that time.

- Any kind of disk migration when Reconfiguration (OCE/RLM) is on progress on drives associated with VD causes
reconfiguration to fail.

- Any new drive added for OCE/RLM becomes part of the VD after reconstruction completes. But State for those new drive
changes to Online just after reconstruction starts.



#### Cancel Initialization

This feature is the ability to cancel the background initialization on a virtual disk. On PERC controllers, the background
initialization of redundant virtual disk starts automatically after a virtual disk is created. The background initialization of
redundant virtual disk prepares the virtual disk for parity information and improves write performance. However, some
processes such as creating a virtual disk cannot be run while the background initialization is in progress. Cancel Initialization
provides the ability to cancel the background initialization manually. Once cancelled, the background initialization automatically
restarts within 0 to 5 minutes.

**NOTE:** Background initialization is not applicable for RAID 0 virtual disks.



### Managing virtual disks using web interface

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Virtual Disks** .
2. From the **Virtual Disks**, select the controller for which you want to manage the virtual disks.
3. From **Action** drop-down menu, select an action.

When you select an action, an additional **Action** window displayed. Select / enter the desired value.

  - **Rename**
  - **Delete**
  - **Edit Cache Policy**  - You can change the cache policy for the following options:
   - **Read Policy**   - Following values are available for selection:
￭ **Adaptive Read Ahead**     - Indicates that for the given volume, the control uses the Read-Ahead cache policy if
the two most recent disks accesses occurred in sequential sectors. If the read requests are random, the controller
returns to No Read Ahead mode.
￭ **No Read Ahead**     - Indicates that for the given volume, no read ahead policy is used.
￭ **Read Ahead**     - Indicates that for the given volume, the controller reads sequentially ahead of the requested data
and stores the additional data in cache memory, anticipating a data requirement. This speeds up sequential data
reads, but there is less improvement when accessing random data.

   - **Write Policy**   - Change the write cache policy to one of the following options:
￭ **Write Through**     - Indicates that for the given volume, the controller sends a data transfer completion signal to
the host system when the disk subsystem has received all the data in a transaction.
￭ **Write Back**     - Indicates that for the given volume, the controller sends a data transfer completion signal to the
host system when the controller cache has received all the data in a transaction. The controller then writes the
cached data to the storage device in the background.
￭ **Force Write Back**     - When using force write-back caching, the write cache is enabled regardless of whether the
controller has a battery. If the controller does not have a battery and force write-back caching is used, data loss
may occur in the event of a power failure.

   - **Disk Cache Policy**   - Change the disk cache policy to one of the following options:
￭ **Default**     - Indicates that the disk is using its default write cache mode. For SATA disks, this is enabled and for
SAS disks this is disabled.
￭ **Enabled**     - Indicates that the disk’s write cache is enabled. This increases performance and the probability of
data loss if there is power loss.
￭ **Disabled**     - Indicates that the disk’s write cache is disabled. This decreases performance and the probability of
data loss.

  - **Edit Disk Capacity**  - You can add the physical disks to the selected virtual disk in this window. This window also
shows the current capacity and new capacity of the virtual disk after adding the physical disks.

  - **RAID Level Migration**  - Displays the Disk Name, Current RAID Level, and size of the virtual disk. Allows you to select a
New RAID Level. User may have to add additional drives to existing Virtual disks to migrate to new raid level. This feature
is not applicable on RAID 10, 50 and 60.

  - **Initialize: Fast**  - Updates the metadata on the physical disks so that all the disk space is available for future write
operations. The initialize option can be completed quickly because existing information on the physical disks is not erased,
although future write operations overwrites any information that remains on the physical disks.

  - **Initialize: Full**  - All existing data and file systems are erased.
**NOTE:** The **Initialize: Full** option is not applicable for PERC H330 controllers.

  - **Check Consistency**  - To check the consistency of a virtual disk, select **Check Consistency** from the corresponding
drop-down menu.

**NOTE:** Consistency check is not supported on drives set up in RAID0 mode.

For more information about these options, see the **iDRAC Online Help** .

4. Click **Apply Now** to apply the changes immediately, **At Next Reboot** to apply the changes after next reboot, **At Scheduled**
**Time** to apply the changes at a particular time, and **Discard All Pending** to discard the changes.

Based on the selected operation mode, the settings are applied.



### Managing virtual disks using RACADM

Use the following commands to manage virtual disks:

- To delete virtual disk:

```
  racadm storage deletevd:<VD FQDD>

```

- To initialize virtual disk:

```
  racadm storage init:<VD FQDD> -speed {fast|full}

```

- To check consistency of virtual disks (not supported on RAID0):

```
  racadm storage ccheck:<vdisk fqdd>

```

To cancel the consistency check:

```
  racadm storage cancelcheck: <vdisks fqdd>

```

- To encrypt virtual disks:

```
  racadm storage encryptvd:<VD FQDD>

```

- To assign or unassign dedicated hot spares:

```
  racadm storage hotspare:<Physical Disk FQDD> -assign <option> -type dhs -vdkey: <FQDD
  of VD>

```

**`<option>`** =yes

Assign hot spare

**`<Option>`** =no

Unassign hot spare



## RAID Configuration Features

Following table lists some of the RAID configuration features which are available in RACADM and WSMan:

**CAUTION: Forcing a physical disk to go online or offline may result in data loss.**



## Table 60. RAID Configuration Features

|Feature|RACADM Command|Description|
|---|---|---|
|Force Online|`racadm storage`<br>`forceonline:<PD FQDD>`|A power failure, corrupted data, or some<br>other reason may lead to a physical disk<br>going offline. You can use this feature to<br>force a physical disk back into an online<br>state when all other options have been<br>exhausted. Once the command is run,<br>the controller places the drive back into<br>online state and restore its membership|
|||within the virtual disk. This happens only<br>if the controller can read from the drive<br>and can write into its metadata.|
|**NOTE:** Data recovery is only possible if a limited portion of the disk is damaged. Force Online feature cannot fix an already<br>failed disk.|**NOTE:** Data recovery is only possible if a limited portion of the disk is damaged. Force Online feature cannot fix an already<br>failed disk.|**NOTE:** Data recovery is only possible if a limited portion of the disk is damaged. Force Online feature cannot fix an already<br>failed disk.|
|Force Offline|`racadm storage`<br>`forceoffline:<PD FQDD>`|This feature removes a drive from a<br>virtual disk configuration so that it<br>goes offline, resulting in a degraded VD<br>configuration. It is helpful if a drive is<br>likely to fail in near future or is reporting<br>a SMART failure but is still online. It can<br>be also used if you would like to utilize<br>a drive which is part of an existing RAID<br>configuration.|
|Replace Physical Disk|`racadm storage`<br>`replacephysicaldisk:<Source`<br>` PD FQDD > -dstpd`<br>`<Destination PD FQDD>`|Allows you to copy data from a physical<br>disk which is a member of a VD, to<br>another physical disk. The source disk<br>should be in online state, while the<br>destination disk should be in ready state<br>and of a similar size and type to replace<br>the source.|
|Virtual Disk as boot device|`racadm storage`<br>`setbootvd:<controller`<br>`FQDD> -vd <VirtualDisk`<br>`FQDD>`|A virtual disk can be configured as<br>a boot device using this feature. This<br>enables fault tolerance when a VD with<br>redundancy is selected as the boot<br>device, and also has the operating<br>system installed on it.|
|Unlock Foreign Configuration|`racadm storage`<br>`unlock:<Controller FQDD>`<br>`-key <Key id> -passwd`<br>`<passphrase>`|This feature is used to authenticate<br>locked drives which have a different<br>source controller encryption than the<br>destination. Once unlocked, the drive<br>can be successfully migrated from one<br>controller to another.|



## Managing controllers

You can perform the following for controllers:

- Configure controller properties
- Import or auto import foreign configuration
- Clear foreign configuration
- Reset controller configuration
- Create, change, or delete security keys
- Discard preserved cache



### Configuring controller properties

You can configure the following properties for the controller:

- Patrol read mode (auto or manual)
- Start or stop patrol read if patrol read mode is manual
- Patrol read unconfigured areas
- Check consistency mode
- Copyback mode
- Load balance mode
- Check consistency rate
- Rebuild rate
- BGI rate
- Reconstruct rate
- Enhanced auto import foreign configuration
- Create or change security keys
- Encryption mode (Local Key Management and Secure Enterprise key Manager)

You must have Login and Server Control privilege to configure the controller properties.



###### Patrol read mode considerations

Patrol read identifies disk errors to avoid disk failures, data loss, or corruption. It runs automatically once a week on SAS and
SATA HDDs.

The Patrol Read does not run on a physical disk in the following circumstances:

- The physical disk is an SSD.
- The physical disk is not included in a virtual disk or assigned as a hot spare.
- The physical disk is included in a virtual disk that is undergoing one of the following:
  - A rebuild
  - A reconfiguration or reconstruction
  - A background initialization
  - A check consistency
In addition, the Patrol Read operation suspends during heavy I/O activity and resumes when the I/O is complete.

**NOTE:** For more information on how often the Patrol Read operation runs when in auto mode, see the respective controller
documentation.

**NOTE:** Patrol read mode operations such as **Start** and **Stop** are not supported if there are no virtual disks available in
the controller. Though you can invoke the operations successfully using the iDRAC interfaces, the operations fail when the
associated job is started.



###### Load balance

The Load Balance property provides the ability to automatically use both controller ports or connectors connected to the same
enclosure to route I/O requests. This property is available only on SAS controllers.



###### Bgi rate

**NOTE:** H330, H345 and H355 require the driver to be loaded for the background initialization operations to run.

On PERC controllers, background initialization of a redundant virtual disk begins automatically within 0 to 5 minutes after the
virtual disk is created. The background initialization of a redundant virtual disk prepares the virtual disk to maintain redundant
data and improves write performance. For example, after the background initialization of a RAID 5 virtual disk completes, the
parity information has been initialized. After the background initialization of a RAID 1 virtual disk completes, the physical disks
are mirrored.

The background initialization process helps the controller identify and correct problems that may occur with the redundant data
later. In this regard, the background initialization process is similar to a check consistency. The background initialization should
be allowed to run to completion. If cancelled, the background initialization automatically restarts within 0 to 5 minutes. Some
processes such as read and write operations are possible while the background initialization is running. Other processes, such
as creating a virtual disk, cannot be run concurrently with a background initialization. These processes cause the background
initialization to cancel.

The background initialization rate, configurable between 0% and 100%, represents the percentage of the system resources
dedicated to running the background initialization task. At 0%, the background initialization has the lowest priority for the
controller, takes the most time to complete, and is the setting with the least impact to system performance. A background
initialization rate of 0% does not mean that the background initialization is stopped or paused. At 100%, the background
initialization is the highest priority for the controller. The background initialization time is minimized and is the setting with the
most impact to system performance.



###### Check consistency

The Check Consistency task verifies the accuracy of the redundant (parity) information. This task only applies to redundant
virtual disks. When necessary, the Check Consistency task rebuilds the redundant data. If the virtual disk is in a Failed
Redundancy state, running a check consistency may be able to return the virtual disk to a Ready state.

The check consistency rate, configurable between 0% and 100%, represents the percentage of the system resources dedicated
to running the check consistency task. At 0%, the check consistency has the lowest priority for the controller, takes the most
time to complete, and is the setting with the least impact to system performance. A check consistency rate of 0% does not
mean that the check consistency is stopped or paused. At 100%, the check consistency is the highest priority for the controller.
The check consistency time is minimized and is the setting with the most impact to system performance.



###### Create or change security keys

When configuring the controller properties, you can create or change the security keys. The controller uses the encryption key
to lock or unlock access to SED. You can create only one encryption key for each encryption-capable controller. The security
key is managed using following features:

1. **Local Key Management (LKM) System** - LKM is used to generate the key ID and the password or key required to secure
the virtual disk. If you are using LKM, you must create the encryption key by providing the Security Key Identifier and the
Passphrase.

**NOTE:** You can enable/disable security on supported NVMe SED when iDRAC is in iLKM security mode.

2. **Secure Enterprise Key Manager (SEKM)** - This feature is used to generate the key using the Key Management Server
(KMS). If you are using SEKM, you must configure iDRAC with KMS information as well as SSL related configuration.

**NOTE:**

  - This task is not supported on PERC hardware controllers running in eHBA mode.
  - If you create the security key in 'Add to Pending Operation' mode and a job is not created, and then if you delete the
security key, the create security key pending operation is cleared.

**NOTE:**

  - For enabling SEKM, ensure that the supported PERC firmware is installed.
  - You cannot downgrade the PERC firmware to the previous version if SEKM is enabled. Downgrading of other PERC
controller firmware in the same system which is not in SEKM mode may also fail. To downgrade the firmware for the
PERC controllers that are not in SEKM mode, you can use OS DUP update method, or disable SEKM on the controllers
and then retry the downgrade from iDRAC.

**NOTE:** When importing a hot plugged locked volume from one server to another, you will see CTL entries for Controller
attributes being applied in the LC Log.

**LKM to SEKM transition**

You need to have SEKM enabled on iDRAC before you perform LKM to SEKM transition. You need to provide PERC LKM
passphrase while doing the transition.

- This requires scheduled reboot.
- PERC does not allow the transition under certain conditions, like when Volume reconstruction is in progress. Please refer to
PERC user guide for details of such conditions.

- Once PERC is transitioned to SEKM mode, it can not be changed back to LKM mode. To switch the controller back to LKM
mode, you need to disable security on the controller and then enable LKM.

- Transition is not allowed when iDRAC is in system lockdown mode.
- If the current PERC firmware version soes not have PERC LKM to SEKM transition capability, then please update the PERC
firmware to supported version.



#### Configuring controller properties using web interface

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Controllers** .
The **Controllers** page is displayed.

**NOTE:** The **Driver Version** of the Operating System for HBA11 and HBA10 controllers is not displayed in the
**Controllers** page.

2. In the **Controller** section, select the controller that you want to configure.
3. Specify the required information for the various properties.

The **Current Value** column displays the existing values for each property. You can modify this value by selecting the option
from the **Action** drop-down menu for each property.

For information about the fields, see the **iDRAC Online Help** .

4. From the **Apply Operation Mode**, select when you want to apply the settings.
5. Click **Apply** .

Based on the selected operation mode, the settings are applied.



#### Configuring controller properties using RACADM

- To set Patrol Read Mode:

```
  racadm set storage.controller.<index>.PatrolReadMode {Automatic | Manual | Disabled}

```

- If Patrol read mode is set to manual, use the following commands to start and stop Patrol read Mode:

```
  racadm storage patrolread:<Controller FQDD> -state {start|stop}

```

**NOTE:** Patrol read mode operations such as Start and Stop are not supported if there are no virtual disks available in
the controller. Though you can invoke the operations successfully using the iDRAC interface, the operations fail when
the associated job is started.

**NOTE:** The storage attributes PatrolReadMode and PersistHotspare that are assigned to HBA12 and PERC12 controllers
are immutable. If you attempt to modify these attributes, you may encounter errors. Though the job is created and run,
the original values remain the same.

- To specify the Check Consistency Mode, use **Storage.Controller.CheckConsistencyMode** object.
- To enable or disable the Copyback Mode, use **Storage.Controller.CopybackMode** object.
- To enable or disable the Load Balance Mode, use **Storage.Controller.PossibleloadBalancedMode** object.
- To specify the percentage of the system's resources dedicated to perform a check consistency on a redundant virtual disk,
use **Storage.Controller.CheckConsistencyRate** object.

- To specify the percentage of the controller's resources dedicated to rebuild a failed disk, use
**Storage.Controller.RebuildRate** object.

- To specify the percentage of the controller's resources dedicated to perform the background initialization (BGI) of a virtual
disk after it is created, use **Storage.Controller.BackgroundInitializationRate** object.

- To specify the percentage of the controller's resources dedicated to reconstruct a disk group after adding a physical disk or
changing the RAID level of a virtual disk residing on the disk group, use **Storage.Controller.ReconstructRate** object.

- To enable or disable the enhanced auto import of foreign configuration for the controller, use
**Storage.Controller.EnhancedAutoImportForeignConfig** object.

- To create, modify, or delete security key to encrypt virtual drives:

```
  racadm storage createsecuritykey:<Controller FQDD> -key <Key id> -passwd <passphrase>
  racadm storage modifysecuritykey:<Controller FQDD> -key <key id> -oldpasswd <old
  passphrase> -newpasswd <new passphrase>
  racadm storage deletesecuritykey:<Controller FQDD>



### Security Protocol and Data Model (SPDM)

```

SPDM Protocol is used for establishing the security capabilities and authenticity between hardware components. SPDM allows
message exchange between iDRAC and end devices such as storage controllers and NIC controllers. This includes hardware
identity certificates.

You can enable SPDM via **iDRAC Settings** - **Settings** - **SPDM Settings** .

**Table 61. SPDM Feature Licensing**

|Feature|License|
|---|---|
|Inventory- Detecting SPDM capable devices|Unlicensed|
|Collecting Hardware Identity of devices|Enterprise|
|Collecting firmware Identity of devices|Datacenter|
|Establishing Trust on device certificate using SCV|SCV License|
|Encrypted communication channel|SEKM License|

When a device is SPDM capable, the SCV data collected contains SPDM Hardware identity certificates in addition to the
existing fields. Firmware identity certificates are not included in the SCV certificate.

**NOTE:** You may notice NIC port number missing in the downloaded SPDM HW certificate file name.

**NOTE:** Export SPDM Certificate job failure can be seen in Job queue when you perform frequent reboots.



### Importing or auto importing foreign configuration

A foreign configuration is data residing on physical disks that have been moved from one controller to another. Virtual disks
residing on physical disks that have been moved are considered to be a foreign configuration.

You can import foreign configurations so that virtual disks are not lost after moving physical disks. A foreign configuration can
be imported only if it contains a virtual disk that is in either Ready or Degraded state or a hot spare that is dedicated to a virtual
disk which can be imported or is already present.

All the virtual disk data must be present, but if the virtual disk is using a redundant RAID level, the additional redundant data is
not required.

For example, if the foreign configuration contains only one side of a mirror in a RAID 1 virtual disk, then the virtual disk is in a
Degraded state and can be imported. If the foreign configuration contains only one physical disk that was originally configured
as a RAID 5 using three physical disks, then the RAID 5 virtual disk is in a Failed state and cannot be imported.

In addition to virtual disks, a foreign configuration may consist of a physical disk that was assigned as a hot spare on one
controller and then moved to another controller. The Import Foreign Configuration task imports the new physical disk as a hot
spare. If the physical disk was set as a dedicated hot spare on the previous controller, but the virtual disk to which the hot spare
was assigned is no longer present in the foreign configuration, then the physical disk is imported as a global hot spare.

If any locked foreign configurations are detected using Local Key manager (LKM), it is not possible to perform the import
foreign configuration operation in iDRAC. You must unlock the drives through CTRL-R, and then continue to import foreign
configuration from iDRAC.

The Import Foreign Configuration task is only displayed when the controller has detected a foreign configuration. You can also
identify whether a physical disk contains a foreign configuration (virtual disk or hot spare) by checking the physical disk state.
If the physical disk state is Foreign, then the physical disk contains all or some portion of a virtual disk or has a hot spare
assignment.

**NOTE:** As part of Foreign Configuration Import, if a configuration is incomplete, it is not imported. However, the job will not
fail. Job status shows as **Completed successfully** . You have to check the PD state to know whether the VD is imported or
not.

**NOTE:** The task of importing foreign configuration imports all virtual disks residing on physical disks that have been added
to the controller. If more than one foreign virtual disk is present, all the configurations are imported.

**NOTE:** When a foreign configured drive (PERC 11 controllers) is inserted in the Midbay backplane, the controller status is
displayed as **Good** instead of **Warning** . Ensure that the foreign configuration is imported or cleared.

PERC9 controller provides support for auto import of foreign configuration without requiring user interactions. The auto import
can be enabled or disabled. If enabled, the PERC controller can auto import any foreign configuration detected without manual
intervention. If disabled, the PERC does not auto import any foreign configuration.

You must have Login and Server Control privilege to import foreign configurations.

This task is not supported on PERC hardware controllers running on HBA mode.

**NOTE:** It is not recommended to remove an external enclosure cable while the operating system is running on the system.
Removing the cable can result in a foreign configuration when the connection is re-established.

You can manage foreign configurations in the following cases:

- All the physical disks in a configuration are removed and re-inserted.
- Some of the physical disks in a configuration are removed and re-inserted.
- All the physical disks in a virtual disk are removed, but at different times, and then re-inserted.
- The physical disks in a nonredundant virtual disk are removed.

The following constraints apply to the physical disks that are considered for import:

- The drive state of a physical disk can change from the time the foreign configuration is scanned to when the actual import
occurs. The foreign import occurs only on drives that are in the Unconfigured Good state.

- Drives in the failed or offline state cannot be imported.
- The firmware does not allow you to import or clear the foreign configurations if more than eight foreign drives are present.



#### Importing foreign configuration using web interface

**NOTE:** If there is an incomplete foreign disk configuration in the system, then the state of one or more existing online
virtual disks is also displayed as foreign.

**NOTE:** Importing foreign configuration for BOSS controller is not supported.

To import foreign configuration:

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Controllers** .
2. From the **Controller** options, select the controller you want to import the foreign configuration to.
3. Click **Import** under the **Foreign Configuration** and then click **Apply** .



#### Importing foreign configuration using RACADM

To import foreign configuration:

```
 racadm storage importconfig:<Controller FQDD>

```

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



### Clearing foreign configuration

After moving a physical disk from one controller to another, you may find that the physical disk contains all or some portion of
a virtual disk (foreign configuration). You can identify whether a previously used physical disk contains a foreign configuration
(virtual disk) by checking the physical disk state. If the physical disk state is Foreign, then the physical disk contains all or some
portion of a virtual disk. You can clear or erase the virtual disk information from the newly attached physical disks.

The Clear Foreign Configuration operation permanently erases all data residing on the physical disks that are added to the
controller. If more than one foreign virtual disk is present, all the configurations are erased. You may prefer to import the virtual
disk rather than destroy the data. An initialization must be performed to remove foreign data. If you have an incomplete foreign
configuration which cannot be imported, you can use the Clearing Foreign Configuration option to erase the foreign data on the
physical disks.



#### Clearing foreign configuration using web interface

To clear the foreign configuration:

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Controllers** .
The **Controller Configuration** page is displayed.

2. From the **Controller** options, select the controller for which you want to clear the foreign configuration.
**NOTE:** To clear foreign configuration on BOSS controllers, click **Reset Configuration** .

3. Click **Clear Configuration** .
4. Click **Apply**

Based on the selected operation mode, the virtual disks residing on the physical disk is erased.



#### Clearing foreign configuration using RACADM

To clear foreign configuration:

```
 racadm storage clearconfig:<Controller FQDD>

```

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



### Resetting controller configuration

You can reset the configuration for a controller. This operation deletes virtual disk drives and unassigns all hot spares on the
controller. It does not erase any data other than removing the disks from the configuration. Reset configuration also does not
remove any foreign configurations. Reset configuration does not erase any data. You may recreate the exact same configuration
without an initialize operation which may result in the data being recovered. You must have server control privilege.

**NOTE:** Resetting the controller configuration does not remove a foreign configuration. To remove a foreign configuration,
perform clear configuration operation.



#### Resetting controller configuration using web interface

To reset the controller configuration:

1. In the iDRAC Web interface, go to **Storage** - **Overview** - **Controllers** .
2. From the **Actions**, select **Reset Configuration** for one or more controllers.
3. For each controller, from the **Apply Operation Mode** drop-down menu, select when you want to apply the settings.
4. Click **Apply** .

Based on the selected operation mode, the settings are applied.



#### Resetting controller configuration using RACADM

To reset the controller configuration:

```
 racadm storage resetconfig:<Controller FQDD>

```

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



### Switching the controller mode

You can change the personality of the controller by switching the mode from RAID to HBA. The controller operates similar to an
HBA controller where the drivers are passed through the operating system. The controller mode change is a staged operation
and does not occur in real time.

PERC 10 and later controllers supports Enhanced HBA mode, replacing HBA from the current controller mode options.

**NOTE:**

  - Enhanced HBA supports Non-RAID PDs and all RAID level VDs.
  - It only supports creation of RAID0, RAID1, and RAID10 VDs.
  - Enhanced HBA is not supported on PERC 11.

Enhanced HBA mode provides the following features:

- Create virtual disks with RAID level 0, 1, or 10.
- Present non-RAID disks to host.
- Configure a default cache policy for virtual disks as write-back with read ahead.
- Configure virtual disks and non-RAID disks as valid boot devices.
- Automatically convert all unconfigured disks to non-RAID:
  - On system boot
  - On controller reset
  - When unconfigured disks are hot-inserted
**NOTE:** Creating or importing RAID 5, 6, 50, or 60 virtual disks is not supported. Also, in enhanced HBA mode, non-RAID
disks are enumerated first in ascending order, while RAID volumes are enumerated in descending order.

Before you change the mode of the controller from RAID to HBA, ensure that:

- The RAID controller supports the controller mode change. The option to change the controller mode is not available on
controllers where the RAID personality requires a license.

- All virtual disks must be deleted or removed.
- Hot spares must be deleted or removed.
- Foreign configurations must be deleted or cleared.
- All physical disks that are in a failed state, must be removed or the pinned cache needs to be cleared.
- Any local security key that is associated with SEDs must be deleted.
- The controller must not have preserved cache.
- You have server control privileges to switch the controller mode.
**NOTE:** Ensure that you back up the foreign configuration, security key, virtual disks, and hot spares before you switch the
mode as the data is deleted.

**NOTE:** Ensure that a CMC license (not applicable for MX platforms) is available for PERC FD33xS and FD33xD storage
sleds before you change the controller mode. For more information on CMC license for the storage sleds, see the
**Dell Chassis Management Controller Version 1.2 for PowerEdge FX2/FX2s User's Guide** available at dell.com/
cmcmanuals .



#### Exceptions while switching the controller mode

The following list provides the exceptions while setting the controller mode using the iDRAC interfaces such as web interface,
RACADM, and WSMan:

- If the PERC controller is in RAID mode, you must clear any virtual disks, hot spares, foreign configurations, controller keys, or
preserved cache before changing it to HBA mode.

- You cannot configure other RAID operations while setting the controller mode. For example, if the PERC is in RAID mode and
you set the pending value of the PERC to HBA mode, and you try to set the BGI attribute, the pending value is not initiated.

- When you switch the PERC controller from HBA to RAID mode, the drives remain in Non-RAID state and are not
automatically set to Ready state. Additionally, the **RAIDEnhancedAutoImportForeignConfig** attribute is automatically set
to **Enabled** .

The following list provides the exceptions while setting the controller mode using the Server Configuration Profile feature using
the WSMan or RACADM interface:

- Server Configuration Profile feature allows you to configure multiple RAID operations along with setting the controller mode.
For example, if the PERC controller is in HBA mode, you can edit the export Server Configuration Profile (SCP) to change
the controller mode to RAID, convert drives to ready and create a virtual disk.

- While changing the mode from RAID to HBA, the **RAIDaction pseudo** attribute is set to update (default behavior). The
attribute runs and creates a virtual disk which fails. The controller mode is changed, however, the job is completed with
errors. To avoid this issue, you must comment out the RAIDaction attribute in the SCP file.

- When the PERC controller is in HBA mode, if you run import preview on export SCP which is edited to change controller
mode to RAID, and try creating a VD, the virtual disk creation fails. Import preview does not support validating stacking RAID
operations with changing controller mode.



#### Switching the controller mode using the iDRAC web interface

To switch the controller mode, perform the following steps:

1. In the iDRAC web interface, click **Storage** - **Overview** - **Controllers** .
2. On the **Controllers** page, click **Action** - **Edit** .

The **Current Value** column displays the current setting of the controller.

3. From the drop-down menu, select the controller mode you want to switch to, and click **At Next Reboot** .

Reboot the system for the change to take effect.



#### Switching the controller mode using RACADM

To switch the controller mode using RACADM, run the following commands.

- To view the current mode of the controller:

```
  $ racadm get Storage.Controller.1.RequestedControllerMode[key=<Controller_FQDD>]

```

The following output is displayed:

```
  RequestedControllerMode = NONE

```

- To set the controller mode as HBA:

```
  $ racadm set Storage.Controller.1.RequestedControllerMode HBA [Key=<Controller_FQDD>]

```

- To create a job and apply changes:

```
  $ racadm jobqueue create <Controller Instance ID> -s TIME_NOW -r pwrcycle

```

For more information, see the **iDRAC RACADM Command Line Interface Reference Guide** available at **dell.com/**
**idracmanuals** .



### HBA adapter operations

Dell PowerEdge servers must have an operating system installed and the appropriate device driver loaded for Dell HBAs to
operate. Following POST, the HBA ports are disabled. The HBA device driver is responsible for resetting the HBA and enabling
its ports connected to storage devices. Without an operating system, the driver will not be loaded, and there is no guarantee
that iDRAC will display storage devices connected to Dell HBAs.

The non-RAID controllers are the HBAs that do not have few RAID capabilities. They do not support virtual disks.

15/16G iDRAC interface supports HBA controllers, HBA330 (integrated and adapter) controllers, HBA330 MMZ, HBA465e, and
HBA330 MX adapters.

AMD platforms support HBA355i front and HBA355i Adapter controllers.

You can perform the following for non-RAID controllers:

- View controller, physical disks, and enclosure properties as applicable to the non-RAID controller. Also, view the EMM, fan,
power supply unit, and temperature probe properties associated with the enclosure. The properties are displayed based on
the type of controller.

- View software and hardware inventory information.
- Update firmware for enclosures behind the 24 Gbps SAS HBA controller (staged)
- Monitor the polling or polling frequency for physical disk with SMART trip status when a change is detected.
- Monitor the physical disks hot plug or hot removal status.
- Blink or unblink LEDs
**NOTE:**

  - There is limited support for tape drives when they are connected behind SAS or HBA355e.
  - Even though LED is not available for tape drive, the blink/unblink option can be successful.
**NOTE:**

  - Enable Collect System Inventory On Reboot (CSIOR) operation before inventorying or monitoring the non-RAID
controllers.

  - Real-time monitoring for SMART enabled drives and SES enclosure sensors is only done for the HBA controllers and
HBA330 internal controllers.

**NOTE:** Detection of failed drives behind SAS HBA controllers is not supported.



### Monitoring predictive failure analysis on drives

Storage management supports Self Monitoring Analysis and Reporting Technology (SMART) on physical disks that are SMARTenabled.

SMART performs predictive failure analysis on each disk and sends alerts if a disk failure is predicted. The controllers check
physical disks for failure predictions and, if found, pass this information to iDRAC. iDRAC immediately logs an alert.



### Controller operations in non-RAID mode or HBA mode

If the controller is in non-RAID mode (HBA mode), then:

- Virtual disks or hot spares are not available.
- Security state of the controller is disabled.
- All physical disks are in non-RAID mode.

You can perform the following operations if the controller is in non-RAID mode:

- Blink/unblink the physical disk.
- Configure all properties including the following:
  - Load balanced mode
  - Check consistency mode
  - Patrol read mode
  - Copyback mode
  - Controller boot mode
  - Enhanced auto import foreign configuration
  - Rebuild rate
  - Check consistency rate
  - Reconstruct rate
  - BGI rate
  - Enclosure or backplane mode
  - Patrol read unconfigured areas
- View all properties that are applicable to a RAID controller expect for virtual disks.
- Clear foreign configuration
**NOTE:** If an operation is not supported in non-RAID mode, an error message is displayed.

You cannot monitor the enclosure temperature probes, fans, and power supplies when the controller is in non-RAID mode.



### Running RAID configuration jobs on multiple storage controllers

While performing operations on more than two storage controllers from any supported iDRAC interface, make sure to:

- Run the jobs on each controller individually. Wait for each job to complete before starting the configuration and job creation
on the next controller.

- Schedule multiple jobs to run at a later time using the scheduling options.



### Manage Preserved cache

The Managed Preserved Cache feature is a controller option which provides the user an option to discard the controller cache
data. In the write-back policy, data is written to the cache before being written to the physical disk. If the virtual disk goes
offline or is deleted for any reason, the data in the cache gets deleted.

The PREC Controller preserves the data written on the preserved or dirty cache in an event of power failure or cable disconnect
until you recover the virtual disk or clear the cache.

The status of the controller is affected by the preserved cache. The controller status is displayed as degraded if the controller
has preserved cache. Discard the preserved cache is possible only if all of the following conditions are met:

- The controller does not have any foreign configuration.
- The controller does not have any offline or missing virtual disks.
- Cables to any virtual disk are not disconnected.



## Managing PCIe SSDs

Peripheral Component Interconnect Express (PCIe) solid-state device (SSD) is a high-performance storage device designed for
solutions requiring low latency, high Input Output Operations per Second (IOPS), and enterprise class storage reliability and
serviceability. The PCIe SSD is designed based on Single Level Cell (SLC) and Multi-Level Cell (MLC) NAND flash technology
with a high-speed PCIe 2.0, PCIe 3.0, or PCIe 4.0 compliant interface. In 14th generation of PowerEdge servers, we have three
different ways to connect SSDs. You can use an extender to connect the SSDs via backplane, directly connect the SSDs from
backplane to mother board using slimline cable without extender, and use HHHL (Add-In) card which sits on the motherboard.

**NOTE:**

  - 14th generation of PowerEdge servers are supporting Industry standard NVMe-MI specification based NVMe SSDs
  - PERC 11 supports PCIe SSD/NVMe devices behind PERC inventory monitoring and configuration.

Using iDRAC interfaces, you can view and configure NVMe PCIe SSDs.

The key features of PCIe SSD are:

- Hot plug capability
- High-performance device

In few of the 14th generation of PowerEdge servers, up to 32 NVMe SSDs are supported.

You can perform the following operations for PCIe SSDs:

- Inventory and remotely monitor the health of PCIe SSDs in the server
- Prepare to remove the PCIe SSD
- Securely erase the data
- Blink or unblink the device LED (Identify the device)

You can perform the following operations for HHHL SSDs:

- Inventory and real-time monitoring of the HHHL SSD in the server
- Failed card reporting and logging in iDRAC and OMSS
- Securely erasing the data and removing the card
- TTY logs reporting

You can perform the following operations for SSDs:

- Drive status reporting such as Online, Failed, and Offline
**NOTE:** Hot plug capability, prepare to remove, and blink or unblink the device LED is not applicable for HHHL PCIe SSD
devices.

**NOTE:** When NVMe devices are controlled behind SW RAID, prepare to remove and cryptographic erase operations are not
supported, blink and unblink are supported.



### Inventorying and monitoring PCIe SSDs

The following inventory and monitoring information is available for PCIe SSDs:

- Hardware information:
  - PCIe SSD Extender card
  - PCIe SSD Backplane
**NOTE:** If the system has a dedicated PCIe backplane, two FQDDs are displayed. One FQDD is for regular drives
and the other is for SSDs. If the backplane is shared (universal), only one FQDD is displayed. In case the SSDs are
directly attached, the controller FQDD reports as CPU.1, indicating that the SSD is directly attached to the CPU.

- Software inventory includes only the firmware version for the PCIe SSD.



#### Inventorying and monitoring PCIe SSDs using web interface

To inventory and monitor PCIe SSD devices, in the iDRAC web interface, go to **Storage** - **Overview** - **Physical Disks** . The
**Properties** page is displayed. For PCIe SSDs, the **Name** column displays **PCIe SSD** . Expand to view the properties.



#### Inventorying and monitoring PCIe SSDs using RACADM

Use the `racadm storage get controllers:<PcieSSD controller FQDD>` command to inventory and monitor PCIe
SSDs.

To view all PCIe SSD drives:

```
 racadm storage get pdisks

```

To view PCIe extender cards:

```
 racadm storage get controllers

```

To view PCIe SSD backplane information:

```
 racadm storage get enclosures

```

**NOTE:** For all the mentioned commands, PERC devices are also displayed.

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



### Preparing to remove PCIe SSD

**NOTE:** This operation is not supported when:

  - PCIe SSD is configured using the S140 controller.
  - NVMe device is behind PERC 11.

PCIe SSDs support orderly hot swap allowing you to add or remove a device without halting or rebooting the system in which
the devices are installed. To prevent data loss, you must use the Prepare to Remove operation before physically removing a
device.

Orderly hot swap is supported only when PCIe SSDs are installed in a supported system running a supported operating system.
To ensure that you have the correct configuration for your PCIe SSD, see the system-specific owner's manual.

The Prepare to Remove operation is not supported for PCIe SSDs on the VMware vSphere (ESXi) systems and HHHL PCIe SSD
devices.

**NOTE:** Prepare to Remove operation is supported on systems with ESXi 6.0 with iDRAC Service Module version 2.1 or
higher.

The Prepare to Remove operation can be performed in real-time using iDRAC Service Module.

The Prepare to Remove operation stops any background activity and any ongoing I/O activity so that device can be removed
safely. It causes the status LEDs on the device to blink. You can safely remove the device from the system under the following
conditions after you initiate the Prepare to Remove operation:

- The PCIe SSD is blinking the safe to remove LED pattern (blinks amber).
- The PCIe SSD is no longer accessible by the system.

Before preparing the PCIe SSD for removal, ensure that:

- iDRAC Service Module is installed.
- Lifecycle Controller is enabled.
- You have Server Control and Login privileges.



#### Preparing to remove PCIe SSD using web interface

To prepare the PCIe SSD for removal:

1. In the iDRAC Web interface, go to **Storage** - **Overview** - **Physical Disks** .
The **Setup Physical Disk** page is displayed.

2. From the **Controller** drop-down menu, select the extender to view the associated PCIe SSDs.
3. From the drop-down menus, select **Prepare to Remove** for one or more PCIe SSDs.

If you have selected **Prepare to Remove** and you want to view the other options in the drop-down menu, then select
**Action** and then click the drop-down menu to view the other options.

**NOTE:** Ensure that iSM is installed and running to perform the `preparetoremove` operation.

4. From the **Apply Operation Mode** drop-down menu, select **Apply Now** to apply the actions immediately.

If there are jobs to be completed, then this option is grayed-out.

**NOTE:** For PCIe SSD devices, only the **Apply Now** option is available. This operation is not supported in staged mode.

5. Click **Apply** .

If the job is not created, a message indicating that the job creation was not successful is displayed. Also, the message ID and
the recommended response action is displayed.

If the job is created successfully, a message indicating that the job ID is created for the selected controller is displayed. Click
**Job Queue** to view the progress of the job in the **Job Queue** page.

If pending operation is not created, an error message is displayed. If pending operation is successful and job creation is not
successful, then an error message is displayed.



#### Preparing to remove PCIe SSD using RACADM

To prepare the PCIeSSD drive for removal:

```
 racadm storage preparetoremove:<PCIeSSD FQDD>

```

To create the target job after executing `preparetoremove` command:

```
 racadm jobqueue create <PCIe SSD FQDD> -s TIME_NOW --realtime

```

To query the job ID returned:

```
 racadm jobqueue view -i <job ID>

```

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



### Erasing PCIe SSD device data

**NOTE:** This operation is not supported when PCIe SSD is configured using the SWRAID controller.

Cryptographic Erase permanently erases all data present on the disk. Performing a Cryptographic Erase on a PCIe SSD
overwrites all blocks and results in permanent loss of all data on the PCIe SSD. During Cryptographic Erase, the host is unable to
access the PCIe SSD. The changes are applied after system reboot.

If the system reboots or experiences a power loss during cryptographic erase, the operation is canceled. You must reboot the
system and restart the process.

Before erasing PCIe SSD device data, ensure that:

- Lifecycle Controller is enabled.
- You have Server Control and Login privileges.
**NOTE:**

  - Erasing PCIe SSDs can only be performed as a staged operation.
  - After the drive is erased, it displays in the operating system as online but it is not initialized. You must initialize and
format the drive before using it again.

  - After you hot-plug a PCIe SSD, it may take several seconds to appear on the web interface.



#### Erasing PCIe SSD device data using web interface

To erase the data on the PCIe SSD device:

1. In the iDRAC Web interface, go to **Storage** - **Overview** - **Physical Disks** .
The **Physical Disk** page is displayed.

2. From the **Controller** drop-down menu, select the controller to view the associated PCIe SSDs.
3. From the drop-down menus, select **Cryptographic Erase** for one or more PCIe SSDs.

If you have selected **Cryptographic Erase** and you want to view the other options in the drop-down menu, then select
**Action** and then click the drop-down menu to view the other options.

4. From the **Apply Operation Mode** drop-down menu, select one of the following options:
  - **At Next Reboot**  - Select this option to apply the actions during the next system reboot.
  - **At Scheduled Time**  - Select this option to apply the actions at a scheduled day and time:
   - **Start Time** and **End Time**   - Click the calendar icons and select the days. From the drop-down menus, select the
time. The action is applied between the start time and end time.

   - From the drop-down menu, select the type of reboot:
￭ No Reboot (Manually Reboot System)
￭ Graceful Shutdown
￭ Force Shutdown
￭ Power Cycle System (cold boot)

5. Click **Apply** .

If the job is not created, a message indicating that the job creation was not successful is displayed. Also, the message ID and
the recommended response action is displayed.

If the job is created successfully, a message indicating that the job ID is created for the selected controller is displayed. Click
**Job Queue** to view the progress of the job in the Job Queue page.

If pending operation is not created, an error message is displayed. If pending operation is successful and job creation is not
successful, then an error message is displayed.



#### Erasing PCIe SSD device data using RACADM

To securely erase a PCIe SSD device:

```
 racadm storage secureerase:<PCIeSSD FQDD>

```

To create the target job after performing the `secureerase` command:

```
 racadm jobqueue create <PCIe SSD FQDD> -s TIME_NOW -e <start_time>

```

To query the job ID returned:

```
 racadm jobqueue view -i <job ID>

```

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



## Managing enclosures or backplanes

You can perform the following for enclosures or backplanes:

- View properties
- Configure universal mode or split mode
- View slot information (universal or shared)
- Set SGPIO mode
- Set Asset Tag
- Asset Name



### Configuring backplane mode

The Dell 14 [th] generation PowerEdge servers support a new internal storage topology, where two storage controllers (PERCs)
can be connected to internal drives through a single expander. This configuration is used for high-performance mode with no
failover or High Availability (HA) functionality. The expander splits the internal drive array between the two storage controllers.
In this mode, virtual disk creation only displays the drives that are connected to a particular controller. There are no licensing
requirements for this feature. This feature is supported only on a few systems.

Backplane supports the following modes:

- Unified mode—This is the default mode. The primary PERC controller has access to all the drives connected to the
backplane even if a second PERC controller is installed.

- Split mode—One controller has access to the first 12 drives and the second controller has access to the last 12 drives. The
drives connected to the first controller are numbered 0-11 while the drives connected to the second controller are numbered
12-23.

- Split mode 4:20—One controller has access to the first 4 drives and the second controller has access to the last 20 drives.
The drives connected to the first controller are numbered 0-3 while the drives connected to the second controller are
numbered 4-23.

- Split mode 8:16—One controller has access to the first 8 drives and the second controller has access to the last 16 drives.
The drives connected to the first controller are numbered 0-7 while the drives connected to the second controller are
numbered 8-23.

- Split mode 16:8—One controller has access to the first 16 drives and the second controller has access to the last 8 drives.
The drives connected to the first controller are numbered 0-15 while the drives connected to the second controller are
numbered 16-23.

- Split mode 20:4—One controller has access to the first 20 drives and the second controller has access to the last four
drives. The drives connected to the first controller are numbered 0-19 while the drives connected to the second controller
are numbered 20-23.

- Split mode 6:6:6:6—Four blades installed in one chassis and each blade have six drives that are assigned. This mode is only
supported on PowerEdge C series blades.

- Information Not Available—Controller information is not available.

iDRAC allows the split mode setting if the expander has the capability to support the configuration. Ensure that you enable this
mode before installing the second controller. iDRAC performs a check for expander capability before allowing this mode to be
configured and does not check whether the second PERC controller is present.

**NOTE:** In PowerEdge R760XD2 servers with two controllers (not in split mode), secondary controller has access to only
1,2,4,5 slots and primary controller has access to 3,6-24.

**NOTE:** Cable errors (or other errors) may appear if you put the backplane into split mode with only one PERC attached, or
if you put the backplane into Unified Mode with two PERCs attached.

**NOTE:** When two or more backplanes are connected to single PERC controller, the controller combines them and shows
as single enclosure. Hence it is expected to see single backplane in the Hardware inventory or Storage page. Firmware
inventory shows the actual number of backplanes present in the system.

To modify the setting, you must have Server Control privilege.

If any other RAID operations are in pending state or any RAID job is scheduled, you cannot change the backplane mode.
Similarly, if this setting is pending, you cannot schedule other RAID jobs.

**NOTE:**

  - Warning messages are displayed when the setting is being changed as there is a possibility of data loss.
  - LC Wipe or iDRAC reset operations do not change the expander setting for this mode.
  - This operation is supported only in real-time and not staged.
  - You can change the backplane configuration multiple times.
  - If the backplane is configured with the **Physical Slots** attribute as **0**, the iDRAC HII does not display the backplane
details.

  - The backplane splitting operation can cause data loss or foreign configuration if the drive association changes from one
controller to another controller.

  - During the backplane splitting operation, the RAID configuration may be impacted depending on the drive association.

Any change in this setting only takes effect after a system power reset. If you change from Split mode to Unified, an error
message is displayed on the next boot as the second controller does not see any drives. Also, the first controller will see a
foreign configuration. If you ignore the error, the existing virtual disks are lost.



#### Configuring backplane mode using web interface

To configure backplane mode using iDRAC web interface:

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Enclosures** .
2. From the **Enclosure** option, select the enclosure to configure.
3. From the **Action** drop-down menu, select **Edit Enclosure Mode** .

The **Edit Enclosure Mode** page is displayed.

4. In the **Current Value** column, select the required enclosure mode for the backplane or enclosure. The options are:
  - Unified Mode
  - Split Mode
  - Split Mode 4:20
  - Split Mode 8:16
  - Split Mode 16:8
  - Split Mode 20:4
**NOTE:** For C6420, the available modes are: Split Mode and Split Mode-6:6:6:6. Few values may be only supported on
certain platforms.

For R740xd and R940, power cycle of the server is needed to apply the new backplane zone and for C6420, A/C cycle (of
the blade chassis) to apply the new backplane zone.

5. Click **Add to Pending Operations** .

A job ID is created.

6. Click **Apply Now** .
7. Go to the **Job Queue** page and verify that it displays the status as Completed for the job.
8. Power cycle the system for the setting to take effect.
**NOTE:** To avoid inventory issues, in case of any back plane cable connection changes you require additional iDRAC
reboot and Host power cycle.



#### Configuring enclosure using RACADM

To configure the enclosure or backplane, use the `set` command with the objects in **BackplaneMode** .

For example, to set the BackplaneMode attribute to split mode:

1. Run the following command to view the current backplane mode:

```
  racadm get storage.enclosure.1.backplanecurrentmode

```

The output is:

```
  BackplaneCurrentMode=UnifiedMode

```

2. Run the following command to view the requested mode:

```
  racadm get storage.enclosure.1.backplanerequestedmode

```

The output is:

```
  BackplaneRequestedMode=None

```

3. Run the following command to set the requested backplane mode to split mode:

```
  racadm set storage.enclosure.1.backplanerequestedmode "splitmode"

```

The message is displayed indicating that the command is successful.

4. Run the following command to verify if the **backplanerequestedmode** attribute is set to split mode:

```
  racadm get storage.enclosure.1.backplanerequestedmode

```

The output is:

```
  BackplaneRequestedMode=None (Pending=SplitMode)

```

5. Run `storage get controllers` command and note down the controller instance ID.
6. Run the following command to create a job:

```
  racadm jobqueue create <controller instance ID> -s TIME_NOW --realtime

```

A job ID is returned.

7. Run the following command to query the job status:

```
  racadm jobqueue view -i JID_xxxxxxxx

```

where, `JID_xxxxxxxx` is the job ID from step 6.

The status is displayed as Pending.

Continue to query the job ID until you view the Completed status (this process may take up to three minutes).

8. Run the following command to view the `backplanerequestedmode` attribute value:

```
  racadm get storage.enclosure.1.backplanerequestedmode

```

The output is:

```
  BackplaneRequestedMode=SplitMode

```

9. Run the following command to cold reboot the server:

```
  racadm serveraction powercycle

```

10. After the system completes POST and CSIOR, type the following command to verify the `backplanerequestedmode` :

```
  racadm get storage.enclosure.1.backplanerequestedmode

```

The output is:

```
  BackplaneRequestedMode=None

```

11. Run the following to verify is the backplane mode is set to split mode:

```
  racadm get storage.enclosure.1.backplanecurrentmode

```

The output is:

```
  BackplaneCurrentMode=SplitMode

```

12. Run the following command and verify that only 0–11 drives are displayed:

```
  racadm storage get pdisks

```

For more information about the RACADM commands, see the **iDRAC RACADM Command Line Interface Reference**
**Guide** available at **dell.com/idracmanuals** .



### Viewing universal slots

Some 14 [th] generation PowerEdge server backplanes supports both SAS/SATA and PCIe SSD drives in the same slot. These
slots are called universal slots and are wired to the primary storage controller (PERC) and either PCIe extender card or direct
connect manager by CPU backplanes supports both SAS/SATA and PCIe SSD drives in the same slot. The backplane firmware
provides information about the slots that support this feature. The backplane supports SAS/SATA disks or PCIe SSDs. Typically,
the four higher number slots are universal. For example, in a universal backplane that supports 24 slots, slots 0-19 support only
SAS/SATA disks while slots 20-23 support either SAS/SATA or PCIe SSD.

The roll-up health status for the enclosure provides the combined health status for all the drives in the enclosure. The enclosure
link on the **Topology** page displays the entire enclosure information irrespective of which controller it is associated with.
Because two storage controllers (PERC and PCIe extender) can be connected to the same backplane, only the backplane
associated with the PERC controller is displayed in **System Inventory** page.

In the **Storage** - **Enclosures** - **Properties** page, the **Physical Disks Overview** section displays the following:

- **Slot Empty** - If a slot is empty.
- **PCIe Capable** - If there are no PCIe capable slots, this column is not displayed.
- **Bus Protocol** - If it is a universal backplane with PCIe SSD installed in one of the slots, this column displays **PCIe** .
- **Hotspare** - This column is not applicable for PCIe SSD.
**NOTE:** Hot swapping is supported for universal slots. If you want to remove a PCIe SSD drive and swap it with a SAS/
SATA drive, ensure that you first complete the PrepareToRemove task for the PCIe SSD drive. If you do not perform this
task, the host operating system may have issues such as a blue screen, kernel panic, and so on.



### Setting SGPIO mode

The storage controller can connect to the backplane in I2C mode (default setting for Dell backplanes) or Serial General Purpose
Input/Output (SGPIO) mode. This connection is required for blinking LEDs on the drives. Dell PERC controllers and backplane
support both these modes. To support certain channel adapters, the backplane mode must be changed SGPIO mode.

The SGPIO mode is only supported for passive backplanes. It is not supported for expander-based backplanes or passive
backplanes in downstream mode. Backplane firmware provides information on capability, current state, and requested state.

After LC wipe operation or iDRAC reset to default, the SGPIO mode is reset to disabled state. It compares the iDRAC setting
with the backplane setting. If the backplane is set to SGPIO mode, iDRAC changes its setting to match the backplane setting.

Server power cycle is required for any change in setting to take effect.

You must have Server Control privilege to modify this setting.

**NOTE:** You cannot set the SGPIO mode using iDRAC Web interface.



#### Setting SGPIO mode using RACADM

To configure the SGPIO mode, use the `set` command with the objects in the `SGPIOMode` group.

If it is set to disabled, it is I2C mode. If enabled, it is set to SGPIO mode.

For more information, see the **iDRAC RACADM Command Line Interface Reference Guide** available at **dell.com/**
**idracmanuals** .



### Set Enclosure Asset Tag

Set Enclosure Asset Tag allows you to configure Asset Tag of a storage enclosure.

User can change the Asset Tag property of the enclosure to identify enclosures. These fields are checked for invalid values and
an error is displayed if an invalid value is entered. These fields are part of the enclosure firmware; the data initially shown are the
values saved in the firmware.

**NOTE:** Asset Tag has a character limit of 10 that includes the null character.

**NOTE:** These operations are not supported on internal enclosures.



### Set Enclosure Asset Name

Set Enclosure Asset Name allows the user to configure the Asset Name of a storage enclosure.

The user can change the Asset Name property of the enclosure to identify enclosures easily. These fields are checked for invalid
values and an error is displayed if an invalid value is entered. These fields are part of the enclosure firmware; the data initially
shown are the values saved in the firmware.

**NOTE:** Asset Name has a character limit of 32 that includes the null character.

**NOTE:** These operations are not supported on internal enclosures.



## Choosing operation mode to apply settings

While creating and managing virtual disks, setting up physical disks, controllers, and enclosures or resetting controllers, before
you apply the various settings, you must select the operation mode. That is, specify when you want to apply the settings:

- Immediately
- During the next system reboot
- At a scheduled time
- As a pending operation to be applied as a batch as part of a single job.



### Choosing operation mode using web interface

To select the operation mode to apply the settings:

1. You can select the operation mode on when you are on any of the following pages:
  - **Storage**  - **Physical Disks** .
  - **Storage**  - **Virtual Disks**
  - **Storage**  - **Controllers**
  - **Storage**  - **Enclosures**
2. Select one of the following from the **Apply Operation Mode** drop-down menu:
  - **At Next Reboot**  - Select this option to apply the settings during the next system reboot.
  - **At Scheduled Time**  - Select this option to apply the settings at a scheduled day and time:
   - **Start Time** and **End Time**   - Click the calendar icons and select the days. From the drop-down menus, select the
time. The settings are applied between the start time and end time.

   - From the drop-down menu, select the type of reboot:
￭ No Reboot (Manually Reboot System)
￭ Graceful Shutdown
￭ Force Shutdown
￭ Power Cycle System (cold boot)

  - **Add to Pending Operations**  - Select this option to create a pending operation to apply the settings. You can view all
pending operations for a controller in the **Storage**    - **Overview**    - **Pending Operations** page.

**NOTE:**

   - The **Add to Pending Operations** option in not applicable for the **Pending Operations** page and for PCIe SSDs in
the **Physical Disks**       - **Setup** page.

   - Only the **Apply Now** option is available on the **Enclosure Setup** page.
3. Click **Apply** .

Based on the operation mode selected, the settings are applied.



### Choosing operation mode using RACADM

To select the operation mode, use the `jobqueue` command.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



## Viewing and applying pending operations

You can view and commit all pending operations for the storage controller. All the settings are either applied at once, during the
next reboot, or at a scheduled time based on the selected options. You can delete all the pending operations for a controller. You
cannot delete individual pending operations.

Pending Operations are created on the selected components (controllers, enclosures, physical disks, and virtual disks).

Configuration jobs are created only on controller. In case of PCIe SSD, job is created on PCIe SSD disk and not on the PCIe
Extender.



### Viewing, applying, or deleting pending operations using web interface

1. In the iDRAC web interface, go to **Storage** - **Overview** - **Pending Operations** .
The **Pending Operations** page is displayed.

2. From the **Component** drop-down menu, select the controller for which you want to view, commit, or delete the pending
operations.
The list of pending operations is displayed for the selected controller.

**NOTE:**

   - Pending operations are created for import foreign configuration, clear foreign configuration, security key operations,
and encrypt virtual disks. But, they are not displayed in the **Pending Operations** page and in the Pending
Operations pop-up message.

   - Jobs for PCIe SSD cannot be created from the **Pending Operations** page
3. To delete the pending operations for the selected controller, click **Delete All Pending Operations** .
4. From the drop-down menu, select one of the following and click **Apply** to commit the pending operations:
  - **At Next Reboot**  - Select this option to commit all the operations during the next system reboot.
  - **At Scheduled Time**  - Select this option to commit the operations at a scheduled day and time.
   - **Start Time** and **End Time**   - Click the calendar icons and select the days. From the drop-down menus, select the
time. The action is applied between the start time and end time.

   - From the drop-down menu, select the type of reboot:
￭ No Reboot (Manually Reboot System)
￭ Graceful Shutdown
￭ Force Shutdown
￭ Power Cycle System (cold boot)

5. If the commit job is not created, a message indicating that the job creation was not successful is displayed. Also, the
message ID and the recommended response action are displayed.

6. If the commit job is created successfully, a message indicating that the job ID is created for the selected controller is
displayed. Click **Job Queue** to view the progress of the job in the **Job Queue** page.

If the clear foreign configuration, import foreign configuration, security key operations, or encrypt virtual disk operations are
in pending state, and if these are the only operations pending, then you cannot create a job from the **Pending Operations**
page. You must perform any other storage configuration operation or use RACADM or WSMan to create the required
configuration job on the required controller.

You cannot view or clear pending operations for PCIe SSDs in the **Pending Operations** page. Use the racadm command to
clear the pending operations for PCIe SSDs.



### Viewing and applying pending operations using RACADM

To apply pending operations, use the **jobqueue** command.

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



## Storage devices — apply operation scenarios

**Case 1: selected an apply operation (apply now, at next reboot, or at scheduled time) and there are no existing**
**pending operations**

If you have selected **Apply Now**, **At Next Reboot**, or **At Scheduled Time** and then clicked **Apply**, first the pending operation
is created for the selected storage configuration operation.

- If the pending operation is successful and there are no prior existing pending operations, then the job is created. If the job is
created successfully, a message indicating that the job ID is created for the selected device is displayed. Click **Job Queue** to
view the progress of the job in the **Job Queue** page. If the job is not created, a message indicating that the job creation was
not successful is displayed. Also, the message ID and the recommended response action are displayed.

- If the pending operation creation is unsuccessful and there are no prior existing pending operations, an error message with ID
and recommended response action is displayed.

**Case 2: selected an apply operation (apply now, at next reboot, or at scheduled time) and there are existing pending**
**operations**

If you have selected **Apply Now**, **At Next Reboot**, or **At Scheduled Time** and then clicked **Apply**, first the pending operation
is created for the selected storage configuration operation.

- If the pending operation is created successfully and if there are existing pending operations, then a message is displayed.
  - Click the **View Pending Operations** link to view the pending operations for the device.
  - Click **Create Job** to create job for the selected device. If the job is created successfully, a message indicating that
the job ID is created for the selected device is displayed. Click **Job Queue** to view the progress of the job in the **Job**
**Queue** page. If the job is not created, a message indicating that the job creation was not successful is displayed. Also,
the message ID and the recommended response action is displayed.

  - Click **Cancel** to not create the job and remain on the page to perform more storage configuration operations.
- If the pending operation is not created successfully and if there are existing pending operations, then an error message is
displayed.

  - Click **Pending Operations** to view the pending operations for the device.
  - Click **Create Job For Successful Operations** to create the job for the existing pending operations. If the job is created
successfully, a message indicating that the job ID is created for the selected device is displayed. Click **Job Queue** to view
the progress of the job in the **Job Queue** page. If the job is not created, a message indicating that the job creation was
not successful is displayed. Also, the message ID and the recommended response action are displayed.

  - Click **Cancel** to not create the job and remain on the page to perform more storage configuration operations.
**Case 3: selected add to pending operations and there are no existing pending operations**

If you have selected **Add to Pending Operations** and then clicked **Apply**, first the pending operation is created for the
selected storage configuration operation.

- If the pending operation is created successfully and if there are no existing pending operations, then an information message
is displayed:

  - Click **OK** to remain on the page to perform more storage configuration operations.
  - Click **Pending Operations** to view the pending operations for the device. Until the job is created on the selected
controller, these pending operations are not applied.

- If the pending operation is not created successfully and if there are no existing pending operations, then an error message is
displayed.

**Case 4: selected add to pending operations and there are prior existing pending operations**

If you have selected **Add to Pending Operations** and then clicked **Apply**, first the pending operation is created for the
selected storage configuration operation.

- If the pending operation is created successfully and if there are existing pending operations, then an information message is
displayed:

  - Click **OK** to remain on the page to perform more storage configuration operations.
  - Click **Pending Operations** to view the pending operations for the device.
- If the pending operation is not created successfully and if there are existing pending operations, then an error message is
displayed.

  - Click **OK** to remain on the page to perform more storage configuration operations.
  - Click **Pending Operations** to view the pending operations for the device.
**NOTE:**

  - At any time, if you do not see the option to create a job on the storage configuration pages, go to **Storage Overview**  **Pending Operations** page to view the existing pending operations and to create the job on the required controller.
  - Only cases 1 and 2 are applicable for PCIe SSD. You cannot view the pending operations for PCIe SSDs and hence **Add**
**to Pending Operations** option is not available. Use racadm command to clear the pending operations for PCIe SSDs.



## Blinking or unblinking component LEDs

You can locate a physical disk, virtual disk drive and PCIe SSDs within an enclosure by blinking one of the Light Emitting Diodes
(LEDs) on the disk.

You must have Login + Control & Configure System privilege to blink or unblink an LED.

The controller must be real-time configuration capable. The real-time support of this feature is available only in PERC 9.1
firmware and later.

**NOTE:** Blink or unblink is not supported for servers without backplane.



### Blinking or unblinking component LEDs using web interface

To blink or unblink a component LED:

1. In the iDRAC Web interface, go to any of the following pages as per your requirement:
  - **Storage**  - **Overview**  - **Physical Disks**  - **Status**  - Displays the identified Physical Disks page where you can blink or
unblink the physical disks and PCIe SSDs.

  - **Storage**  - **Overview**  - **Virtual Disks**  - **Status**  - Displays the identified Virtual Disks page where you can blink or unblink
the virtual disks.

2. If you select the physical disk:
  - Select or deselect all component LEDs — Select the **Select/Deselect All** option and click **Blink** to start blinking the
component LEDs. Similarly, click **Unblink** to stop blinking the component LEDs.

  - Select or deselect individual component LEDs — Select one or more component(s) and click **Blink** to start blinking the
selected component LED(s). Similarly, click **Unblink** to stop blinking the component LEDs.

3. If you select the virtual disk:
  - Select or deselect all physical disk drives or PCIe SSDs — Select the **Select/Deselect All** option and click **Blink** to start
blinking all the physical disk drives and the PCIe SSDs. Similarly, click **Unblink** to stop blinking the LEDs.

  - Select or deselect individual physical disk drives or PCIe SSDs — Select one or more physical disk drives and click **Blink**
to start blinking the LEDs for the physical disk drives or the PCIe SSDs. Similarly, click **Unblink** to stop blinking the LEDs.

4. If you are on the **Identify Virtual Disk** page:
  - Select or deselect all virtual disks — Select the **Select/Deselect All** option and click **Blink** to start blinking the LEDs for
all the virtual disks. Similarly, click **Unblink** to stop blinking the LEDs.

  - Select or deselect individual virtual disks — Select one or more virtual disks and click **Blink** to start blinking the LEDs for
the virtual disks. Similarly, click **Unblink** to stop blinking the LEDs.

If the blink or unblink operation is not successful, error messages are displayed.



### Blinking or unblinking component LEDs using RACADM

To blink or unblink component LEDs, use the following commands:

```
 racadm storage blink:<PD FQDD, VD FQDD, or PCIe SSD FQDD>

 racadm storage unblink:<PD FQDD, VD FQDD, or PCIe SSD FQDD>

```

For more information, see the **iDRAC RACADM Command Line Reference Guide** available at **dell.com/idracmanuals** .



## Warm reboot

When warm reboot is performed, following behaviors are observed:

- PERC controllers in iDRAC UI are grayed out immediately after warm reboot. They are available once re-inventory is
completed after warm reboot. This is only applicable for PERC controllers and not for NVME/HBA/BOSS.

- Storage files in SupportAssist are empty when PERC controllers are grayed out in GUI.
- LC Logging for PAST event and Critical events are done for PERC during `perc reinventory` . Rest all LCL for PERC
components are suppressed. LCL resumes after PERC re-inventory finishes.

- You cannot start any Real-time job until PERC re-inventory is finished.
- Telemetry data is not collected until PERC re-inventory is finished.
- After the PERC inventory is finished, the behavior is normal.
**NOTE:** After performing a server warm boot, iDRAC may report `Disk Inserted` message in LC logs for drives that are

behind the HBA. Please ignore this log entry.



# 20 BIOS Settings

You can view multiple attributes, which are being used for a specific server under the BIOS Settings. You can modify different
parameters of each attribute from this BIOS configuration setting. Once you select one attribute, it shows different parameters
which are related to that specific attribute. You can modify multiple parameters of an attribute and apply changes before
modifying a different attribute. When a user expands a configuration group, attributes are displayed in an alphabetical order.

**NOTE:**

  - Attribute-level help content are dynamically generated.
  - The iDRAC Direct USB port is available without host reboot, even when all USB ports are disabled.



#### Apply

**Apply** button remains grayed-out until any of the attributes are modified. Once you made changes to an attribute and click
**Apply**, it allows you to modify the attribute with required changes. In case the request fails to set the BIOS attribute, it throws
an error with the corresponding HTTP Response Status code mapped to SMIL API error or Job Creation error. A message is
generated and displayed at that point. For more information, see _Event and Error Message Reference Guide for 14th Generation_
_Dell PowerEdge Servers_ [available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)



#### Discard changes

The **Discard Changes** button is grayed-out until any of the attributes are modified . If you click **Discard Changes** button, all
the recent changes are discarded and restored with the previous or initial values.



#### Apply and Reboot

When a user modifies value of an attribute or boot sequence, user is presented with two choices to apply the configuration;
**Apply and Reboot** or **Apply on Next Reboot** . In either of the apply options, the user is redirected to the job queue page to
monitor the progress of that specific job.

A user can view auditing information that is related to BIOS configuration in the LC logs.

If you click **Apply and Reboot**, it restarts the server immediately to configure all the required changes. In case, the request fails
to set the BIOS attributes, it throws an error with the corresponding HTTP Response Status code mapped to SMIL API error or
Job Creation error. An Event and Error Message (EEM) message is generated and displayed at that point.



#### Apply At Next Reboot

When a user modifies value of an attribute or boot sequence, user is presented with two choices to apply the configuration;
**Apply and Reboot** or **Apply on Next Reboot** . In either of the apply options, the user is redirected to the job queue page to
monitor the progress of that specific job.

A user can view auditing information that is related to BIOS configuration in the LC logs.

If you click **Apply At Next Reboot**, it configures all the required changes on the next restart of the server. You will not
experience any immediate modifications based on the recent configuration changes until the next reboot session is taking place
successfully. In case, the request fails to set the BIOS attributes, it throws an error with the corresponding HTTP Response
Status code mapped to SMIL API error or Job Creation error. An Event and Error message is generated and displayed at that
point.



#### Delete All Pending Values

**Delete All pending Values** button is enabled only when there are pending values based on the recent configuration changes.
In case, user decides not to apply the configuration changes, user can click **Delete All Pending Values** button to terminate
all the modifications. In case, the request fails to remove the BIOS attributes, it throws an error with the corresponding HTTP
Response Status code that is mapped to SMIL API error or Job Creation error. An EEMI message is generated and displayed at
that point.



#### Pending Value

Configuration of a BIOS attribute using iDRAC is not applied immediately to BIOS. It requires a server reboot for the changes to
take place. When you modify a BIOS attribute, **Pending Value** is updated. If an attribute already has a pending value (and that
has been configured) it is displayed on the GUI.



#### Modifying BIOS Configuration

Modifying BIOS configuration results in audit log entries, which gets entered in LC logs.



## BIOS Live Scanning

BIOS live scanning verifies the integrity and authenticity of the BIOS image in the BIOS primary ROM when the host is powered
ON but not in POST.

**NOTE:**

  - This feature requires an iDRAC Datacenter license.
  - You need to have Debug privilege for operating this feature.

iDRAC performs verification of immutable sections of BIOS image automatically at the following scenarios:

- At AC cycle/Cold boot
- On a schedule determined by user
- On demand (initiated by user)

Successful result of live scanning is logged to LC log. Failure result is logged to both LCL and SEL.

**Topics:**

- BIOS Live Scanning
- BIOS Recovery and Hardware Root of Trust (RoT)

## BIOS Live Scanning

BIOS live scanning verifies the integrity and authenticity of the BIOS image in the BIOS primary ROM when the host is powered
ON but not in POST.

**NOTE:**

  - This feature requires iDRAC Datacenter license.
  - You need to have Debug privilege for operating this feature.

iDRAC performs verification of immutable sections of BIOS image automatically at the followings scenarios:

- At AC cycle/Cold boot
- On a schedule determined by user
- On demand (initiated by user)

Successful result of live scanning is logged to LC log. Failure result is logged to both LCL and SEL.



## BIOS Recovery and Hardware Root of Trust (RoT)

For PowerEdge server, it is mandatory to recover from corrupted or damaged BIOS image either due to malicious attack or
power surges or any other unforeseeable events. An alternate reserve of BIOS image would be necessary to recover BIOS in
order to bring the PowerEdge server back to functional mode from unbootable mode. This alternative/recovery BIOS is stored in
a 2nd SPI (mux'ed with primary BIOS SPI).

The recovery sequence can be initiated through any of the following approaches with iDRAC as the main orchestrator of the
BIOS recovery task:

1. **Auto recovery of BIOS primary image/recovery image** - BIOS image is recovered automatically during the host boot
process after the BIOS corruption is detected by BIOS itself.
2. **Forced recovery of BIOS Primary/recovery image** - User initiates an OOB request to update BIOS either because they
have a new updated BIOS or BIOS was just crashing by failing to boot.
3. **Primary BIOS ROM update** - The single Primary ROM is split into Data ROM and Code ROM. iDRAC has full access/
control over Code ROM. It switches MUX to access Code ROM whenever needed.
4. **BIOS Hardware Root of Trust (RoT)** - This feature is available in severs with model number RX5X, CX5XX, and TX5X.
During every host boot (only cold boot or A/C cycle, not during warm reboot), iDRAC ensures that RoT is performed. RoT
runs automatically and user cannot initiate it using any interfaces. This iDRAC boot first policy verifies host BIOS ROM
contents on every AC cycle and host DC cycle. This process ensures secure boot of BIOS and further secures the host boot
process.

**NOTE:** For more information on Hardware RoT, refer to this link: Improved security with iDRAC9 using Root of Trust and
BIOS Live Scanning

**NOTE:** When powering on the server from **Off** state, it may take 20-30 s for iDRAC to report power state as **On** .



# 21 Configuring and using virtual console

iDRAC has added an enhanced HTML5 option in vConsole which allows vKVM (virtual Keyboard, Video, and Mouse) over
standard VNC client. You can use the virtual console to manage a remote system using the keyboard, video, and mouse on your
management station to control the corresponding devices on a managed server. This is a licensed feature for rack and tower
servers. It is available by default in blade servers. You need iDRAC Configure privilege to access all configurations on virtual
console.

**NOTE:** Vconsole session is available with basic license for some blade servers like PowerEdge C6420, PowerEdge C6520,
PowerEdge C6525, and PowerEdge M640.

Following are the list of configurable attributes in Virtual Console:

- vConsole Enabled — Enabled / Disabled
- Max Sessions — 1-6
- Active sessions — 0-6
- Video Encryption — Enabled / Disabled
- Local Server Video — Enabled / Disabled
- Dynamic Action on Sharing Request Timeout — Full Access, Read Only Access, And Deny Access
- Automatic System Lock — Enabled / Disabled
- Keyboard/Mouse Attach State — Auto-attach, Attached, and Detached

The key features are:

- A maximum of six simultaneous Virtual Console sessions are supported. All the sessions view the same managed server
console simultaneously.

- You can launch virtual console in a supported web browser.
**NOTE:**

   - Any change in web server configuration will result in termination of existing virtual console session.
   - Even if the Video Encryption option is disabled in GUI, you can still configure the feature using other interfaces,
Video encryption is enabled by default.

   - Starting with release version 6.00.02.00, access to vConsole uses only eHTML5. Java, ActiveX, and HTML5 are no
longer supported.

   - Virtual console link may get interrupted while running video stress in Internet Explorer.
- When you open a Virtual Console session, the managed server does not indicate that the console has been redirected.
- You can open multiple Virtual Console sessions from a single management station to one or more managed systems
simultaneously.

- You can open up to 6 virtual console sessions from the management station to the managed server.
- If a second user requests a Virtual Console session, the first user is notified and is given the option to refuse access, allow
read-only access, or allow full shared access. The second user is notified that another user has control. The first user must
respond within thirty seconds, or else access is granted to the second user based on the default setting. If neither the first
or second user has administrator privileges, terminating the first user's session automatically terminates the second user's
session.

- Boot logs and crash logs are captured as Video logs and are in MPEG1 format.
- Crash screen is captured as JPEG file.
**NOTE:** The number of active virtual-console sessions displayed in the web interface is only for active web-interface
sessions. This number does not include sessions from other interfaces such as SSH and RACADM.

**NOTE:** For information about configuring your browser to access the virtual console, see Configuring web browsers to use
virtual console.

**NOTE:** To disable KVM access, use the option under the settings for chassis in the OME Modular web interface.

**Topics:**

- Supported screen resolutions and refresh rates
- Configuring virtual console
- Previewing virtual console
- Launching virtual console
- Using virtual console viewer



## Supported screen resolutions and refresh rates

The following table lists the supported screen resolutions and corresponding refresh rates for a Virtual Console session running
on the managed server.



## Table 62. Supported screen resolutions and refresh rates

|Screen Resolution|Refresh Rate (Hz)|
|---|---|
|720x400|70|
|640x480|60, 72, 75, 85|
|800x600|60, 70, 72, 75, 85|
|1024x768|60, 70, 72, 75, 85|
|1280x1024|60|
|1920x1200|60|

It is recommended that you configure the monitor display resolution to 1920x1200 pixels.

Virtual Console supports a maximum video resolution of 1920x1200 at 60 Hz refresh rate. In order to achieve this resolution,
following conditions are required:

- KVM / monitor attached to VGA that supports 1920x1200 resolution
- Latest Matrox video driver (for Windows)

When a local KVM / Monitor with maximum resolution below 1920x1200 is connected to either VGA connector, it will reduce the
maximum resolution supported in virtual console.

iDRAC virtual console leverages the onboard Matrox G200 graphics controller to determine the maximum resolution of the
attached monitor when a physical display is present. When the monitor supports 1920x1200 or greater resolution, the virtual
console supports 1920x1200 resolution. If the monitor attached supports lower max resolution (like many KVMs), the virtual
console max resolution is limited.

**Maximum virtual console resolutions based on monitor display ratio:**

- 16:10 monitor: 1920x1200 will be the max resolution
- 16:9 monitor: 1920x1080 will be the max resolution

When a physical monitor is not connected to either VGA port on the server, the OS installed will dictate the available resolutions
for virtual console.

**Maximum virtual console resolutions based on host OS without physical monitor:**

- Windows: 1600x1200 (1600x1200, 1280x1024, 1152x864, 1024x768, 800x600)
- Linux: 1024x768 (1024x768, 800x600, 848x480, 640x480)
**NOTE:** If a higher resolution through virtual console is required when physical KVM or monitor is not present, a VGA Display
Emulator dongle can be leveraged to mimic an external monitor connection with a resolution up to 1920x1080.

**NOTE:** If you have an active Virtual Console session and a lower resolution monitor is connected to the Virtual Console, the
server console resolution may reset if the server is selected on the local console. If the system is running a Linux operating
system, an X11 console may not be viewable on the local monitor. Press <Ctrl><Alt><F1> at the iDRAC Virtual Console to
switch Linux to a text console.



## Configuring virtual console

**NOTE:** Starting with release version 6.00.02.00, access to vConsole uses only eHTML5. Java, ActiveX, and HTML5 are no
longer supported.

Before configuring the Virtual Console, make sure that the management station is configured.

You can configure the virtual console using iDRAC Web interface or RACADM command line interface.



### Configuring virtual console using web interface

To configure Virtual Console using iDRAC Web interface:

1. Go to **Configuration** - **Virtual Console** . Click **Start the Virtual Console** link, then Virtual Console page is displayed.
2. Enable virtual console and specify the required values. For information about the options, see the **iDRAC Online Help** .
**NOTE:** If you are using Nano operating system, disable the **Automatic System Lock** feature on the **Virtual Console**
page.

3. Click **Apply** . The virtual console is configured.



### Configuring virtual console using RACADM

To configure the Virtual Console, use the `set` command with the objects in the **iDRAC.VirtualConsole** group.

For more information, see the _Integrated Dell Remote Access Controller RACADM CLI Guide_ .



## Previewing virtual console

Before launching the Virtual Console, you can preview the state of the Virtual Console on the **System** - **Properties** - **System**
**Summary** page. The **Virtual Console Preview** section displays an image showing the state of the Virtual Console. The image is
refreshed every 30 seconds. This is a licensed feature.

**NOTE:** The Virtual Console image is available only if you have enabled Virtual Console.



## Launching virtual console

You can launch the virtual console using the iDRAC Web Interface or a URL.

**NOTE:** Do not launch a virtual console session from a web browser on the managed system.

Before launching the virtual console, ensure that:

- You have administrator privileges.
- Minimum network bandwidth of 1 MB/sec is available.
**NOTE:** When the custom HTTP port or default port is configured in iDRAC, clear the browser cache, and then launch
iDRAC with HTTPS and accept the certificates. After this, log in to iDRAC and launch the virtual console.

**NOTE:** If the embedded video controller is disabled in the BIOS and if you launch the Virtual Console, the Virtual Console
Viewer is blank.

The virtual console has the following Console controls:

1. **General** —Sets Keyboard Macros, Aspect Ratio, and Touch Mode.
2. **KVM** —Shows the values for Frame Rate, Bandwidth, Compression, and Packet Rate.
3. **Performance** —Changes the video quality and video speed.
4. **User List** —Views the list of users who are connected to the console.

You can access Virtual Media by clicking the **Connect to Virtual Media** option available in the virtual console.

**NOTE:** In iDRAC release 5.10.00.00, if the RFS session is active, the Virtual Media Session is blocked. Hence when you
upgrade from the 4.40.00.00 release to the 5.10.00.00 release with RFS Session Active, RFS gets remounted when iDRAC
is up. In this case, if you try to launch Virtual Media Session, it fails with an error message `Virtual media already in`

`use` .



### Launching virtual console using web interface

You can launch the virtual console in the following ways:

- Go to **Configuration** - **Virtual Console** . Click **Start the Virtual Console** link. Virtual console page is displayed.

The **Virtual Console Viewer** displays the remote system’s desktop. Using this viewer, you can control the remote system’s
mouse and keyboard functions from your management station.

Multiple message boxes may appear after you launch the application. To prevent unauthorized access to the application,
navigate through these message boxes within three minutes. Otherwise, you are prompted to relaunch the application.

If one or more Security Alert windows appear while launching the viewer, click Yes to continue.

Two mouse pointers may appear in the viewer window: one for the managed server and another for your management station.



### Launching virtual console using a URL

To launch the Virtual Console using the URL:

1. Open a supported Web browser and in the address box, type the following URL in lower case: **https://iDRAC_ip/console**
2. Based on the login configuration, the corresponding **Login** page is displayed:
  - If Single Sign On is disabled and Local, Active Directory, LDAP, or Smart Card login is enabled, the corresponding **Login**
page is displayed.

  - If Single-Sign On is enabled, the **Virtual Console Viewer** is launched and the **Virtual Console** page is displayed in the
background.

**NOTE:** Internet Explorer supports Local, Active Directory, LDAP, Smart Card (SC) and Single Sign-On (SSO) logins.
Firefox supports Local, AD, and SSO logins on Windows-based operating system and Local, Active Directory, and LDAP
logins on Linux-based operating systems.

**NOTE:** If you do not have Access Virtual Console privilege but have Access Virtual Media privilege, then using this URL
launches the Virtual Media instead of the Virtual Console.



## Using virtual console viewer

The Virtual Console Viewer provides various controls such as mouse synchronization, virtual console scaling, chat options,
keyboard macros, power actions, next boot devices, and access to Virtual Media. For information to use these features, see the
**iDRAC Online Help** .

**NOTE:** If the remote server is powered off, the message ’No Signal’ is displayed.

The Virtual Console Viewer title bar displays the DNS name or the IP address of the iDRAC you are connected to from the
management station. If iDRAC does not have a DNS name, then the IP address is displayed. The format is:

- For rack and tower servers: `<DNS name / IPv6 address / IPv4 address>, <Model>, User: <username>,`
```
  <fps>
```

- For blade servers: `<DNS name / IPv6 address / IPv4 address>, <Model>, <Slot number>, User:`
```
  <username>, <fps>

```

Sometimes the Virtual Console Viewer may display low quality video. This is due to slow network connectivity that leads to
loss of one or two video frames when you start the Virtual Console session. To transmit all the video frames and improve the
subsequent video quality, do any of the following:

- In the **System Summary** page, under **Virtual Console Preview** section, click **Refresh** .
- In the **Virtual Console Viewer**, under **Performance** tab, set the slider to **Maximum Video Quality** .



### Using a virtual console

**NOTE:** Starting with release version 6.00.02.00, access to vConsole uses only eHTML5. Java, ActiveX, and HTML5 are no
longer supported.

**NOTE:** By default the virtual console type is set to eHTML5.

You can launch a virtual console as a pop-up window by using one of the following methods:

- From the iDRAC home page, click the **Start the Virtual Console** link available in the Console Preview session.
- From the iDRAC Virtual Console page, click the **Start the Virtual Console** link.
- From the iDRAC login page, type **https//<iDRAC IP>/console** . This method is called as Direct Launch.

In the eHTML5 virtual console, the following menu options are available:

- Power
- Boot
- Chat
- Keyboard
- Screen Capture
- Refresh
- Full Screen
- Disconnect Viewer.
- Console Controls
- Virtual Media

The **Pass all keystrokes to server** option is not supported on the eHTML5 virtual console. Use keyboard and keyboard macros
for all the functional keys.

- **General**
  - **Console control**  - This has the following configuration options:
￭ Keyboard Macros—This is supported in eHTML5 virtual console and are listed as the following drop-down options.
Click **Apply** to apply the selected key combination on the server.

       - Ctrl+Alt+Del
       - Ctrl+Alt+F1
       - Ctrl+Alt+F2
       - Ctrl+Alt+F3
       - Ctrl+Alt+F4
       - Ctrl+Alt+F5
       - Ctrl+Alt+F6
       - Ctrl+Alt+F7
       - Ctrl+Alt+F8
       - Ctrl+Alt+F9
       - Ctrl+Alt+F10
       - Ctrl+Alt+F11
       - Ctrl+Alt+F12
       - Alt+Tab
       - Alt+ESC
       - Ctrl+ESC
       - Alt+Space
       - Alt+Enter
       - Alt+Hyphen
       - Alt+F1
       - Alt+F2
       - Alt+F3
       - Alt+F4
       - Alt+F5
       - Alt+F6
       - Alt+F7
       - Alt+F8
       - Alt+F9
       - Alt+F10
       - Alt+F11
       - Alt+F12
       - PrntScrn
       - Alt+PrntScrn
       - F1
       - Pause
       - Tab
       - Ctrl+Enter
       - SysRq
       - Alt+SysRq
       - Win-P
￭ Aspect Ratio—The eHTML5 virtual console video image automatically adjusts the size to make the image visible. The
following configuration options are displayed as a drop-down list:

       - Maintain
       - Do not Maintain.
Click **Apply** to apply the selected settings on the server.
￭ Touch Mode—The eHTML5 virtual console supports the Touch Mode feature. The following configuration options are
displayed as a drop-down list:

       - Direct
       - Relative
Click **Apply** to apply the selected settings on the server.

- **Virtual Clipboard** - Virtual clipboard enables you to cut/copy/paste text buffer from virtual console to iDRAC host server.
Host server could be BIOS, UEFI or in operating system prompt. This is a one-way action from client system to iDRAC host
server only. Follow these steps to use the Virtual clipboard:

  - Place the mouse cursor or keyboard focus on the desired window in the host server desktop.
  - Select the **Console Controls** menu from vConsole.
  - Copy the OS clipboard buffer using keyboard hotkeys, mouse, or touchpad controls depending on the Client operating
system. Or, you can type the text manually in the text box.

  - Click **Send Clipboard to Host** .
  - Then, the text appears on the host server active window.
**NOTE:**

   - This feature is available in Enterprise and Datacenter license.
   - This feature only supports ASCII text.
   - This feature supports only English Language Keyboard.
   - Control characters are not supported.
   - Characters such as **New line** and **Tab** are allowed.
   - Text buffer size is limited to 4000 characters.
   - If more than the maximum buffer is pasted, then the edit box in the iDRAC UI truncates it to the maximum buffer
size.

- **KVM** - This menu has a list of the following read-only components:
  - Frame Rate
  - Bandwidth
  - Compression
  - Packet Rate
- **Performance** - You can use the slider button to adjust **Maximum Video Quality** and **Maximum Video Speed** .
- **User List** - You can see the list of users that are logged in to the Virtual console.
- **Keyboard** - The difference between physical and virtual keyboard is that the virtual keyboard changes its layout according
to the browser language.

**NOTE:** Starting from iDRAC release 7.00.30.00, you can see the option for changing the vKeyboard language without
changing the browser language. Ensure that the vKeyboard language and Host operating system language should be the
same.

- **Virtual Media** - Click the **Connect Virtual Media** option to start the virtual media session.
  - **Connect Virtual Media**  - This menu contains the options for Map CD/DVD, Map Removable Disk, Map External Device,
and Reset USB.

  - **Virtual Media Statistics**  - This menu shows the Transfer Rate (Read-only). Also, it shows the details of CD/DVD and
Removable Disks details such as Mapping details, status (read-only or not), duration, and Read/Write Bytes.

  - **Create Image**  - This menu allows you to select a local folder and generate a FolderName.img file with local folder
contents.

**NOTE:** For security reasons, read/write access is disabled while accessing the virtual console in eHTML5.



#### Supported Browsers

The eHTML5 virtual console is supported on the following browsers:

- Microsoft EDGE
- Safari 16.6
- Safari 17.x
- Mozilla Firefox 128
- Mozilla Firefox 129
- Mozilla Firefox 130
- Google Chrome 137
- Google Chrome 138
**NOTE:** It is recommended to have Mac operating system version 10.10.2 (or onward) installed in the system.

**NOTE:** If you are using Chrome/Edge browser, you may see the Login denied message.

For more details on supported browsers and versions, see the _Integrated Dell Remote Access Controller User's Guide Release_
_Notes_ [available on the iDRAC manuals page.](https://www.dell.com/idracmanuals)



# 22 Using iDRAC Service Module

The iDRAC Service Module is a software application that is recommended to be installed on the server (it is not installed by
default). It complements iDRAC with monitoring information from the operating system. It complements iDRAC by providing
additional data to work with iDRAC interfaces such as the Web interface, Redfish, RACADM, and WSMan. You can configure
the features that are monitored by the iDRAC Service Module to control the CPU and memory that is consumed on the server’s
operating system. The host operating system command-line interface has been introduced to enable or disable the status of Full
Power Cycle for all System components except the PSU.

**NOTE:**

  - iDRAC version 7.00.00.00 requires iSM version 5.1.0.0 or later.
  - Use the iDRAC Service Module only if you have installed iDRAC Express or iDRAC Enterprise/Datacenter license.
  - iSM versions older than 4.2 do not support TLS 1.3.
  - If the HOST network is not configured properly, the iDRAC SupportAssist page reports the LC Log indicating that there
is a problem connecting with iSM.

  - If you observe the SRV042 warning in iDRAC LC while creating SupportAssist collections, perform the hard reset of
iDRAC to resolve this warning in iDRAC LC.

Before using iDRAC Service Module, ensure that:

- You have login, configuration, and server control privileges in iDRAC to enable or disable the iDRAC Service Module features.
- You do not disable the **iDRAC Configuration using local RACADM** option.
- The operating system to iDRAC pass-through channel is enabled through the internal USB bus in iDRAC.
**NOTE:** If you perform LC wipe, `idrac.Servicemodule` values may still show the old values.

**NOTE:**

  - When iDRAC Service Module runs for the first time, by default it enables the operating system to iDRAC pass-through
channel in iDRAC. If you disable this feature after installing the iDRAC Service Module, then you must enable it manually
in iDRAC.

  - If the operating system to iDRAC pass-through channel is enabled through LOM in iDRAC, then you cannot use the
iDRAC Service Module.

**Topics:**

- Installing iDRAC Service Module
- Supported operating systems for iDRAC Service Module
- iDRAC Service Module monitoring features
- Using iDRAC Service Module from iDRAC web interface
- Using iDRAC Service Module from RACADM



## Installing iDRAC Service Module

You can download and install the iDRAC Service Module from **dell.com/support** . You must have administrator privilege on the
server’s operating system to install the iDRAC Service Module. For information on installation, see the iDRAC Service Module
[User's Guide available on the iDRAC Service Modulepage.](https://www.dell.com/support/home/us/en/19/products/software_int/software_ent_systems_mgmt/remote_ent_sys_mgmt/ent_sys_mgmt_idrac_svc_module)

**NOTE:** This feature is not applicable for Dell Precision PR7910 systems.

**NOTE:** If USB NIC is disabled on the iDRAC, iSM installer auto enables USB NIC. Once the installation is complete, disable
USB NIC if needed.



## Supported operating systems for iDRAC Service Module

For the list of operating systems supported by the iDRAC Service Module, see the iDRAC Service Module User's Guide available
[on the iDRAC Service Modulepage.](https://www.dell.com/support/home/us/en/19/products/software_int/software_ent_systems_mgmt/remote_ent_sys_mgmt/ent_sys_mgmt_idrac_svc_module)



## iDRAC Service Module monitoring features

The iDRAC Service Module (iSM) provides the following monitoring features:

**Table 63. iSM supported features**

|Running|Running (Limited Functionality)|
|---|---|
|Redfish profile support for network attributes|Service on Host OS|
|iDRAC Hard Reset|OS information|
|iDRAC access via Host OS (Experimental Feature)|Auto System Recovery|
|In-band iDRAC SNMP alerts|Allow Service Module to perform iDRAC Hard Reset|
|View operating system (OS) information|N/A|
|Replicate Lifecycle Controller logs to operating system logs|N/A|
|Perform automatic system recovery options|N/A|
|Populate Windows Management Instrumentation (WMI)<br>Management Providers|N/A|
|Integrate with SupportAssist Collection.<br>**NOTE:** This is applicable only if iDRAC Service Module<br>version 2.0 or later is installed.|N/A|
|Prepare to Remove NVMe PCIe SSD.<br>**NOTE:** For more information, see theSupport for Dell<br>iDRAC Service Modulepage.|N/A|
|Remote Server Power Cycle|N/A|



##### Redfish profile support for network attributes

iDRAC Service Module v2.3 or later provides additional network attributes to iDRAC, which can be obtained through the REST
clients from iDRAC. For more details, see iDRAC Redfish profile support.



##### Operating system information

The OpenManage Server Administrator currently shares operating system information and host name with iDRAC. The iDRAC
Service Module provides similar information such as OS name, OS version, and Fully Qualified Domain Name (FQDN) with
iDRAC. By default, this monitoring feature is enabled. It is not disabled if OpenManage Server Administrator is installed on the
host OS.

In iSM version 2.0 or later, the operating system information feature is amended with the OS network interface monitoring.
When iDRAC Service Module version 2.0 or later is used with iDRAC 2.00.00.00, it starts monitoring the operating system
network interfaces. You can view this information using iDRAC web interface, RACADM, or WSMan.



##### Replicate Lifecycle logs to OS log

You can replicate the Lifecycle Controller Logs to the OS logs from the time when the feature is enabled in iDRAC. This is similar
to the System Event Log (SEL) replication performed by OpenManage Server Administrator. All events that have the **OS Log**
option selected as the target (in the **Alerts** page, or in the equivalent RACADM or WSMan interfaces) are replicated in the OS
log using the iDRAC Service Module. The default set of logs to be included in the OS logs is the same as configured for SNMP
alerts or traps.

iDRAC Service Module also logs the events that have occurred when the operating system is not functioning. The OS logging
performed by iDRAC Service Module follows the IETF syslog standards for Linux-based operating systems.

**NOTE:** Starting iDRAC Service Module version 2.1, the Lifecycle Controller Logs replication location in the Windows OS logs
can be configured using the iDRAC Service Module installer. You can configure the location while installing iDRAC Service
Module or modifying the iDRAC Service Module installer.

If OpenManage Server Administrator is installed, this monitoring feature is disabled to avoid duplicate SEL entries in the OS log.

**NOTE:** On Microsoft Windows, if iSM events get logged under System logs instead of Application logs, restart the Windows
Event Log service or restart the host OS.



##### Automatic system recovery options

The Automatic system recovery feature is a hardware-based timer. If a hardware failure occurs, a notification may not be
available, but the server is reset as if the power switch was activated. ASR is implemented using a timer that continuously
counts down. The Health Monitor frequently reloads the counter to prevent it from counting down to zero. If the ASR counts
down to zero, it is assumed that the operating system has locked up and the system automatically attempts to reboot.

You can perform automatic system recovery operations such as reboot, power cycle, or power off the server after a
specified time interval. This feature is enabled only if the operating system watchdog timer is disabled. If OpenManage Server
Administrator is installed, this monitoring feature is disabled to avoid duplicate watchdog timers.



##### Windows Management Instrumentation providers

WMI is a set of extensions to the Windows Driver Model that provides an operating system interface through which
instrumented components provide information and notification. WMI is Microsoft's implementation of the Web-Based Enterprise
Management (WBEM) and Common Information Model (CIM) standards from the Distributed Management Task Force (DMTF)
to manage Server hardware, operating systems and applications. WMI Providers helps to integrate with Systems Management
Consoles such as Microsoft System Center and enables scripting to manage Microsoft Windows Servers.

You can enable or disable the WMI option in iDRAC. iDRAC exposes the WMI classes through the iDRAC Service Module
providing the server’s health information. By default, WMI information feature is enabled. The iDRAC Service Module exposes
the WSMan monitored classes in iDRAC through WMI. The classes are exposed in the `root/cimv2/dcim` namespace.

The classes can be accessed using any of the standard WMI client interfaces. For more information, see the profile documents.

This content use the **DCIM_iDRACCardString** and **DCIM_iDRACCardInteger** classes to illustrate the capability that WMI
information feature provides in iDRAC Service Module. For the details of the supported classes and profiles, see the WSMan
[profiles documentation available on the Dell Supportpage.](https://www.dell.com/support/home/en-us)

The listed attributes are used to configure **User Accounts** along with the required privileges:

**Table 64. User accounts and privileges**

|AttributeName|WSMAN-Class|Privilege|License|Description|Supported<br>Operation|
|---|---|---|---|---|---|
|UserName|DCIM_iDRACCardS<br>tring|**Write Privileges:**<br>ConfigUsers,<br>Login**Read**<br>**Privileges:**Login|Basic|**16users:**<br>Users.1#UserName<br>to<br>Users.16#UserNam<br>e|Enum, Get, Invoke|
|Password|DCIM_iDRACCardS<br>tring|**Write Privileges:**<br>ConfigUsers, Login|Basic|Users.1#Password<br>to<br>Users.16#Password|Enum, Get, Invoke|
|||**Read Privileges:**<br>Login||||
|Privilege|DCIM_iDRACCardI<br>nteger|**Write Privileges:**<br>ConfigUsers, Login<br>**Read Privileges:**<br>Login|Basic|Users.1#Password<br>to<br>Users.16#Password|Enum, Get, Invoke|

- `Enumerate` or `Get` operation on the mentioned classes will provide the attribute related data.
- The attribute can be set by invoking the `ApplyAttribute` or `SetAttribute` command from
**DCIM_iDRACCardService** class.

**NOTE:** **DCIM_Account** class is removed from WSMAN and provided the feature through attribute model.
**DCIM_iDRACCardString** and **DCIM_iDRACCardInteger** classes provide similar support to configure iDRAC users
accounts.



##### Remote iDRAC Hard Reset

By using iDRAC, you can monitor the supported servers for critical system hardware, firmware, or software issues. Sometimes,
iDRAC may become unresponsive due to various reasons. During such scenarios, you must turn off the server and reset iDRAC.
To reset the iDRAC CPU, you must either power off and power on the server or perform an AC power cycle.

By using the remote iDRAC hard reset feature, whenever iDRAC becomes unresponsive, you can perform a remote iDRAC reset
operation without an AC power cycle.. To reset the iDRAC remotely, make sure that you have administrative privileges on the
host OS. By default, the remote iDRAC hard reset feature is enabled. You can perform a remote iDRAC hard reset using iDRAC
Web interface, RACADM, and WSMan.

**Command usage**

This section provides the command usages for Windows, Linux, and ESXi operating systems to perform iDRAC hard reset.

- **Windows**
  - Using the local Windows Management Instrumentation (WMI):
  - `winrm i iDRACHardReset wmi/root/cimv2/dcim/DCIM_iSMService?`
```
   InstanceID=”iSMExportedFunctions”
```

  - Using the remote WMI interface: `winrm i iDRACHardReset wmi/root/cimv2/dcim/dcim_ismservice?`
`InstanceID="iSMExportedFunctions" -u:<admin-username> -p:<admin-password> -r:` **http://**
**<remote-hostname** `OR IP>/wsman -a:Basic -encoding:utf-8 -skipCACheck -skipCNCheck`

  - Using the Windows PowerShell script with force and without force:
￭ `Invoke-iDRACHardReset –force`
￭ `Invoke-iDRACHardReset`

  - Using the **Program Menu** shortcut: For simplicity, iSM provides a shortcut in the **Program Menu** of the Windows
operating system. When you select the **Remote iDRAC Hard Reset** option, you are prompted for a confirmation to
reset the iDRAC. After you confirm, the iDRAC is reset and the result of the operation is displayed.

**NOTE:** The following warning message appears in the **Event Viewer** under the **Application Logs** category. This
warning does not require any further action.

**NOTE:** `A provider, ismserviceprovider, has been registered in the Windows Management`
```
    Instrumentation namespace Root\CIMV2\DCIM to use the LocalSystem account. This
    account is privileged and the provider may cause a security violation if it does not
    correctly impersonate user requests.

```

- **Linux**
  - iSM provides an executable command on all iSM supported Linux operating system. You can run this command by logging
into the operating system by using SSH or equivalent.

  - `Invoke-iDRACHardReset`
  - `Invoke-iDRACHardReset –f`
- **ESXi**
  - On all iSM supported ESXi operating systems, the iSM v2.3 supports a Common Management Programming Interface
(CMPI) method provider to perform the iDRAC reset remotely by using the WinRM remote commands.

  - `winrm i iDRACHardReset http://schemas.dell.com/wbem/wscim/1/cim-schema/2/root/cimv2/`
```
   dcim/DCIM_iSMService?__cimnamespace=root/cimv2/dcim+InstanceID= iSMExportedFunctions
   -u:<root-username> -p:<passwd> -r:https://<Host-IP>:443/WSMan -a:basic -encoding:utf-8
   -skipCNCheck -skipCACheck -skipRevocationcheck

```

**NOTE:** VMware ESXi operating system does not prompt for confirmation before resetting the iDRAC.

**NOTE:** Due to limitations on the VMware ESXi operating system, iDRAC connectivity is not restored completely after
the reset. Ensure that you manually reset iDRAC.

**Table 65. Error Handling**

|Result|Description|
|---|---|
|0|Success|
|1|Unsupported BIOS version for iDRAC reset|
|2|Unsupported platform|
|3|Access denied|
|4|iDRAC reset failed|



##### In-band Support for iDRAC SNMP Alerts

By using iDRAC Service Module v2.3, you can receive SNMP alerts from the host operating system, which is similar to the alerts
that are generated by iDRAC.

You can also monitor the iDRAC SNMP alerts without configuring the iDRAC and manage the server remotely by configuring the
SNMP traps and destination on the host OS. In iDRAC Service Module v2.3 or later, this feature converts all the Lifecycle logs
replicated in the OS logs into SNMP traps.

**NOTE:** This feature is active only if the Lifecycle Logs replication feature is enabled.

**NOTE:** On Linux operating systems, this feature requires a master or OS SNMP enabled with SNMP multiplexing (SMUX)
protocol.

By default, this feature is disabled. Though the In-band SNMP alerting mechanism can coexist along with iDRAC SNMP alerting
mechanism, the recorded logs may have redundant SNMP alerts from both the sources. It is recommended to either use the
in-band or out-of-band option, instead of using both.

**Command usage**

This section provides the command usages for Windows, Linux, and ESXi operating systems.

- **Windows operating system**
  - Using the local Windows Management Instrumentation (WMI): `winrm i EnableInBandSNMPTraps wmi/root/`
```
   cimv2/dcim/DCIM_iSMService?InstanceID="iSMExportedFunctions" @{state="[0/1]"}
```

  - Using the remote WMI interface: `winrm i EnableInBandSNMPTraps wmi/root/cimv2/dcim/`
```
   DCIM_iSMService?InstanceID="iSMExportedFunctions" @{state="[0/1]"} -u:<admin-username>
   -p:<admin-passwd> -r:http://<remote-hostname OR IP>/WSMan -a:Basic -encoding:utf-8
   -skipCACheck –skipCNCheck
```

- **Linux operating system**
  - On all iSM supported Linux operating system, iSM provides an executable command. You can run this command by
logging into the operating system by using SSH or equivalent.

  - Beginning with iSM 2.4.0, you can configure Agent-x as the default protocol for in-band iDRAC SNMP alerts using the
following command:

```
  ./Enable-iDRACSNMPTrap.sh 1/agentx –force

```

If `–force` is not specified, ensure that the net-SNMP is configured and restart the snmpd service.

  - To enable this feature:

```
    Enable-iDRACSNMPTrap.sh 1

    Enable-iDRACSNMPTrap.sh enable

```

  - To disable this feature:

```
    Enable-iDRACSNMPTrap.sh 0

    Enable-iDRACSNMPTrap.sh disable

```

**NOTE:** The **--force** option configures the Net-SNMP to forward the traps. However, you must configure the trap
destination.

- **VMware ESXi operating system**
  - On all iSM supported ESXi operating systems, the iSM v2.3 supports a Common Management Programming Interface
(CMPI) method provider to enable this feature remotely by using the WinRM remote commands.

  - `winrm i EnableInBandSNMPTraps http://schemas.dell.com/wbem/`
```
   wscim/1/cim-schema/2/root/cimv2/dcim/DCIM_iSMService? __cimnamespace=root/cimv2/
   dcim+InstanceID=iSMExportedFunctions -u:<user-name> -p:<passwd> -r:https://<remote   host-name
```

  - `ip-address>:443/WSMan -a:basic -encoding:utf-8 -skipCNCheck -skipCACheck`
```
   -skipRevocationcheck @{state="[0/1]"}

```

**NOTE:** You must review and configure the VMware ESXi system-wide SNMP settings for traps.

**NOTE:** For more details, refer to the **In-BandSNMPAlerts** [technical white paper available on the Dell Support page.](https://supportkb.dell.com/attachment/ka06P0000008SM2QAM/In_Band_SNMP_Alerts_v3_pkb_en_US_1.pdf)



##### iDRAC access via Host OS

By using this feature, you can configure and monitor the hardware parameters through iDRAC Web interface, WSMan, and
RedFish interfaces using the host IP address without configuring the iDRAC IP address. You can use the default iDRAC
credentials if the iDRAC server is not configured or continue to use the same iDRAC credentials if the iDRAC server was
configured earlier.

**iDRAC access via Windows Operating Systems**

You can perform this task by using the following methods:

- Install the iDRAC access feature by using the webpack.
- Configure using iSM PowerShell script
**Installation by using MSI**

You can install this feature by using the web-pack. This feature is disabled on a typical iSM installation. If enabled, the
default listening port number is 1266. You can modify this port number within the range 1024 through 65535. iSM redirects
the connection to the iDRAC. iSM then creates an inbound firewall rule, OS2iDRAC. The listening port number is added to
the OS2iDRAC firewall rule in the host operating system, which allows incoming connections. The firewall rule is enabled
automatically when this feature is enabled.

Beginning with iSM 2.4.0, you can retrieve the current status and listening-port configuration by using the following Powershell
cmdlet:

```
 Enable-iDRACAccessHostRoute –status get

```

The output of this command indicates whether this feature is enabled or disabled. If the feature is enabled, it displays the
listening-port number.

**NOTE:** Ensure that the Microsoft IP Helper Services is running on your system for this feature to function.

To access the iDRAC Web interface, use the format `https://<host-name>` or `OS-IP>:443/login.html` in the browser,
where:

- `<host-name>` - Complete host name of the server on which iSM is installed and configured for iDRAC access via OS
feature. You can use the OS IP address if the host name is not present.

- `443` - Default iDRAC port number. This is called the Connect Port number to which all the incoming connections on
listen port number are redirected. You can modify the port number through iDRAC Web interface, WSMan, and RACADM
interfaces.

**Configuration by using iSM PowerShell cmdlet**

If this feature is disabled while installing iSM, you can enable the feature by using the following Windows PowerShell command
provided by iSM:

```
 Enable-iDRACAccessHostRoute

```

If the feature is already configured, you can disable or modify it by using the PowerShell command and the corresponding
options. The available options are as follows:

- **Status** - This parameter is mandatory. The values are not case sensitive and the value can be **true**, **false**, or **get** .
- **Port** - This is the listening port number. If you do not provide a port number, the default port number (1266) is used. If the
**Status** parameter value is FALSE, then you can ignore rest of the parameters. You must enter a new port number that is
not already configured for this feature. The new port number settings overwrite the existing OS2iDRAC in-bound firewall rule
and you can use the new port number to connect to iDRAC. The value range is from 1024 to 65535.

- **IPRange** - This parameter is optional and it provides a range of IP addresses that are allowed to connect to iDRAC through
the host operating system. The IP address range format is in Classless Inter-Domain Routing (CIDR) format, which is a
combination of IP address and subnet mask. For example, 10.94.111.21/24. Access to iDRAC is restricted for IP addresses
that are not within the range.

**NOTE:** This feature supports only IPv4 addresses.

**iDRAC access via Linux Operating Systems**

You can install this feature by using the `setup.sh` file that is available with the web-pack. This feature is disabled on a default
or typical iSM installation. To get the status of this feature, use the following command:

To install, enable, and configure this feature, use the following command:

```
./Enable-iDRACAccessHostRoute <Enable-Flag> [ <source-port> <source-IP-range/source-iprange-mask>]

```

**`<Enable-Flag>`** =0

Disable

`<source-port>` and `<source-IP-range/source-ip-range-mask>` are not required.

**`<Enable-Flag>`** =1

Enable

`<source-port>` is required and `<source-ip-range-mask>` is optional.

```
<source-IP-range>
```

IP range in **<IP-Address/subnet-mask>** format. Example: 10.95.146.98/24



##### Coexistence of OpenManage Server Administrator and iDRAC Service Module

In a system, both OpenManage Server Administrator and the iDRAC Service Module can co-exist and continue to function
correctly and independently.

If you have enabled the monitoring features during the iDRAC Service Module installation, then after the installation is complete
if the iDRAC Service Module detects the presence of OpenManage Server Administrator, it disables the set of monitoring
features that overlap. If OpenManage Server Administrator is running, the iDRAC Service Module disables the overlapping
monitoring features after logging to the OS and iDRAC.

When you re-enable these monitoring features through the iDRAC interfaces later, the same checks are performed and the
features are enabled depending on whether OpenManage Server Administrator is running or not.



## Using iDRAC Service Module from iDRAC web interface

To use the iDRAC Service Module from the iDRAC web interface:

1. Go to **IDRAC Settings** - **Overview** - **iDRAC Service Module** - **Configure Service Module** .
The **iDRAC Service Module Setup** page is displayed.

2. You can view the following:
  - Installed iDRAC Service Module version on the host operating system
  - Connection status of the iDRAC Service Module with iDRAC.
**NOTE:** When a server has multiple operating systems and iDRAC Service Module is installed in all operating systems,
then iDRAC connects only with the most recent instance of iSM among all operating systems. An error is displayed for
all the older instances of iSM on other operating systems. To connect iSM with iDRAC on any other operating system
which already has iSM installed, uninstall and reinstall iSM on that particular operating system.

3. To perform out-of-band monitoring functions, select one or more of the following options:
  - **OS Information** —View the operating system information.
  - **Replicate Lifecycle Log in OS Log** —Include Lifecycle Controller logs to operating system logs. This option is disabled
if OpenManage Server Administrator is installed on the system.

  - **WMI Information**  - Include WMI information.
  - **Auto System Recovery Action** —Perform auto recovery operations on the system after a specified time (in seconds):
   - **Reboot**
   - **Power Off System**
   - **Power Cycle System**
This option is disabled if OpenManage Server Administrator is installed on the system.

**NOTE:** When iSM is in either full or limited mode functionality state and iDRAC is reset to factory settings, there is no way
for iDRAC to set the Limited mode functionality state for iSM state.



## Using iDRAC Service Module from RACADM

To use the iDRAC Service Module from RACADM, use the objects in the `ServiceModule` group.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



# 23 Using USB port for server management

On the 14th generation servers, a dedicated micro USB port is available to configure iDRAC. You can perform the following
functions using the micro USB port:

- Connect to the system using the USB network interface to access system management tools such as iDRAC web interface
and RACADM.

- Configure a server by using SCP files that are stored on a USB drive.
**NOTE:** To manage a USB port or to configure a server by importing Server Configuration Profile (SCP) files on a USB drive,
you must have the System Control privilege.

**NOTE:** An alert / report is generated when a USB device is inserted. This feature is only available on Intel based servers.

To configure Management USB Settings, go to **iDRAC Settings** - **Settings** - **Management USB Settings** . Following options
are available:

- **USB Management Port** —Select **Enabled** to enable the port either to import the SCP file when a USB drive is connected
or to access iDRAC using the micro USB port.

**NOTE:** Ensure that the USB drive contains a valid SCP file.

**NOTE:** Use an OTG adapter to convert from Type-A to Micro-B USB. Connections from USB hubs are not supported.

**NOTE:** It is permitted to attempt to modify USB Management Port Mode when an USB device is in use. iDRAC can
gracefully handle it.

- **iDRAC Managed: USB SCP** —Select from following options to configure the system by importing SCP stored on a USB
drive:

  - **Disabled** —Disables SCP imports
  - **Enabled only when server has default credential settings**  - If this option is selected then the SCP can only be
imported when the default password is not changed for the following:
￭ BIOS
￭ iDRAC web interface

  - **Enabled only for compressed configuration files** —Select this option to allow SCP file import only if the files are in
compressed format.

**NOTE:** Selecting this option allows you to password protect the compressed file. You can enter a password to
secure the file by using **Password for Zip file** option.

  - **Enabled** —Select this option to allow importing SCP file without running a check during runtime.
**Topics:**

- Accessing iDRAC interface over direct USB connection
- Configuring iDRAC using server configuration profile on USB device



## Accessing iDRAC interface over direct USB connection

The iDRAC direct feature allows you to directly connect your laptop to the iDRAC USB port. This feature allows you to interact
directly with the iDRAC interfaces such as the web interface, RACADM, and WSMan for advanced server management and
servicing.

For a list of supported browsers and operating systems, see the _Integrated Dell Remote Access Controller User's Guide Release_
_Notes_ [available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)

**CAUTION: Avoid connecting USB devices to the iDRAC direct port of Dell PowerEdge XE9680 servers during**
**system initialization, POST, boot operations, or GPU firmware updates.**

**NOTE:** If you are using Windows operating system, install an RNDIS driver to use this feature.

**NOTE:** iDRAC direct USB access is not recommended for Dell PowerEdge XR5610 servers when iDRAC network is
configured as shared LOM from OCP on cold aisle configuration.

To access the iDRAC interface over the USB port:

1. Turn off any wireless networks and disconnect from any other hard wired network.
2. Ensure that the USB port is enabled. For more information, see Configuring USB management port settings.
3. Wait for the laptop to acquire IP address 169.254.0.4. It may take several seconds for the IP addresses to be acquired.
iDRAC acquires the IP address 169.254.0.3.

4. Start using iDRAC network interfaces such as the web interface, RACADM, Redfish, or WSMan.

For example, to access the iDRAC web interface, open a supported browser, and type the address **169.254.0.3** and press
enter.

5. When iDRAC is using the USB port, the LED blinks indicating activity. The blink frequency is four per second.
6. After completing the required actions, disconnect the USB cable from the system.

The LED turns off.



## Configuring iDRAC using server configuration profile on USB device

With the iDRAC USB management port, you can configure iDRAC at-the-server. Configure the USB Management port settings
in iDRAC, insert the USB device that has the server configuration profile, and then import the server configuration profile from
the USB device to iDRAC.

**NOTE:** You can set the USB Management port settings using the iDRAC interfaces only if there is no USB device
connected to the server.



### Configuring USB management port settings

Configuring USB management port settings allows you to manage USB ports and devices that are connected to the client or
server.

Configure the USB management port settings to manage the USB ports and devices that are connected to the client or server.

You can enable or disable the **iDRAC Direct USB Port** using the system BIOS. Go to **Configuration** - **System BIOS** **Integrated Devices** . Select **On** to enable and **Off** to disable the **iDRAC Direct USB Port** . The **iDRAC Direct USB Port** must
be enabled to access GPU sensor data when Host Management Controller (HMC) Lock is active.

In iDRAC, you must have Server Control privilege to configure the USB management port. When a USB device is connected, the
**System Inventory** page displays the USB device information under the Hardware Inventory section.

An event is logged in the Lifecycle Controller logs when:

- The device is in Automatic or iDRAC mode, and the USB device is inserted or removed.
- USB Management Port Mode is modified.
- Device is automatically switched from iDRAC to operating system.
- Device is ejected from iDRAC or operating system

When a device exceeds its power requirements as allowed by USB specification, the device is detached and an over-current
event is generated with the following properties:

- Category : System Health
- Type: USB device
- Severity: Warning
- Allowed notifications: Email, SNMP trap, remote syslog, and WS-Eventing
- Actions: None

An error message is displayed and logged to Lifecycle Controller log when:

- You try to configure the USB management port without the Server Control user privilege.
- A USB device is in use by iDRAC, and you attempt to modify the USB Management Port Mode.
- A USB device is in use by iDRAC, and you remove the device.



#### Configuring USB management port using web interface

To configure the USB port:

1. In the iDRAC Web interface, go to **iDRAC Settings** - **Settings** - **Management USB Settings** .
2. The **USB Management Port** is set to Enabled.
3. From the **iDRAC Managed: USB SCP** Configuration drop-down menu, select options to configure a server by importing
Server Configuration Profile files stored on a USB drive:

  - **Disabled**
  - **Enabled only when server has default credential settings**
  - **Enabled only for compressed configuration files**
  - **Enabled**
For information about the fields, see the **iDRAC Online Help** .

**NOTE:** iDRAC9 allows you to password protect the compressed file after you select Enabled only for compressed
configuration files to compress the file before importing. You can enter a password to secure the file by using Password
for Zip file option.

4. Click **Apply** to apply the settings.



#### Configuring USB management port using RACADM

To configure the USB management port, use the following RACADM sub commands and objects:

- To view the USB port status:

```
  racadm get iDRAC.USB.PortStatus

```

- To view the USB port configuration:

```
  racadm get iDRAC.USB.ManagementPortMode

```

- To view USB device inventory:

```
  racadm hwinventory

```

- To set up overcurrent alert configuration:

```
  racadm eventfilters

```

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Configuring USB management port using iDRAC settings utility

To configure the USB port:

1. In the iDRAC Settings Utility, go to **Media and USB Port Settings** .
The **iDRAC Settings Media and USB Port Settings** page is displayed.

2. From the **iDRAC Direct: USB Configuration XML** drop-down menu, select options to configure a server by importing
server configuration profile stored on a USB drive:

  - **Disabled**
  - **Enabled while server has default credential settings only**
  - **Enabled only for compressed configuration files**
  - **Enabled**
For information about the fields, see the **iDRAC Settings Utility Online Help** .

3. Click **Back**, click **Finish** and then click **Yes** to apply the settings.



### Importing Server Configuration Profile from USB device

Make sure to create a directory in root of the USB device called `System_Configuration_XML` that contains both the config
and control files:

- Server Configuration Profile (SCP) is in the `System_Configuration_XML` sub-directory under the USB device root
directory. This file includes all the attribute-value pairs of the server. This includes attributes of iDRAC, PERC, RAID, and
BIOS. You can edit this file to configure any attribute on the server. The file name can be `<servicetag>-config.xml`,
`<servicetag>-config.json`, `<modelnumber>-config.xml`, `<modelnumber>-config.json`, `config.xml` or
`config.json` .

- Control file – Includes parameters to control the import operation and does not have attributes of iDRAC or any other
component in the system. The control file contain three parameters:

  - ShutdownType – Graceful, Forced, No Reboot.
  - TimeToWait (in secs) – 300 minimum and 3600 maximum.
  - EndHostPowerState – on/off.

Example of `control.xml` file:

```
 <InstructionTable>
 <InstructionRow>
 <InstructionType>Configuration XML import Host control Instruction
 </InstructionType>
 <Instruction>ShutdownType</Instruction>
 <Value>NoReboot</Value>
 <ValuePossibilities>Graceful,Forced,NoReboot</ValuePossibilities>
 </InstructionRow>
 <InstructionRow>
 <InstructionType>Configuration XML import Host control Instruction
 </InstructionType>
 <Instruction>TimeToWait</Instruction>
 <Value>300</Value>
 <ValuePossibilities>Minimum value is 300 -Maximum value is
 3600 seconds.</ValuePossibilities>
 </InstructionRow>
 <InstructionRow>
 <InstructionType>Configuration XML import Host control Instruction
 </InstructionType>
 <Instruction>EndHostPowerState</Instruction>
 <Value>On</Value>
 <ValuePossibilities>On,Off</ValuePossibilities>
 </InstructionRow>
 </InstructionTable>

```

You must have Server Control privilege to perform this operation.

**NOTE:** While importing the SCP, changing the USB management settings in the SCP file results in a failed job or job
completed with errors. You can comment out the attributes in the SCP to avoid the errors.

To import the server configuration profile from the USB device to iDRAC:

1. Configure the USB management port:
  - Set **USB Management Port Mode** to **Automatic** or **iDRAC** .
  - Set **iDRAC Managed: USB XML Configuration** to **Enabled with default credentials** or **Enabled** .
2. Insert the USB key (that has the `configuration.xml` and the `control.xml` file) to the iDRAC USB port.
**NOTE:** File name and file type are case sensitive for XML files. Ensure that both are in lower case.

3. The server configuration profile is discovered on the USB device in the `System_Configuration_XML` sub-directory
under the USB device root directory. It is discovered in the following sequence:

  - `<servicetag>-config.xml` / `<servicetag>-config.json`
  - `<modelnum>-config.xml` / `<modelnum>-config.json`
  - `config.xml` / `config.json`
4. A server configuration profile import job starts.

If the profile is not discovered, then the operation stops.

If **iDRAC Managed: USB XML Configuration** was set to **Enabled with default credentials** and the BIOS setup
password is not null or if one of the iDRAC user accounts have been modified, an error message is displayed and the
operation stops.

5. LCD panel and LED, if present, display the status that an import job has started.
6. If there is a configuration that needs to be staged and the **Shut Down Type** is specified as **No Reboot** is specified in the
control file, you must reboot the server for the settings to be configured. Else, server is rebooted and the configuration is
applied. Only when the server was already powered down, then the staged configuration is applied even if the **No Reboot**
option is specified.

7. After the import job is complete, the LCD/LED indicates that the job is complete. If a reboot is required, LCD displays the job
status as “Paused waiting on reboot”.

8. If the USB device is left inserted on the server, the result of the import operation is recorded in the `results.xml` file in
the USB device.



#### LCD messages

If the LCD panel is available, it displays the following messages in a sequence:
1. Importing – When the server configuration profile is being copied from the USB device.
2. Applying — When the job is in-progress.
3. Completed — When the job has completed successfully.
4. Completed with errors — When the job has completed with errors.
5. Failed — When the job has failed.
For more details, see the results file on the USB device.



#### LED blinking behavior

The USB LED indicates the status of a server-configuration profile operation being performed using the USB port. The LED may
not be available on all systems.

- Solid green — The server configuration profile is being copied from the USB device.
- Blinking green — The job is in progress.
- Blinking amber — The job has failed or completed with errors.
- Solid green — The job has completed successfully.
**NOTE:** On PowerEdge R840 and R940xa, if there is a LCD present, the USB LED does not blink when an import operation
is in progress using the USB port. Check the status of the operation using the LCD.



#### Logs and results file

The following information is logged for the import operation:

- Automatic import from USB is logged in the Lifecycle Controller log file.
- If the USB device is left inserted, the job results are recorded in the Results file located in the USB key.

A Result file named `Results.xml` is updated or created in the subdirectory with the following information:

- Service tag – Data is recorded after the import operation has either returned a job ID or returned an error.
- Job ID – Data is recorded after the import operation has returned a job ID.
- Start Date and Time of Job - Data is recorded after the import operation has returned a job ID.
- Status – Data is recorded when the import operation returns an error or when the job results are available.



# 24 Using Quick Sync 2

With Dell OpenManage Mobile running on an Android or iOS mobile device, you can easily access server directly or through
OpenManage Essentials or OpenManage Enterprise (OME) console. It allows you to review server details and inventory, view LC
and System Event logs, get automatic notifications on mobile device from an OME console, assign IP address and modify iDRAC
password, configure key BIOS attributes, and take remediation actions as needed. You can also power cycle a server, access
system console, or access iDRAC GUI.

OMM can be downloaded for free from the Apple App Store, or from Google Play Store.

You must install the OpenManage Mobile application on the mobile device (supports Android 5.0+ and iOS 9.0+ mobile devices)
to manage server using iDRAC Quick Sync 2 interface.

**NOTE:** This section is displayed only in those servers that has Quick Sync 2 module in left rack ear.

**NOTE:** This feature is currently supported on mobile devices with Android operating system and Apple iOS.

In the current release, this feature is available on all 14th generation of PowerEdge servers. It requires Quick Sync 2 Left Control
Panel (embedded in **Left rack ear** ) and Bluetooth Low Energy (and optionally Wi-Fi) enabled mobile devices. Therefore, it is a
hardware up-sell and the feature capabilities are not dependent on iDRAC software licensing.

**NOTE:** For more information on configuring Quick Sync 2 in MX platform systems, see the **OpenManage Enterprise**
**Modular User's Guide** and **OpenManage Mobile User’s Guide** available at **dell.com/support/manuals** .

The iDRAC Quick Sync 2 Configuration procedures:

**NOTE:** Not applicable for MX platforms.

Once Quick Sync is configured, activate the Quick Sync 2 button on the Left Control Panel. Make sure the Quick Sync 2 light
turns on. Access the Quick Sync 2 Information using a mobile device (Android 5.0+ or IOS 9.0+, OMM 2.0 or above).

Using OpenManage Mobile, you can:

- View inventory information
- View monitoring information
- Configure the basic iDRAC network settings

For more information about OpenManage Mobile, see the _Dell OpenManage Mobile User's Guide_ available on the OpenManage
manualspage..

**Topics:**

- Configuring iDRAC Quick Sync 2
- Using mobile device to view iDRAC information



## Configuring iDRAC Quick Sync 2

Using iDRAC web interface, RACADM, WSMan and iDRAC HII you can configure iDRAC Quick Sync 2 feature to allow access to
the mobile device:

- **Access** - Configure to Read-Write, Read-only, and Disabled. Read-Write is the default option.
- **Timeout** - Configure to Enabled or Disabled. Enabled is the default option.
- **Timeout Limit** - Indicates the time after which the Quick Sync 2 mode is disabled. By default, Minutes option is selected.
The default value is 2 Minutes. The range is 2 to 60 Minutes.
1. If enabled, you can specify a time after which the Quick Sync 2 mode is turned off. To turn on, press the activation
button again.
2. If disabled, the timer does not allow you to enter a time-out period.
- **Read Authentication** - Configures to Enabled, this is the default option.
- **WiFi** - Configures to Enabled, this is the default option.

You must have Server Control privilege to configure the settings. A server reboot is not required for the settings to take effect.
once configured, you can activate the Quick Sync 2 button on the Left Control Panel. Make sure the Quick Sync light turns on.
Then, access the Quick Sync Information via a mobile device.

An entry is logged to the Lifecycle Controller log when the configuration is modified.



### Configuring iDRAC Quick Sync 2 settings using web interface

To configure iDRAC Quick Sync 2:

1. In the iDRAC web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **iDRAC Quick Sync** .
2. In the **iDRAC Quick Sync** section, from the **Access** menu, select one of the following to provide access to the Android or
iOS mobile device:

  - Read-write
  - Read-only
  - Disabled
3. Enable the Timer.
4. Specify the Timeout Limit.

For more information about the fields, see the **iDRAC Online Help** .

5. Click **Apply** to apply the settings.



### Configuring iDRAC Quick Sync 2 settings using RACADM

To configure the iDRAC Quick Sync 2feature, use the racadm objects in the **System.QuickSync** group. For more information,
[see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Configuring iDRAC Quick Sync 2 settings using iDRAC settings utility

To configure iDRAC Quick Sync 2:

1. In the iDRAC GUI, go to **Configuration** - **Systems Settings** - **Hardware Settings** - **iDRAC Quick Sync** .
2. In the **iDRAC Quick Sync** section:
  - Specify the access level.
  - Enable Timeout.
  - Specify the User Defined Timeout Limit (the range is 120 to 3600 seconds.).

For more information about the fields, see the **iDRAC Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The settings are applied.



## Using mobile device to view iDRAC information

To view iDRAC information from the mobile device, see the _Dell OpenManage Mobile User's Guide_ available on the OpenManage
manualspage. for the steps.



# 25 Managing virtual media

iDRAC provides virtual media with HTML5 based client with local ISO and IMG file, remote ISO and IMG file support. Virtual
media allows the managed server to access media devices on the management station or ISO CD/DVD images on a network
share as if they were devices on the managed server. You need iDRAC Configure privilege to modify the configuration.

Following are the configurable attributes:

- Attached Media Enabled — Enabled / Disabled
- Attach Mode — Auto-attach, Attached, and Detached
- Max Sessions — 1
- Active Sessions — 1
- Virtual Media Encryption — Enabled (by default)
- Floppy Emulation — Disabled (by default)
- Boot Once — Enabled / Disabled
- Connection Status — Connected / Disconnected

Using the Virtual Media feature, you can:

- Remotely access media connected to a remote system over the network
- Install applications
- Update drivers
- Install an operating system on the managed system

This is a licensed feature for rack and tower servers. One session is available with basic license for these blade servers PowerEdge C6420, PowerEdge C6520, PowerEdge C6525, and PowerEdge M640.

The key features are:

- Virtual Media supports virtual optical drives (CD/DVD) and USB flash drives.
- You can attach only one USB flash drive, image, or key and one optical drive on the management station to a managed
system. Supported optical drives include a maximum of one available optical drive or one ISO image file. The following figure
shows a typical Virtual Media setup.

- Any connected Virtual Media emulates a physical device on the managed system.
- On Windows-based managed systems, the Virtual Media drives are auto-mounted if they are attached and configured with a
drive letter.

- On Linux-based managed systems with some configurations, the Virtual Media drives are not auto-mounted. To manually
mount the drives, use the mount command.

- All the virtual drive access requests from the managed system are directed to the management station across the network.
- Virtual devices appear as two drives on the managed system without the media being installed in the drives.
- You can share the management station CD/DVD drive (read only), but not a USB media, between two managed systems.
- Virtual media requires a minimum available network bandwidth of 128 Kbps.
- If LOM or NIC failover occurs, then the Virtual Media session may be disconnected.

After attaching a Virtual Media image through Virtual Console, the drive may not show up in Windows host OS. Check Windows
Device Manager for any unknown mass storage devices. Right click on the unknown device and update the driver or choose
uninstall driver. The device is recognized by Windows after disconnecting and reconnecting vMedia.

**Figure 4. Virtual media setup**

**Topics:**

- Supported drives and devices
- Configuring virtual media
- Accessing virtual media
- Enabling boot once for virtual media
- Remote File Share
- Setting boot order through BIOS
- Accessing drivers



## Supported drives and devices

The following table lists the drives supported through virtual media.



## Table 66. Supported drives and devices

|Drive|Supported Storage Media|
|---|---|
|Virtual Optical Drives|●<br>ISO Image File<br>●<br>IMG Image File|
|USB flash drives|●<br>USB Key image in the ISO9660 format|



## Configuring virtual media





### Configuring virtual media using iDRAC web interface

To configure virtual media settings:

**CAUTION: Do not reset iDRAC when running a Virtual Media session. Otherwise, undesirable results may occur,**
**including data loss.**

1. In the iDRAC Web interface, go to **Configuration** - **Virtual Media** - **Attached Media** .
2. Specify the required settings. For more information, see the **iDRAC Online Help** .
3. Click **Apply** to save the settings.



### Configuring virtual media using RACADM

To configure the virtual media, use the `set` command with the objects in the **iDRAC.VirtualMedia group** .

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Configuring virtual media using iDRAC settings utility

You can attach, detach, or auto-attach virtual media using the iDRAC Settings utility. To do this:

1. In the iDRAC Settings utility, go to **Media and USB Port Settings** .
The **iDRAC Settings Media and USB Port Settings** page is displayed.

2. In the **Virtual Media** section, select **Detach**, **Attach**, or **Auto attach** based on the requirement. For more information about
the options, see **iDRAC Settings Utility Online Help** .

3. Click **Back**, click **Finish**, and then click **Yes** .

The Virtual Media settings are configured.



### Attached media state and system response

The following table describes the system response based on the Attached Media setting.



### Table 67. Attached media state and system response

|Attached Media State|System Response|
|---|---|
|Detach|Cannot map an image to the system.|
|Attach|Media is mapped even when**Client View** is closed.|
|Auto-attach|Media is mapped when**Client View** is opened and unmapped when**Client View** is closed.|



#### Server settings for viewing virtual devices in virtual media

You must configure the following settings in the management station to allow visibility of empty drives. To do this, in Windows
Explorer, from the **Organize** menu, click **Folder and search options** . On the **View** tab, deselect **Hide empty drives in the**
**Computer folder** option and click **OK** .



## Accessing virtual media

You can access Virtual Media with or without using the Virtual Console. Before you access Virtual Media, make sure to configure
your Web browser(s).

Virtual Media and RFS are mutually exclusive. If the RFS connection is active and you attempt to launch the Virtual Media client,
the following error message is displayed: **Virtual Media is currently unavailable. A Virtual Media or Remote File Share**
**session is in use** .

Virtual Media and RFS are mutually exclusive. If the RFS connection is active and you attempt to launch the Virtual Media
client, the following error message is displayed: `Virtual Media is currently unavailable. A Virtual Media`
```
or Remote File Share session is in use. If virtual media connected first then user can able
```

`to connect RFS1 also` .

If the RFS connection is not active and you attempt to launch the Virtual Media client, the client launches successfully. You can
then use the Virtual Media client to map devices and files to the Virtual Media virtual drives.

.img file mapped via **Virtual Console** - **Virtual Media or standalone Virtual Media** does not support write operations in host
OS.



### Launching virtual media using virtual console

Before you launch Virtual Media through the Virtual Console, make sure that:

- Virtual Console is enabled.
- System is configured to not hide empty drives — In Windows Explorer, navigate to **Folder Options**, clear the **Hide empty**
**drives in the Computer folder** option, and click **OK** .

To access Virtual Media using Virtual Console:

1. In the iDRAC web interface, go to **Configuration** - **Virtual Console** .
The **Virtual Console** page is displayed.

2. Click **Launch Virtual Console** .

The **Virtual Console Viewer** is launched.

3. Click **Virtual Media** - **Connect Virtual Media** .

The Virtual Media session is established and the **Virtual Media** menu displays the list of devices available for mapping.

**NOTE:** The **Virtual Console Viewer** window must remain active while you access the Virtual Media.



### Launching virtual media without using virtual console

Before you launch Virtual Media when the **Virtual Console** is disabled, ensure that System is configured to unhide empty drives.
To do this, in Windows Explorer, go to **Folder Options**, clear the **Hide empty drives in the Computer folder** option, and click
**OK** .

To access Virtual Media when Virtual Console is disabled:

1. In the iDRAC web Interface, go to **Configuration** - **Virtual Media** .
2. Click **Connect Virtual Media** .

Alternatively, you can also launch the Virtual Media by following these steps:

1. Go to **Configuration** - **Virtual Console** .
2. Click **Launch** **Virtual Console** . The following message is displayed:

```
  Virtual Console has been disabled. Do you want to continue using Virtual Media
  redirection?

```

3. Click **OK** . The **Virtual Media** window is displayed.
4. From the **Virtual Media** menu, click **Map CD/DVD** or **Map Removable Disk** . For more information, see Mapping virtual

drive.
5. **Virtual Media Statistics** shows the list of target drives, their mapping, status (Read-Only or Not), Duration of connection,
Read/Write Bytes, and the transfer rate.

**NOTE:** The virtual device drive letters on the managed system do not coincide with the physical drive letters on the
management station.

**NOTE:** The Virtual Media may not function correctly on systems running Windows operating system configured with
Internet Explorer Enhanced Security. To resolve this issue, see the Microsoft operating system documentation or contact
the system administrator.



### Adding virtual media images

You can create a media image of the remote folder and mount it as a USB attached device to the server’s operating system. To
add Virtual Media images:

1. Click **Virtual Media** - **Create Image...** .
2. In the **Source Folder** field, click **Browse** and browse to the folder or directory to be used as the source for the image file.
The image file is on the management station or the C: drive of the managed system.

3. In the **Image File Name** field, the default path to store the created image files (typically the desktop directory) appears. To
change this location, click **Browse** and navigate to a location.

4. Click **Create Image** .

The image creation process starts. If the image file location is within the source folder, a warning message is displayed
indicating that the image creation cannot proceed as the image file location within the source folder causes an infinite loop.
If the image file location is not within the source folder, then the image creation proceeds.

After the image is created, a success message is displayed.

5. Click **Finish** .

The image is created.

When a folder is added as an image, a **.img** file is created on the Desktop of the management station from which this feature
is used. If this **.img** file is moved or deleted, then the corresponding entry for this folder in the **Virtual Media** menu does not
work. Therefore, it is recommended not to move or delete the **.img** file while the **image** is being used. However, the **.img**
file can be removed after the relevant entry is first deselected and then removed using **Remove Image** to remove the entry.



### Viewing virtual device details

To view the virtual device details, in the Virtual Console Viewer, click **Tools** - **Stats** . In the **Stats** window, the **Virtual Media**
section displays the mapped virtual devices and the read/write activity for each device. If Virtual Media is connected, this
information is displayed. If Virtual Media is not connected, the “Virtual Media is not connected” message is displayed.

If the Virtual Media is launched without using the Virtual Console, then the **Virtual Media** section is displayed as a dialog box. It
provides information about the mapped devices.



### Resetting USB

To reset the USB device:

1. In the Virtual Console viewer, click **Tools** - **Stats** .
The **Stats** window is displayed.

2. Under **Virtual Media**, click **USB Reset** .

A message is displayed warning the user that resetting the USB connection can affect all the input to the target device
including Virtual Media, keyboard, and mouse.

3. Click **Yes** .

The USB is reset.

**NOTE:** iDRAC Virtual Media does not terminate even after you log out of iDRAC Web interface session.



### Mapping virtual drive

To map the virtual drive:

**NOTE:** While using Virtual Media, you must have administrative privileges to map an operating system DVD or a USB flash
drive (that is connected to the management station). To map the drives, launch IE as an administrator or add the iDRAC IP
address to the list of trusted sites.

1. To establish a Virtual Media session, from the **Virtual Media** menu, click **Connect Virtual Media** .

For each device available for mapping from the host server, a menu item appears under the **Virtual Media** menu. The menu
item is named according to the device type such as:

  - Map CD/DVD
  - Map Removable Disk
  - Map External Device

The **Map DVD/CD** option can be used for ISO files and the **Map Removable Disk** option can be used for images with
ehtml5 based Virtual Media. The **Map External Device** option can be used for mapping physical USB drives.

**NOTE:**

   - You cannot map physical media such USB-based drives, CD, or DVD by using the HTML5 based virtual console.
   - You cannot map USB keys as virtual media disks using Virtual Console/Virtual media over a RDP session.
   - You cannot map physical media with NTFS format in ehtml removable media, use FAT or exFAT devices
2. Click the device type that you want to map.
**NOTE:** The active session displays if a Virtual Media session is currently active from the current Web interface session,
from another Web interface session.

3. In the **Drive/Image File** field, select the device from the drop-down list.

The list contains all the available (unmapped) devices that you can map (CD/DVD and Removable Disk) and image file types
that you can map (ISO or IMG). The image files are located in the default image file directory (typically the user’s desktop).
If the device is not available in the drop-down list, click **Browse** to specify the device.

The correct file type for CD/DVD is ISO and for removable disk it is IMG.

If the image is created in the default path (Desktop), when you select **Map Removable Disk**, the created image is available
for selection in the drop-down menu.

If image is created in a different location, when you select **Map Removable Disk**, the created image is not available for
selection in the drop-down menu. Click **Browse** to specify the image.

**NOTE:** Floppy emulation is not supported in ehtml5 plugin.

4. Select **Read-only** to map writable devices as read-only.

For CD/DVD devices, this option is enabled by default and you cannot disable it.

**NOTE:** The ISO and IMG files map as read-only files if you map these files by using the HTML5 virtual console.

5. Click **Map Device** to map the device to the host server.

After the device/file is mapped, the name of its **Virtual Media** menu item changes to indicate the device name. For
example, if the CD/DVD device is mapped to an image file named `foo.iso`, then the CD/DVD menu item on the Virtual
Media menu is named **foo.iso mapped to CD/DVD** . A check mark for that menu item indicates that it is mapped.



#### Displaying correct virtual drives for mapping

On a Linux-based management station, the Virtual Media **Client** window may display removable disks that are not part of the
management station. To make sure that the correct virtual drives are available to map, you must enable the port setting for the
connected SATA hard drive. To do this:

1. Reboot the operating system on the management station. During POST, press <F2> to enter **System Setup** .
2. Go to **SATA settings** . The port details are displayed.
3. Enable the ports that are actually present and connected to the hard drive.
4. Access the Virtual Media **Client** window. It displays the correct drives that can be mapped.



#### Clearing Java Cache

In case of any unexpected errors while using USB, please clear the Java cache. Follow these steps to clear Java cache:

1. In the Java Control Panel, under the **General** tab, click **Settings** under the **Temporary Internet Files** section. The
**Temporary Files Settings** dialog box appears.

2. Click **Delete Files** on the Temporary Files Settings dialog.

The **Delete Files and Applications** dialog box appears.

3. Click **OK** on the **Delete Files and Applications** dialog. This deletes all the Downloaded Applications and Applets from the
cache.

4. Click **OK** on the **Temporary Files Settings** dialog. If you want to delete a specific application and applet from the cache,
click on View Application and View Applet options respectively.



### Unmapping virtual drive

To unmap the virtual drive:

1. From the **Virtual Media** menu, do any of the following:
  - Click the device that you want to unmap.
  - Click **Disconnect Virtual Media** .

A message appears asking for confirmation.

2. Click **Yes** .

The check mark for that menu item does not appear indicating that it is not mapped to the host server.

**NOTE:** After unmapping a USB device attached to vKVM from a client system running the Macintosh operating system,
the unmapped device may be unavailable on the client. Restart the system or manually mount the device on the client
system to view the device.

**NOTE:** To unmap a virtual DVD drive on Linux OS, unmount the drive and eject it.



## Enabling boot once for virtual media

You can change the boot order only once when you boot after attaching remote Virtual Media device.

Before you enable the boot once option, make sure that:

- You have **Configure User** privilege.
- Map the local or virtual drives (CD/DVD, Floppy, or USB flash device) with the bootable media or image using the Virtual
Media options

- Virtual Media is in **Attached** state for the virtual drives to appear in the boot sequence.

To enable the boot once option and boot the managed system from the Virtual Media:

1. In the iDRAC Web interface, go to **Overview** - **Server** - **Attached Media** .
2. Under **Virtual Media**, select the **Enable Boot Once** and click **Apply** .
3. Turn on the managed system and press **<F2>** during boot.
4. Change the boot sequence to boot from the remote Virtual Media device.
5. Reboot the server.

The managed system boots once from the Virtual Media.



## Remote File Share

This feature is available only with the iDRAC Enterprise or Datacenter license.

RFS mounts are capable of Read Write attribute changes, and it is supported from racadm/redfish only.

**NOTE:** Before using RFS, ensure that you have a minimum network bandwidth of 1 MB/Sec.

**Remote File Share 1 (RFS1)**

The Remote File Share 1 (RFS1) feature uses the Virtual Media Implementation in iDRAC.

When an image file is mounted using the RFS1 feature, both the Virtual Media virtual disk drives are visible to the host operating
system. If an **.img** file is mapped, and then the floppy/hard disk Virtual drive is used to present the image file to the operating
system. If an **.iso** file is mapped, and then the CD/DVD Virtual drive is used to present the image file to the operating system.
The unused Virtual drive appears as an empty drive to the operating system. The Virtual Media client can map images or hard
drives to both Virtual drives, but RFS can use only one at a time. RFS and Virtual Media features are mutually exclusive.

**NOTE:**

  - RFS1 appears as Virtual Optical or Floppy Drive when there is no active Virtual Media Session, based on the image
attached.

  - RFS1 appears as Virtual Network File 1 when there is an active Virtual Media Session, as Virtual Optical Drive and Virtual
Floppy Drives are consumed with Virtual Media.

Enter all the required information and click **Connect** to connect to the RFS1. To disconnect from RFS1, click **Disconnect** . To
know more about the required field information, see **Online Help** in iDRAC UI.

**NOTE:**

  - iDRAC timeout for RFS connect is 55 s. If any connection takes longer that 55 s, you may get Timeout error.
  - Basic auth and Digest auth for HTTP/HTTPS shares are supported.
  - **Connect** is disabled if the RFS feature is not licensed. **Disconnect** option is always available regardless of the license
status. Click **Disconnect** to disconnect an existing RFS connection.

**Scenarios**

- If the Virtual Media client has not been launched and if you attempt to establish an RFS connection, the connection is
established, and the Remote image is available to the host operating system.

- If the RFS connection is not active and if you attempt to launch the Virtual Media client, the client launches successfully.
You can then use the Virtual Media client to map devices and files to the Virtual Media virtual drives.

- If the RFS1 Session is active, and you attempt to establish an vMedia connection, then vMedia Connection is denied.
- If the Virtual Media client is active, and you attempt to establish an RFS connection, it is possible that the Virtual Optical
Drive/Virtual Floppy assigned to Virtual media and Virtual Network File1 gets assigned to RFS.

**Remote File Share 2 (RFS2)**

RFS2 is only supported from release version 6.00.02.00 onwards.

**NOTE:** RFS2 is not supported for PowerEdge R6415, PowerEdge R7415, and PowerEdge R7425 servers.

The Remote File Share 2 (RFS2) is independent of RFS1 and Virtual media. RFS2 has its own copy of attributes independent
of RFS1. The RFS2 image option has the same behavior as the existing RFS1 on all the iDRAC interfaces. Both are allowed to
connect/disconnect independently. RFS2 is controlled using Enabled/Disabled and Attach Mode RFS2 attributes.

To boot with RFS2 Virtual Network File 2, select **Virtual Network File 2** from boot options. Virtual Media Boot Once has no
impact on RFS2 when enabled.

Enter the required information and click **Connect** to connect to RFS2, and click **Disconnect** to disconnect from RFS2.

When you upload/delete HTTPS certificate in RFS1, the certificate is uploaded/deleted in RFS2 as well. Because this certificate
is for iDRAC's identity, and it remains the same for multiple RFS or any shared connections.

The connection status for RFS is available in the iDRAC log. Once connected, an RFS-mounted virtual drive does not disconnect
even if you log out from iDRAC. The RFS connection is closed if iDRAC is reset or the network connection is dropped. The Web
interface and command-line options are also available in CMCOME Modular and iDRAC to close the RFS connection. The RFS
connection from CMC always overrides an existing RFS mount in iDRAC.

If you update the iDRAC firmware while there is an active RFS connection and the Virtual Media Attach Mode is set to **Attach**
or **Auto Attach**, the iDRAC attempts to reestablish the RFS connection after the firmware upgrade is completed, and the
iDRAC reboots.

If you update the iDRAC firmware while there is an active RFS connection and the Virtual Media Attach Mode is set to **Detach**,
the iDRAC does not attempt to reestablish the RFS connection after the firmware upgrade is completed, and the iDRAC
reboots.

**NOTE:**

  - CIFS and NFS support both IPv4 and IPv6 addresses.
  - While connecting to a remote file share using IPv6 by providing an FQDN, IPv4 must be disabled on the HTTPS server.
  - When the iDRAC is configured with both IPv4 and IPv6, the DNS server can contain records associating the iDRAC
hostname to both addresses. If the IPv4 option is disabled in iDRAC, then iDRAC may not be able to access the external
IPv6 share. This is because the DNS server may still contain IPv4 records, and DNS name resolution can return the IPv4
address. In such cases, it is recommended to delete the IPv4 DNS records from the DNS server, when disabling the IPv4
option in iDRAC.

  - If you are using CIFS and are part of an Active Directory domain, enter the domain name with the IP address in the
image file path.

  - If you want to access a file from an NFS share, configure the following share permissions. These permissions are
required because iDRAC interfaces run in non-root mode.

   - Linux: Ensure that the share permissions are set to at least **Read** for the **Others** account.
   - Windows: Go to the **Security** tab of the share properties and add **Everyone** to **Groups or user names** field with
**Read & execute** privilege.

  - If ESXi is running on the managed system and if you mount a floppy image ( **.img** ) using RFS, the connected floppy
image is not available to the ESXi operating system.

  - iDRAC vFlash feature and RFS are not related.
  - Only English ASCII characters are supported in network share file paths.
  - The operating system drive eject feature is not supported when virtual media is connected using RFS.
  - RFS through HTTP or HTTPS feature is not available on CMC web interface.
  - RFS may get disconnected when iDRAC IP is not reachable for more than 1 minute. Try to remount once the network is
up.

  - While specifying the network share settings, it is recommended to avoid special characters for username, and password
or percent encode the special characters.

  - The following characters are supported for **User Name**, **Password**, and the **Image File Path** fields:
   - A-Z
   - a-z
   - 0-9
   - Special characters: . _ - ? < > / \ :* | @
   - Whitespace
  - For HTTP, do not use the following characters: ! @ # % ^. These characters are supported on other share types.
However, to maintain compatibility, use the recommended characters.

**Folder Mount though RFS**

Starting from iDRAC release 6.10.00.00, iDRAC supports folder mount directly through RFS. This feature allows you to attach a
folder directly without converting to ISO/IMG File.

**NOTE:**

  - This feature is available with the iDRAC Enterprise or Datacenter license.
  - Folder attach is possible only through NFS and CIFS share. HTTP/HTTPS share is not supported.
  - The size of the NFS/CIFS Folder to be attached is limited to 1GB and maximum number of sub-folders is limited to 1000.
  - It is not possible to map an empty folder.

Following scenarios explains how RFS1 and RFS2 are listed in BIOS Boot order:

**Scenario 1:**

If Virtual media is already attached using virtual console, BIOS boot order reports devices as **Virtual Optical** or **Virtual Floppy**
**Drive** depending on the image type. When RFS 1 device is attached, BIOS boot order reports it as **Virtual Network File 1** . For
RFS 2 device, BIOS boot order reports it as **Virtual Network File 2** .

**Scenario 2:**

When no virtual media is attached, and you attach RFS 1 device, BIOS boot order reports it as **Virtual Optical** or **Virtual**
**Floppy Drive** depending on image type. When you attach an RFS 2 device, the BIOS boot order reports it as **Virtual Network**
**File 2** .

**Scenario 3**

When Virtual Media is not connected, and RFS1 is attached:

- Virtual Optical Drive for ISO image
- Virtual Floppy Drive For IMG image

Virtual Media session is going to be blocked as RFS1 session is active.

When Virtual Media is connected and RFS1 is attached, RFS1 is listed as Virtual Network File 1 for both ISO/IMG Image. This is
to maintain compatibility with existing vMedia and RFS, which allows only one at a time. RFS2 is listed as **Virtual Network File**
**2** irrespective of Virtual Media and RFS1.



## Setting boot order through BIOS

Using the System BIOS Settings utility, you can set the managed system to boot from virtual optical drives or virtual floppy
drives.

**NOTE:** Changing Virtual Media while connected may stop the system boot sequence.

To enable the managed system to boot:

1. Boot the managed system.
2. Press <F2> to enter the **System Setup** page.
3. Go to **System BIOS Settings** - **Boot Settings** - **BIOS Boot Settings** - **Boot Sequence** .

In the pop-up window, the virtual optical drives, virtual floppy drives, Virtual Network File 1, and Virtual Network File 2 are
listed with the standard boot devices.

4. Make sure that the virtual drive is enabled and listed as the first device with bootable media. If required, follow the on-screen
instructions to modify the boot order.

5. Click **OK**, navigate back to **System BIOS Settings** page, and click **Finish** .
6. Click **Yes** to save the changes and exit.

The managed system reboots.

The managed system attempts to boot from a bootable device based on the boot order. If the virtual device is connected
and a bootable media is present, the system boots to the virtual device. Otherwise, the system overlooks the device—similar
to a physical device without bootable media.



## Accessing drivers

Dell PowerEdge servers have all the supported operating system drivers embedded on the system flash memory. Using iDRAC,
you can mount or unmount drivers easily to deploy the operating system on your server.

To mount the drivers:

1. On the iDRAC web interface, go to **Configuration** - **Virtual Media** .
2. Click **Mount Drivers** .
3. Select the OS from the pop-up window and click **Mount Drivers** .
**NOTE:** The Expose duration is 18 hours by default.

To unmount the drivers post completion of the mount:

1. Go to **Configuration** - **Virtual Media** .
2. Click **Unmount Drivers** .
3. Click **OK** on the pop-up window.
**NOTE:** The **Mount Drivers** option may not be displayed if the driver pack is not available on the system. Ensure to
[download and install the latest driver pack from Dell Support page.](https://www.dell.com/support)



# 26 Managing vFlash SD card

**NOTE:** vFlash is supported on AMD platform servers.

The vFlash SD card is a Secure Digital (SD) card that can be ordered and installed from the factory. You can use a card with
a maximum of 16 GB capacity. After you insert the card, you must enable vFlash functionality to create and manage partitions.
vFlash is a licensed feature.

**NOTE:** There is no limitation of the size of SD card, you can open and replace the factory installed SD card with a higher
capacity SD card. Since vFlash uses FAT32 file system, file size is limited to 4GB.

If the card is not available in the system's vFlash SD card slot, the following error message is displayed in the iDRAC Web
interface at **Overview** - **Server** - **vFlash** :

```
SD card not detected. Please insert an SD card of size 256MB or greater.

```

**NOTE:** Make sure that you only insert a vFlash compatible SD card in the iDRAC vFlash card slot. If you insert a noncompatible SD card, the following error message is displayed when you initialize the card: **An error has occurred while**
**initializing SD card** .

The key features are:

- Provides storage space and emulates USB device (s).
- Create up to 16 partitions. These partitions, when attached, are exposed to the system as a Floppy drive, Hard Disk drive, or
a CD/DVD drive depending on the selected emulation mode.

- Create partitions from supported file system types. Supports . **img** format for floppy, **.iso** format for CD/DVD, and both **.iso**
and **.img** formats for Hard Disk emulation types.

- Create bootable USB device(s).
- Boot once to an emulated USB device.
**NOTE:** It is possible that a vFlash license may expire during a vFlash operation. If it happens, the on-going vFlash
operations complete normally.

**NOTE:** If FIPS mode is enabled, you cannot perform any vFlash actions.

**Topics:**

- Configuring vFlash SD card
- Managing vFlash partitions



## Configuring vFlash SD card

Before configuring vFlash, ensure that the vFlash SD card is installed on the system. For information about how to install and
remove the card from your system, see the _Installation and Service Manual_ [available on the PowerEdge Manuals page.](https://www.dell.com/poweredgemanuals)

**NOTE:** You must have Access Virtual Media privilege to enable or disable vFlash functionality, and initialize the card.



### Viewing vFlash SD card properties

After vFlash functionality is enabled, you can view the SD card properties using iDRAC Web interface or RACADM.



#### Viewing vFlash SD card properties using web interface

To view the vFlash SD card properties, in the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware**
**Settings** - **vFlash** . The Card Properties page is displayed. For information about the displayed properties, see the **iDRAC**
**Online Help** .



#### Viewing vFlash SD card properties using RACADM

To view the vFlash SD card properties using RACADM, use the `get` command with the following objects:

- iDRAC.vflashsd.AvailableSize
- iDRAC.vflashsd.Health
- iDRAC.vflashsd.Licensed
- iDRAC.vflashsd.Size
- iDRAC.vflashsd.WriteProtect

[For more information about these objects, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Viewing vFlash SD card properties using iDRAC settings utility

To view the vFlash SD card properties, in the **iDRAC Settings Utility**, go to **Media and USB Port Settings** . The **Media**
**and USB Port Settings** page displays the properties. For information about the displayed properties, see the **iDRAC Settings**
**Utility Online Help** .



### Enabling or disabling vFlash functionality

You must enable the vFlash functionality to perform partition management.



#### Enabling or disabling vFlash functionality using web interface

To enable or disable the vFlash functionality:

1. In the iDRAC web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** .
The **SD Card Properties** page is displayed.

2. Select or clear the **vFLASH Enabled** option to enable or disable the vFlash functionality. If any vFlash partition is attached,
you cannot disable vFlash and an error message is displayed.

**NOTE:** If vFlash functionality is disabled, SD card properties are not displayed.

3. Click **Apply** . The vFlash functionality is enabled or disabled based on the selection.



#### Enabling or disabling vFlash functionality using RACADM

To enable or disable the vFlash functionality using RACADM:

```
 racadm set iDRAC.vflashsd.Enable [n]

```

**`n`** =0

Disabled

**`n`** =1

Enabled

**NOTE:** The RACADM command functions only if a vFlash SD card is present. If a card is not present, the following message
is displayed: **ERROR: SD Card not present** .



#### Enabling or disabling vFlash functionality using iDRAC settings utility

To enable or disable the vFlash functionality:

1. In the iDRAC Settings utility, go to **Media and USB Port Settings** .
The **iDRAC Settings . Media and USB Port Settings** page is displayed.

2. In the **vFlash Media** section, select **Enabled** to enable vFlash functionality or select **Disabled** to disable the vFlash
functionality.

3. Click **Back**, click **Finish**, and then click **Yes** .

The vFlash functionality is enabled or disabled based on the selection.



### Initializing vFlash SD card

The initialize operation reformats the SD card and configures the initial vFlash system information on the card.

**NOTE:** If the SD card is write-protected, then the Initialize option is disabled.



#### Initializing vFlash SD card using web interface

To initialize the vFlash SD card:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** .
The **SD Card Properties** page is displayed.

2. Enable **vFLASH** and click **Initialize** .

All existing contents are removed and the card is reformatted with the new vFlash system information.

If any vFlash partition is attached, the initialize operation fails and an error message is displayed.



#### Initializing vFlash SD card using RACADM

To initialize the vFlash SD card using RACADM:

```
 racadm set iDRAC.vflashsd.Initialized 1

```

All existing partitions are deleted and the card is reformatted.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



#### Initializing vFlash SD card using iDRAC settings utility

To initialize the vFlash SD card using iDRAC Settings utility:

1. In the iDRAC Settings utility, go to **Media and USB Port Settings** .
The **iDRAC Settings . Media and USB Port Settings** page is displayed.

2. Click **Initialize vFlash** .
3. Click **Yes** . The initialization operation starts.
4. Click **Back** and navigate to the same **iDRAC Settings . Media and USB Port Settings** page to view the successful
message.
All existing contents are removed and the card is reformatted with the new vFlash system information.



### Getting the last status using RACADM

To get the status of the last initialize command sent to the vFlash SD card:

1. Open SSH or Serial console to the system and log in.
2. Enter the command: `racadm vFlashsd status`

The status of commands sent to the SD card is displayed.

3. To get the last status of all the vflash partitions, use the command: `racadm vflashpartition status -a`
4. To get the last status of a particular partition, use command: `racadm vflashpartition status -i (index)`
**NOTE:** If iDRAC is reset, the status of the last partition operation is lost.



## Managing vFlash partitions

You can perform the following using the iDRAC Web interface or RACADM:

**NOTE:** An administrator can perform all operations on the vFlash partitions. Else, you must have **Access Virtual Media**
privilege to create, delete, format, attach, detach, or copy the contents for the partition.

- Creating an empty partition
- Creating a partition using an image file
- Formatting a partition
- Viewing available partitions
- Modifying a partition
- Attaching or detaching partitions
- Deleting existing partitions
- Downloading partition contents
- Booting to a partition
**NOTE:** If you click any option on the vFlash pages when an application such as WSMan, iDRAC Settings utility, or
RACADM is using vFlash, or if you navigate to some other page in the GUI, iDRAC may display the message: `vFlash is`

`currently in use by another process. Try again after some time` .

vFlash is capable of performing fast partition creation when there is no other on-going vFlash operation such as formatting,
attaching partitions, and so on. Therefore, it is recommended to first create all partitions before performing other individual
partition operations.



### Creating an empty partition

An empty partition, when attached to the system, is similar to an empty USB flash drive. You can create empty partitions on a
vFlash SD card. You can create partitions of type **Floppy** or **Hard Disk** . The partition type CD is supported only while creating
partitions using images.

Before creating an empty partition, make sure that:

- You have **Access Virtual Media** privilege.
- The card is initialized.
- The card is not write-protected.
- An initialize operation is not being performed on the card.



#### Creating an empty partition using the web interface

To create an empty vFlash partition:

1. In iDRAC Web interface, go to **Configuration** - **Systems Settings** - **Hardware Settings** - **vFlash** - **Create Empty**
**Partition** .
The **Create Empty Partition** page is displayed.

2. Specify the required information and click **Apply** . For information about the options, see the **iDRAC Online Help** .

A new unformatted empty partition is created that is read-only by default. A page indicating the progress percentage is
displayed. An error message is displayed if:

  - The card is write-protected.
  - The label name matches the label of an existing partition.
  - A non-integer value is entered for the partition size, the value exceeds the available space on the card, or the partition
size is greater than 4 GB.

  - An initialize operation is being performed on the card.



#### Creating an empty partition using RACADM

To create an empty partition:

1. Log in to the system using SSH or Serial console.
2. Enter the command:

```
  racadm vflashpartition create -i 1 -o drive1 -t empty -e HDD -f fat16 -s [n]

```

where `[n]` is the partition size.

By default, an empty partition is created as read-write.

If the share is not configured using Username / Password, you need to specify the parameters as

```
  -u anonymous -p anonymous

```

.



### Creating a partition using an image file

You can create a new partition on the vFlash SD card using an image file (available in the **.img** or **.iso** format.) The partitions
are of emulation types: Floppy ( **.img** ), Hard Disk ( **.img** ), or CD ( **.iso** ). The created partition size is equal to the image file size.

Before creating a partition from an image file, make sure that:

- You have Access Virtual Media privilege.
- The card is initialized.
- The card is not write-protected.
- An initialize operation is not being performed on the card.
- The image type and the emulation type match.
**NOTE:** The uploaded image and the emulation type must match. There are issues when iDRAC emulates a device with
incorrect image type. For example, if the partition is created using an ISO image and the emulation type is specified as
Hard Disk, then the BIOS cannot boot from this image.

- Image file size is less than or equal to the available space on the card.
- Image file size is less than or equal to 4 GB as the maximum partition size supported is 4 GB. However, while creating a
partition using a Web browser, the image file size must be less than 2 GB.

**NOTE:** The vFlash partition is an image file on a FAT32 file system. Thus, the image file has the 4 GB limitation.

**NOTE:** Installation of a full OS is not supported.



#### Creating a partition using an image file using web interface

To create a vFlash partition from an image file:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Create From Image** .
The **Create Partition from Image File** page is displayed.

2. Enter the required information and click **Apply** . For information about the options, see the **iDRAC Online Help** .

A new partition is created. For CD emulation type, a read-only partition is created. For Floppy or Hard Disk emulation type, a
read-write partition is created. An error message is displayed if:

  - The card is write-protected
  - The label name matches the label of an existing partition.
  - The size of the image file is greater than 4 GB or exceeds the available space on the card.
  - The image file does not exist or the image file extension is neither .img nor .iso.
  - An initialize operation is already being performed on the card.



#### Creating a partition from an image file using RACADM

To create a partition from an image file using RACADM:

1. Log in to the system using SSH or Serial console.
2. Enter the command

```
  racadm vflashpartition create –i 1 –o drive1 –e HDD –t image –l //myserver/
  sharedfolder/foo.iso –u root –p mypassword

```

By default, the created partition is read-only. This command is case sensitive for the image file name extension. If the file
name extension is in upper case, for example FOO.ISO instead of FOO.iso, then the command returns a syntax error.

**NOTE:** This feature is not supported in local RACADM.

**NOTE:** Creating vFlash partition from an image file located on the CFS or NFS IPv6 enabled network share is not
supported.

If the share is not configured using Username / Password, you need to specify the parameters as

```
  -u anonymous -p anonymous

```

.



### Formatting a partition

You can format an existing partition on the vFlash SD card based on the type of file system. The supported file system types
are EXT2, EXT3, FAT16, and FAT32. You can only format partitions of type Hard Disk or Floppy, and not CD. You cannot format
read-only partitions.

Before creating a partition from an image file, ensure that:

- You have **Access Virtual Media** privilege.
- The card is initialized.
- The card is not write-protected.
- An initialize operation is not being performed on the card.

To format vFlash partition:

1. In iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Format** .
The **Format Partition** page is displayed.

2. Enter the required information and click **Apply** .

For information about the options, see the **iDRAC Online Help** .

A warning message indicating that all the data on the partition will be erased is displayed.

3. Click **OK** .

The selected partition is formatted to the specified file system type. An error message is displayed if:

  - The card is write-protected.
  - An initialize operation is already being performed on the card.



### Viewing available partitions

Make sure that the vFlash functionality is enabled to view the list of available partitions.



#### Viewing available partitions using web interface

To view the available vFlash partitions, in the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware**
**Settings** - **vFlash** - **Manage** . The **Manage Partitions** page is displayed listing the available partitions and related information
for each partition. For information on the partitions, see the **iDRAC Online Help** .



#### Viewing available partitions using RACADM

To view the available partitions and their properties using RACADM:

1. Open a SSH or Serial console to the system and log in.
2. Enter the following commands:
  - To list all existing partitions and its properties: `racadm vflashpartition list`
  - To get the status of operation on partition 1: `racadm vflashpartition status -i 1`
  - To get the status of all existing partitions: `racadm vflashpartition status -a`
**NOTE:** The -a option is valid only with the status action.



### Modifying a partition

You can change a read-only partition to read-write or vice-versa. Before modifying the partition, make sure that:

- The vFlash functionality is enabled.
- You have **Access Virtual Media** privileges.
**NOTE:** By default, a read-only partition is created.



#### Modifying a partition using web interface

To modify a partition:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Manage** .
The **Manage Partitions** page is displayed.

2. In the **Read-Only** column:
  - Select the checkbox for the partition(s) and click **Apply** to change to read-only.
  - Clear the checkbox for the partition(s) and click **Apply** to change to read-write.
**NOTE:** The partitions are changed to read-only or read-write, based on the selections.

**NOTE:** If the partition is of type CD, the state is read-only. You cannot change the state to read-write. If the partition is
attached, the check box is grayed-out.



#### Modifying a partition using RACADM

To view the available partitions and their properties on the card:

1. Log in to the system using SSH or Serial console.
2. Use one of the following:
  - Using `set` command to change the read-write state of the partition:
   - To change a read-only partition to read-write:

```
     racadm set iDRAC.vflashpartition.<index>.AccessType 1

```

   - To change a read-write partition to read-only:

```
     racadm set iDRAC.vflashpartition.<index>.AccessType 0

```

  - Using `set` command to specify the Emulation type:

```
    racadm set iDRAC.vflashpartition.<index>.EmulationType <HDD, Floppy, or CD-DVD>

```



### Attaching or detaching partitions

When you attach one or more partitions, they are visible to the operating system and BIOS as USB mass storage devices. When
you attach multiple partitions, based on the assigned index, they are listed in an ascending order in the operating system and the
BIOS boot order menu.

If you detach a partition, it is not visible in the operating system and the BIOS boot order menu.

When you attach or detach a partition, the USB bus in the managed system is reset. This affects applications that are using
vFlash and disconnects the iDRAC Virtual Media sessions.

Before attaching or detaching a partition, make sure that:

- The vFlash functionality is enabled.
- An initialize operation is not already being performed on the card.
- You have **Access Virtual Media** privileges.



#### Attaching or detaching partitions using web interface

To attach or detach partitions:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Manage** .
The **Manage Partitions** page is displayed.

2. In the **Attached** column:
  - Select the checkbox for the partition(s) and click **Apply** to attach the partition(s).
  - Clear the checkbox for the partition(s) and click **Apply** to detach the partition(s).
**NOTE:** The partitions are attached or detached, based on the selections.



#### Attaching or detaching partitions using RACADM

To attach or detach partitions:

1. Log in to the system using SSH or Serial console.
2. Use the following commands:
  - To attach a partition:

```
    racadm set iDRAC.vflashpartition.<index>.AttachState 1

```

  - To detach a partition:

```
    racadm set iDRAC.vflashpartition.<index>.AttachState 0



#### Operating system behavior for attached partitions

```

For Windows and Linux operating systems:

- The operating system controls and assigns the drive letters to the attached partitions.
- Read-only partitions are read-only drives in the operating system.
- The operating system must support the file system of an attached partition. Else, you cannot read or modify the contents
of the partition from the operating system. For example, in a Windows environment the operating system cannot read the
partition type EXT2 which is native to Linux. Also, in a Linux environment the operating system cannot read the partition
type NTFS which is native to Windows.

- The vFlash partition label is different from the volume name of the file system on the emulated USB device. You can change
the volume name of the emulated USB device from the operating system. However, it does not change the partition label
name stored in iDRAC.



### Deleting existing partitions

Before deleting existing partition(s), make sure that:

- The vFlash functionality is enabled.
- The card is not write-protected.
- The partition is not attached.
- An initialize operation is not being performed on the card.



#### Deleting existing partitions using web interface

To delete an existing partition:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Manage** .
The **Manage Partitions** page is displayed.

2. In the **Delete** column, click the delete icon for the partition that you want to delete.

A message is displayed indicating that this action permanently deletes the partition.

3. Click **OK** .

The partition is deleted.



#### Deleting existing partitions using RACADM

To delete partitions:

1. Open a SSH or Serial console to the system and log in.
2. Enter the following commands:
  - To delete a partition:

```
    racadm vflashpartition delete -i 1

```

  - To delete all partitions, re-initialize the vFlash SD card.



### Downloading partition contents

You can download the contents of a vFlash partition in the **.img** or **.iso** format to the:

- Managed system (where iDRAC is operated from)
- Network location mapped to a management station.

Before downloading the partition contents, make sure that:

- You have Access Virtual Media privileges.
- The vFlash functionality is enabled.
- An initialize operation is not being performed on the card.
- For a read-write partition, it must not be attached.

To download the contents of the vFlash partition:

1. In the iDRAC Web interface, go to **Configuration** - **System Settings** - **Hardware Settings** - **vFlash** - **Download** .
The **Download Partition** page is displayed.

2. From the **Label** drop-down menu, select a partition that you want to download and click **Download** .
**NOTE:** All existing partitions (except attached partitions) are displayed in the list. The first partition is selected by
default.

3. Specify the location to save the file.

The contents of the selected partition are downloaded to the specified location.

**NOTE:** If only the folder location is specified, then the partition label is used as the file name, along with the
extension **.iso** for CD and Hard Disk type partitions, and **.img** for Floppy and Hard Disk type partitions.



### Booting to a partition

You can set an attached vFlash partition as the boot device for the next boot operation.

Before booting a partition, make sure that:

- The vFlash partition contains a bootable image (in the **.img** or **.iso** format) to boot from the device.
- The vFlash functionality is enabled.
- You have Access Virtual Media privileges.



#### Booting to a partition using web interface

To set the vFlash partition as a first boot device, see Booting to a partition using web interface.

**NOTE:** If the attached vFlash partition(s) are not listed in the **First Boot Device** drop-down menu, make sure that the
BIOS is updated to the latest version.



#### Booting to a partition using RACADM

To set a vFlash partition as the first boot device, use the `iDRAC.ServerBoot` object.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)

**NOTE:** When you run this command, the vFlash partition label is automatically set to boot once
( `iDRAC.ServerBoot.BootOnce` is set to `1` .) Boot once boots the device to the partition only once and does not keep it

persistently first in the boot order.



# 27 Using SMCLP

**NOTE:** SMCLP is only supported in iDRAC versions earlier than 4.00.00.00.

The Server Management Command-Line Protocol (SMCLP) specification enables CLI-based systems management. It defines a
protocol for management commands transmitted over standard character-oriented streams. This protocol accesses a Common
Information Model Object Manager (CIMOM) using a human-oriented command set. The SMCLP is a subcomponent of the
Distributed Management Task Force (DMTF) SMASH initiative to streamline systems management across multiple platforms.
The SMCLP specification, along with the Managed Element Addressing Specification and numerous profiles to SMCLP-mapping
specifications, describes the standard verbs and targets for various management task executions.

**NOTE:** It is assumed that you are familiar with the Systems Management Architecture for Server Hardware (SMASH)
Initiative and the Server Management Working Group (SMWG) SMCLP specifications.

The SM-CLP is a subcomponent of the Distributed Management Task Force (DMTF) SMASH initiative to streamline server
management across multiple platforms. The SM-CLP specification, along with the Managed Element Addressing Specification
and numerous profiles to SM-CLP mapping specifications, describes the standard verbs and targets for various management
task executions.

The SMCLP is hosted from the iDRAC controller firmware and supports SSH and serial-based interfaces. The iDRAC SMCLP
interface is based on the SMCLP Specification Version 1.0 provided by the DMTF organization.

**NOTE:** [Information about the profiles, extensions, and MOFs are available at Dell Support page and all DMTF information is](https://www.dell.com/support)
available at **dmtf.org/standards/profiles/** .

SM-CLP commands implement a subset of the local RACADM commands. The commands are useful for scripting since you can
perform these commands from a management station command line. You can retrieve the output of commands in well-defined
formats, including XML, facilitating scripting and integration with existing reporting and management tools.

**Topics:**

- System management capabilities using SMCLP
- Running SMCLP commands
- iDRAC SMCLP syntax
- Navigating the map address space
- Using show verb
- Usage examples



## System management capabilities using SMCLP

iDRAC SMCLP enables you to:

- Manage Server Power — Turn on, shut down, or reboot the system
- Manage System Event Log (SEL) — Display or clear the SEL records
- View iDRAC user accounts
- View system properties



## Running SMCLP commands

You can run the SMCLP commands using SSH interface. Open an SSH and log in to iDRAC as an administrator. The SMCLP
prompt (admin ->)is displayed.

SMCLP prompts:

- yx1x blade servers use `-$` .
- yx1x rack and tower servers use `admin->` .
- yx2x blade, rack, and tower servers use `admin->` .

where, y is an alpha-numeric character such as M (for blade servers), R (for rack servers), and T (for tower servers) and x is a
number. This indicates the generation of Dell PowerEdge servers.

**NOTE:** Scripts using `-$` can use these for yx1x systems, but starting with yx2x systems one script with `admin->` can be

used for blade, rack, and tower servers.



## iDRAC SMCLP syntax

The iDRAC SMCLP uses the concept of verbs and targets to provide systems management capabilities through the CLI. The
verb indicates the operation to perform, and the target determines the entity (or object) that runs the operation.

The SMCLP command line syntax:

```
<verb> [<options>] [<target>] [<properties>]

```

The following table provides the verbs and its definitions.

**Table 68. SMCLP verbs**

|Verb|Definition|
|---|---|
|cd|Navigates through the MAP using the shell|
|set|Sets a property to a specific value|
|help|Displays help for a specific target|
|reset|Resets the target|
|show|Displays the target properties, verbs, and subtargets|
|start|Turns on a target|
|stop|Shuts down a target|
|exit|Exits from the SMCLP shell session|
|version|Displays the version attributes of a target|
|load|Moves a binary image to a specified target address from a<br>URL|

The following table provides a list of targets.

**Table 69. SMCLP targets**

|Target|Definitions|
|---|---|
|`admin1`|admin domain|
|`admin1/profiles1`|Registered profiles in iDRAC|
|`admin1/hdwr1`|Hardware|
|`admin1/system1`|Managed system target|
|`admin1/system1/capabilities1`|Managed system SMASH collection capabilities|
|`admin1/system1/capabilities1/elecap1`|Managed system target capabilities|
|`admin1/system1/logs1`|Record Log collections target|
|`admin1/system1/logs1/log1`|System Event Log (SEL) record entry|
|`admin1/system1/logs1/log1/record*`|An individual SEL record instance on the managed system|
|`admin1/system1/settings1`|Managed system SMASH collection settings|
|`admin1/system1/capacities1`|Managed system capacities SMASH collection|
|`admin1/system1/consoles1`|Managed system consoles SMASH collection|
|`admin1/system1/sp1`|Service Processor|
|`admin1/system1/sp1/timesvc1`|Service Processor time service|
|`admin1/system1/sp1/capabilities1`|Service processor capabilities SMASH collection|
|`admin1/system1/sp1/capabilities1/clpcap1`|CLP service capabilities|
|`admin1/system1/sp1/capabilities1/`<br>`pwrmgtcap1`|Power state management service capabilities on the system|
|`admin1/system1/sp1/capabilities1/`<br>`acctmgtcap*`|Account management service capabilities|
|`admin1/system1/sp1/capabilities1/`<br>`rolemgtcap*`|Local Role Based Management capabilities|
|`admin1/system1/sp1/capabilities1/elecap1`|Authentication capabilities|
|`admin1/system1/sp1/settings1`|Service Processor settings collection|
|`admin1/system1/sp1/settings1/clpsetting1`|CLP service settings data|
|`admin1/system1/sp1/clpsvc1`|CLP service protocol service|
|`admin1/system1/sp1/clpsvc1/clpendpt*`|CLP service protocol endpoint|
|`admin1/system1/sp1/clpsvc1/tcpendpt*`|CLP service protocol TCP endpoint|

**Table 69. SMCLP targets (continued)**

|Target|Definitions|
|---|---|
|`admin1/system1/sp1/jobq1`|CLP service protocol job queue|
|`admin1/system1/sp1/jobq1/job*`|CLP service protocol job|
|`admin1/system1/sp1/pwrmgtsvc1`|Power state management service|
|`admin1/system1/sp1/account1-16`|Local user account|
|`admin1/sysetm1/sp1/account1-16/identity1`|Local user identity account|
|`admin1/sysetm1/sp1/account1-16/identity2`|IPMI identity (LAN) account|
|`admin1/sysetm1/sp1/account1-16/identity3`|IPMI identity (Serial) account|
|`admin1/sysetm1/sp1/account1-16/identity4`|CLP identity account|
|`admin1/system1/sp1/acctsvc2`|IPMI account management service|
|`admin1/system1/sp1/acctsvc3`|CLP account management service|
|`admin1/system1/sp1/rolesvc1`|Local Role Base Authorization (RBA) service|
|`admin1/system1/sp1/rolesvc1/Role1-16`|Local role|
|`admin1/system1/sp1/rolesvc1/Role1-16/`<br>`privilege1`|Local role privilege|
|`admin1/system1/sp1/rolesvc2`|IPMI RBA service|
|`admin1/system1/sp1/rolesvc2/Role1-3`|IPMI role|
|`admin1/system1/sp1/rolesvc2/Role4`|IPMI Serial Over LAN (SOL) role|
|`admin1/system1/sp1/rolesvc3`|CLP RBA Service|
|`admin1/system1/sp1/rolesvc3/Role1-3`|CLP role|
|`admin1/system1/sp1/rolesvc3/Role1-3/`<br>`privilege1`|CLP role privilege|



## Navigating the map address space

Objects that can be managed with SM-CLP are represented by targets arranged in a hierarchical space called the Manageability
Access Point (MAP) address space. An address path specifies the path from the root of the address space to an object in the
address space.

The root target is represented by a slash (/) or a backslash (\). It is the default starting point when you log in to iDRAC.
Navigate down from the root using the `cd` verb.

**NOTE:** The slash (/) and backslash (\) are interchangeable in SM-CLP address paths. However, a backslash at the end of a
command line continues the command on the next line and is ignored when the command is parsed.

For example to navigate to the third record in the System Event Log (SEL), enter the following command:

```
->cd /admin1/system1/logs1/log1/record3

```

Enter the `cd` verb with no target to find your current location in the address space. The `..` and `.` abbreviations work as they do
in Windows and Linux: `..` refers to the parent level and `.` refers to the current level.



## Using show verb

To learn more about a target use the `show` verb. This verb displays the target’s properties, sub-targets, associations, and a list
of the SM-CLP verbs that are allowed at that location.



### Using the -display option

The `show –display` option allows you to limit the output of the command to one or more of properties, targets, associations,
and verbs. For example, to display just the properties and targets at the current location, use the following command:

```
show -display properties,targets

```

To list only certain properties, qualify them, as in the following command:

```
show –d properties=(userid,name) /admin1/system1/sp1/account1

```

If you only want to show one property, you can omit the parentheses.



### Using the -level option

The `show -level` option runs the `show` command on additional levels below the specified target. To see all targets and
properties in the address space, use the `-l all` option.



### Using the -output option

The `-output` option specifies one of four formats for the output of SM-CLP verbs: **text**, **clpcsv**, **keyword**, and **clpxml** .

The default format is **text**, and is the most readable output. The **clpcsv** format is a comma-separated values format suitable
for loading into a spreadsheet program. The **keyword** format outputs information as a list of keyword=value pairs one per line.
The **clpxml** format is an XML document containing a **response** XML element. The DMTF has specified the **clpcsv** and **clpxml**
formats and their specifications can be found on the DMTF website at **dmtf.org** .

The following example shows how to output the contents of the SEL in XML:

```
show -l all -output format=clpxml /admin1/system1/logs1/log1



## Usage examples

```

This section provides use case scenarios for SMCLP:

- Server power management
- SEL management
- Map target navigation



### Server power management

The following examples show how to use SMCLP to perform power management operations on a managed system.

Type the following commands at the SMCLP command prompt:

- To switch off the server: `stop /system1` The following message is displayed: `system1 has been stopped`
```
  successfully
```

- To switch on the server: `start /system1` The following message is displayed: `system1 has been started`
```
  successfully
```

- To reboot the server: `reset /system1` The following message is displayed: `system1 has been reset`
```
  successfully



### SEL management

```

The following examples show how to use the SMCLP to perform SEL-related operations on the managed system. Type the
following commands at the SMCLP command prompt:

- To view the SEL: `show/system1/logs1/log1` The following output is displayed `:`
  - `/system1/logs1/log1`
  - `Targets:`
  - `Record1`
  - `Record2`
  - `Record3`
  - `Record4`
  - `Record5`
  - `Properties:`
  - `InstanceID = IPMI:BMC1 SEL Log`
  - `MaxNumberOfRecords = 512`
  - `CurrentNumberOfRecords = 5`
  - `Name = IPMI SEL`
  - `EnabledState = 2`
  - `OperationalState = 2`
  - `HealthState = 2`
  - `Caption = IPMI SEL`
  - `Description = IPMI SEL`
  - `ElementName = IPMI SEL`
  - `Commands:`
  - `cd`
  - `show`
  - `help`
  - `exit`
  - `version`
- To view the SEL record: `show/system1/logs1/log1` The following output is displayed `:`
  - `/system1/logs1/log1/record4`
  - `Properties:`
  - `LogCreationClassName= CIM_RecordLog`
  - `CreationClassName= CIM_LogRecord`
  - `LogName= IPMI SEL`
  - `RecordID= 1`
  - `MessageTimeStamp= 20050620100512.000000-000`
  - `Description= FAN 7 RPM: fan sensor, detected a failure`
  - `ElementName= IPMI SEL Record`
  - `Commands:`
  - `cd`
  - `show`
  - `helpexit`
  - `version`



### Map target navigation

The following examples show how to use the cd verb to navigate the MAP. In all examples, the initial default target is assumed
to be /.

Type the following commands at the SMCLP command prompt:

- To navigate to the system target and reboot: cd system1 reset The current default target is /.
- To navigate to the SEL target and display the log records:
  - `cd system1`
  - `cd logs1/log1`
  - `show`
- To display current target: type `cd .`
- To move up one level: type `cd ..`
- To exit: `exit`



# 28 Installing operating systems

You can use any of the following utilities to deploy operating systems to managed systems:

- Remote File Share
- Console
**Topics:**

- Deploying an operating system using remote file share
- Deploying operating system using virtual media
- Deploying embedded operating system on SD card



## Deploying an operating system using remote file share

Before you deploy the operating system using Remote File Share (RFS), ensure that:

- **Configure** **User** and **Access Virtual Media** privileges for iDRAC are enabled for the user.
- Network share contains drivers and operating system bootable image file, in an industry standard format such as **.img**, **.iso**,
or **folder path** .

**NOTE:** While creating the image file, follow standard network-based installation procedures, and mark the deployment
image as read-only to make sure that each target system boots and runs the same deployment procedure.

To deploy an operating system using RFS:

1. Using Remote File Share (RFS), mount the ISO or IMG image file to the managed system through NFS, CIFS, HTTP, or
HTTPs.

2. Go to **Configuration** - **System Settings** - **Hardware Settings** - **First Boot Device** .
3. Set the boot order in the **First Boot Device** list to select a virtual media such as floppy, CD, DVD, ISO, Virtual Network File
1, and Virtual Network File 2.

4. Select the **Boot Once** option to enable the managed system to reboot using the image file for the next instance only.
5. Click **Apply** .
6. Reboot the managed system and follow the on-screen instructions to complete the deployment.



### Managing remote file shares

Using Remote File Share (RFS) feature, you can set an ISO or IMG image file on a network share and make it available to the
managed server’s operating system as a virtual drive by mounting it as a CD or DVD using NFS, CIFS, HTTP or HTTPs. RFS is a
licensed feature.

Remote file share supports only **.img** and **.iso** image file formats. A **.img** file is redirected as a virtual floppy and a **.iso** file is
redirected as a virtual CDROM.

You must have Virtual Media privileges to perform an RFS mounting.

This feature is available only with the iDRAC Enterprise or Datacenter license.



### Configuring remote file share using web interface

To enable remote file sharing:

1. In the iDRAC web interface, go to **Configuration** - **Virtual Media** - **Attached Media** .
The **Attached Media** page is displayed.

2. Under **Attached Media**, select **Attach** or **Auto Attach** .
3. Under **Remote File Share**, specify the **Directory/File Path**, **Domain Name**, **User Name**, and **Password** . For information
about the fields, see the **iDRAC Online Help** .

Examples for image file path:

  - CIFS — `//<IP to connect for CIFS file system>/<file path>/<image name>`
  - NFS— `< IP to connect for NFS file system>:/<file path>/<image name>`
  - HTTP— `http://<URL>/<file path>/<image name>`
  - HTTPs— `https://<URL>/<file path>/<image name>`
**NOTE:** To avoid I/O errors when using CIFS shares hosted on Windows 7 systems, modify the following registry keys:

   - Set HKLM\SYSTEM\CurrentControlSet\Control\Session Manager\Memory Management\LargeSystemCache to `1`
   - Set HKLM\SYSTEM\CurrentControlSet\Services\LanmanServer\Parameters\Size to `3`
**NOTE:** Both '/' or '\' characters can be used for the file path.

CIFS supports both IPv4 and IPv6 addresses, but NFS supports only the IPv4 address.

If you are using NFS share, ensure that you provide the exact <file path> and <image name> as it is case-sensitive.

**NOTE:** For information about recommended characters for user names and passwords, see Reccommended characters
in user names and passwords..

**NOTE:** The characters that are allowed in user names and passwords for network shares are determined by the
network-share type. iDRAC supports valid characters for network share credentials as defined by the share type, except
<, >, and, (comma).

4. Click **Apply** and then click **Connect** .

After the connection is established, the **Connection Status** displays **Connected** .

**NOTE:** Even if you have configured remote file sharing, the Web interface does not display user credential information
due to security reasons.

**NOTE:** If the image path contains user credentials, use HTTPS to avoid the credentials from displaying in the UI and
RACADM. If entering the credentials in the URL, avoid using "@" symbol, because it is a separator character.

For Linux distributions, this feature may require a manual mount command when operating at run level init 3. The syntax for
the command is:

```
  mount /dev/OS_specific_device / user_defined_mount_point

```

Where, `user_defined_mount_point` is any directory you choose to use for the mount similar to any mount command.

For RHEL, the CD device ( **.iso** virtual device) is `/dev/scd0` and floppy device ( **.img** virtual device) is `/dev/sdc` .

For SLES, the CD device is `/dev/sr0` and the floppy device is `/dev/sdc` . Ensure that the correct device is used (for
either SLES or RHEL). When you connect the virtual device on the Linux operating system, run the following command
immediately:

```
  tail /var/log/messages | grep SCSI

```

This displays the text that identifies the device (example, SCSI device sdc). This procedure also applies to Virtual Media
when you are using Linux distributions in run level init 3. By default, the virtual media is not automounted in init 3.



### Configuring remote file share using RACADM

To configure remote file share using RACADM, use:

```
racadm remoteimage

racadm remoteimage <options>

```

Options are:

`–c` : connect image

`–d` : disconnect image

`–u` <username>: username to access the shared folder

`–p` <password>: password to access the shared folder

`–l` <image_location>: image location on the network share; use double quotes around the location. See examples for image file
path in Configuring Remote File Share Using Web Interface section

`–s` : display current Remote Image status



## Usage Examples

- CIFS based RFS:

```
  racadm remoteimage -c -u "user" -p "pass" -l //shrloc/foo.iso

```

- NFS Based RFS:

```
  racadm remoteimage -c -u "user" -p "pass" -l <nfs ip>:/shrloc/foo.iso

```

- HTTP/HTTPS Based RFS:

```
  racadm remoteimage -c -u "user" -p "pass" -l http://url/shrloc/foo.iso

  racadm remoteimage -c -l https://url/shareloc/foo.iso

```

- Disconnect from the remote image:

```
  racadm remoteimage -d

```

- Display current Remote Image status:
**NOTE:** -u and -p options are mandatory if the share type is cifs.

**NOTE:** All characters including alphanumeric and special characters are allowed as part of user name, password, and
image_location except the following characters: ’ (single quote), “(double quote),,(comma), < (less than), and > (greater
than).

**NOTE:** To avoid I/O errors when using CIFS shares hosted on Windows 7 systems, modify the following registry keys:

  - Set HKLM\SYSTEM\CurrentControlSet\Control\Session Manager\Memory Management\LargeSystemCache to `1`
  - Set HKLM\SYSTEM\CurrentControlSet\Services\LanmanServer\Parameters\Size to `3`

For help on viewing the properties of a group, run the command `- racadm help get` .

For help on configuring the properties of a group, run the command `- racadm help set` .

```
racadm>>help remoteimage2

```

**NOTE:** remoteimage2 -- makes a remote ISO image available to the server. It requires Remote File Share license.

**Usage**

```
racadm remoteimage2 -c -u <user> -p <pass> -l <image_location>

racadm remoteimage2 -d

racadm remoteimage2 -s

```

Options are:

`–c` : connect image

`–d` : disconnect image

`–u` <username>: username to access the shared folder

`–p` <password>: password to access the shared folder

`–l` <image_location>: image location on the network share; use double quotes around the location. See examples for image file
path in Configuring Remote File Share Using Web Interface section

`–s` : display current Remote Image status

## Usage Examples

- CIFS based RFS:

```
  racadm remoteimage2 -c -u "user" -p "pass" -l //shrloc/foo.iso

```

- NFS Based RFS:

```
  racadm remoteimage2 -c -u "user" -p "pass" -l <nfs ip>:/shrloc/foo.iso

```

- HTTP/HTTPS Based RFS:

```
  racadm remoteimage2 -c -u "user" -p "pass" -l http://url/shrloc/foo.iso

  racadm remoteimage2 -c -l https://url/shareloc/foo.iso

```

- Disconnect from the remote image:

```
  racadm remoteimage2 -d

```

- Display current Remote Image status:
**NOTE:** -u and -p options are mandatory if the share type is cifs.

For help on viewing the properties of a group, run the command `- racadm help get` .

For help on configuring the properties of a group, run the command `- racadm help set` .



## Deploying operating system using virtual media

Before you deploy the operating system using Virtual Media, make sure that:

- Virtual Media is in **Attached** state for the virtual drives to appear in the boot sequence.
- If Virtual Media is in **Auto Attached** mode, the Virtual Media application must be launched before booting the system.
- Network share contains drivers and operating system bootable image file, in an industry standard format such as **.img**
or **.iso** .

To deploy an operating system using Virtual Media:

1. Do one of the following:
  - Insert the operating system installation CD or DVD into the management station CD or DVD drive.
  - Attach the operating system image.
2. Select the drive on the management station with the required image to map it.
3. Use one of the following methods to boot to the required device:
  - Set the boot order to boot once from **Virtual Floppy** or **Virtual CD/DVD/ISO** using the iDRAC Web interface.
  - Set the boot order through **System Setup**  - **System BIOS Settings** by pressing <F2> during boot.
4. Reboot the managed system and follow the on-screen instructions to complete the deployment.



## Deploying embedded operating system on SD card

To install an embedded hypervisor on an SD card:

1. Insert the two SD cards in the Internal Dual SD Module (IDSDM) slots on the system.
2. Enable SD module and redundancy (if required) in BIOS.
3. Verify if the SD card is available on one of the drives when you <F11> during boot.
4. Deploy the embedded operating system and follow the operating system installation instructions.



### Enabling SD module and redundancy in BIOS

To enable SD module and redundancy in BIOS:

1. Press <F2> during boot.
2. Go to **System Setup** - **System BIOS Settings** - **Integrated Devices** .
3. Set the **Internal USB Port** to **On** . If it is set to **Off**, the IDSDM is not available as a boot device.
4. If redundancy is not required (single SD card), set **Internal SD Card Port** to **On** and **Internal SD Card Redundancy** to
**Disabled** .

5. If redundancy is required (two SD cards), set **Internal SD Card Port** to **On** and **Internal SD Card Redundancy** to **Mirror** .
6. Click **Back** and click **Finish** .
7. Click **Yes** to save the settings and press <Esc> to exit **System Setup** .



#### About IDSDM

Internal Dual SD Module (IDSDM) is available only on applicable platforms. IDSDM provides redundancy on the hypervisor SD
card by using another SD card that mirrors the first SD card’s content.

Either of the two SD cards can be the master. For example, if two new SD cards are installed in the IDSDM, SD1 is active
(master) card and SD2 is the standby card. The data is written on both the cards, but the data is read from SD1. At any time if
SD1 fails or is removed, SD2 automatically become the active (master) card.

You can view the status, health, and the availability of IDSDM using iDRAC Web Interface or RACADM. The SD card redundancy
status and failure events are logged to SEL, displayed on the front panel, and PET alerts are generated if alerts are enabled.



# 29 Troubleshooting managed system using iDRAC

You can diagnose and troubleshoot a remote managed system using:

- Diagnostic console
- Post code
- Boot and crash capture videos
- Last system crash screen
- System event logs
- Lifecycle logs
- Front panel status
- Trouble indicators
- System health
**Topics:**

- Using diagnostic console
- Viewing post codes
- Viewing boot and crash capture videos
- Viewing logs
- Viewing last system crash screen
- Viewing System status
- Hardware trouble indicators
- Viewing system health
- Checking server status screen for error messages
- Restarting iDRAC
- Reset to Custom Defaults (RTD)
- Erasing system and user data
- Resetting iDRAC to factory default settings



## Using diagnostic console

iDRAC provides a standard set of network diagnostic tools that are similar to the tools included with Microsoft Windows or
Linux-based systems. Using iDRAC Web interface, you can access the network debugging tools.

To access Diagnostics Console:

1. In the iDRAC Web interface, go to **Maintenance** - **Diagnostics** .
The **Diagnostics Console Command** page is displayed.

2. In the **Command** text box, enter a command and click **Submit** . For information about the commands, see the **iDRAC**
**Online Help** .
The results are displayed on the same page.



### Reset iDRAC and Reset iDRAC to default

1. In the iDRAC Web interface, go to **Maintenance** - **Diagnostics** .
You have the following options:

  - Click **Reset iDRAC** to reset the iDRAC. A normal reboot operation is performed on the iDRAC. After reboot, refresh the
browser to reconnect and log in to iDRAC.

  - Click **Reset iDRAC to Default Settings** to reset the iDRAC to the default settings. After you click **Reset iDRAC to**
**Default Settings**, **Reset iDRAC to factory default window** is displayed. This action reset the iDRAC to the factory
defaults. Chose any of the following options:
a. Preserve user and network settings.
b. Discard all settings and reset users to the shipping value (root/shipping value).
c. Discard all settings and reset username and password.

2. A warning message is displayed. Click **Ok** to proceed further.



### Scheduling remote automated diagnostics

You can remotely invoke automated offline diagnostics on a server as a one-time event and return the results. If the diagnostics
require a reboot, you can reboot immediately or stage it for a subsequent reboot or maintenance cycle (similar to updates).
When diagnostics are run, the results are collected and stored in the internal iDRAC storage. You can then export the results
to an NFS, CIFS, HTTP, or HTTPs network share using the `diagnostics export` racadm command. You can also run
diagnostics using the appropriate WSMan command(s). For more information, see the WSMan documentation.

You must have iDRAC Express license to use remote automated diagnostics.

You can perform the diagnostics immediately or schedule it on a particular day and time, specify the type of diagnostics, and the
type of reboot.

For the schedule, you can specify the following:

- Start time – Run the diagnostic at a future day and time. If you specify TIME NOW, the diagnostic is run on the next reboot.
- End time - Run the diagnostic until a date and time after the Start time. If it is not started by End time, it is marked as failed
with End time expired. If you specify TIME NA, then the wait time is not applicable.

The types of diagnostic tests are:

- Express test
- Extended test
- Both in a sequence

The types of reboot are:

- Power cycle system
- Graceful shutdown (waits for operating system to turn off or for system restart)
- Forced Graceful shutdown (signals operating system to turn off and waits for 10 minutes. If the operating system does not
turn off, the iDRAC power cycles the system)

Only one diagnostic job can be scheduled or run at one time. A diagnostic job can complete successfully, complete with error, or
is unsuccessful. The diagnostic events including the results are recorded in Lifecycle Controller log. You can retrieve the results
of the last diagnostic execution using remote RACADM or WSMan.

You can export the diagnostic results of the last completed diagnostics that were scheduled remotely to a network share such
as CIFS, NFS, HTTP or HTTPS. The maximum file size is 5 MB.

You can cancel a diagnostic job when the status of the job is Unscheduled or Scheduled. If the diagnostic is running, then restart
the system to cancel the job.

Before you run the remote diagnostics, make sure that:

- Lifecycle Controller is enabled.
- You have Login and Server Control privileges.



### Scheduling remote automated diagnostics and exporting the results using RACADM

- To run the remote diagnostics and save the results on the local system, use the following command:

```
  racadm diagnostics run -m <Mode> -r <reboot type> -s <Start Time> -e <Expiration Time>

```

- To export the diagnostic results, ensure that the server is in the **Out of POST** state, and LC is in the **Ready** state. To check
the status of LC and server, run the following command:

```
  racadm getremoteservicesstatus

```

- To export the last run remote diagnostics results, use the following command:

```
  racadm diagnostics export -f <file name> -l <NFS / CIFS / HTTP / HTTPs share> -u
  <username> -p <password>

```

[For more information about the options, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Viewing post codes

Post codes are progress indicators from the system BIOS, indicating various stages of the boot sequence from power-on-reset,
and allows you to diagnose any faults related to system boot-up. The **Post Codes** page displays the last system post code prior
to booting the operating system.

To view the Post Codes, go to **Maintenance** - **Troubleshooting** - **Post Code** .

The **Post Code** page displays the system health indicator, a hexadecimal code, and a description of the code.



## Viewing boot and crash capture videos

You can view the video recordings of:

- **Last three boot cycles** - A boot cycle video logs the sequence of events for a boot cycle. The boot cycle videos are
arranged in the order of latest to oldest.

- **Last crash video** - A crash video logs the sequence of events leading to the failure.
**NOTE:** Crash video feature is enabled by default. You can enable or disable based on the requirement.

This is a licensed feature.

iDRAC records fifty frames during boot time. Playback of the boot screens occur at a rate of 1 frame per second. If iDRAC is
reset, the boot capture video is not available as it is stored in RAM and is deleted.

**NOTE:**

  - You must have Access Virtual Console or administrator privileges to playback the Boot Capture and Crash Capture
videos.

  - The video capture time displayed in the iDRAC GUI video player may differ from the video capture time displayed in
other video players. The iDRAC GUI video player displays the time in the iDRAC time zone while all other video players
display the time in the respective operating system time zones.

**NOTE:**

  - The reason for the delay in boot capture file availability is because the boot capture buffer is not full after the host boot.
  - Default /inbox SLES/RHEL video players do not support the MPEG-1 video decoder. You need to install a MPEG
decoder supported video player and play the files.

  - MPEG-1 format videos are not supported in MAC OS native player.

To view the **Boot Capture** screen, click **Maintenance** - **Troubleshooting** - **Video Capture** .

The **Video Capture** screen displays the video recordings. For more information, see the **iDRAC Online Help** .

**NOTE:** When embedded video controller is disabled and server has add-on video controller, then certain latency is expected
with respect to boot capture. Hence, End of Post Messages of a video will be recorded in next capture.



### Configuring video capture settings

To configure the video capture settings:

1. In the iDRAC Web interface, go to **Maintenance** - **Troubleshooting** - **Video Capture** .
The **Video Capture** page is displayed.

2. From the **Video Capture Settings** drop-down menu, select any of the following options:
  - **Disable**  - Boot capture is disabled.
  - **Capture until buffer full**  - Boot sequence is captured until the buffer size has reached.
  - **Capture until end of POST**  - Boot sequence is captured until end of POST.
3. Click **Apply** to apply the settings.



## Viewing logs

You can view System Event Logs (SELs) and Lifecycle logs. For more information, see Viewing System Event Log and Viewing
Lifecycle log.



## Viewing last system crash screen

The last crash screen feature captures a screenshot of the most recent system crash, saves, and displays it in iDRAC. This is a
licensed feature.

To view the last crash screen:

1. Make sure that the last system crash screen feature is enabled.
2. In iDRAC Web interface, go to **Overview** - **Server** - **Troubleshooting** - **Last Crash Screen** .

The **Last Crash Screen** page displays the last saved crash screen from the managed system.

Click **Clear** to delete the last crash screen.

**NOTE:** Once iDRAC is reset or an AC power cycle event occurs, then the crash capture data is cleared.

**NOTE:** Last crash screen resolution is always 1024x768 irrespective of host OS resolution.



## Viewing System status

The System Status summarizes the status of the following components in the system:

- Summary
- Batteries
- Cooling
- CPUs
- Front Panel
- Intrusion
- Memory
- Network Devices
- Power Supplies
- Voltages
- Removable Flash Media
- Chassis Controller

You can view the status of the managed system:

- For rack and tower servers: LCD front panel and system ID LED status or LED front panel and system ID LED status.
- For blade servers: Only system ID LEDs.



### Viewing system front panel LCD status

To view the LCD front panel status for applicable rack and tower servers, in iDRAC Web interface, go to **System** - **Overview** **Front Panel** . The **Front Panel** page is displayed.

The **Front Panel** section displays the live feed of the messages currently being displayed on the LCD front panel. When the
system is operating normally (indicated by solid blue color in the LCD front panel), both **Hide Error** and **UnHide Error** are
grayed-out.

**NOTE:** You can hide or unhide the errors only for rack and tower servers.

Based on the selection, the text box displays the current value. If you select User Defined, enter the required message in the
text box. The character limit is 62. If you select None, home message is not displayed on the LCD.

To view LCD front panel status using RACADM, use the objects in the `System.LCD` group. For more information, see the
[Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



### Viewing system front panel LED status

To view the current system ID LED status, in iDRAC web interface, go to **System** - **Overview** - **Front Panel** . The **Front Panel**
section displays the current front panel status:

- Solid blue — No errors present on the managed system.
- Blinking blue — Identify mode is enabled (regardless of managed system error presence).
- Solid amber — Managed system is in failsafe mode.
- Blinking amber — Errors present on managed system.

When the system is operating normally (indicated by blue Health icon on the LED front panel), then both **Hide Error** and
**UnHide Error** is grayed-out. You can hide or unhide the errors only for rack and tower servers.

To view system ID LED status using RACADM, use the `getled` command.

**NOTE:** During hot removal of M.2 drive for BOSS N-1 controller, iDRAC dashboard health status turns amber, but server
front/back health indicator LED stays blue.

[For more information, see the Integrated Dell Remote Access Controller RACADM CLI Guide.](https://www.dell.com/idracmanuals)



## Hardware trouble indicators

The hardware related problems are:

- Failure to power up
- Noisy fans
- Loss of network connectivity
- Hard drive failure
- USB media failure
- Physical damage

Based on the problem, use the following methods to correct the problem:

- Reseat the module or component and restart the system
- In case of a blade server, insert the module into a different bay in the chassis
- Replace hard drives or USB flash drives
- Reconnect or replace the power and network cables

If problem persists, see the _Installation and Service Manual_ [available on the PowerEdge Manuals page for specific](https://www.dell.com/poweredgemanuals)
troubleshooting information about the hardware device.

**CAUTION: You should only perform troubleshooting and simple repairs as authorized in your product**
**documentation, or as directed by online or telephone service and support team. Damage due to servicing that is**
**not authorized by Dell is not covered by your warranty. Read and follow the safety instructions that came with**
**the product.**



## Viewing system health

You can view the status for the following components on the iDRAC, CMC and, OME-Modular Web interfaces:

- Batteries
- CPUs
- Cooling
- Intrusion
- Memory
- Power Supplies
- Removable Flash Media
- Voltages
- Miscellaneous

Click any component name in the **Server Health** section to view details about the component.



## Checking server status screen for error messages

When a flashing amber LED is blinking, and a particular server has an error, the main Server Status Screen on the LCD highlights
the affected server in orange. Use the LCD navigation buttons to highlight the affected server, then click the center button.
Error and warning messages will be displayed on the second line. For the list of error messages displayed on the LCD panel, see
the server’s Owner’s Manual.



## Restarting iDRAC

You can perform a hard or soft iDRAC restart without turning off the server:

- Hard restart — On the server, press and hold the LED button for 15 seconds.
- Soft restart — Using iDRAC Web interface or RACADM.



## Reset to Custom Defaults (RTD)

You can use Reset to Custom Defaults feature to upload a custom config file and RTD to the settings. The new settings are
applied on top of preserving users and network settings.

Reset to Custom Defaults feature has following options:

- Upload Custom Default Settings —
  - You can upload custom defaults settings file. This file can be obtained by exporting the Server Configuration Profile(SCP)
in XML format (JSON format is not supported for this feature). The contents of the file can be modified by customer to
add or delete the settings.

  - You can upload the SCP XML file using iDRAC GUI or RACADM interfaces.
  - The uploaded configurations are saved in the default database.
- Save current settings as custom defaults —
  - This operation saves the current settings as default settings.
  - This is only supported via RACADM interface.
- Download custom default settings —
  - You can download SCP XML for all the default settings.
  - This is only supported via RACADM interface.
- Initiate reset to custom defaults —
  - The uploaded/saved default settings are applied.



### Resetting iDRAC using iDRAC web interface

To reset iDRAC, do one of the following in the iDRAC Web interface:

- Upload Custom Defaults file:
  - Go to **Configuration**  - **Server Configuration Profile**  - **Custom Defaults**  - **Upload Custom Defaults**
  - Upload the customized **CustomConfigured.xml** file from Local Share path
  - Click **Apply** . New Upload Custom Defaults Job is created.
- Reset to Custom Defaults:
  - When Upload Custom Defaults job is successful, go to **Maintainance**  - **Diagnostics**, click **Reset iDRAC to Factory**
**Defalts** option.

  - Select **Discard all settings** and set to **Custom default configuration** .
  - Click **Continue** to initiate Reset to customs Defaults configuration.



### Resetting iDRAC using RACADM

To restart iDRAC, use the **racreset** command. For more information, see the _Chassis Management Controller RACADM CLI_
_Guide_ [available on the CMC manuals page. .For more information, see the](https://www.dell.com/cmcmanuals) _Dell OME - Modular for PowerEdge MX7000 Chassis_
_RACADM Command Line Reference Guide_ [available on the OpenManage manuals page.](https://www.dell.com/openmanagemanuals)

For Reset to default operations, use the following commands:

- Upload Custom Defaults file — `racadm –r <iDracIP> -u <username> -p <Password> set -f <filename>`
```
  -t xml --customdefaults
```

- Save Current Settings as Default settings — `racadm –r <iDracIP> -u <username> -p <Password> set`
```
  --savecustomdefaults
```

- Download Custom Default settings — `racadm –r <iDracIP> -u <username> -p <Password> get -f`
```
  <filename> -t xml --customdefaults
```

- Reset to Custom Defaults — `Racadm –r <iDracIP> -u <username> -p <Password> racresetcfg -custom`



## Erasing system and user data

**NOTE:** Erasing system and user data is not supported from iDRAC GUI.

You can erase system components and user data for the following components:

- BIOS reset to default
- Embedded Diagnostics
- Embedded operating system Driver Pack
- Lifecycle Controller Data
- iDRAC reset to default
- Overwrite hard drives that do not support Instant Secure Erase (ISE)
- Reset controller cache
- Reset vFLASH
- Erase Hard Drives, SSDs, and NVMes that support ISE.
- Clear all operating system applications.

Before performing system erase, ensure that:

- You have iDRAC Server Control privilege.
- Lifecycle Controller is enabled.

The Lifecycle Controller Data option erases any content such as the LC Log, configuration database, rollback firmware, factory
as-shipped logs, and the configuration information from the FP SPI (or management riser).

**NOTE:** The Lifecycle Controller log contains the information about the system erase request and any information that is
generated when iDRAC restarts. All previous information is removed.

You can delete individual or multiple system components using the **SystemErase** command:

```
 racadm systemErase <BIOS | DIAG | DRVPACK | LCDATA | IDRAC >

```

Where,

- bios—BIOS reset to default
- diag—Embedded Diagnostics
- drvpack—Embedded OS Driver Pack
- lcdata—Clear the Lifecycle Controller Data
- idrac—iDRAC reset to default
- overwritepd—Overwrite hard drives that do not support Instant Secure Erase (ISE)
- percnvcache—Reset controller cache
- vflash—Reset vFLASH
- secureerasepd—Erase Hard Drives, SSDs, and NVMes that support ISE
- allapps—Clears all operating system applications
**NOTE:**

  - Secure erase does not erase **iDRAC rollback firmware** from the partition when the command `racadm systemerase`

`lcdata` is used.

  - While erasing vFlash, ensure that all partitions on the vFlash card are detached before performing the operation.
  - If SEKM is enabled on the server, then disable SEKM using the `racadm sekm disable` command before using

this command. This can avoid any storage devices being locked out which are secured by iDRAC, if SEKM settings
are erased from iDRAC by performing this command. For more information, see the Integrated Dell Remote Access
Controller RACADM CLI Guide.

  - he Dell tech center link appears on the iDRAC UI on Dell branded systems. If you erase system data by using the WSMan
command and want the link to appear again, reboot the host manually and wait for CSIOR to run.

  - After you run System Erase, the VDs may still appear. Run CSIOR after System Erase is completed and iDRAC is
rebooted.

  - In the latest iDRAC releases, the `LCWipe` command is deprecated. To perform the system erase operation, run the

`systemerase` command.

  - System Erase does not clear the data from the Easy Restore flash memory.
  - After you perform System Erase, the SDPM Default Memory Size is configured to 32 GB. You can see SPDM Default
Memory Size attribute by going to **GUIConfigurationBios SettingsMemory SettingsPersistent MemorySoftware**
**Defined Persistent Memory**

  - You cannot perform system erase when iDRAC is in iLKM mode. Disable iLKM to perform system erase.
  - After you perform the System Erase operation, nine entries of PR7 logs for each Intel GPU slots are displayed.



## Resetting iDRAC to factory default settings

You can reset iDRAC to the factory default settings using the iDRAC Settings utility or the iDRAC Web interface.



### Resetting iDRAC to factory default settings using iDRAC web interface

To reset iDRAC to factory default settings using the iDRAC Web interface:

1. Go to **Maintenance** - **Diagnostics** .
The **Diagnostics Console** page is displayed.

2. Click **Reset iDRAC to Default Settings** .

The completion status is displayed in percentage. iDRAC reboots and is restored to factory defaults. The iDRAC IP is reset
and is not accessible. You can configure the IP using the front panel or BIOS.



### Resetting iDRAC to factory default settings using iDRAC settings utility

To reset iDRAC to factory default values using the iDRAC Settings utility:

1. Go to **Reset iDRAC configurations to defaults** .
The **iDRAC Settings Reset iDRAC configurations to defaults** page is displayed.

2. Click **Yes** .

iDRAC reset starts.

3. Click **Back** and navigate to the same **Reset iDRAC configurations to defaults** page to view the success message.



# 30 SupportAssist Integration in iDRAC

SupportAssist allows you to create SupportAssist collections and utilize other SupportAssist features to monitor your system
and datacenter. iDRAC provides an application interfaces for gathering platform information that enables support services to
resolve platform and system problems. iDRAC helps you to generate a SupportAssist collection of the server and then export
the collection to a location on the management station (local) or to a shared network location such as FTP, Trivial File Transfer
Protocol (TFTP), HTTP, HTTPS, Common Internet File System (CIFS) or Network File Share (NFS). The collection is generated
in the standard ZIP format. You can send this collection to technical support for troubleshooting or inventory collection.
**Topics:**

- SupportAssist
- SupportAssist
- Collection Log
- Generating SupportAssist Collection
- Collection Settings



## SupportAssist

**NOTE:** SupportAssist registration is no longer supported in FW versions 7.00.00.00 and higher. You can use OpenManage
Enterprise or Secure Connect Gateway for the same.

You can generate and save a collection locally or to a network.

**NOTE:** Some OEM customers do not have the Model name.

## SupportAssist

Once SupportAssist is configured, you can check the SupportAssist dashboard to view the **Collection log** . Registration is not
required to view or send the Collection log.



## Collection Log

**Collection Log** shows the details of **Collection Date and Time, Collection Type** (Manual), **Data Collected** (Custom
Selection, All Data), **Collection Status** (Complete with Errors, Complete), and **Job ID** You can send the last persisted
collection in iDRAC to Dell.

**NOTE:** Once generated, the Collection Log Details can be filtered to remove the Personally Identifiable Information (PII)
based on the user selection.



## Generating SupportAssist Collection

For generating the OS and Application logs, iDRAC Service Module must be installed and running in Host Operating System.

**NOTE:** SupportAssist Collection takes more than 10 minutes to complete when performed from OS/iDRAC while OMSA
10.1.0.0 is running with it.

If you have to work with Tech Support on an issue with a server but the security policies restrict direct internet connection,
then you can provide Tech Support with necessary data to facilitate troubleshooting of the problem without having to install
software or download tools from Dell and without having access to the Internet from the server operating system or iDRAC.

You can generate a health report of the server and then export the Collection log:

- To a location on the management station (local).
- To a shared network location such as Common Internet File System (CIFS) or Network File Share (NFS). To export to a
network share such as CIFS or NFS, direct network connectivity to the iDRAC shared or dedicated network port is required.

- To Dell.

The SupportAssist Collection is generated in the standard ZIP format. The collection may contain the following information:

- Hardware inventory for all components (includes system component configuration and firmware details, Motherboard
System Event Logs, iDRAC state information and Lifecycle Controller logs).

- Operating system and application information.
- Storage Controller logs.
- iDRAC Debug Logs.
- It contains an HTML5 viewer, that can be accessed once the collection is complete.
- The collection provides a massive amount of detailed system information and logs in a user friendly format that can be
viewed without uploading the collection to the Tech Support site.

After the data is generated, you can view the data which contains multiple XML files and log files.

Each time the data collection is performed, an event is recorded in the Lifecycle Controller log. The event includes information
such as the user who initiated the report, interface used, and the date and time of export.

On Windows, If WMI is disabled, OS Collector collection stops with an error message.

Check the appropriate privilege levels and make sure there is no firewall or security settings that may prevent from collecting
the registry or software data.

Before generating the health report, make sure:

- Lifecycle Controller is enabled.
- Collect System Inventory On Reboot (CSIOR) is enabled.
- You have Login and Server Control privileges.



### Generating SupportAssist Collection manually using iDRAC web interface

To generate the SupportAssist collection manually:

1. In the iDRAC Web interface, go to **Maintenance** - **SupportAssist** .
2. Click **Start a Collection** .
3. Select the data sets to be included in the Collection.
4. You can opt to filter the collection for PII.
5. Select the destination where Collection needs to be saved.

a. **Save locally** option allows you to save the generated Collection in the local system.
b. **Save to Network** option saves the generated Collection to user defined CIFS or NFS share location.

**NOTE:** If **Save to Network** is selected, and no default location is available, the provided network details will be
saved as default location for future collections. If default location already exist, then the collection will use the details
specified once only.

If **Save to Network** option is selected, the user provided network details is saved as defaults (if no prior network share
location have been saved) for any future collections.

6. Click **Collect** to proceed with Collection generation.
7. If prompted, accept the **End User Level Agreement (EULA)** to continue.

OS and Application Data option is grayed out and not selectable if:

  - iSM is not installed or running in Host OS, or
  - OS Collector has been removed from iDRAC, or
  - OS-BMC pass through is disabled in iDRAC, or
  - cached OS Application data is not available in iDRAC from a previous collection



## Collection Settings

You can save the collections to a preferred network location. Use **Set Archive Directory** to set the network location. You
can save the collections to a preferred network location. Use Set Archive Directory to set the network location. Enter the
type of Protocol (CIFS/NFS) that you want to opt for, corresponding IP Address, Share Name, Domain Name, User Name
and Password before you Test Network Connection. The Test Network Connection button will confirm a connection to the
destination share.



# 31 Frequently asked questions

This section lists the frequently asked questions for the following:

**Topics:**

- System Event Log
- Custom sender email configuration for iDRAC alerts
- Network security
- Telemetry streaming
- Active Directory
- Single Sign-On
- Smart card login
- Virtual console
- Virtual media
- vFlash SD card
- SNMP authentication
- Storage devices
- GPU (Accelerators)
- iDRAC Service Module
- RACADM
- Permanently setting the default password to calvin
- Miscellaneous
- Proxy server settings



## System Event Log

**While using iDRAC Web interface through Internet Explorer, why does SEL not save using the Save As option?**

This is due to a browser setting. To resolve this:

1. In Internet Explorer, go to **Tools** - **Internet Options** - **Security** and select the zone you are attempting to download in. For
example, if the iDRAC device is on the local intranet, select **Local Intranet** and click **Custom level...** .
2. In the **Security Settings** window, under **Downloads** make sure that the following options are enabled:
  - Automatic prompting for file downloads (if this option is available)
  - File download
**CAUTION: To make sure that the computer used to access iDRAC is safe, under Miscellaneous, do not enable**
**the Launching applications and unsafe files option.**



## Custom sender email configuration for iDRAC alerts

**Alert generated email is not from Custom sender email set on Cloud based email service.**

[You need to register your cloud email through this process : Support.google.com.](https://support.google.com/mail/answer/22370?hl=en)



## Network security

**While accessing the iDRAC Web interface, a security warning is displayed stating that the SSL certificate issued by**
**the Certificate Authority (CA) is not trusted.**

iDRAC includes a default iDRAC server certificate to ensure network security while accessing through the Web-based interface
and remote RACADM. This certificate is not issued by a trusted CA. To resolve this, upload a iDRAC server certificate issued by
a trusted CA (for example, Microsoft Certificate Authority, Thawte or Verisign).

**Why the DNS server not registering iDRAC?**

Some DNS servers register iDRAC names that contain only up to 31 characters.

**When accessing the iDRAC Web-based interface, a security warning is displayed stating that the SSL certificate**
**hostname does not match the iDRAC hostname.**

iDRAC includes a default iDRAC server certificate to ensure network security while accessing through the Web-based interface
and remote RACADM. When this certificate is used, the web browser displays a security warning because the default certificate
that is issued to iDRAC does not match the iDRAC hostname (for example, the IP address).

To resolve this, upload an iDRAC server certificate issued to the IP address or the iDRAC hostname. When generating the CSR
(used for issuing the certificate), ensure that the common name (CN) of the CSR matches the iDRAC IP address (if certificate
issued to IP) or the registered DNS iDRAC name (if certificate is issued to iDRAC registered name).

To make sure that the CSR matches the registered DNS iDRAC name:

1. In iDRAC Web interface, go to **Overview** - **iDRAC Settings** - **Network** . The **Network** page is displayed.
2. In the **Common Settings** section:
  - Select the **Register iDRAC on DNS** option.
  - In the **DNS iDRAC Name** field, enter the iDRAC name.
3. Click **Apply** .
**Why am I unable to access iDRAC from my web browser?**

This issue may occur if HTTP Strict Transport Security (HSTS) is enabled. HSTS is a web security mechanism which allows web
browsers to interact using only the secure HTTPS protocol, and not HTTP.

Enable HTTPS on your browser and login to iDRAC to resolve the issue.



##### Why am I unable to complete operations that involve a remote CIFS share?

Import/export or any other remote file share operations that involve a CIFS share fail if they use only SMBv1. Ensure that the
SMBv2 protocol is enabled on the server providing SMB/CIFS share. Refer to the Operating System documentation on how to
enable the SMBv2 protocol.



## Telemetry streaming

**Few report data are missing while streaming telemetry reports for Rsyslog servers.**

Older versions of rsyslog servers may intermittently miss few report data in some reports. You can upgrade to a newer version
to avoid this issue.



## Active Directory

**Active Directory login failed. How to resolve this?**

To diagnose the problem, on the **Active Directory Configuration and Management** page, click **Test Settings** . Review the
test results and fix the problem. Change the configuration and run the test until the test user passes the authorization step.

In general, check the following:

- While logging in, make sure that you use the correct user domain name and not the NetBIOS name. If you have a local iDRAC
user account, log into iDRAC using the local credentials. After logging in, make sure that:

  - The **Active Directory Enabled** option is selected on the **Active Directory Configuration and Management** page.
  - The DNS setting is correct on the **iDRAC Networking configuration** page.
  - The correct Active Directory root CA certificate is uploaded to iDRAC if certificate validation was enabled.
  - The iDRAC name and iDRAC Domain name matches the Active Directory environment configuration if you are using
extended schema.

  - The Group Name and Group Domain Name matches the Active Directory configuration if you are using standard schema.
  - If the user and the iDRAC object is in different domain, then do not select the **User Domain from Login** option. Instead
select **Specify a Domain** option and enter the domain name where the iDRAC object resides.

- Check the domain controller SSL certificates to make sure that the iDRAC time is within the valid period of the certificate.
**Active Directory login fails even if certificate validation is enabled. The test results display the following error**
**message. Why does this occur and how to resolve this?**

```
 ERROR: Can't contact LDAP server, error:14090086:SSL
 routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed: Please check the correct
 Certificate Authority (CA) certificate has been uploaded to iDRAC. Please also check
 if the iDRAC date is within the valid period of the certificates and if the Domain
 Controller Address configured in iDRAC matches the subject of the Directory Server
 Certificate.

```

If certificate validation is enabled, when iDRAC establishes the SSL connection with the directory server, iDRAC uses the
uploaded CA certificate to verify the directory server certificate. The most common reasons for failing certification validation
are:

- iDRAC date is not within the validity period of the server certificate or CA certificate. Check the iDRAC time and the validity
period of your certificate.

- The domain controller addresses configured in iDRAC does not match the Subject or Subject Alternative Name of the
directory server certificate. If you are using an IP address, read the next question. If you are using FQDN, make sure
you are using the FQDN of the domain controller and not the domain. For example, **servername.example.com** instead of
**example.com** .

**Certificate validation fails even if IP address is used as the domain controller address. How to resolve this?**

Check the Subject or Subject Alternative Name field of your domain controller certificate. Normally, Active Directory uses the
host name and not the IP address of the domain controller in the Subject or Subject Alternative Name field of the domain
controller certificate. To resolve this, do any of the following:

- Configure the host name (FQDN) of the domain controller as the **domain controller address(es)** on iDRAC to match the
Subject or Subject Alternative Name of the server certificate.

- Reissue the server certificate to use an IP address in the Subject or Subject Alternative Name field, so that it matches the IP
address configured in iDRAC.

- Disable certificate validation if you choose to trust this domain controller without certificate validation during the SSL
handshake.

**How to configure the domain controller address(es) when using extended schema in a multiple domain**
**environment?**

This must be the host name (FQDN) or the IP address of the domain controller(s) that serves the domain in which the iDRAC
object resides.

**When to configure Global Catalog Address(es)?**

If you are using standard schema and the users and role groups are from different domains, Global Catalog Address(es) are
required. In this case, you can use only Universal Group.

If you are using standard schema and all the users and role groups are in the same domain, Global Catalog Address(es) are not
required.

If you are using extended schema, the Global Catalog Address is not used.

**How does standard schema query work?**

iDRAC connects to the configured domain controller address(es) first. If the user and role groups are in that domain, the
privileges are saved.

If Global Controller Address(es) is configured, iDRAC continues to query the Global Catalog. If additional privileges are retrieved
from the Global Catalog, these privileges are accumulated.

**Does iDRAC always use LDAP over SSL?**

Yes. All the transportation is over secure port 636 and/or 3269. During test setting, iDRAC does a LDAP CONNECT only to
isolate the problem, but it does not do an LDAP BIND on an insecure connection.

**Why does iDRAC enable certificate validation by default?**

iDRAC enforces strong security to ensure the identity of the domain controller that iDRAC connects to. Without certificate
validation, a hacker can spoof a domain controller and hijack the SSL connection. If you choose to trust all the domain
controllers in your security boundary without certificate validation, you can disable it through the Web interface or RACADM.

**Does iDRAC support the NetBIOS name?**

Not in this release.

**Why does it take up to four minutes to log in to iDRAC using Active Directory Single Sign–On or Smart Card Login?**

The Active Directory Single Sign–On or Smart Card log in normally takes less than 10 seconds, but it may take up to four
minutes to log in if you have specified the preferred DNS server and the alternate DNS server, and the preferred DNS server
has failed. DNS time-outs are expected when a DNS server is down. iDRAC logs you in using the alternate DNS server.

**The Active Directory is configured for a domain present in Windows Server 2008 Active Directory. A child or sub**
**domain is present for the domain, the user and group is present in the same child domain, and the user is a member**
**of that group. When trying to log in to iDRAC using the user present in the child domain, Active Directory Single**
**Sign-On login fails.**

This may be because of the an incorrect group type. There are two kinds of Group types in the Active Directory server:

- Security — Security groups allow you to manage user and computer access to shared resources and to filter group policy
settings.

- Distribution — Distribution groups are intended to be used only as email distribution lists.

Always make sure that the group type is Security. You cannot use distribution groups to assign permission on any object,
however use them to filter group policy settings.



## Single Sign-On

**SSO login fails on Windows Server 2008 R2 x64. What are the settings required to resolve this?**

1. Run the **technet.microsoft.com/en-us/library/dd560670(WS.10).aspx** for the domain controller and domain policy.
2. Configure the computers to use the DES-CBC-MD5 cipher suite.
**NOTE:** These settings may affect compatibility with client computers or services and applications in your environment.
The Configure encryption types allowed for Kerberos policy setting is located at **Computer Configuration**     - **Security**
**Settings**    - **Local Policies**    - **Security Options** .

3. Make sure that the domain clients have the updated GPO.
4. At the command line, type `gpupdate /force` and delete the old key tab with `klist purge` command.
5. After the GPO is updated, create the new keytab.
6. Upload the keytab to iDRAC.

You can now log in to iDRAC using SSO.

**Why does SSO login fail with Active Directory users on Windows 7 and Windows Server 2008 R2?**

You must enable the encryption types for Windows 7 and Windows Server 2008 R2. To enable the encryption types:

1. Log in as administrator or as a user with administrative privilege.
2. Go to **Start** and run **gpedit.msc** . The **Local Group Policy Editor** window is displayed.
3. Go to **Local Computer Settings** - **Windows Settings** - **Security Settings** - **Local Policies** - **Security Options** .
4. Right-click **Network Security: Configure encryption types allowed for kerberos** and select **Properties** .
5. Enable all the options.
6. Click **OK** . You can now log in to iDRAC using SSO.

Perform the following additional settings for Extended Schema:

1. In the **Local Group Policy Editor** window, navigate to **Local Computer Settings** - **Windows Settings** - **Security**
**Settings**  - **Local Policies**  - **Security Options** .
2. Right-click **Network Security: Restrict NTLM: Outgoing NTLM traffic to remote server** and select **Properties** .
3. Select **Allow all**, click **OK**, and close the **Local Group Policy Editor** window.
4. Go to **Start** and run cmd. The command prompt window is displayed.
5. Run the command `gpupdate /force` . The group policies are updated. Close the command prompt window.
6. Go to **Start** and run regedit. The **Registry Editor** window is displayed.
7. Navigate to **HKEY_LOCAL_MACHINE** - **System** - **CurrentControlSet** - **Control** - **LSA** .
8. In the right-pane, right-click and select **New** - **DWORD (32-bit) Value** .
9. Name the new key as **SuppressExtendedProtection** .
10. Right-click **SuppressExtendedProtection** and click **Modify** .
11. In the **Value** data field, type **1** and click **OK** .
12. Close the **Registry Editor** window. You can now log in to iDRAC using SSO.
**If you have enabled SSO for iDRAC and you are using Internet Explorer to log in to iDRAC, SSO fails and you are**
**prompted to enter your user name and password. How to resolve this?**

Make sure that the iDRAC IP address is listed in the **Tools** - **Internet Options** - **Security** - **Trusted sites** . If it is not listed,
SSO fails and you are prompted to enter your user name and password. Click **Cancel** and proceed.



## Smart card login

**It takes up to four minutes to log into iDRAC using Active Directory Smart Card login.**

The normal Active Directory Smart Card login normally takes less than 10 seconds, however it may take up to four minutes if you
have specified the preferred DNS server and the alternate DNS server in the **Network** page, and the preferred DNS server has
failed. DNS time-outs are expected when a DNS server is down. iDRAC logs you in using the alternate DNS server.

**Incorrect Smart Card PIN.**

Check if the smart card is locked due to too many attempts with an incorrect PIN. In such cases, contact the smart card issuer
in the organization to get a new smart card.



## Virtual console

**Can a new remote console video session be started when the local video on the server is turned off?**

Yes.

**Why does it take 15 seconds to turn off the local video on the server after requesting to turn off the local video?**

It gives a local user an opportunity to take any action before the video is switched off.

**Is there a time delay when turning on the local video?**

No, after a local video turn ON request is received by iDRAC, the video is turned on instantly.

**Can the local user also turn off or turn on the video?**

When the local console is disabled, the local user cannot turn off or turn on the video.

**Does switching off the local video also switch off the local keyboard and mouse?**

No.

**Does turning off the local console turn off the video on the remote console session?**

No, turning the local video on or off is independent of the remote console session.

**What privileges are required for an iDRAC user to turn on or turn off the local server video?**

Any user with iDRAC configuration privileges can turn on or turn off the local console.

**How to get the current status of the local server video?**

The status is displayed on the Virtual Console page.

To display the status of the object `iDRAC.VirtualConsole.AttachState`, use the following command:

```
 racadm get idrac.virtualconsole.attachstate

```

Or, use the following command from a SSH or a remote session:

```
 racadm -r (iDrac IP) -u (username) -p (password) get iDRAC.VirtualConsole.AttachState

```

The status is also seen on the Virtual Console OSCAR display. When the local console is enabled, a green status is displayed next
to the server name. When disabled, a yellow dot indicates that iDRAC has locked the local console.

**Why is the bottom of the system screen not seen from the Virtual Console window?**

Make sure that the management station’s monitor resolution is set to 1280 x 1024.

**Why is the Virtual Console Viewer window garbled on Linux operating system?**

The console viewer on Linux requires a UTF-8 character set. Check your locale and reset the character set if required.

**Why does the mouse not synchronize under the Linux text console in Lifecycle Controller?**

Virtual Console requires the USB mouse driver, but the USB mouse driver is available only under the X-Window operating
system. In the Virtual Console viewer, do any of the following:

- Go to **Tools** - **Session Options** - **Mouse** tab. Under **Mouse Acceleration**, select **Linux** .
- Under the **Tools** menu, select **Single Cursor** option.
**How to synchronize the mouse pointers on the Virtual Console Viewer window?**

Before starting a Virtual Console session, make sure that the correct mouse is selected for your operating system.

Make sure that the **Single Cursor** option under **Tools** in the iDRAC Virtual Console menu is selected on iDRAC Virtual Console
client. The default is two cursor mode.

**Can a keyboard or mouse be used while installing a Microsoft operating system remotely through the Virtual**
**Console?**

No. When you remotely install a supported Microsoft operating system on a system with Virtual Console enabled in the BIOS, an
EMS Connection Message is sent that requires that you select **OK** remotely. You must either select **OK** on the local system or
restart the remotely managed server, reinstall, and then turn off the Virtual Console in BIOS.

This message is generated by Microsoft to alert the user that Virtual Console is enabled. To make sure that this message does
not appear, always turn off Virtual Console in the iDRAC Settings utility before remotely installing an operating system.

**Why does the Num Lock indicator on the management station not reflect the status of the Num Lock on the remote**
**server?**

When accessed through the iDRAC, the Num Lock indicator on the management station does not necessarily coincide with the
state of the Num Lock on the remote server. The state of the Num Lock depends the setting on the remote server when the
remote session is connected, regardless of the state of the Num Lock on the management station.

**Why do multiple Session Viewer windows appear when a Virtual Console session is established from the local host?**

You are configuring a Virtual Console session from the local system. This is not supported.

**If a Virtual Console session is in-progress and a local user accesses the managed server, does the first user receive a**
**warning message?**

No. If a local user accesses the system, both have control of the system.

**How much bandwidth is required to run a Virtual Console session?**

It is recommended to have a 5 MBPS connection for good performance. A 1 MBPS connection is required for minimal
performance.

**What is the minimum system requirements for the management station to run Virtual Console?**

The management station requires an Intel Pentium III 500 MHz processor with at least 256 MB of RAM.

**Why does Virtual Console Viewer window sometimes displays No Signal message?**

You may see this message because the iDRAC Virtual Console plug-in is not receiving the remote server desktop video.
Generally, this behavior may occur when the remote server is turned off. Occasionally, the message may be displayed due to a
remote server desktop video reception malfunction.

**Why does Virtual Console Viewer window sometimes display an Out of Range message?**

You may see this message because a parameter necessary to capture video is beyond the range for which the iDRAC can
capture the video. Parameters such as display resolution or refresh rate too high causes an out of range condition. Normally,
physical limitations such as video memory size or bandwidth sets the maximum range of parameters.

**Why is the Virtual Console Viewer window blank?**

If you have Virtual Media privilege, but not Virtual Console privilege, you can start the viewer to access the virtual media
feature, but the managed server’s console is not displayed.

**Why doesn’t the mouse synchronize in DOS when using Virtual Console?**

The Dell BIOS is emulating the mouse driver as a PS/2 mouse. By design, the PS/2 mouse uses relative position for the mouse
pointer, which causes the lag in syncing. iDRAC has a USB mouse driver that allows absolute position and closer tracking of the
mouse pointer. Even if iDRAC passes the USB absolute mouse position to the Dell BIOS, the BIOS emulation converts it back to
relative position and the behavior remains. To fix this problem, set the mouse mode to USC/Diags in the Configuration screen.

**After launching the Virtual Console, the mouse cursor is active on the Virtual Console, but not on the local system.**
**Why does this occur and how to resolve this?**

This occurs if the **Mouse Mode** is set to **USC/Diags** . Press **Alt + M** hot key to use the mouse on the local system. Press **Alt +**
**M** again to use the mouse on the Virtual Console.

**Why does GUI session time out after launching a virtual console from the iDRAC interface that is launched from**
**CMC?**

When launching the Virtual Console to iDRAC from the CMC web interface a popup is opened to launch the Virtual Console. The
popup closes shortly after the Virtual Console opens.

When launching both the GUI and Virtual Console to the same iDRAC system on a management station, a session time-out for
the iDRAC GUI occurs if the GUI is launched before the popup closes. If the iDRAC GUI is launched from the CMC web interface
after the popup with the Virtual Console closed, this issue does not appear.

**NOTE:** Not applicable for MX platforms.

**Why does Linux SysRq key not work with Internet Explorer?**

The Linux SysRq key behavior is different when using Virtual Console from Internet Explorer. To send the SysRq key, press the
**Print Screen** key and release while holding the **Ctrl** and **Alt** keys. To send the SysRq key to a remote Linux server though
iDRAC, while using Internet Explorer:

1. Activate the magic key function on the remote Linux server. You can use the following command to activate it on the Linux
terminal:

```
  echo 1 > /proc/sys/kernel/sysrq

```

2. Activate the keyboard pass-through mode of Active X Viewer.
3. Press **Ctrl+Alt+Print Screen** .
4. Release only **Print Screen** .
5. Press **Print Screen+Ctrl+Alt** .
**NOTE:** The SysRq feature is currently not supported with Internet Explorer and Java.

**Why is the "Link Interrupted" message displayed at the bottom of the Virtual Console?**

When using the shared network port during a server reboot, iDRAC is disconnected while BIOS is resetting the network card.
This duration is longer on 10 Gb cards, and is also exceptionally long if the connected network switch has Spanning Tree
Protocol (STP) enabled. In this case, it is recommended to enable "portfast" for the switch port connected to the server. In
most cases, the Virtual Console restores itself.

**To enable console redirection using the web server port (443)**

```
 racadm>>set iDRAC.VirtualConsole.WebRedirect Enabled

```

To close the external virtual console port (5900), set the following iDRAC property.

To close the external virtual console port (5900), both `iDRAC.VirtualConsole.WebRedirect` and
`iDRAC.VirtualConsole.CloseUnusedPort` must be enabled.

```
 racadm>>set iDRAC.VirtualConsole.CloseUnusedPort Enabled

```

**NOTE:**

  - If the Virtual Media port is disabled, the stand-alone Virtual Media will not be accessible and you may use the Virtual
Media through Virtual Console.



## Virtual media

**Why does the Virtual Media client connection sometimes drop?**

When a network time-out occurs, iDRAC firmware drops the connection, disconnecting the link between the server and the
virtual drive.

If you change the CD in the client system, the new CD may have an autostart feature. In this case, the firmware can time out
and the connection is lost if the client system takes too long to read the CD. If a connection is lost, reconnect from the GUI and
continue the previous operation.

If the Virtual Media configuration settings are changed in the iDRAC web interface or through local RACADM commands, any
connected media is disconnected when the configuration change is applied.

To reconnect to the Virtual Drive, use the Virtual Media **Client View** window.

**Why does a Windows operating system installation through Virtual Media take an extended amount of time?**

If you are installing the Windows operating system using the **Dell Systems Management Tools and Documentation DVD**
and the network connection is slow, the installation procedure may require an extended amount of time to access iDRAC web
interface due to network latency. The installation window does not indicate the installation progress.

**How to configure the virtual device as a bootable device?**

On the managed system, access BIOS Setup and go to the boot menu. Locate the virtual CD, virtual floppy, or vFlash and
change the device boot order as required. Also, press the "spacebar" key in the boot sequence in the CMOS setup to make the
virtual device bootable. For example, to boot from a CD drive, configure the CD drive as the first device in the boot order.

**What are the types of media that can be set as a bootable device?**

iDRAC allows you to boot from the following bootable media:

- CDROM/DVD Data media
- ISO 9660 image
- 1.44 Floppy disk or floppy image
- A USB key that is recognized by the operating system as a removable disk
- A USB key image
**How to make the USB key a bootable device?**

You can also boot with a Windows 98 startup disk and copy system files from the startup disk to the USB key. For example,
from the DOS prompt, type the following command:

```
 sys a: x: /s

```

where, x: is the USB key that is required to be set as a bootable device.

**The Virtual Media is attached and connected to the remote floppy. But, cannot locate the Virtual Floppy/Virtual CD**
**device on a system running Red Hat Enterprise Linux or the SUSE Linux operating system. How to resolve this?**

Some Linux versions do not auto-mount the virtual floppy drive and the virtual CD drive in the same method. To mount the
virtual floppy drive, locate the device node that Linux assigns to the virtual floppy drive. To mount the virtual floppy drive:

1. Open a Linux command prompt and run the following command:

```
  grep "Virtual Floppy" /var/log/messages

```

2. Locate the last entry to that message and note the time.
3. At the Linux prompt, run the following command:

```
  grep "hh:mm:ss" /var/log/messages

```

where, hh:mm:ss is the time stamp of the message returned by grep in step 1.
4. In step 3, read the result of the grep command and locate the device name that is given to the Virtual Floppy.
5. Make sure that you are attached and connected to the virtual floppy drive.
6. At the Linux prompt, run the following command:

```
  mount /dev/sdx /mnt/floppy

```

where, `/dev/sdx` is the device name found in step 4 and `/mnt/floppy` is the mount point.

To mount the virtual CD drive, locate the device node that Linux assigns to the virtual CD drive. To mount the virtual CD drive:

1. Open a Linux command prompt and run the following command:

```
  grep "Virtual CD" /var/log/messages

```

2. Locate the last entry to that message and note the time.
3. At the Linux prompt, run the following command:

```
  grep "hh:mm:ss" /var/log/messages

```

where, hh:mm:ss is the timestamp of the message returned by grep in step 1.
4. In step 3, read the result of the grep command and locate the device name that is given to the **Dell Virtual** CD.
5. Make sure that the Virtual CD Drive is attached and connected.
6. At the Linux prompt, run the following command:

```
  mount /dev/sdx /mnt/CD

```

where: `/dev/sdx` is the device name found in step 4 and `/mnt/floppy` is the mount point.

**Why are the virtual drives attached to the server removed after performing a remote firmware update using the**
**iDRAC web interface?**

Firmware updates cause the iDRAC to reset, drop the remote connection, and unmount the virtual drives. The drives reappear
when iDRAC reset is complete.

**Why are all the USB devices detached after connecting a USB device?**

Virtual media devices and vFlash devices are connected as a composite USB device to the Host USB BUS, and they share a
common USB port. Whenever any virtual media or vFlash USB device is connected to or disconnected from the host USB bus,
all the Virtual Media and vFlash devices are disconnected momentarily from the host USB bus, and then they are reconnected. If
the host operating system uses a virtual media device, do not attach or detach one or more virtual media or vFlash devices. It is
recommended that you connect all the required USB devices first before using them.

**What does the USB Reset do?**

It resets the remote and local USB devices connected to the server.

**How to maximize Virtual Media performance?**

To maximize Virtual Media performance, launch the Virtual Media with the Virtual Console disabled or do one of the following:

- Change the performance slider to Maximum Speed.
- Disable encryption for both Virtual Media and Virtual Console.
**NOTE:** In this case, the data transfer between managed server and iDRAC for Virtual Media and Virtual Console will not
be secured.

- If you are using any Windows server operating systems, stop the Windows service named Windows Event Collector. To do
this, go to **Start**   - **Administrative Tools**   - **Services** . Right-click **Windows Event Collector** and click **Stop** .

**While viewing the contents of a floppy drive or USB key, a connection failure message is displayed if the same drive**
**is attached through the virtual media?**

Simultaneous access to virtual floppy drives is not allowed. Close the application used to view the drive contents before
attempting to virtualize the drive.

**What file system types are supported on the Virtual Floppy Drive?**

The virtual floppy drive supports FAT16 or FAT32 file systems.

**Why is an error message displayed when trying to connect a DVD/USB through virtual media even though the virtual**
**media is currently not in use?**

The error message is displayed if Remote File Share (RFS) feature is also in use. At a time, you can use RFS or Virtual Media and
not both.



## vFlash SD card

**When is the vFlash SD card locked?**

The vFlash SD card is locked when an operation is in-progress. For example, during an initialize operation.



## SNMP authentication

**Why is the message 'Remote Access: SNMP Authentication Failure' displayed?**

As part of discovery, IT Assistant attempts to verify the get and set community names of the device. In IT Assistant, you have
the get community name = public and the set community name = private. By default, the SNMP agent community name for
iDRAC agent is public. When IT Assistant sends out a set request, the iDRAC agent generates the SNMP authentication error
because it accepts requests only from community = public.

To prevent SNMP authentication errors from being generated, you must enter community names that are accepted by the
agent. Since the iDRAC only allows one community name, you must use the same get and set community name for IT Assistant
discovery setup.



## Storage devices

**OpenManage Storage Management displays more storage devices than iDRAC, why?**

iDRAC displays information only for the Comprehensive Embedded Management (CEM) supported devices.

**For External JBODs/Insights behind the HBA, EEMI Message for the SAS Connector/IOM removal is generated with**
**the EEMI message ID ENC42. However, EEMI message ENC41 and ENC1 for the SAS Connector/IOM restoration is**
**not generated.**

To confirm the restoration of the IOM in the iDRAC web interface:

1. Go to **Storage** - **Overview** - **Enclosures** .
2. Select the enclosure.
3. Under **Advanced Properties**, ensure that the value for **Redundant Path** is set to **Present** .
**Why is there a difference in the serial number printed on the PCIe device and in the iDRAC GUI?**

Devices based out of PCIe Base Class can be of different types and form factors. In such scenarios, the serial numbers of the
device form may not be the same as that of a base PCIe device. For example, derived forms of PCIe devices such as NVMe
Drives, NIC cards, and so on.



## GPU (Accelerators)

**Accelerators section under CPU/Accelerators in iDRAC GUI is grayed out.**

Few pages in GUI may not show expected response when respective attribute is disabled in Redfish.



## iDRAC Service Module

**iSM details are missing / not updated correctly in iDRAC GUI page of some PowerEdge servers**

When a user adds SUB NIC under teaming, the configuration is invalid. This causes iSM to not to communicate with iDRAC
properly.

**Before installing or running the iDRAC Service Module, should the OpenManage Server Administrator be**
**uninstalled?**

No you do not have to uninstall Server Administrator. Before you install or run the iDRAC Service Module, make sure that you
have stopped the features of Server Administrator that the iDRAC Service Module provides.

**How to check whether iDRAC Service Module is installed in the host operating system?**

To know if the iDRAC Service Module is installed on the system,

- On systems running Windows: Open the **Control Panel**, verify if iDRAC Service Module is listed in the list of installed
programs displayed.

- On systems running Linux: Run the command `rpm —qi dcism` . If the iDRAC Service Module is installed, the status
displayed is **installed** .

- On systems running ESXi: Run the command `esxcli software vib list|grep -i open` on the host. iDRAC
Service module is displayed.

**NOTE:** To check if the iDRAC Service Module is installed on Red Hat Enterprise Linux 7, use the `systemctl status`

`dcismeng.service` command instead of the `init.d` command.

**How to check the version number of the iDRAC Service Module installed in the system?**

To check the version of the iDRAC Service Module in the system, do any of the following:

- Click **Start** - **Control Panel** - **Programs and Features** . The version of the installed iDRAC Service Module is listed in the
**Version** tab.

- Go to **My Computer** - **Uninstall or change a program** .
**What is the minimum permission level required to install the iDRAC Service Module?**

To install the iDRAC Service Module, you must have administrator level privileges.

**On iDRAC Service Module version 2.0 and earlier, while installing the iDRAC Service Module, an error message**
**is displayed stating this is not a supported server. Consult the User Guide for additional information about the**
**supported servers. How to resolve this error?**

Before installing the iDRAC Service Module, make sure that the server is a 12th generation PowerEdge server or later. Also,
make sure that you have a 64-bit system.

**The following message is displayed in the OS log, even when the OS to iDRAC Pass-through over USBNIC is**
**configured properly. Why?**

**The iDRAC Service Module is unable to communicate with iDRAC using the OS to iDRAC Pass-through channel**

iDRAC Service Module uses the OS to iDRAC pass-through over USB NIC feature to establish the communication with iDRAC.
Sometimes, the communication is not established though the USB NIC interface is configured with the correct IP endpoints.
This may happen when the host operating system routing table has multiple entries for the same destination mask and the USB
NIC destination is not listed as the first one in routing order.

**Table 70. Example of a routing order**

|Destination|Gateway|Genmask|Flags|Metric|Ref|Use Iface|
|---|---|---|---|---|---|---|
|default|10.94.148.1|0.0.0.0|UG|1024|0|0 em1|
|10.94.148.0|0.0.0.0|255.255.255.0|U|0|0|0 em1|
|link-local|0.0.0.0|255.255.255.0|U|0|0|0 em1|
|link-local|0.0.0.0|255.255.255.0|U|0|0|0 enp0s20u12u3|

In the example **enp0s20u12u3** is the USB NIC interface. The link-local destination mask is repeated and the USB NIC is not
the first one in the order. This results in the connectivity issue between iDRAC Service Module and iDRAC over the OS to
iDRAC Pass-through. To troubleshoot the connectivity issue, make sure that the iDRAC USBNIC IPv4 address (by default it is
169.254.1.1) is reachable from the host operating system.

If not:

- Change the iDRAC USBNIC address on a unique destination mask.
- Delete the entries that are not required from the routing table to make sure that USB NIC is chosen by route when the host
wants to reach the iDRAC USB NIC IPv4 address.

**On iDRAC Service Module version 2.0 and earlier, when uninstalling iDRAC Service Module from a VMware ESXi**
**server, the virtual switch is named as vSwitchiDRACvusb and port group as iDRAC Network on the vSphere client.**
**How to delete them?**

While installing iDRAC Service Module VIB on a VMware ESXi server, iDRAC Service Module creates the vSwtich and Portgroup
to communicate with iDRAC over the OS to iDRAC Pass-through in USB NIC mode. After the uninstallation, the virtual switch
**vSwitchiDRACvusb** and the port group **iDRAC Network** are not deleted. To delete it manually, perform one of the following
steps:

- Go to vSphere Client Configuration wizard and delete the entries.
- Go to the Esxcli and type the following commands:
  - To remove port group: `esxcfg-vmknic -d -p "iDRAC Network"`
  - To remove vSwitch: `esxcfg-vswitch -d vSwitchiDRACvusb`
**NOTE:** You can reinstall iDRAC Service Module on the VMware ESXi server as this is not a functional issue for the
server.

**Where is the Replicated Lifecycle log available on the operating system?**

To view the replicated Lifecycle logs:

|Table 71. Lifecycle logs location|Col2|
|---|---|
|**Operating System**|**Location**|
|Microsoft Windows|**Event viewer** >**Windows Logs** >**System**. All the iDRAC<br>Service Module Lifecycle logs are replicated under the source<br>name**iDRAC Service Module**.<br>**NOTE:** In iSM version 2.1 and later, Lifecycle logs are<br>replicated under the Lifecycle Controller Log source name.|
|Table 71. Lifecycle logs location (continued)|Col2|
|**Operating System**|**Location**|
||In iSM version 2.0 and earlier, the logs are replicated<br>under iDRAC Service Module source name.<br>**NOTE:** The location of the Lifecycle log can be configured<br>using the iDRAC Service Module installer. You can<br>configure the location while installing iDRAC Service<br>Module or modifying the installer.|
|Red Hat Enterprise Linux, SUSE Linux, CentOS, and Citrix<br>XenServer|`/var/log/messages`|
|VMware ESXi|`/var/log/syslog.log`|

**What are the Linux-dependent packages or executables available for installation while completing the Linux**
**installation?**

To see the list of Linux-dependent packages, see the **Linux Dependencies** section in the _iDRAC Service Module User's Guide_
[available on the iDRAC manuals page..](https://www.dell.com/idracmanuals)

**How to increase GPU performance for certain configuration?**

BIOS system performance profile set to performance

Under Processor Settings, set NPS to 4 and CCX to auto

Minimum 1 DIMM per channel

IOmmu=passthrough on Linux OS



## RACADM

**After performing an iDRAC reset (using the racadm racreset command), if any command is issued, the following**
**message is displayed. What does this indicate?**

```
 ERROR: Unable to connect to RAC at specified IP address

```

The message indicates that you must wait until the iDRAC completes the reset before issuing another command.

**When using RACADM commands and subcommands, some errors are not clear.**

You may see one or more of the following errors when using the RACADM commands:

- Local RACADM error messages—Problems such as syntax, typographical errors, and incorrect names.
- Remote RACADM error messages—Problems such as incorrect IP Address, incorrect user name, or incorrect password.
**During a ping test to iDRAC, if the network mode is switched between Dedicated and Shared modes, there is no ping**
**response.**

Clear the ARP table on your system.

**Remote RACADM fails to connect to iDRAC from SUSE Linux Enterprise Server (SLES) 11 SP1.**

Make sure that the official openssl and libopenssl versions are installed. Run the following command to install the RPM
packages:

```
 rpm -ivh --force <filename>

```

Where, `filename` is the openssl or libopenssl rpm package file.

For example:

```
 rpm -ivh --force openssl-0.9.8h-30.22.21.1.x86_64.rpm
 rpm -ivh --force libopenssl0_9_8-0.9.8h-30.22.21.1.x86_64.rpm

```

**Why are the remote RACADM and web-based services unavailable after a property change?**

It may take a while for the remote RACADM services and the Web-based interface to become available after the iDRAC web
server resets.

The iDRAC web server resets when:

- The network configuration or network security properties are changed using the iDRAC web user interface.
- Any of the following attributes in the iDRAC.Webserver group is changed:
  - BlockHTTPPort
  - CustomCipherString
  - HostHeaderCheck
  - Http2Enable
  - HttpPort
  - HttpsPort
  - HttpsRedirection
  - SSLEncryptionBitLength
  - TLSProtocol
- The `racresetcfg` command is used.
- iDRAC is reset.
- A new SSL server certificate is uploaded.
**Why is an error message displayed if you try to delete a partition after creating it using local RACADM?**

This occurs because the create partition operation is in-progress. However, the partition is deleted after sometime and a
message that the partition is deleted is displayed. If not, wait until the create partition operation is completed and then delete
the partition.



## Permanently setting the default password to calvin

If your system shipped with a unique default iDRAC password but you want to set **calvin** as the default password, you must use
the jumpers available on the system board.

**CAUTION: Changing the jumper settings permanently changes the default password to calvin. You cannot revert**
**to the unique password even if you reset iDRAC to factory settings.**

[For information about the jumper location and the procedure, see the documentation for your server at Dell Support page.](https://www.dell.com/support)



## Miscellaneous





##### In PowerEdge XR systems, sensor report shows Bezel filter as Absent after selecting the Active sensing mode.

In XR systems, all the sleds except for sled1 support only countdown mode for Bezel filters. Hence selecting active mode when
the air filter is connected to any sleds other than sled 1 does not show Bezel filter options. Although RACADM displays and
allows to modify the attributes, it does not cause any impact.

This limitation is observed in PowerEdge XR4000r/XR4000z. PowerEdge XR4510C, and PowerEdge XR4520c servers.



##### For High-Bandwidth Memory (HBM) CPUs in HBM mode, MemoryRollupStatus is shown as Unknown.

For HBM-only mode, memory-related data reported in HW inventory, sensors, telemetry, and so on, are not available. You should
not consider it as a faulty configuration. For those interfaces that report all individual DIMM slot sensors, they are reported with
Unknown state. Similarly, Max DIMM Temperature sensor can also continue to be reported with Unknown state.



##### Cannot update iDRAC from version 3.00.00.00 to version 5.10.00.00

**NOTE:** 3.30.30.30 is the minimum iDRAC version that is required to upgrade to 5.00.00.00 / 5.10.00.00 or later build.

Updating iDRAC from version 3.xx or 4.xx to the latest version directly is not supported. If the current iDRAC version is the 3xx
or 4.xx series, Dell Technologies recommends upgrading iDRAC to the next available version and continue upgrading to the next
alternate versions until you reach the latest available version.

Here is an example of a PowerEdge R740xd system with iDRAC version 3.15.15.15 installed. Following is the list of versions that
are available after the 3.15.15.15 release:

- 3.18.18.18
- 3.21.21.21
- 3.30.30.30
- 3.32.32.32
- 3.34.34.34
- 3.36.36.36
- 4.00.00.00
- 4.10.10.10
- 4.20.20.20
- 4.22.00.00
- 4.40.00.00
- 4.40.10.00
- 4.40.40.00
- 5.00.00.00
- 5.00.10.20
**NOTE:** To access the available versions list, go to the latest available version under the Drivers and Download page and
select the older versions option.

If iDRAC version 5.10.00.00 is the latest available firmware, and then to upgrade to the 5.10.00.00 firmware, you must first
install the following firmware versions:

- 3.18.18.18
- 3.30.30.30
- 3.34.34.34
- 4.00.00.00
- 4.20.20.20
- 4.40.00.00
- 4.40.40.00
- 5.00.10.20

And then install the later version 5.10.00.00.



##### When attempting to connect the iDRAC to a different network, the iDRAC does not get a different IP address from the new subnet.

Ensure that the network cable is disconnected from the iDRAC for at least 5 s.



##### After an iDRAC reset, iDRAC UI may not display all the values.

**NOTE:** If you reset the iDRAC for some reason, ensure that you wait for at least two minutes after resetting iDRAC to
access or modify any settings in iDRAC.



##### When an operating system is installed, the hostname may or may not appear/change automatically.

There are two scenarios:

- Scenario 1: iDRAC is not showing the latest hostname once you install an operating system. You need to install OMSA or iSM
along with the iDRAC to get the hostname reflected.

- Scenario 2: iDRAC had a hostname for a specific operating system and another different operating system has been installed
and still the hostname is appearing as the old hostname without overwriting the hostname. The reason behind, hostname is
an information which is coming from the operating system, iDRAC only saves the information. If there is a new operating
system has been installed, iDRAC does not reset the value of the hostname. However, newer versions of the OSs are
capable to update the hostname in iDRAC during the first OS startup.



##### How to find an iDRAC IP address for a blade server?

**NOTE:** The Chassis Management Controller (CMC) option is applicable only for Blade servers.

- **Using CMC web interface** : Go to **Chassis** - **Servers** - **Setup** - **Deploy** . In the table that is displayed, view the IP address
for the server.

- **Using the Virtual Console** : Reboot the server to view the iDRAC IP address during POST. Select the "Dell CMC" console
in the OSCAR interface to log in to CMC through a local serial connection. CMC RACADM commands can be sent from this
connection.

**NOTE:** For more information about CMC RACADM commands, see the _Chassis Management Controller RACADM CLI_
_Guide_ [available on the CMC manuals page..](https://www.dell.com/cmcmanuals)

**NOTE:** For more information about iDRAC RACADM commands, see the Integrated Dell Remote Access Controller
RACADM CLI Guide.

- **Using local RACADM** : Use the command: `racadm getsysinfo` For example:

```
  $ racadm getniccfg -m server-1
  DHCP Enabled = 1
  IP Address  = 192.168.0.1
  Subnet Mask = 255.255.255.0
  Gateway   = 192.168.0.1

```

- **Using LCD** : On the main menu, highlight the server, press the check button, select the required server, and press the check
button.



##### How to find an iDRAC IP address for a blade server ?

**NOTE:** The OME-Modular web interface option is applicable only for MX platforms.

- **Using OME-Modular web interface** : Go to **Devices** - **Compute** . Select the system sled and iDRAC IP is displayed as
**Management IP** .

- **Using OMM Application** : See the _Dell OpenManage Mobile User's Guide_ [available on the OpenManage manualspage.](https://www.dell.com/openmanagemanuals)
- **Using Serial Connection**
- **Using LCD** : On the main menu, highlight the server, press the check button, select the required server, and press the check
button.



##### How to find the CMC IP address related to the blade server?

**NOTE:** Not applicable for MX platforms.

- **From iDRAC web interface** : Go to **iDRAC Settings** - **CMC** . The **CMC Summary** page displays the CMC IP address.
- **From the Virtual Console** : Select the "Dell CMC" console in the OSCAR interface to log in to CMC through a local serial
connection. CMC RACADM commands can be issued from this connection.

```
  $ racadm getniccfg -m chassis
  NIC Enabled     = 1
  DHCP Enabled    = 1
  Static IP Address  = 192.168.0.120
  Static Subnet Mask = 255.255.255.0
  Static Gateway   = 192.168.0.1
  Current IP Address = 10.35.155.151
  Current Subnet Mask = 255.255.255.0
  Current Gateway   = 10.35.155.1
  Speed        = Autonegotiate
  Duplex       = Autonegotiate

```

**NOTE:**

   - You can also perform this using remote RACADM.
   - For more information about CMC RACADM commands, see the _Chassis Management Controller RACADM CLI Guide_
[available on the CMC manuals page..](https://www.dell.com/cmcmanuals)

   - For more information about iDRAC RACADM commands, see the Integrated Dell Remote Access Controller RACADM
CLI Guide.



##### How to find the OME Modular IP address?

**NOTE:** Applicable only for MX platforms.

- **From iDRAC web interface** : Go to **iDRAC Settings** - **Management Module** . The **Managment Module** page displays the
OME Modular IP address.



##### How to find iDRAC IP address for rack and tower server?

- **From Local RACADM** : Use the command `racadm getsysinfo` .
- **From LCD** : On the physical server, use the LCD panel navigation buttons to view the iDRAC IP address. Go to **Setup View**
  - **View**   - **iDRAC IP**   - **IPv4** or **IPv6**   - **IP** .
- **From OpenManage Server Administrator** : In the Server Administrator web interface, go to **Modular Enclosure** **System/Server Module**  - **Main System Chassis/Main System**  - **Remote Access** .



##### iDRAC network connection is not working.

For blade servers:

- Ensure that the LAN cable is connected to CMC. (not for MX platforms)
- Ensure that NIC settings, IPv4 or IPv6 settings, and either Static or DHCP is enabled for your network.

For rack and tower servers:

- In shared mode, ensure that the LAN cable is connected to the NIC port where the wrench symbol is present.
- In Dedicated mode, ensure that the LAN cable is connected to the iDRAC LAN port.
- Ensure that NIC settings, IPv4, and IPv6 settings and either Static or DHCP is enabled for your network.



##### iDRAC not accessible in shared LOM

iDRAC may be inaccessible if there are fatal errors in the host operating system such as BSOD error in Windows. To access
iDRAC, reboot the host to recover the connection.



##### Shared LOM not functional after enabling Link Aggregation Control Protocol (LACP).

The host operating system driver for the network adapter must be loaded before LACP is enabled. However, if a passive LACP
configuration is in use, the shared LOM may be functional before the host operating system driver is loaded. See the switch
documentation for LACP configuration.

**NOTE:** Shared LOM IP of iDRAC is not accessible in pre-boot state when the switch is configured with LACP.



##### Inserted the blade server into the chassis and pressed the power switch, but it did not power on.

- iDRAC requires up to two minutes to initialize before the server can power on.
- Check CMC, andOME Modular (only for MX platforms) power budget. The chassis power budget may have exceeded.



##### How to retrieve an iDRAC administrative username and password?

You must restore iDRAC to its default settings. For more information, see Resetting iDRAC to factory default settings.



##### How to change the name of the slot for the system in a chassis?

**NOTE:** Not applicable for MX platforms.

1. Log in to CMC web interface and go to **Chassis** - **Servers** - **Setup** .
2. Enter the new name for the slot in the row for your server and click **Apply** .



##### iDRAC on blade server is not responding during boot.

Remove and reinsert the server.

Check CMC (not for MX platforms), and OME Modular (Applicable for MX platforms) web interface to see if iDRAC is displayed
as an upgradable component. If it does, follow the instructions in Updating firmware using CMC web interface update the
firmware.

**NOTE:** Update feature not applicable for MX platforms.

If the problem persists, contact technical support.



##### When attempting to boot the managed server, the power indicator is green, but there is no POST or no video.

This happens due to any of the following conditions:

- Memory is not installed or is inaccessible.
- CPU is not installed or is inaccessible.
- Video riser card is missing or not connected properly.
Also, see error messages in iDRAC log using iDRAC web interface or from the server LCD.



##### Unable to log in to iDRAC web interface using Firefox browser on Linux or Ubuntu. Unable to enter the password.

To resolve this issue, reinstall or upgrade the Firefox browser.



##### Unable to access iDRAC through USB NIC in SLES and Ubuntu

**NOTE:** In SLES, set the iDRAC interface to DHCP.

In Ubuntu, use the Netplan utility to configure the iDRAC interface into DHCP mode. To configure the DHCP:

1. Use `/etc/netplan/01-netcfg.yaml` .
2. Specify Yes for iDRAC DHCP.
3. Apply the configuration.
**Figure 5. Configuring iDRAC interface to DHCP mode in Ubuntu**



##### Model, Manufacturer, and other properties are not listed for Embedded Network Adapters in Redfish

FRU details for embedded devices will not be displayed. There will not be any FRU object for devices which are embedded on
Motherboard. Hence dependent property will not be there.



##### TotalCacheSizeMiB attribute shows wrong value for PERC H755 adapter

In Redfish, the terminology is defined by the "Unified Code for Units of Measure". For example, in the Memory model, the
**CapacityMiB** property is annotated with "Measures.Unit" that is set to "MiB," which is UCUM's notation for "Mebi-bytes"
(bytes x 1048576). You may see the difference in cache size, since it is displayed in MiB.

**NOTE:** One Mebibyte equals 1.048576 MB.



## Proxy server settings

**How to configure proxy server settings in RACADM CLI and Redfish API?**

In RACADM, the following LC attributes must be set to configure the proxy server:

- LifeCycleController.LCAttributes.UserProxyPassword
- LifeCycleController.LCAttributes.UserProxyPort
- LifeCycleController.LCAttributes.UserProxyServer
- LifeCycleController.LCAttributes.UserProxyType
- LifeCycleController.LCAttributes.UserProxyUserName

For more information about how to run these commands, see the **Integrated Dell Remote Access Controller CLI guide** .

When using HTTP with a proxy, the connection between iDRAC and the proxy is not as secure as the connection between
iDRAC and the HTTPS server. The `UserProxyServer` is an important attribute. If it is not set, the other attributes cannot be
used. The benefit of using RACADM and Redfish API is that it is not required to provide the password each time you use the
proxy server.

In the Redfish API, perform a patch operation using the URI `/redfish/v1/Managers/<Manager-ID>/Oem/Dell/`
`DellAttributes/<Dell-attributes-ID>` to configure the proxy server.

**How to configure proxy server settings in the iDRAC UI?**

In the iDRAC UI, you can update the proxy settings on all the pages where the proxy server is required. Even if you have set
up the proxy settings using RACADM and Redfish API, you can still update the proxy settings in the iDRAC UI. To configure the
proxy settings in the **System Update** page:

1. Go to **Maintenance** - **System Update** - **Manual Update** .
2. Under **Manual Update**, select **HTTPS** in the **Location Type** .
3. Select **Enabled** in the **Enable Proxy Server** .
4. Enter **Server**, **Port**, **User Name**, and **Password** .
5. Select **Type** and click **Save Proxy Settings as Default** .
**NOTE:** You can configure proxy settings in any of the pages such as **Export Lifecycle Log**, **Automatic Update**,
**SupportAssist Collection Settings**, **Server Configuration Profile Import**, and **Server Configuration Profile Export** .

**NOTE:** By default, **Enable Proxy Settings** in the iDRAC UI is disabled. It will reset to a disabled state after each use. For
more information, see the **Integrated Dell Remote Access Controller iDRAC Online Help** .



# 32 Use case scenarios

This section helps you in navigating to specific sections in the guide to perform typical use case scenarios.

**Topics:**

- Troubleshooting an inaccessible managed system
- Obtaining system information and assess system health
- Setting up alerts and configuring email alerts
- Viewing and exporting System Event Log and Lifecycle Log
- Interfaces to update iDRAC firmware
- Performing a graceful shutdown
- Creating new administrator user account
- Launching servers remote console and mounting a USB drive
- Installing bare metal OS using attached virtual media and remote file share
- Managing rack density
- Installing new electronic license
- Applying IO Identity configuration settings for multiple network cards in single host system reboot



## Troubleshooting an inaccessible managed system

After receiving alerts from OpenManage Essentials, Dell Management Console, or a local trap collector, five servers in a data
center are not accessible with issues such as hanging operating system or server. Need to identify the cause to troubleshoot
and bring up the server using iDRAC.

Before troubleshooting the inaccessible system, make sure that the following prerequisites are met:

- Enable last crash screen
- Alerts are enabled on iDRAC

To identify the cause, check the following in the iDRAC web interface and re-establish the connection to the system:

**NOTE:** If you cannot access the iDRAC web interface, go to the server, access the LCD panel, write down the IP address
or the host name, and then perform the following operations using iDRAC web interface from your management station:

- Server’s LED status — Blinking amber or Solid amber.
- Front Panel LCD status or error message — Amber LCD or error message.
- Operating system image is seen in the Virtual Console. If you can see the image, reset the system (warm boot) and log in
again. If you are able to log in, the issue is fixed.

- Last crash screen.
- Boot capture video.
- Crash capture video.
- Server Health status — Red **x** icons for the system components with issues.
- Storage array status — Possible array offline or failed
- Lifecycle log for critical events related to system hardware and firmware and the log entries that were logged at the time of
system crash.

- Generate Tech Support report and view the collected data.
- Use the monitoring features provided by iDRAC Service Module



## Obtaining system information and assess system health

To obtain system information and assess system health:

- In iDRAC Web interface, go to **Overview** - **Summary** to view the system information and access various links on this page
to asses system health. For example, you can check the health of the chassis fan.

- You can also configure the chassis locator LED and based on the color, assess the system health.
- If iDRAC Service Module is installed, the operating system host information is displayed.



## Setting up alerts and configuring email alerts

To set up alerts and configure email alerts:

1. Enable alerts.
2. Configure the email alert and check the ports.
3. Perform a reboot, power off, or power cycle the managed system.
4. Send test alert.



## Viewing and exporting System Event Log and Lifecycle Log

To view and export lifecycle log and system event log (SEL):

1. In iDRAC Web interface, go to **Maintenance** - **System Event Logs** to view SEL and **Lifecycle Log** to view lifecycle log.
**NOTE:** The SEL is also recorded in the lifecycle log. Using the filtering options to view the SEL.

2. Export the SEL or lifecycle log in the XML format to an external location (management station, USB, network share,
and so on). Alternatively, you can enable remote system logging, so that all the logs written to the lifecycle log are also
simultaneously written to the configured remote server(s).

3. If you are using the iDRAC Service Module, export the Lifecycle log to OS log.



## Interfaces to update iDRAC firmware

Use the following interfaces to update the iDRAC firmware:

- iDRAC Web interface
- Redfish API
- RACADM CLI (iDRAC_) and CMC (not applicable for MX platforms))
- Dell Update Package (DUP)
- CMC (not applicable for MX platforms)OME Modular (applicable only for MX platforms) Web interface
- Lifecycle Controller–Remote Services
- Lifecycle Controller
- Dell Remote Access Configuration Tool (DRACT)



## Performing a graceful shutdown

The software initiates a graceful shutdown by turning off the server, allowing the operating system to safely shutdown
processes. It also powers off the PCIe slots. As a result, the adapters in PCIe slots do not respond to NC-SI control commands.

If the commands do not respond, the NIC-CEM module treats the adapters as nonresponsive and it logs HWC8607 Lifecycle
Controller logs (LCLOGs) to indicate that communication with the adapters is lost.

To perform graceful shutdown, in the iDRAC Web interface, go to one of the following locations:

- On the **Dashboard**, select **Graceful Shutdown** and click **Apply** .
**NOTE:** After the request is sent to the host, it is up to the host to honor that request and run it. Success of Graceful
shutdown depends on the state of the host.

For more information, see the **iDRAC Online Help** .



## Creating new administrator user account

You can modify the default local administrator user account or create a new administrator user account. To modify the local
administrator user account, see Modifying local administrator account settings.

To create a new administrator account, see the following sections:

- Configuring local users
- Configuring active directory users
- Configuring generic LDAP users



## Launching servers remote console and mounting a USB drive

To launch the remote console and mount a USB drive:

1. Connect a USB flash drive (with the required image) to the management station.
2. Use the following method to launch virtual console through the iDRAC Web Interface:
  - Go to **Dashboard**  - **Virtual Console** and click **Launch Virtual Console** .

The **Virtual Console Viewer** is displayed.

3. From the **File** menu, click **Virtual Media** - **Launch Virtual Media** .
4. Click **Add Image** and select the image that is located on the USB flash drive.

The image is added to the list of available drives.

5. Select the drive to map it. The image on the USB flash drive is mapped to the managed system.



## Installing bare metal OS using attached virtual media and remote file share

See the Deploying operating system using remote file share section.



## Managing rack density

Before you install additional servers in a rack, you must determine the remaining capacity in the rack.

To assess the capacity of a rack to add additional servers:

1. View the current power consumption data and historical power consumption data for the servers.
2. Based on the data, power infrastructure and cooling system limitations, enable the power cap policy and set the power cap
values.

**NOTE:** It is recommended that you set a cap close to the peak, and then use that capped level to determine how much
capacity is remaining in the rack for adding more servers.



## Installing new electronic license

See License operations for more information.



## Applying IO Identity configuration settings for multiple network cards in single host system reboot

If you have multiple network cards in a server that is part of a Storage Area Network (SAN) environment and you want to apply
different virtual addresses, initiator and target configuration settings to those cards, use the I/O Identity Optimization feature to
reduce the time in configuring the settings. To do this:

1. Make sure that BIOS, iDRAC, and the network cards are updated to the latest firmware version.
2. Enable IO Identity Optimization.
3. Export the Server Configuration Profile (SCP) file from iDRAC.
4. Edit the I/O Identity optimization settings in the SCP file.
5. Import the SCP file to iDRAC.